
var documents = [{
    "id": 0,
    "url": "localhost:4000/404/",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "localhost:4000/about.html",
    "title": "About",
    "body": "Made with by Sal @wowthemesnet. "
    }, {
    "id": 2,
    "url": "localhost:4000/author-jane.html",
    "title": "Jane",
    "body": "                        Jane Follow:                                                    Posts by Jane:               "
    }, {
    "id": 3,
    "url": "localhost:4000/author-sal.html",
    "title": "Sal",
    "body": "                        Sal Follow:                                                    Posts by Sal:               "
    }, {
    "id": 4,
    "url": "localhost:4000/authors-list.html",
    "title": "Authors",
    "body": "Authors:                                             Amir Ghahrai :       (View Posts)                                &nbsp;       &nbsp;                                      "
    }, {
    "id": 5,
    "url": "localhost:4000/buy-me-a-coffee.html",
    "title": "Buy me a coffee",
    "body": "Hi! I am Sal, web designer &amp; developer at WowThemes. net. The free items I create are my side projects and Mundana for Jekyll is one of them. You can find all the work I release for free here. You have my permission to use the free items I develop in your personal, commercial or client projects. If you’d like to reward my work, I would be honored and I could dedicate more time maintaining the free projects. Thank you so much! Buy me a coffee "
    }, {
    "id": 6,
    "url": "localhost:4000/categories.html",
    "title": "Categories",
    "body": "          Categories               software testing:                                  		Software Testing and Different Thinking Types	: 		  When it comes to Software Testing, the human brain is the best testing tool. When we test software, we process information, solve problems, make decisions and create new ideas. 	 			In 				software testing, 								Dec 11, 2018						                                 		SDET Unicorns - Why is it so Hard to Hire SDETs?	: 		  SDET, also known as Software Development Engineer in Test, is a job role within Software Testing and Quality Assurance Domain.  The term was originally used by Microsoft and then Googl. . . 	 			In 				software testing, 								Nov 22, 2018						                                 		Problems with Test Automation and Modern QA	: 		  What are some common problems with test automation in agile and DevOps? Modern Software Development and QA focus too much on test automation and not enough on exploratory testing. 	 			In 				software testing, 								Oct 12, 2018						                                 		Testing in DevOps World	: 		  DevOps is an amalgamation of the Development and Operations practices for Software development and Delivery. 	 			In 				software testing, 								Oct 06, 2018						                                 		How to Capture Browser Network Traffic (XHR) with Cypress	: 		  Cypress is a next generation front-end testing tool built for the modern web. Cypress has a lot of nice features to facilitate browser automation. One of those features is the ability. . . 	 			In 				software testing, 								May 31, 2018						                                 		Karate API Testing Tool Cheat Sheet	: 		  Karate is an opensource API testing tool developed by Peter Thomas from Intuit.  Karate is built on top of HttpClient and Cucumber and has its own DSL to make API testing very easy. Al. . . 	 			In 				software testing, 								May 30, 2018						                                 		Software Testing Interview Questions and Answers - Ultimate List	: 		  This post is a large collection of Software Testing Interview Questions and Answers. The list covers foundations of Software Testing, Technical Testing, Test Automation, API Testing, . . . 	 			In 				software testing, 								Apr 08, 2018						                                 		How to Parameterize Gatling Variables	: 		  How can we parameterize Gatling variables and pass parameters from the command line to Gatling? On most occasions, when you create a performance script, you want to run the simulation. . . 	 			In 				software testing, 								Apr 05, 2018						                                 		Testing and Quality Assurance in Agile	: 		  What does testing and quality assurance look like in an agile environment? How can we ensure that during the limited time that we have in a sprint we can deliver software that is func. . . 	 			In 				software testing, 								Apr 04, 2018						                                 		HTTP Basics for Software Testers	: 		  If you are a technical tester or you are involved in testing APIs then you need to be familiar with the HTTP basics and terminologies. Without knowing the basics of HTTP, you cannot d. . . 	 			In 				software testing, 								Mar 25, 2018						                                 		Subject7 - A Cloud-Based SaaS Test Automation Platform	: 		  Two of the most common challenges QAs face in an agile team, is keeping up with the developers to automate new functionality, and the other is to have decent technical skills to be ab. . . 	 			In 				software testing, 								Mar 20, 2018						                                 		How to Set Multiple Headers in HTTP Request With Karate	: 		  How to set HTTP headers in Karate?	 			In 				software testing, 								Jan 23, 2018						                                 		Gatling - How to Set Ramp-up and Max Duration	: 		  In Gatling, you can set the ramp-up period and the maximum duration of the load testing. You can define the values in seconds or minutes. You might get a “Cannot resolve symbol minute. . . 	 			In 				software testing, 								Jan 22, 2018						                                 		Gatling - How to Send Post Request in StringBody() With Random Data	: 		  In this Gatling tutorial, we show how to send post requests which contain random data in the StringBody(). 	 			In 				software testing, 								Jan 19, 2018						                                 		How To Run WebDriver in Headless Mode	: 		  How to run WebDriver in headless mode? This might be needed if your CI tool, for example, Jenkins doesn’t support UI. 	 			In 				software testing, 								Jan 18, 2018						                                 		Performance Testing with Gatling, Maven and Scala	: 		  This post shows how to set up a Gatling simulation test using Maven and Scala on IntelliJ IDE. 	 			In 				software testing, 								Jan 18, 2018						                                 		Automated Testing of Emails Using Karate	: 		  	 			In 				software testing, 								Nov 28, 2017						                                 		How to Parse JSON Response with REST-assured	: 		  In this API Testing tutorial, we take a look at how to parse JSON response and extract information using the REST-assured library. 	 			In 				software testing, 								Oct 30, 2017						                                 		Difference Between PUT and PATCH Requests	: 		  What is the main difference between PUT and PATCH requests, and when should we use one over the other?	 			In 				software testing, 								Oct 29, 2017						                                 		Should Automated UI Tests Run in CI Pipeline?	: 		  Should Automated UI Tests (e. g. Selenium Tests) be run as part of the continuous integration build pipeline? The problem with automated UI tests is that they are slow and brittle as t. . . 	 			In 				software testing, 								Oct 26, 2017						                                 		Automated API Testing Made Easy With Karate	: 		  If you would like to get involved in Automated API Testing, but don’t have the programming background, then you might want to give Karate a go!	 			In 				software testing, 								Oct 20, 2017						                                 		Appium Starter Project - Step By Step Guide	: 		  In this Appium tutorial, we take a look at how to create a sample maven project to use for Mobile Test Automation using Appium with Java. 	 			In 				software testing, 								Oct 05, 2017						                                 		Difference Between Iterative and Incremental Development in Agile	: 		  In agile software development, what is the difference between iterative and incremental development? Are they the same thing? What is the distinction between these two words?	 			In 				software testing, 								Aug 10, 2017						                                 		How To Pass Cookies From Selenium WebDriver To Rest-Assured	: 		  How to pass cookies from Selenium WebDriver to Rest-Assured? When you do automated testing at API and UI layer, there could be situations where you are doing both and that you need to. . . 	 			In 				software testing, 								Aug 10, 2017						                                 		How Does Testing Fit Within Agile Development?	: 		  Question:	 			In 				software testing, 								Aug 08, 2017						                                 		Test Automation Tools for Testing ReactJS Applications	: 		  I am planning to test a ReactJS application and wanted to find out what is the best tool out there in the market to carry out end-to-end tests? After doing a little research I found t. . . 	 			In 				software testing, 								Aug 04, 2017						                                 		What is the Difference Between Agile Testing and Continuous Testing?	: 		  Question:	 			In 				software testing, 								Aug 02, 2017						                                 		Difference Between Green/Blue Deployments, A/B Testing and Canary Releases	: 		  This article describes the differences between Green/Blue deployments, A/B testing and Canary releases. 	 			In 				software testing, 								Jul 28, 2017						                                 		What Are Scrum Ceremonies?	: 		  Scrum has four main ceremonies that bring structure to each sprint:	 			In 				software testing, 								Jul 20, 2017						                                 		What are Test Oracles and Test Heuristics?	: 		  Within the world of testing and quality assurance, we often hear the words Test Oracles and Test Heuristics, but what are they and how we can implement them into our daily testing act. . . 	 			In 				software testing, 								Jul 10, 2017						                                 		How to Make Testing and Quality Everyone's Responsibility?	: 		  I want to work in a properly cross-functional team. I’ve heard they exist. I’ve never seen one, but I’ve heard that they exist. 	 			In 				software testing, 								Jun 21, 2017						                                 		How to Parse a JSON Response Using JMeter's JSON Extractor	: 		  As of JMeter 3. 0, it’s far easier to extract data from JSON responses using the JSON variable extractor. JSON is an extremely simple data format which has taken over XML a few years ago. 	 			In 				software testing, 								Jun 14, 2017						                                 		How to Install JMeter With Extra Plugins on Mac OS Using HomeBrew	: 		  There are multiple approaches to installing JMeter on Mac OS. You can either do it manually just like we do in windows (i. e. downloading the binaries and executing the installer) or y. . . 	 			In 				software testing, 								Jun 13, 2017						                                 		How To Query For All Partition Keys in DynamoDB?	: 		  Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. 	 			In 				software testing, 								Jun 12, 2017						                                 		How to Get the Current Working Directory in Java	: 		  The current working directory means the root folder of your current Java project. We can get the current working directory in Java using the following system property function:	 			In 				software testing, 								Jun 12, 2017						                                 		How to Encode and Decode JSON Byte Array	: 		  The typical way to send binary in JSON is to base64 encode it. Java provides different ways to Base64 encode and decode a byte[]. One of these is DatatypeConverter. 	 			In 				software testing, 								Jun 12, 2017						                                 		Easiest Way to Read Properties File in Java With ResourceBundle	: 		  There are a number of ways to load and read properties file from Java, but the easiest and most straightforward is using the ResourceBundle class. 	 			In 				software testing, 								Jun 12, 2017						                                 		Selenium WebDriver With Java 8 - Lambda Expressions and Collections Stream	: 		  From Selenium 3. 0, minimum Java version is 8. In this article, we illustrate how to use Java 8 features like Lambda expression and Collections Stream to simplify Selenium WebDriver code. 	 			In 				software testing, 								Jun 10, 2017						                                 		WebDriver Implicit, Explicit and Fluent Wait Examples	: 		  WebDriver Waits	 			In 				software testing, 								Jun 08, 2017						                                 		Testing Microservices - A Beginner's Guide	: 		  Testing Microservices are becoming more and more important as many of the new applications are being built using Microservices architecture. 	 			In 				software testing, 								Apr 19, 2017						                                 		How to Install Git on Mac and Generate SSH Keys	: 		  In this step-by-step Git Tutorial, we will go through how to install Git on a Mac machine, how to generate SSH keys and upload your public SSH key to your GitHub account for authoriza. . . 	 			In 				software testing, 								Apr 05, 2017						                                 		How to Develop a Test Automation Framework From Scratch?	: 		  In this step-by-step guide, I will describe how to develop a modularized Test Automation Framework from scratch using Java, Selenium, TestNG and Maven. 	 			In 				software testing, 								Mar 15, 2017						                                 		How do we Measure Software Quality in Agile Projects?	: 		  Question	 			In 				software testing, 								Feb 26, 2017						                                 		Difference Between Acceptance Tests and Requirements	: 		  Question	 			In 				software testing, 								Feb 20, 2017						                                 		Continuous Testing - What Does it Mean?	: 		  What is Continuous Testing?	 			In 				software testing, 								Feb 18, 2017						                                 		Most Common Agile Development Methodologies	: 		  What are the most common Agile Development Methodologies?	 			In 				software testing, 								Feb 18, 2017						                                 		Testing in Agile: The Sprint Is Too Short!	: 		  While many developers love Agile, testers… not so much. “It’s not possible to finish all the testing in one sprint”, “the sprint is too short, let’s add a week”, “we need two or three. . . 	 			In 				software testing, 								Feb 16, 2017						                                 		TestLodge - a Test Case Management Tool	: 		  Introduction	 			In 				software testing, 								Feb 12, 2017						                                 		TestLodge - a Test Case Management Tool	: 		  How do you choose which tests to automate and which tests to leave for manual testing?	 			In 				software testing, 								Feb 08, 2017						                                 		How Agile Killed Managers	: 		  Once upon a time in a land far away every few developers and every few testers had a manager. Everybody wanted to be managers because they had power and were paid better. But only the. . . 	 			In 				software testing, 								Feb 06, 2017						                                 		Performance Testing Terminologies	: 		  Below are a list of common performance testing terminologies:	 			In 				software testing, 								Feb 05, 2017						                                 		Pros and Cons of Test Driven Development	: 		  	 			In 				software testing, 								Feb 03, 2017						                                 		Where to Start with Test Automation for an Existing Website?	: 		  Andrew asks:	 			In 				software testing, 								Jan 31, 2017						                                 		Error, Fault and Failure in Software Testing	: 		  	 			In 				software testing, 								Jan 29, 2017						                                 		10 Traits of an Agile Self Organizing Team	: 		  	 			In 				software testing, 								Jan 28, 2017						                                 		Transitioning from Waterfall to Agile Testing	: 		  	 			In 				software testing, 								Jan 25, 2017						                                 		Should Test Automation be Done by Separate Dedicated Team?	: 		  What are the advantages and disadvantages of having a dedicated team focusing only on test automation?	 			In 				software testing, 								Jan 22, 2017						                                 		A Tester's Quick Guide to Exploratory Testing	: 		  	 			In 				software testing, 								Jan 15, 2017						                                 		Definitive Guide to Writing Good Agile User Stories	: 		  One of the first steps in delivering a quality product, is writing good user stories. A user story is a place to capture product functionality and as the name suggests, user stories d. . . 	 			In 				software testing, 								Jan 13, 2017						                                 		What is the Difference Between Scrum, Kanban and XP?	: 		  In Agile Software Development Methodology, software is developed incrementally and iteratively and delivered bit by bit, rather than everything at once. Each iteration is time-boxed, . . . 	 			In 				software testing, 								Jan 11, 2017						                                 		How Can Testers Add Value in Agile Projects?	: 		  What do Agile Testers do and how can they add value in Agile projects?	 			In 				software testing, 								Jan 10, 2017						                                 		Static Analysis vs Dynamic Analysis in Software Testing	: 		  	 			In 				software testing, 								Jan 08, 2017						                                 		Agile Testing Mindset and the Role of the Agile Tester	: 		  In an Agile team, testers must closely collaborate with all other team members and with business stakeholders. This has a number of implications in terms of the skills a tester must h. . . 	 			In 				software testing, 								Jan 06, 2017						                                 		Roles and Responsibilities of a Product Owner in Agile	: 		  	 			In 				software testing, 								Jan 05, 2017						                                 		Fundamental Test Process	: 		  What is the Fundamental Test Process?	 			In 				software testing, 								Dec 31, 2016						                                 		Why We Test Software	: 		  Why is software testing necessary?	 			In 				software testing, 								Dec 30, 2016						                                 		How Much Testing Is Enough?	: 		  It is possible to do enough testing but determining the how much is enough is difficult. Simply doing what is planned is not sufficient since it leaves the question as to how much sho. . . 	 			In 				software testing, 								Dec 29, 2016						                                 		Waterfall Model in Software Testing	: 		  What is the Waterfall Model in Software Testing?	 			In 				software testing, 								Dec 28, 2016						                                 		V Model	: 		  V Model in Software Testing	 			In 				software testing, 								Dec 28, 2016						                                 		Prototyping	: 		  What is System Testing?	 			In 				software testing, 								Dec 28, 2016						                                 		Prototyping	: 		  What is the Spiral Model SDLC?	 			In 				software testing, 								Dec 28, 2016						                                 		Rapid Application Development (RAD)	: 		  What is the RAD Model?	 			In 				software testing, 								Dec 28, 2016						                                 		Prototyping	: 		  What is Prototyping Model?	 			In 				software testing, 								Dec 28, 2016						                                 		Iterative Model	: 		  What is the Iterative Model?	 			In 				software testing, 								Dec 28, 2016						                                 		Integration Testing in Small	: 		  What is Integration Testing in Small?	 			In 				software testing, 								Dec 28, 2016						                                 		Incremental Model	: 		  What is the Incremental Model?	 			In 				software testing, 								Dec 28, 2016						                                 		Component Testing	: 		  Component Testing	 			In 				software testing, 								Dec 28, 2016						                                 		5 Reasons Why There Are Bugs in Software	: 		  There are many reasons for which a software contains bugs, but the root causes of the defects can normally be classed into the following	 			In 				software testing, 								Dec 28, 2016						                                 		Integration Testing in Large	: 		  What is Integration Testing in Large?	 			In 				software testing, 								Dec 27, 2016						                                 		Acceptance Testing	: 		  User Acceptance TestingUser Acceptance Testing is the final stage of validation. This is the time that customers get their hands on the system (or should do) and the end product of th. . . 	 			In 				software testing, 								Dec 26, 2016						                                 		Equivalence Partitioning	: 		  Equivalence Partitioning Test Technique	 			In 				software testing, 								Dec 25, 2016						                                 		Boundary Value Analysis	: 		  Boundary Value Analysis Test Technique	 			In 				software testing, 								Dec 24, 2016						                                 		State Transition Testing	: 		  State Transition Testing Technique	 			In 				software testing, 								Dec 23, 2016						                                 		Exploratory Testing	: 		  What is Exploratory Testing?	 			In 				software testing, 								Dec 22, 2016						                                 		Black Box Testing	: 		  What is Black Box Testing?	 			In 				software testing, 								Dec 21, 2016						                                 		Retesting and Regression Testing	: 		  Difference Between Retesting and Regression Testing	 			In 				software testing, 								Dec 20, 2016						                                 		Defect Life Cycle in Software Testing	: 		  Defect Life Cycle is the stages that the defect or bug goes through from when it is first reported until it is fixed and confirmed. 	 			In 				software testing, 								Dec 19, 2016						                                 		Defect Clustering in Software Testing	: 		  [caption id=”attachment_10047” align=”aligncenter” width=”493”] defect-clustering-istqb[/caption]	 			In 				software testing, 								Dec 18, 2016						                                 		Elements of a Bug Report	: 		  How to Write a Good Bug Report	 			In 				software testing, 								Dec 17, 2016						                                 		MoSCoW Prioritization in Software Testing	: 		  Prioritization of Requirements	 			In 				software testing, 								Dec 16, 2016						                                 		Test Strategy and Test Plan	: 		  Test Strategy	 			In 				software testing, 								Dec 15, 2016						                                 		MoSCoW Prioritization in Software Testing	: 		  	 			In 				software testing, 								Dec 14, 2016						                                 		Seven Principles of Software Testing	: 		  Software testing is an extremely creative and intellectually challenging task. When testing follows the principles given below, the creative element of test design and execution rival. . . 	 			In 				software testing, 								Dec 13, 2016						                                 		Top 10 Negative Test Cases	: 		  Negative test cases are designed to test the software in ways it was not intended to be used, and should be a part of your testing effort. Below are the top 10 negative test cases you. . . 	 			In 				software testing, 								Dec 12, 2016						                                 		White Box Testing	: 		  What is a White Box Testing Strategy?	 			In 				software testing, 								Dec 11, 2016						                                 		Test Policy Document	: 		  What is a Test Policy Document?	 			In 				software testing, 								Dec 10, 2016						                                 		Regression Testing Best Practices	: 		  Regression Testing Best Practices	 			In 				software testing, 								Dec 09, 2016						                                 		Should You Prioritise Your Software Testing?	: 		  Prioritize Your Software Testing	 			In 				software testing, 								Dec 08, 2016						                                 		Why Do We Need Software Testing?	: 		  Why Do We Test Software	 			In 				software testing, 								Dec 07, 2016						                                 		What is Software Testing Methodology?	: 		  Choosing a Testing Methodology	 			In 				software testing, 								Dec 06, 2016						                                 		Web Application Testing Techniques	: 		  Web Application Testing	 			In 				software testing, 								Dec 05, 2016						                                 		Software Testing Jokes	: 		  The field of Software Testing can be boring at times and a bit of humor is always nice. Software Testing Jokes is a collection of jokes, anecdotes, quotes, related to software testing. . . 	 			In 				software testing, 								Dec 04, 2016						                                 		100+ Open Source/Free Functional Testing Tools	: 		  It is very important to make sure that your application functions as expected. There may be times that you add one little piece of code and all of a sudden other parts of the applicat. . . 	 			In 				software testing, 								Dec 03, 2016						                                 		9 Open Source Link Checking Tools	: 		  It is very important to make sure that there are no broken links on your site. A link may be active when your first added it but as the days, months, years go by the link may end up b. . . 	 			In 				software testing, 								Dec 02, 2016						                                 		3 Main Types of Software Testing	: 		  Main Types of Software Testing	 			In 				software testing, 								Dec 01, 2016						                                 		Why do we Test? What is the Purpose of Software Testing?	: 		  Why We Test Software?	 			In 				software testing, 								Nov 30, 2016						                                 		How to Start Selenium Server with Java Code	: 		  When test automating a web application using Selenium, we have to start the Selenium server first, so that a new Selenium session is created to talk to the web browser. This can be ei. . . 	 			In 				software testing, 								Nov 29, 2016						                                 		Severity and Priority - What is the Difference?	: 		  Severity and Priority	 			In 				software testing, 								Nov 28, 2016						                                 		How to Download and Save Images with Selenium RC	: 		  In this tutorial we will take a look at how we can download and save images from a website using Selenium RC and Java. 	 			In 				software testing, 								Nov 27, 2016						                                 		10 Best Open Source Web Testing Tool	: 		  	 			In 				software testing, 								Nov 26, 2016						                                 		How to Capture Screenshots Using WebDriver in Java	: 		  Selenium 2 (or WebDriver) has come up with some great new functionality that makes website testing much easier. This is because of the webdriver architecture allows interaction outsid. . . 	 			In 				software testing, 								Nov 25, 2016						                                 		Agile Test Plan - Do We Really Need One?	: 		  Agile Test Plan Document	 			In 				software testing, 								Nov 24, 2016						                                 		When to Automate User Stories	: 		  If you have worked in an agile environment as a QA role, most probably you would have come across some sort of test automation. I don’t mean unit test automation which is typically a . . . 	 			In 				software testing, 								Nov 23, 2016						                                 		How to Capture Network Traffic and Http Requests From WebDriver	: 		  Selenium 1 has a built-in mechanism to record network traffic and http requests by setting the selenium. start(“captureNetworkTraffic=true”);	 			In 				software testing, 								Nov 22, 2016						                                 		5 Reasons Why Automated Tests Fail to Find Regression Bugs	: 		  It is widely believed that the purpose of automated tests is not to find new defects but rather find regression bugs as new features are developed. But even so, there are many occasio. . . 	 			In 				software testing, 								Nov 21, 2016						                                 		What is Acceptance Testing in Agile	: 		  Acceptance testing	 			In 				software testing, 								Nov 20, 2016						                                 		What is Acceptance Testing in Agile	: 		  AGILE is a methodology that enables continuous iteration of development and testing throughout the software development life cycle of the project. Iteration is defined as a small rele. . . 	 			In 				software testing, 								Nov 19, 2016						                                 		How to Click a Link by href value in WebDriver	: 		  In Selenium WebDriver, there are a number of ways we can interact with web elements, such as by element’s ID, XPath, CSS, etc…	 			In 				software testing, 								Nov 18, 2016						                                 		WebDriver Wait for AJAX Call to Complete	: 		  How to wait for an AJAX call to complete in WebDriver	 			In 				software testing, 								Nov 17, 2016						                                 		Test Automation Tips and Best Practices	: 		  Top Tips for Test Automation	 			In 				software testing, 								Nov 16, 2016						                                 		How to Open a New Tab in Browser Using Selenium WebDriver with Java	: 		  Quite often you may want to open a new tab in the same browser window that is running your Selenium WebDriver tests. Instead of opening a new browser, you can simply use the code belo. . . 	 			In 				software testing, 								Nov 15, 2016						                                 		10+ Open Source Mobile Test Automation Tools	: 		  Mobile Test Tools - A collection of the best open source mobile test automation tools than you can use to test mobile apps and websites on mobile devices	 			In 				software testing, 								Nov 14, 2016						                                 		Common Myths of Test Automation	: 		  	 			In 				software testing, 								Nov 13, 2016						                                 		Best Software Testing Quotes	: 		  Here are some of the best interesting quotes on software testing and quality assurance:	 			In 				software testing, 								Nov 12, 2016						                                 		Software Testing Definitions	: 		  [caption id=”attachment_10031” align=”aligncenter” width=”472”] software-testing-definitions[/caption]	 			In 				software testing, 								Nov 11, 2016						                                 		Tester's Role in Agile Environment	: 		  There are many diverse ideas about what being a tester means in agile development environments. This leads to confusion between how agile testers “fit” into development teams and what. . . 	 			In 				software testing, 								Nov 10, 2016						                                 		BDD Guidelines and Best Practices	: 		  BDD Best Practices	 			In 				software testing, 								Nov 09, 2016						                                 		Why Exploratory Testing is Important in Agile Projects	: 		  Exploratory Testing is an important activity in an agile environment as it can help software testers to keep up with the rapid development pace of agile software projects. 	 			In 				software testing, 								Nov 08, 2016						                                 		Software Development Life Cycle - SDLC Phases	: 		  SDLC Phases Explained	 			In 				software testing, 								Nov 07, 2016						                                 		Acceptance Criteria vs. Acceptance Tests	: 		  What is the difference between acceptance criteria and acceptance tests? Many organizations that follow agile methodology, especially in Behaviour Driven Development (BDD) use these t. . . 	 			In 				software testing, 								Nov 06, 2016						                                 		Exploratory Testing: Tips and Best Practices	: 		  In a previous post we discussed Why Exploratory Testing is Important in Agile Projects. 	 			In 				software testing, 								Nov 05, 2016						                                 		10 Characteristics of a Bad Software Tester	: 		  Traits to Avoid as a Tester	 			In 				software testing, 								Nov 04, 2016						                                 		What Makes a Good Agile Tester?	: 		  Are You a Good Agile Tester?	 			In 				software testing, 								Nov 03, 2016						                                 		No Such Thing As Negative Testing?	: 		  [caption id=”attachment_10084” align=”aligncenter” width=”640”] what-is-negative-testing[/caption]	 			In 				software testing, 								Nov 02, 2016						                                 		Can You Really Automate a User Journey?	: 		  [caption id=”attachment_10071” align=”aligncenter” width=”600”] automating-user-journey[/caption]	 			In 				software testing, 								Nov 01, 2016						                                 		Q: Are we not testers? A: We are QA!	: 		  [caption id=”attachment_10135” align=”aligncenter” width=”520”] qa-vs-testing[/caption]	 			In 				software testing, 								Oct 31, 2016						                                 		Top 10 Books Every Agile Tester Should Read	: 		  Top 10 Books for Agile Testers	 			In 				software testing, 								Oct 30, 2016						                                 		Why Would You Want To Automate a Test?	: 		  [caption id=”attachment_10128” align=”aligncenter” width=”750”] why-automate-testing[/caption]	 			In 				software testing, 								Oct 29, 2016						                                 		Why Risk Based Testing is Important in Agile Projects	: 		  Risk Based Testing in Agile	 			In 				software testing, 								Oct 28, 2016						                                 		Top 8 Open Source Bug Tracking Tools	: 		  Open source Bug Tracking Tools	 			In 				software testing, 								Oct 27, 2016						                                 		7 Deadly Sins of Test Automation	: 		  7 Deadly Sins of Test Automation	 			In 				software testing, 								Oct 26, 2016						                                 		Overview of Scrum Agile Development Methodology	: 		  What is Scrum?	 			In 				software testing, 								Oct 25, 2016						                                 		Agile Test Strategy Example Template	: 		  Agile Test Strategy	 			In 				software testing, 								Oct 24, 2016						                                 		What is Daily Stand-up in Scrum?	: 		  	 			In 				software testing, 								Oct 23, 2016						                                 		Best Open Source Test Management Tools	: 		  Open source and Free Test Management tools. Here we have selected the top best open source test management tools. They are totally free to download and to use in your projects. 	 			In 				software testing, 								Oct 22, 2016						                                 		How to Test Responsive Web Design	: 		  Testing Responsive Web Design	 			In 				software testing, 								Oct 21, 2016						                                 		Role of QA Manager in Agile Project	: 		  What is the role of the QA Manager in an agile environment? Do we really need QA Managers in Agile projects?	 			In 				software testing, 								Oct 20, 2016						                                 		How to Locate Web Elements in WebDriver	: 		  One of the most important skills of a test automation engineer working with Selenium WebDriver is to be able to use appropriate methods to locate elements on a page. 	 			In 				software testing, 								Oct 19, 2016						                                 		CSS Selectors in Selenium WebDriver with Example	: 		  CSS Selectors Tutorial	 			In 				software testing, 								Oct 18, 2016						                                 		Top 10 QA Myths of Agile Testing	: 		  What is Agile Testing?	 			In 				software testing, 								Oct 17, 2016						                                 		Software Testing - Practical Tips for Software Testers	: 		  	 			In 				software testing, 								Oct 16, 2016						                                 		What to Test When There is Not Enough Time to Test	: 		  Not Enough Time To Test	 			In 				software testing, 								Oct 15, 2016						                                 		How to Create, Update and Delete Cookies in WebDriver	: 		  Almost all websites use cookies in one form or another. Cookies are a way of remembering users and their interaction with the site by storing information in the cookie file as key-val. . . 	 			In 				software testing, 								Oct 14, 2016						                                 		Web Testing Tips - How to Test Web Applications	: 		  Web Testing Guidelines	 			In 				software testing, 								Oct 13, 2016						                                 		Testing E-commerce Websites	: 		  Guidelines for Testing E-commerce Websites	 			In 				software testing, 								Oct 12, 2016						                                 		JMeter Tutorial: Testing REST Web Services	: 		  In this Jmeter Tutorial, we look at how we can test a REST API or Web Service using Jmeter tool. 	 			In 				software testing, 								Oct 11, 2016						                                 		Test Automation Advantages and Disadvantages	: 		  Test Automation, when done correctly can have many advantages and be very beneficial to the project and organization. There are however some pitfalls or disadvantages of test automati. . . 	 			In 				software testing, 								Oct 10, 2016						                                 		How to Resize Browser Window in WebDriver	: 		  How to resize browser window with Selenium WebDriver? Here, we look at three different ways we can resize browser window in WebDriver. 	 			In 				software testing, 								Oct 09, 2016						                                 		How to Test Carousel Rotation with Selenium Webdriver	: 		  Some websites have carousel with rotating items in the list. In this webdriver tutorial we look at how to test and verify carousel rotation with webdriver. 	 			In 				software testing, 								Oct 08, 2016						                                 		Software Testing - Ask the Questions!	: 		  	 			In 				software testing, 								Oct 07, 2016						                                 		Head of QA - Roles and Responsibilities	: 		  What are the roles and responsibilities of a Head of QA?	 			In 				software testing, 								Oct 06, 2016						                                 		Bad Requirements – A Software Tester’s Nightmare!	: 		  The real world is never an “ideal” place, and the same applies to so many assignments that one might work on. Numerous times in the past, as a quality professional I have been caught . . . 	 			In 				software testing, 								Oct 05, 2016						                                 		Useful Tools for Testing Websites on Mobile Devices	: 		  As there are more and more people using their mobile devices to browse the web, it is important to make sure that your website is compatible with the different devices with different . . . 	 			In 				software testing, 								Oct 04, 2016						                                 		Ecommerce Testing - It can be make or break!	: 		  	 			In 				software testing, 								Oct 03, 2016						                                 		There is NO QA Team in Agile	: 		  Agile is all about working collaboratively with people who have different skills and mindsets to achieve a common goal. 	 			In 				software testing, 								Oct 02, 2016						                                 		Best Practices for Continuous Testing in Agile	: 		  What is Continuous Testing?	 			In 				software testing, 								Oct 01, 2016						                                 		What is a Web Service?	: 		  A Web Service is a program that can be accessed by other programs over the web (http). For example, let’s assume that you have a function that prints a text in HTML format. The applic. . . 	 			In 				software testing, 								Sep 30, 2016						                                 		WebDriver - How to Open New Browser Window With Javascript	: 		  In previous WebDriver tutorial, we showed how to open a new browser tab in Selenium WebDriver. 	 			In 				software testing, 								Sep 29, 2016						                                 		WebDriver - How to Restore Cookies in New Browser Window	: 		  Suppose we have to test for the following scenario:	 			In 				software testing, 								Sep 28, 2016						                                 		Run All Test Classes in a Package from testng. xml Suite	: 		  1234567&lt;suite name= Suite1  verbose= 1 &gt;  &lt;test name= all-tests &gt;    &lt;packages&gt;      &lt;package name= com. testingexcellence. tests. ui /&gt;    &lt;/p. . . 	 			In 				software testing, 								Sep 27, 2016						                                 		How to get Response Status Code with Selenium WebDriver	: 		  Quite often when you are running automated checks with Selenium WebDriver, you also want to check the response status code for a resource, such as a web service or other web pages on . . . 	 			In 				software testing, 								Sep 26, 2016						                                 		What is the Difference Between driver. get() and driver. navigate(). to(“url”) in Webdriver?	: 		  What is the difference between using driver. get() method or driver. navigate(). to(“url”) method in WebDriver? Is one faster than the other?	 			In 				software testing, 								Sep 25, 2016						                                 		Jmeter Tutorial: How to Send a JSON File as Request in Body	: 		  In this JMeter Tutorial, we explain how to send one or multiple JSON files in the body of the HTTP request. 	 			In 				software testing, 								Sep 24, 2016						                                 		Is Automated Testing on the UI Worth the Effort?	: 		  Automated UI Testing	 			In 				software testing, 								Sep 23, 2016						                                 		Can Agile Succeed Without Automated Testing?	: 		  Is Automated Testing really necessary in agile projects? Can we be agile without any automated testing?	 			In 				software testing, 								Sep 22, 2016						                                 		9 Useful Open Source Testing Tools for Agile Testers	: 		  If you are a technical tester in an agile project, most likely you will be using various testing tools to verify the functionality of the application you are testing. We have compiled. . . 	 			In 				software testing, 								Sep 21, 2016						                                 		Difference Between Performance Testing and Load Testing	: 		  	 			In 				software testing, 								Sep 20, 2016						                                 		Is it Possible to Automate Stories During the Sprint?	: 		  Test Automation During Sprint	 			In 				software testing, 								Sep 19, 2016						                                 		Why Selenium and Cucumber Should Not Be Used Together	: 		  In this post, I will explain why I believe it is a bad idea to write UI automated tests with Selenium and Cucumber. 	 			In 				software testing, 								Sep 18, 2016						                                 		Different Ways to Iterate Through a Map in Java	: 		  Looping over a Map in Java. In this post, we look at four different ways we can iterate through a map in Java. As of Java 8, we can use the forEach method as well as the iterator clas. . . 	 			In 				software testing, 								Sep 17, 2016						                                 		How to Overcome Agile Testing Challenges	: 		  	 			In 				software testing, 								Sep 16, 2016						                                 		Is it Possible to do Sufficient Testing Without QA Resource?	: 		  	 			In 				software testing, 								Sep 15, 2016						                                 		How To Setup a QA Function From Scratch For Agile Startups	: 		  How to setup a QA function from scratch?	 			In 				software testing, 								Sep 14, 2016						                                 		Agile Terminologies and Definitions - Complete Glossary	: 		  	 			In 				software testing, 								Sep 13, 2016						                                 		Test Automation Strategy For Agile Projects	: 		  This Test Automation Strategy example assumes a continuous delivery model with multiple agile teams. 	 			In 				software testing, 								Sep 12, 2016						                                 		Delivery Pipeline For Agile Projects	: 		  What is a Delivery Pipeline?	 			In 				software testing, 								Sep 11, 2016						                                 		Automated versus Manual Testing – Make an Informed Decision!	: 		  Being a manual software testing resource, like many others I have lived the past few years under the constant fear of my job being taken over by the hype of “Automation”. I have worke. . . 	 			In 				software testing, 								Sep 10, 2016						                                 		WebDriver Tutorial - How to Open a Browser With Extensions	: 		  In this WebDriver tutorial we look at how we can use WebDriver to open Chrome and FireFox browsers with extensions using ChromeOptions and FirefoxProfile. 	 			In 				software testing, 								Sep 09, 2016						                                 		Overview of SDLC Methodologies in Software Testing	: 		  	 			In 				software testing, 								Sep 08, 2016						                                 		12 Qualities of a Good Agile Leader	: 		  How do you spot a good Agile leader?	 			In 				software testing, 								Sep 07, 2016						                                 		30+ Essential Software Testing Questions to Prepare for Interview	: 		  Whether you are preparing for a Software Testing Interview or you are interviewing candidates for a QA role, this mind map will help you with the preparation and to remember the main . . . 	 			In 				software testing, 								Sep 06, 2016						                                 		Automated Testing – Setting the Right Expectations	: 		  How to set the right expectations in test automation so that you get the most out of your automated tests and you don’t get disappointed by your efforts. This post looks at the myths . . . 	 			In 				software testing, 								Sep 05, 2016						                                 		Automated Testing – Setting the Right Expectations	: 		  In this WebDriver tutorial, we take a look at how to wait for a page to complete loading before doing other actions. Two examples in Java on wait for page to load in WebDriver. 	 			In 				software testing, 								Sep 04, 2016						                                 		Top 10 Selenium WebDriver Books	: 		  Here is our list of Top 10 Selenium WebDriver Books that you can use to learn Selenium. The books are varied and are for beginners to advanced users with many useful examples. 	 			In 				software testing, 								Sep 03, 2016						                                 		What is Whole Team Approach in Agile Testing?	: 		  	 			In 				software testing, 								Sep 02, 2016						                              performance:                                  		Gatling Quick Reference - Common Gatling Functions	: 		  This post serves as a quick reference guide for Gatling tool for performance testing. 	 			In 				performance, 								Dec 15, 2018						                                 		Soak Testing With Gatling Example	: 		  How to perform Soak Testing with Gatling?	 			In 				performance, 								Nov 29, 2018						                                 		Gatling - How to Save Response Body	: 		  How to save response body in Gatling?	 			In 				performance, 								Nov 15, 2018						                                 		Performance Testing Framework with Gatling and Maven	: 		  What is the best way to organize and structure a Gatling project for performance testing?	 			In 				performance, 								Oct 15, 2018						                                 		How to Use ForEach Controller in JMeter	: 		  ForEach Controller in Jmeter iterates through an array of variables. 	 			In 				performance, 								Oct 08, 2018						                              java:                                  		Java Create File Examples	: 		  In this post, we will look at four different ways to create files in Java. 	 			In 				java, 								Apr 16, 2019						                                 		Java Random Number Generation	: 		  Generating random numbers in Java is a common task. For example, you might want to execute tests with random values each time. In this post, we look at different ways we can generate . . . 	 			In 				java, 								Mar 15, 2019						                                 		How to Convert Java Map to JSON	: 		  There are a number of ways to convert a Java Map into JSON. It is quite common to convert Java Arrays and Maps into JSON and vice versa. 	 			In 				java, 								Mar 12, 2019						                                 		Easiest Way to Reverse a String in Java	: 		  Reversing a string is one of the most frequently asked questions in a Java technical interview. The Interviewers may ask you to write different ways to reverse a string, or they may a. . . 	 			In 				java, 								Feb 20, 2019						                                 		Purpose of Overriding toString() Method in Java	: 		  What is the purpose of toString() method in Java?	 			In 				java, 								Jan 31, 2019						                                 		Convert String to Int in Java With Examples	: 		  How to convert a String to an Int in Java? If the String contains only numbers, then the best way to convert the String to Int is by using Integer. parseInt() or Integer. valueOf(). 	 			In 				java, 								Nov 15, 2018						                                 		Extract Numbers From String Using Java Regular Expressions	: 		  The following are examples which show how to extract numbers from a string using regular expressions in Java. 	 			In 				java, 								Nov 14, 2018						                                 		How to Loop Over ArrayList in Java	: 		  Looping over an ArrayList in Java. In this tutorial, we look at five different ways we can iterate through an ArrayList in Java. As of Java 8, we can use the forEach method as well as. . . 	 			In 				java, 								Nov 10, 2018						                                 		JUnit 5 Annotations With Examples	: 		  This tutorial explains the Junit 5’s most common annotations with examples. 	 			In 				java, 								Oct 25, 2018						                                 		Convert List to Array in Java	: 		  Converting between List and Array is a very common operation in Java. 	 			In 				java, 								Oct 17, 2018						                                 		How to Parse JSON in Java	: 		  JSON stands for JavaScript Object Notation, and it is based on a subset of JavaScript. As a data-exchange format, it is widely used in web programming. Here we show how to parse JSON . . . 	 			In 				java, 								Oct 10, 2018						                              technical testing:                                  		HTTP Status Codes With Explanations	: 		  HTTP Status Codes or Response Codes are grouped into five categories. 1×× Informational, 2×× Success, 3×× Redirection, 4×× Client Error, 5×× Server Error. 	 			In 				technical testing, 								Nov 16, 2018						                                 		Git Commands Every Tester Should Know	: 		  This post is a Git Cheat Sheet with the most common Git commands you will likely use on a daily basis. 	 			In 				technical testing, 								Nov 02, 2018						                                 		How to Submit Form Data With REST-assured Post Request	: 		  How to send a POST request with REST-assured. HTML Forms use POST request to submit form data and in this tutorial, we use REST-assured to submit a form. 	 			In 				technical testing, 								Oct 22, 2018						                                 		Page Object Model Framework with Java and WebDriver	: 		  This tutorial is the second part of the Test Automation Framework development. In the first part, we learned how to create the structure of the framework from scratch. 	 			In 				technical testing, 								Oct 18, 2018						                              testing tools:                                  		Top 10 Open Source Performance Testing Tools	: 		  Performance testing is becoming an integral part of the development process, so it is essential to know what tools are out there.  This post contains a list of top 10 open source perfo. . . 	 			In 				testing tools, 								Nov 19, 2018						                              cybersecurity:                                  		What are Different Types of Hackers?	: 		  What are the different types of hackers and what are their motives? Who are hackers anyway? Well, a hacker is an individual who uses their computer skills and knowledge to gain access. . . 	 			In 				cybersecurity, 								Jun 08, 2019						                                 		Ethical Hacking and Penetration Testing Fundamentals	: 		  This blog post is an introduction to Penetration Testing and Ethical Hacking. We’ll cover the basics of Pen testing and explain why penetration testing is important to organizations. 	 			In 				cybersecurity, 								Apr 02, 2019						                                 		Confidentiality, Integrity and Availability	: 		  Confidentiality, integrity, and availability, often known as the CIA triad, are the building blocks of information security. 	 			In 				cybersecurity, 								Feb 11, 2019						                              linux:                                  		SCP and Rsync - Transfer Files From Local to Remote	: 		  SCP (Secure Copy) and Rsync are two commands that can be used in transferring files between two machines. 	 			In 				linux, 								May 27, 2019						                              node. js:                                  		Node. js - Hello World HTTP Server Example	: 		  In this example we’ll create an HTTP server listening on port 1337, which sends Hello, World! to the browser. 	 			In 				node. js, 				tutorials, 								Jun 04, 2019						                              tutorials:                                  		Node. js - Hello World HTTP Server Example	: 		  In this example we’ll create an HTTP server listening on port 1337, which sends Hello, World! to the browser. 	 			In 				node. js, 				tutorials, 								Jun 04, 2019						                                             Featured:    				                                          Ethical Hacking and Penetration Testing Fundamentals                          In                     cybersecurity,                                                                                           Software Testing and Different Thinking Types                          In                     software testing,                                                                                           SDET Unicorns - Why is it so Hard to Hire SDETs?                          In                     software testing,                                                                                           Problems with Test Automation and Modern QA                          In                     software testing,                                                                                           Testing in DevOps World                          In                     software testing,                                                                   "
    }, {
    "id": 7,
    "url": "localhost:4000/contact.html",
    "title": "Contact",
    "body": "  Please send your message to Testing Excellence. We will reply as soon as possible!   "
    }, {
    "id": 8,
    "url": "localhost:4000/",
    "title": "Mundana Free Jekyll Theme",
    "body": "                                  What are Different Types of Hackers?  :       What are the different types of hackers and what are their motives? Who are hackers anyway? Well, a hacker is an individual who uses . . .               In                 cybersecurity,                                        Jun 08, 2019                                                                                                                             Node. js - Hello World HTTP Server Example          :                       In                         node. js,                         tutorials,                                                                  Jun 04, 2019                                                                                                                                     SCP and Rsync - Transfer Files From Local to Remote          :                       In                         linux,                                                                  May 27, 2019                                                                                                                                    Java Create File Examples          :                       In                         java,                                                                  Apr 16, 2019                                                            Software Testing and Different Thinking Types                  When it comes to Software Testing, the human brain is the best testing tool. When we test software, we process information, solve pro. . .                 Read More            	                                                                                                                                       Latest Posts:                   		What are Different Types of Hackers?	: 		  What are the different types of hackers and what are their motives? Who are hackers anyway? Well, a hacker is an individual who uses their computer skills and knowledge to gain access. . . 	 			In 				cybersecurity, 								Jun 08, 2019						                  		Node. js - Hello World HTTP Server Example	: 		  In this example we’ll create an HTTP server listening on port 1337, which sends Hello, World! to the browser. 	 			In 				node. js, 				tutorials, 								Jun 04, 2019						                  		SCP and Rsync - Transfer Files From Local to Remote	: 		  SCP (Secure Copy) and Rsync are two commands that can be used in transferring files between two machines. 	 			In 				linux, 								May 27, 2019						                  		Java Create File Examples	: 		  In this post, we will look at four different ways to create files in Java. 	 			In 				java, 								Apr 16, 2019						                  		Ethical Hacking and Penetration Testing Fundamentals	: 		  This blog post is an introduction to Penetration Testing and Ethical Hacking. We’ll cover the basics of Pen testing and explain why penetration testing is important to organizations. 	 			In 				cybersecurity, 								Apr 02, 2019						                  		Java Random Number Generation	: 		  Generating random numbers in Java is a common task. For example, you might want to execute tests with random values each time. In this post, we look at different ways we can generate . . . 	 			In 				java, 								Mar 15, 2019						                  		How to Convert Java Map to JSON	: 		  There are a number of ways to convert a Java Map into JSON. It is quite common to convert Java Arrays and Maps into JSON and vice versa. 	 			In 				java, 								Mar 12, 2019						                  		Easiest Way to Reverse a String in Java	: 		  Reversing a string is one of the most frequently asked questions in a Java technical interview. The Interviewers may ask you to write different ways to reverse a string, or they may a. . . 	 			In 				java, 								Feb 20, 2019						                  		Confidentiality, Integrity and Availability	: 		  Confidentiality, integrity, and availability, often known as the CIA triad, are the building blocks of information security. 	 			In 				cybersecurity, 								Feb 11, 2019						                  		Purpose of Overriding toString() Method in Java	: 		  What is the purpose of toString() method in Java?	 			In 				java, 								Jan 31, 2019						                                                &laquo;                              1                               2                               3                               4                               5                               6                               7                               8                               9                               10                               11                               12                               13                               14                               15                               16                               17                               18                               19                               20                               21                               22                               23                              Next &raquo;                                          Featured:    				                                          Ethical Hacking and Penetration Testing Fundamentals                          In                     cybersecurity,                                                                                           Software Testing and Different Thinking Types                          In                     software testing,                                                                                           SDET Unicorns - Why is it so Hard to Hire SDETs?                          In                     software testing,                                                                                           Problems with Test Automation and Modern QA                          In                     software testing,                                                                                           Testing in DevOps World                          In                     software testing,                                                               "
    }, {
    "id": 9,
    "url": "localhost:4000/privacy-policy.html",
    "title": "Privacy Policy",
    "body": "”{{site. name}}” takes your privacy seriously. To better protect your privacy we provide this privacy policy notice explaining the way your personal information is collected and used. Collection of Routine Information: This website track basic information about their visitors. This information includes, but is not limited to, IP addresses, browser details, timestamps and referring pages. None of this information can personally identify specific visitor to this website. The information is tracked for routine administration and maintenance purposes. Cookies: Where necessary, this website uses cookies to store information about a visitor’s preferences and history in order to better serve the visitor and/or present the visitor with customized content. Advertisement and Other Third Parties: Advertising partners and other third parties may use cookies, scripts and/or web beacons to track visitor activities on this website in order to display advertisements and other useful information. Such tracking is done directly by the third parties through their own servers and is subject to their own privacy policies. This website has no access or control over these cookies, scripts and/or web beacons that may be used by third parties. Learn how to opt out of Google’s cookie usage. Links to Third Party Websites: We have included links on this website for your use and reference. We are not responsible for the privacy policies on these websites. You should be aware that the privacy policies of these websites may differ from our own. Security: The security of your personal information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage, is 100% secure. While we strive to use commercially acceptable means to protect your personal information, we cannot guarantee its absolute security. Changes To This Privacy Policy: This Privacy Policy is effective and will remain in effect except with respect to any changes in its provisions in the future, which will be in effect immediately after being posted on this page. We reserve the right to update or change our Privacy Policy at any time and you should check this Privacy Policy periodically. If we make any material changes to this Privacy Policy, we will notify you either through the email address you have provided us, or by placing a prominent notice on our website. Contact Information: For any questions or concerns regarding the privacy policy, please contact us here. "
    }, {
    "id": 10,
    "url": "localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 11,
    "url": "localhost:4000/page2/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 12,
    "url": "localhost:4000/page3/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 13,
    "url": "localhost:4000/page4/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 14,
    "url": "localhost:4000/page5/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 15,
    "url": "localhost:4000/page6/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 16,
    "url": "localhost:4000/page7/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 17,
    "url": "localhost:4000/page8/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 18,
    "url": "localhost:4000/page9/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 19,
    "url": "localhost:4000/page10/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 20,
    "url": "localhost:4000/page11/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 21,
    "url": "localhost:4000/page12/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 22,
    "url": "localhost:4000/page13/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 23,
    "url": "localhost:4000/page14/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 24,
    "url": "localhost:4000/page15/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 25,
    "url": "localhost:4000/page16/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 26,
    "url": "localhost:4000/page17/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 27,
    "url": "localhost:4000/page18/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 28,
    "url": "localhost:4000/page19/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 29,
    "url": "localhost:4000/page20/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 30,
    "url": "localhost:4000/page21/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 31,
    "url": "localhost:4000/page22/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 32,
    "url": "localhost:4000/page23/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                Latest Posts:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 33,
    "url": "localhost:4000/types-of-hackers/",
    "title": "What are Different Types of Hackers?",
    "body": "2019/06/08 - What are the different types of hackers and what are their motives? Who are hackers anyway? Well, a hacker is an individual who uses their computer skills and knowledge to gain access to systems and networks. Hackers are intelligent and skilled individuals who break into systems and networks with the intent of stealing information or performing malicious attacks. Their motives differ: some do it for fun, others to commit a crime. Types of Hackers: Despite the popular belief, not all hackers are bad. Today, there are several types of hackers, and in this video we will go through them. So, hackers can be categorized as:  Black hat White hat Grey hat Suicide hackers Script kiddies Cyber terrorists State sponsored hackers HacktivistsBlack hat: Black hats are hackers who use their knowledge and skills to discover and exploit security vulnerabilities for financial gain or malicious reasons. Their activities can cause major damage to their targets and their systems. Black hats are usually involved with criminal activities such as stealing personal and financial information or shutting down websites and networks. White hat: White hats are ethical hackers who use their knowledge and skills to improve security of a system by discovering vulnerabilities before black hats do. They pretty much use the same methods and tools black hats do, but unlike black hats, white hats have a permission of the system owner to use those methods. Grey hat: Grey hats are hackers who are not as bad as black hats, but also not as ethical as white hats. They might help black hats in their endeavors, but they also might help in discovering vulnerabilities or checking the limitations of a system. Suicide hackers: Suicide hackers are ready and willing to perform an attack for a “cause”, even if they get caught and prosecuted. Script kiddies: Script kiddies are hackers who are new to hacking and don’t have much knowledge or skills to perform hacks. Instead, they use tools and scripts developed by more experienced hackers. Cyber terrorists: Cyber terrorists are hackers who are influenced by certain religious or political beliefs. They work to cause fear and disruption of systems and networks. State sponsored hackers: State sponsored hackers are recruited by governments to gain access to secret information of other governments. Hacktivists: Hacktivists break into government or corporate systems out of protest. They use their skills to promote a political or social agenda. Targets are usually government agencies or big corporations. "
    }, {
    "id": 34,
    "url": "localhost:4000/nodejs-server-example/",
    "title": "Node.js - Hello World HTTP Server Example",
    "body": "2019/06/04 - In this example we’ll create an HTTP server listening on port 1337, which sends Hello, World! to the browser. Note that, instead of using port 1337, you can use any port number of your choice which is currently not in use by any other service. The http module is a Node. js core module (a module included in Node. js’s source, that does not require installing additional resources). The http module provides the functionality to create an HTTP server using the http. createServer() method. To create the application, create a file containing the following JavaScript code. 12345678910111213141516const http = require('http'); // Loads the http module http. createServer((request, response) =&gt; {    // 1. Tell the browser everything is OK (Status code 200), and the data is in plain text  response. writeHead(200, {    'Content-Type': 'text/plain'  });  // 2. Write the announced text to the body of the page  response. write('Hello, World!\n');  // 3. Tell the server that all of the response headers and body have been sent  response. end();}). listen(1337); // 4. Tells the server what port to be onSave the file with any file name. In this case, if we name it hello. js we can run the application by going to the directory the file is in and using the following command: 1node hello. jsThe created server can then be accessed with the URL http://localhost:1337 or http://127. 0. 0. 1:1337 in the browser. A simple web page will appear with a Hello, World! text at the top, as shown in the screenshot below: "
    }, {
    "id": 35,
    "url": "localhost:4000/scp-rsync-transfer-files/",
    "title": "SCP and Rsync - Transfer Files From Local to Remote",
    "body": "2019/05/27 - SCP (Secure Copy) and Rsync are two commands that can be used in transferring files between two machines. For example, we can copy a file or directory from local to remote or from remote to local systems. When using scp to transfer files, everything is encrypted so sensitive details are not exposed. In this tutorial, we give examples of how to use scp and rsync commands to transfer files. SCP (Secure Copy): scp copies files between hosts on a network. It uses ssh(1) for data transfer, and uses the same authentication and provides the same security as ssh(1). The scp command relies on ssh for data transfer, therefore it requires an ssh key or password to authenticate on the remote systems. You can read more on how to set up ssh keys. The general syntax and usage of scp is: 1scp [OPTION] [user@]local:]file1 [user@]remote:]file2scp provides a number of options which are explained in more detail. Transfer Files from Local to Remote with SCP: To copy or transfer a file from a local machine to a remote machine, run the following command: 1scp image. png remote_username@10. 10. 0. 1:/remote/directoryWhere:  image. png is the name of the file we want to transfer from local to remote, remote_username is the user on the remote server, 10. 10. 0. 1 is the server IP address, /remote/directory is the path to the directory we want to copy the file to. Note: If you don’t specify a remote directory, the file will be copied to the remote user home directory. When you press enter, you will be prompted to enter the remote user password and the transfer will start. Omitting the filename from the destination location copies the file with the original name. If you want to save the file under a different name you need to specify a new name: For example: 1scp image1. png remote_username@10. 10. 0. 1:/remote/directory/new_image. pngTransfer Files from Remote to Local with SCP: To transfer a file from a remote machine to your local machine, run the following command: 1scp remote_username@10. 10. 0. 1:/remote/directory/new_image. png /local/directoryTransfer a Directory Recursively from Local to Remote: To transfer a directory and all it’s contents from a local machine to a remote host, use the following command: 1scp -rp sourcedirectory user@dest:/pathNB: This creates the sourcedirectory inside /path thus the files will be in /path/sourcedirectory Rsync: Like scp, rsync is used to copy files either to or from a remote host, or locally on the current host. rsync is generally used to transfer large files. Transfer a File from Local to Remote with Rsync: To copy a file from your local machine to a remote host with rsynch, run the following command 1rsync -ave ssh mydirectory remote_user@10. 10. 0. 2:/remote/directory/Conclusion: In this tutorial, you learned how to use the scp and rsync command to copy files and directories between two machines. "
    }, {
    "id": 36,
    "url": "localhost:4000/java-create-file-examples/",
    "title": "Java Create File Examples",
    "body": "2019/04/16 - In this post, we will look at four different ways to create files in Java. Creating files in Java is easy. All we need to do is import the relevant package in our class file and use relevant methods. The examples below make use of java. io. file, java. io. fileOutputStream, and java. nio package. These classes are provided out of the box in Java API. We also look at creating a file with Apache Commons. Create File with java. io. file class: In the first example, we will use createNewFile() method from the java. io. file class. This method returns a boolean value. It returns false if the file already exists, or true if created. 123456789101112131415161718192021package com. testingexcellence. tutorials;import java. io. File;import java. io. IOException;public class CreateFileJavaExamples {  public static void main(String[] args) {    File file = new File( c://examples//newFile. txt );    try {      if (file. createNewFile()) {        System. out. println( File create );      } else {        System. out. println( File already exists! );      }    } catch (IOException e) {      System. out. println(e. getMessage());    }  }}NOTE: The above example creates an empty file in the provided location. Using java. io. fileOutputStream: The next example uses fileOutputStream. It’s important to note that this is mostly used to create a file and write content to it in one go. 1234567891011121314package com. testingexcellence. tutorials;import java. io. FileOutputStream;public class CreateFileJavaExamples {  public static void main(String[] args) {    try {      new FileOutputStream( newFile. txt , true);    } catch (Exception e) {      System. out. println(e. getMessage());    }  }}If the file doesn’t exist, the above method will create it. If  the file exists, passing true will just append content to it. NOTE: Be careful when using fileOutputStream. If the file exists with content, if we pass false as the parameter to the fileOutputStream method, it will overwrite the file and the content will be lost! Create File with java. nio Package: In the following example, we will use java. nio package which was introduced in JDK 7. In order to create a file with the nio package, we first need to set the path and then use the createFile() method from Files class. Creating files via the new nio package is the preferred option as the API is more intuitive. 12345678910111213141516171819package com. testingexcellence. tutorials;import java. io. IOException;import java. nio. file. Files;import java. nio. file. Path;import java. nio. file. Paths;public class CreateFileJavaExamples {  public static void main(String[] args) {    try {      Path newFilePath = Paths. get( src/test/resources/newFile. txt );      Files. createFile(newFilePath);    }    catch (IOException e) {    }  }}The above code example assumes the path src/test/resources already exists. Apache Commons FileUtils: If you don’t want to use standard libraries provided out of the box from Java, you can use FileUtils class from Apache Commons 123456789101112131415161718package com. testingexcellence. tutorials;import org. apache. commons. io. FileUtils;import java. io. File;import java. io. IOException;public class CreateFileJavaExamples {  public static void main(String[] args) {    File myFile = new File( src/test/resources/newFile. txt );        try {      FileUtils. touch(myFile);    } catch (IOException e) {      System. out. println(e. getMessage());    }  }}In the above example, we use the touch method to create a file. Conclusion: In this tutorial, you learned different ways you can create files in Java. Further reading  Extract Numbers From String Using Java Regular Expressions Easiest Way to Read Properties File in Java With ResourceBundle Easiest Way to Reverse a String in Java How to Loop Over ArrayList in Java"
    }, {
    "id": 37,
    "url": "localhost:4000/penetration-testing-ethical-hacking-fundamentals/",
    "title": "Ethical Hacking and Penetration Testing Fundamentals",
    "body": "2019/04/02 - This blog post is an introduction to Penetration Testing and Ethical Hacking. We’ll cover the basics of Pen testing and explain why penetration testing is important to organizations. We will also cover the stages of penetration testing and explain what happens at each phase. Finally, we’ll take a look at some of the tools commonly used in Penetration Testing. Penetration Testing - Ethical Hacking Basics: What is Ethical Hacking?: When we think of Hacking, we often associate it with illegal or criminal activity. When a hacker attacks a system, they do so without the knowledge and consent of the owner of the system. Put simply, it is like entering someone’s house without the owner’s full permission and prior agreement. Ethical hacking, on the other hand, is still hacking. It involves gathering information about a system, finding loopholes and gaining access. However, in ethical hacking, the pen tester has_ the full consent and permission_ of the system owner. Therefore, the activity becomes ethical, i. e. done with good intentions. Customers employ ethical hackers to improve security. What is Penetration Testing?: Penetration testing involves simulating real attacks to assess the risk associated with potential security breaches. During pen testing, testers use various tools and methodologies to find vulnerabilities. They will then try to exploit the vulnerabilities to assess what attackers might gain after successful exploitation. Why Penetration Testing is Necessary?: Over the years, there has been a constant rise in the number of cyber threats and criminal activities involving Information Technology. Businesses need to undertake regular vulnerability assessment and penetration testing to identify weaknesses in their systems. They can then use effective measures to protect their systems against malicious hackers. Who Performs a Pen Test?: Ethical hackers are the people who normally carry out Penetration Testing. In order to catch a thief, you have to think like one. The same is true in Ethical hacking. In order to find and fix security holes in a computer system, you have to think like a malicious hacker. You would use the same tactics, tools, and processes they might employ. An ethical hacker employs the same tools and techniques a criminal might use. But they do so with the customer’s full support and approval, in order to help secure a network or system. Penetration Testing vs Vulnerability Assessment: Vulnerability assessment examines the exposed assets (network, server, applications) for vulnerabilities. The downside of a vulnerability scan is that it frequently reports false positives. False positives may be a sign that an existing control is not fully effective. Penetration testing goes one step further and looks at vulnerabilities and will try and exploit them. Types of Penetration Testing: Black Box Penetration Testing: In black-box penetration testing, the tester has no prior knowledge about the target. This closely simulates the real-world attacks and reduces false positives. This type of testing requires extensive research and information gathering on the target system/network. It typically consumes more time, effort, and cost to perform a black box penetration test. Gray-Box Penetration Testing: In gray-box penetration testing, the tester has limited or partial knowledge about the target infrastructure. They have some knowledge of security mechanisms in place. This simulates an attack by an insider or an external hacker who has some knowledge or privileges on the target system. White-Box Penetration Testing: In white-box penetration testing, the testers have complete in-depth knowledge about the target infrastructure. They know about the security mechanisms in place. This makes the test much quicker, easier, and less expensive. This simulates an attack which could happen by an insider who has full knowledge and privileges on the target system. Announced Testing: In this type of testing, everyone is aware when the testing will be initiated. The IT staff the network team, and the management team all have prior knowledge of the pen testing activity. Unannounced Testing: In this type of testing, IT staff and support teams don’t have the prior knowledge of the pen testing activity. Only the top management is aware of the test schedule. Such testing helps determine the responsiveness of the IT and support staff in case of a security attack. Automated Penetration Testing: Because penetration testing involves many tasks and the attack surface area is also complex at times, it is sometimes necessary to use tools to automate many of the tasks. The tool will run against an infrastructure at regular intervals and then share the reports with concerned teams to address the issues. The downside of using automated tools is that they will only check for predefined vulnerabilities thus reporting false positives. It also cannot review architecture and system integration from a security perspective. However, it is suitable for scanning multiple targets repeatedly and to complement manual testing. Manual Penetration Testing: In manual testing, the tester uses his own expertise and skills in order to penetrate the target system. The tester can also perform reviews of architecture and other procedural aspects in consultation with respective teams. For holistic security testing, it is best to use a combination of automated and manual testing. Stages of Penetration Testing: Pen testing begins with the pre-engagement phase. This involves talking to the client about their goals for the pen test and mapping out the scope of the test. The client and the pen tester as questions and set expectations. Some clients put boundaries on the scope of activities. For example, the client grants permission to the tester to find vulnerabilities of a database, but not to fetch sensitive data. The pre-engagement phase also covers other details, such as the testing window, contact information, and payment terms. Information Gathering: In the information-gathering phase, the pen testers search for publicly available information about the client and identify potential ways to connect to the client’s systems. The testers begin to use tools such as port scanners to get an idea of what systems are out there on the internal network as well as what software is running. Threat Modelling: In the threat-modeling phase, the testers use information gathered in the previous phase to determine the value of each finding and the impact on the client if the finding permitted an attacker to break into a system. This evaluation allows the pentester to develop an action plan and methods of attack. Vulnerability Analysis: Before the Pen Testers can start attacking a system, they perform a vulnerability analysis. Here, Pen Testers attempt to discover weaknesses in the systems that can be taken advantage of in the next phase. Exploitation: In the exploitation phase, Pen Testers begin their exploit against the target system. They use previously discovered vulnerabilities in an attempt to access a client’s systems. They will try various tools and method in order to penetrate the system. Post Exploitation: In post-exploitation, testers evaluate the extent of damage that can be done via a particular exploit. In other words, they assess the risks. For example, during the pen test, the testers compromised the client’s system. Does that intrusion really mean anything to the client? If you broke into a system that doesn’t reveal any vital information of interest to an attacker, then so what? That vulnerability’s risk is significantly lower than if you were able to exploit a client’s development system. Reporting: The final phase of penetration testing is reporting. In this phase, the Pen Testers convey their findings to the customer in a meaningful way. The report informs the client what they’re doing correctly and where they need to improve their security posture. The report may include details of each exploit and measures to correct them. Common Tools Used for Penetration Testing: Two of the most common tools used during pen testing are Nmap and Metasploit. Both tools can provide a wealth of information on a target system. Kali Linux from offensive security includes many other tools used in various stages of testing. Further reading Confidentiality, Integrity, and Availability "
    }, {
    "id": 38,
    "url": "localhost:4000/java-random-number/",
    "title": "Java Random Number Generation",
    "body": "2019/03/15 - Generating random numbers in Java is a common task. For example, you might want to execute tests with random values each time. In this post, we look at different ways we can generate random numbers in Java. Random Number Generation: In Java, we can generate random numbers by using the java. util. Random class. Once we import the Random class, we can create an object from it which gives us the ability to use random numbers. For example, methods nextInt() and nextLong() will return a number that is within the range of values (negative and positive) of the int and long data types respectively. Generating random Int, Long, and Boolean: 123456789101112131415package com. testingexcellence. tutorials;import java. util. Random;public class GenerateRandomNumbers {  static Random rand;  public static void main(String[] args) {    rand = new Random();    System. out. println( Random integer:   + rand. nextInt());    System. out. println( Random long:    + rand. nextLong());    System. out. println( Random boolean:   + rand. nextBoolean());  }}Generating Random Numbers in a Range: Sometimes, we want random numbers to be generated from a certain range, e. g. between 1 and 50. To do this, we can provide an integer parameter to the nextInt() method. This parameter defines the upper limit for the range. One thing to note here is that the upper limit number is not included as one of the numbers that are generated. For example, nextInt(5)generates numbers from 0 to 4 inclusive. If we also wish 5 to be in the list of the random numbers, we need to use nextInt(5)+1 1234567891011121314package com. testingexcellence. tutorials;import java. util. Random;public class GenerateRandomNumbers {  static Random rand;  public static void main(String[] args) {    rand = new Random();    int randInt = rand. nextInt(5) + 1;    System. out. println( Random integer:   + randInt);  }}Generating Secure Random Numbers in Java: The Random class generates random numbers in a deterministic way. The algorithm that produces the randomness is based on a number called a seed. If the seed number is known then it’s possible to figure out the numbers that are going to be produced from the algorithm. The goal of the SecureRandom Class is to generate cryptographically strong random numbers. The SecureRandom must produce non-deterministic output. Therefore any seed material passed to a SecureRandom object must be unpredictable. Below is an example usage of the SecureRandom class to generate random numbers in Java 1234567891011121314151617181920212223package com. testingexcellence. tutorials;import java. security. NoSuchAlgorithmException;import java. security. NoSuchProviderException;import java. security. SecureRandom;public class GenerateRandomNumbers {  static SecureRandom secureRandomGenerator;  public static void main(String[] args) {        try {      secureRandomGenerator = SecureRandom. getInstance( SHA1PRNG ,  SUN );    }     catch (NoSuchAlgorithmException | NoSuchProviderException e) {    }    //Get random integer in range    int randInRange = secureRandomGenerator. nextInt(499);    System. out. println(randInRange);  }}The above examples illustrate how to generate random numbers in Java. Reference: Secure Random Number Generation Further reading  How to Convert Java Map to JSON Convert List to Array in Java Easiest Way to Reverse a String in Java"
    }, {
    "id": 39,
    "url": "localhost:4000/how-to-convert-java-map-to-json/",
    "title": "How to Convert Java Map to JSON",
    "body": "2019/03/12 - There are a number of ways to convert a Java Map into JSON. It is quite common to convert Java Arrays and Maps into JSON and vice versa. In this post, we look at 3 different examples to convert Java Map to JSON. We will be using Jackson, Gson and org. json libraries. Java Map to JSON using Jackson: The following example uses Jackson Core and Jackson Binding to convert Java Map to JSON. In order to use the Jackson libraries, we first need to add them to our pom. xml file: 123456789101112&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;com. fasterxml. jackson. core&lt;/groupId&gt;     &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;    &lt;version&gt;2. 9. 8&lt;/version&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;com. fasterxml. jackson. core&lt;/groupId&gt;    &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;    &lt;version&gt;2. 9. 8&lt;/version&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;Then: 12345678910111213141516171819202122232425262728package com. testingexcellence. tutorials;import com. fasterxml. jackson. core. JsonProcessingException;import com. fasterxml. jackson. databind. ObjectMapper;import org. junit. jupiter. api. Test;import java. util. HashMap;import java. util. Map;public class ConvertJavaMapToJson {  @Test  public void convertMapToJson() {    Map&lt;String, String&gt; elements = new HashMap();    elements. put( Key1 ,  Value1 );    elements. put( Key2 ,  Value2 );    elements. put( Key3 ,  Value3 );    ObjectMapper objectMapper = new ObjectMapper();    try {      String json = objectMapper. writeValueAsString(elements);      System. out. println( json =   + json);    } catch (JsonProcessingException e) {      e. printStackTrace();    }  }}Output: 1json = { Key2 : Value2 , Key1 : Value1 , Key3 : Value3 }As can be seen from the output, the order of the elements in the JSON are not the same as the order we added them to the map. To retain the order, we need to use SortedMap instead. e. g. 1SortedMap&lt;String, String&gt; elements = new TreeMap();Output: 1json = { Key1 : Value1 , Key2 : Value2 , Key3 : Value3 }Java Map to JSON using Gson: The following example uses Gson library to convert Java Map to JSON, but first, we need to add Gson as a dependency to pom. xml file. 1234567&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;com. google. code. gson&lt;/groupId&gt;    &lt;artifactId&gt;gson&lt;/artifactId&gt;    &lt;version&gt;2. 8. 5&lt;/version&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;Then: 1234567891011121314151617181920212223242526package com. testingexcellence. tutorials;import com. google. gson. Gson;import com. google. gson. reflect. TypeToken;import org. junit. jupiter. api. Test;import java. lang. reflect. Type;import java. util. HashMap;import java. util. SortedMap;import java. util. TreeMap;public class ConvertJavaMapToJson {  @Test  public void convertMapToJson() {    SortedMap&lt;String, String&gt; elements = new TreeMap();    elements. put( Key1 ,  Value1 );    elements. put( Key2 ,  Value2 );    elements. put( Key3 ,  Value3 );    Gson gson = new Gson();    Type gsonType = new TypeToken&lt;HashMap&gt;(){}. getType();    String gsonString = gson. toJson(elements,gsonType);    System. out. println(gsonString);  }}Output: 1  json = { Key1 : Value1 , Key2 : Value2 , Key3 : Value3 }Java Map to JSON using org. json: The following example uses org. json library to convert Java Map to JSON, but first, we need to add org. json as a dependency to pom. xml file. 1234567&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org. json&lt;/groupId&gt;    &lt;artifactId&gt;json&lt;/artifactId&gt;    &lt;version&gt;20180813&lt;/version&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;Then: 12345678910111213141516171819202122package com. testingexcellence. tutorials;import org. json. JSONObject;import org. junit. jupiter. api. Test;import java. util. HashMap;import java. util. Map;public class ConvertJavaMapToJson {  @Test  public void convertMapToJson() {    Map&lt;String, String&gt; elements = new HashMap&lt;&gt;();    elements. put( Key1 ,  Value1 );    elements. put( Key2 ,  Value2 );    elements. put( Key3 ,  Value3 );    JSONObject json = new JSONObject(elements);    System. out. println(json);  }}Output: 1  json = { Key2 : Value2 , Key1 : Value1 , Key3 : Value3 }Further Reading  Convert List to Array in Java Convert String to Int in Java With Examples"
    }, {
    "id": 40,
    "url": "localhost:4000/reverse-string-java/",
    "title": "Easiest Way to Reverse a String in Java",
    "body": "2019/02/20 - Reversing a string is one of the most frequently asked questions in a Java technical interview. The Interviewers may ask you to write different ways to reverse a string, or they may ask you to reverse a string without using in-built methods, or they may even ask you to reverse a string using recursion. Below are various methods you can use to reverse a string in Java. Reverse String in Java, Easiest Way: The easiest way to reverse a string in Java is to use the built-in reverse() function of the StringBuilder class. Example: 12345678910111213141516package com. testingexcellence. tutorials;import org. junit. jupiter. api. Test;import static org. junit. jupiter. api. Assertions. assertEquals;class ReverseString {  String reverse(String inputString) {    return new StringBuilder(inputString). reverse(). toString();  }  @Test  public void testAWord() {    assertEquals( tobor , new ReverseString(). reverse( robot ));  }}Reverse String using Recursion: Another way to reverse a string in java is to use recursion and utilizing the charAt() method of the String class Example: 1234567891011121314151617181920212223package com. testingexcellence. tutorials;import org. junit. jupiter. api. Test;import static org. junit. jupiter. api. Assertions. assertEquals;class ReverseString {  String reverse(String inputString) {    StringBuilder reverseStringBuilder = new StringBuilder();    for(int i = inputString. length() - 1; i&gt;=0; i--){      reverseStringBuilder. append(inputString. charAt(i));    }    return reverseStringBuilder. toString();  }  @Test  public void testAWord() {    assertEquals( tobor , new ReverseString(). reverse( robot ));  }}A variation of the above is to use the toCharArray() and loop over the characters, for example: 1234567891011121314151617181920package com. testingexcellence. tutorials;import org. junit. jupiter. api. Test;import static org. junit. jupiter. api. Assertions. assertEquals;class ReverseString {  String reverse(String inputString) {    String outString =   ;    for(char c : inputString. toCharArray()) {      outString = c + outString;    }    return outString;  }  @Test  public void testAWord() {    assertEquals( tobor , new ReverseString(). reverse( robot ));  }}Reverse String in Java 8: 123456789101112131415161718192021package com. testingexcellence. tutorials;import org. junit. jupiter. api. Test;import java. util. stream. Collectors;import java. util. stream. IntStream;import static org. junit. jupiter. api. Assertions. assertEquals;class ReverseString {  String reverse(String inputString) {    return IntStream. range(0, inputString. length())      . mapToObj(x-&gt; inputString. charAt((inputString. length()-1) - x))      . map(character -&gt; String. valueOf(character))      . collect(Collectors. joining(  ));  }  @Test  public void testAWord() {    assertEquals( tobor , new ReverseString(). reverse( robot ));  }}Further reading  How to Loop Over ArrayList in Java Purpose of Overriding toString() in Java Convert List to Array in Java"
    }, {
    "id": 41,
    "url": "localhost:4000/confidentiality-integrity-availability/",
    "title": "Confidentiality, Integrity and Availability",
    "body": "2019/02/11 - Confidentiality, integrity, and availability, often known as the CIA triad, are the building blocks of information security. Any attack on an information system will compromise one, two, or all three of these components. Based on which of these components is being compromised the most, efficient security controls can be designed accordingly.  Confidentiality: In simple terms, confidentiality means something that is secret and is not supposed to be disclosed to unintended people or entities. Confidentiality ensures that sensitive information is accessed only by an authorized person and kept away from those not authorized to possess them. Everyone has information which they wish to keep secret. Thus Protecting such information is an important part of information security. Examples of confidential information::  Bank account statements Personal information Credit card numbers Trade secrets Government documentsIn the event that confidentiality is compromised, it might result in unauthorized access to personal information or even complete loss of privacy! Examples of attacks that affect confidentiality::  Packet sniffing Password cracking Dumpster diving Wiretapping Keylogging PhishingWays to ensure confidentiality::  Usernames and passwords Two-factor authentication Biometric verification Security tokens or key fobs Data encryptionIntegrity: In the context of the information security (InfoSec) world, integrity means that when a sender sends data, the receiver must receive exactly the same data as sent by the sender. Data must not be changed in transit. For example, if someone sends a message “Hello!”, then the receiver must receive “Hello!” That is, it must BE exactly the same data as sent by the sender. Any addition or subtraction of data during transit would mean the integrity has been compromised. Example attacks that affect Integrity::  Salami attack Data diddling attacks Session hijacking Man-in-the-middle (MITM) attackAvailability: Availability implies that information is available to the authorized parties whenever required. Unavailability to data and systems can have serious consequences. It is essential to have plans and procedures in place to prevent or mitigate data loss as a result of a disaster. A disaster recovery plan must include unpredictable events such as natural disasters and fire. A routine backup job is advised in order to prevent or minimize total data loss from such occurrences. Also, extra security equipment or software such as firewalls and proxy servers can guard against downtime and unreachable data due to malicious actions such as denial-of-service (DoS) attacks and network intrusions. Example attacks that affect Availability::  DoS and DDoS attacks SYN flood attacks Physical attacks on server infrastructure"
    }, {
    "id": 42,
    "url": "localhost:4000/overriding-tostring-java-class/",
    "title": "Purpose of Overriding toString() Method in Java",
    "body": "2019/01/31 - What is the purpose of toString() method in Java? If we want to represent an object of a class as a String, then we can use the toString() method which returns a textual representation of the object. When you print an object, by default the Java compiler invokes the toString() method on the object. So by overriding the toString() method, we can provide meaningful output. Let’s see this concept in the following example: Overriding toString() Method: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com. testingexcellence. tutorials;public class ToStringExample {  private String firstName;  private String lastName;  private String email;  public ToStringExample() {  }    public String getFirstName() {    return firstName;  }      public void setFirstName(String firstName) {    this. firstName = firstName;  }      public String getLastName() {    return lastName;  }      public void setLastName(String lastName) {    this. lastName = lastName;  }      public String getEmail() {    return email;  }    public void setEmail(String email) {    this. email = email;  }  public String toString() {    StringBuilder sb = new StringBuilder();    sb. append( First name :  ). append(this. firstName). append( \n );    sb. append( Last name :  ). append(this. lastName). append( \n );    sb. append( Email :  ). append(this. email). append( \n );    return sb. toString();  }  public static void main(String args[]) {    ToStringExample example = new ToStringExample();    example. setFirstName( Testing );    example. setLastName( Excellence );    example. setEmail( testing@excellence. com );    System. out. println(example);  }}The above code outputs the following: 123First name : TestingLast name : ExcellenceEmail : testing@excellence. comIf we didn’t override the toString() method, the output would have been 1com. testingexcellence. tutorials. ToStringExample@60e53b93As can be seen, by overriding the toString() method, we can output meaningful presentation of the object. Further reading  How to Loop Over ArrayList in Java How to Parse JSON in Java Easiest Way to Reverse a String in Java"
    }, {
    "id": 43,
    "url": "localhost:4000/gatling-quick-reference/",
    "title": "Gatling Quick Reference - Common Gatling Functions",
    "body": "2018/12/15 - This post serves as a quick reference guide for Gatling tool for performance testing. Previously, we saw how to organize your Gatling project in a logical and easy to understand structure. In this post, we look at some examples and usages of some common Gatling functions when creating performance test scripts. Gatling examples covered in this post are:  Simple simulation Using HTTP proxy HTTP requests Scenario Injection of virtual users Loops Checks and Assertions FeedersSimple simulation: 12345678import io. gatling. core. Predef. _import io. gatling. http. Predef. _class SimplestSimulation extends Simulation {  setUp(scenario( Homepage )  . exec(http( Home ). get( https://www. testingexcellence. com ))  . inject(atOnceUsers(1)))}Using an HTTP Proxy: 12345setUp(scenario( Proxy on )  . exec(http( World ). get( https://www. testingexcellence. com ))  . inject(atOnceUsers(1)))  . protocols(http. proxy(Proxy( proxy. company. net , 8080)))}In the above example, proxy. company. net is the proxy URL and 8080 is the proxy port. HTTP Requests: GET Request: A simple GET request with query parameters 12345http( Get Gatling posts )  . get( https://www. testingexcellence. com )  . queryParam( post ,  gatling )  . queryParam( category ,  performance testing )  . header( Accept-Language ,  en )POST Request: A sample POST request with form params, e. g. submitting a form: 12345http( POST with params )  . post( https://www. example. com/login )  . formParam( firstname ,  David )  . formParam( lastname ,  Brown )  . header( Accept-Language ,  en )A sample POST request with a file payload which must be in src/test/resources/bodies 1234http( Post with file payload )  . post( https://example. com/users )  . body(RawFileBody( bodyFileName. json )). asJSON  . header( Content-type , application/json )Scenario: Pauses: Note: In order to use the pause, you need to add this importimport scala. concurrent. duration. DurationInt 12345678scenario( with secode pause )  // . . .   . pause(2, 3) // will make a random pause of 2-3 seconds  . pause(2) // will make a fixed pause of 2 seconds  scenario( millisecond pause )  // . . .   . pause(200. milliseconds) // fixed pause of 0. 2 secondLoops: 1234scenario( repeat )  . repeat(3)( // repeat 3 times    exec(http( google ). get( https://www. example. com ))  )Injection of virtual users: 123456val scn=scenario( Virtual users )setUp(   scn. inject(   nothingFor(4. seconds),   atOnceUsers(10),   rampUsers(10) over(5. seconds))Ramp up: 1234567rampUsers(10) over(5. seconds)   // linear rampup   // 10 users added over 5 seconds (1 extra user every 500 ms)  constantUsersPerSec(10) during(5. seconds)   // adds 10 users every second  // (so a total of 50 users after 5 seconds)At once: 123456789nothingFor(4. seconds)// no new users added during 4 secondsatOnceUsers(10)// 10 users added immediately// not really recommended since it can hammer down the tested serverheavisideUsers(10) over(2. seconds)// better approximation of a peak of usersChecks and Assertions: In Gatling, checks are usually used to check for status codes response bodies, whereas assertions are normally used to assert on timings of responses. Checks: Checking status and JSON data: 123http( name ). get( /path )  . check(status. is(200))  . check(jsonPath( $. name ). is( some name ))Saving response data to Gatling session 123456http( name ). get( /path )  . check(header( location ). saveAs( newLocation ))  . check(jsonPath( $. name ). saveAs( name ))  // You can now use $newLocation and $name in your requests :  http( get home ). get( /users/${name} )Assertions: 1234setUp(scn). assertions(   global. responseTime. mean. lt(50), // mean resp time &lt; 50 ms    forAll. failedRequests. percent. gt(5) // for each request, &lt; 5% failure)Feeders: Basic usage: 12345678910111213141516171819202122232425val feeder1 = Array(   Map( foo  -&gt;  foo1 ,  bar  -&gt;  bar1 ),   Map( foo  -&gt;  foo2 ,  bar  -&gt;  bar2 ),   Map( foo  -&gt;  foo3 ,  bar  -&gt;  bar3 ))// repeating the values val feeder1a = feeder1. circularval feeder1b = feeder1. random// infinite entries with keys  value1 ,  value2 val feeder2 = Iterator. continually(Map( value1  -&gt; 100,  value2  -&gt;  toto ))// infinite random entries val feeder3 = Iterator. continually(Map(   value1  -&gt; Random. nextInt(100),   value2  -&gt; Random. alphanumeric. take(4)))// using the feeder to build the URLsscenario( scenario name )  . feed(feeder)  . exec(http( request name )  . get( /path/${value1} ))Advanced usage: 123456789// reading a csv file to build a feederval feeder = csv( data. csv )// the csv file must have a header row which defines the keys and be comma (,) separated// filling a template file with the content of a feederscn. feed(feeder). exec(  http( request name )  . post( https://www. example. com )  . body(ElFileBody( filename. xml )). asXML))"
    }, {
    "id": 44,
    "url": "localhost:4000/software-testing-and-different-thinking-types/",
    "title": "Software Testing and Different Thinking Types",
    "body": "2018/12/11 - When it comes to Software Testing, the human brain is the best testing tool. When we test software, we process information, solve problems, make decisions and create new ideas. As testers, we should be aware of the different thinking types so that we can relate them to different situations. For example, when we look at a design diagram, we need to be analytical. When we think of scenarios, we need to think in an abstract way. Different testing activities require different thought processes. For this reason, it is important to be able to “switch on” the different thinking modes for each activity. Types of thinking covered in this post are:  Thinking Types in the Context of Software Testing     Creative or Lateral Thinking   Analytical Thinking   Critical Thinking   Concrete Thinking   Abstract Thinking   Divergent Thinking   Convergent Thinking   Sequential Thinking   Holistic Thinking   In Summary:   Thinking Types in the Context of Software Testing: Let’s examine the different thinking types and how each can be applied in the context of Software Testing and various testing activities. Creative or Lateral Thinking: Creative thinking means looking at something in a new way. It is the very definition of “thinking outside the box. ” In creative thinking, we break away from established theories, rules and procedures and do things in a new and imaginative way. In the context of testing, for example, this could be when we apply new test techniques, e. g. pairwise test technique to reduce the number of permutations yet increase coverage. Analytical Thinking: Analytical thinking refers to the ability to separate a whole into its basic parts in order to examine the parts and their relationships. It involves thinking in a logical, step-by-step manner to break down a larger system of information into its parts. For instance when we look at architectural diagrams and try to figure out the path through the system and individual components. A good example is when we analyze what happens when a user submits a form and the request is sent to an API which communicates with a Database. Critical Thinking: Critical thinking is the ability to reason by carefully analyzing something in order to determine its validity or accuracy. It is about being an active learner rather than a passive recipient of information. Critical thinking is possibly the most important type of thinking in the context of testing. As testers, we should always question ideas and assumptions rather than accept them at face value. For example, when looking at a user story, we could be asking questions about the acceptance criteria rather than accepting them as they are given to us. Concrete Thinking: Concrete thinking refers to the ability to comprehend and apply factual knowledge. It is the opposite of abstract thinking. People who think concretely like to follow instructions and have detailed plans. They hate anything that is fuzzy or ambiguous. As such concrete thinkers prefer to work with lists and spreadsheets. In the context of testing, this is when testers demand that all instructions should exist before starting to test. E. g. some testers won’t start testing until all acceptance criteria are defined in a user story. Abstract Thinking: Opposite of concrete thinking, abstract thinking refers to the ability to think about things that are not actually present. Software testers who think in an abstract way look at the broader significance of ideas and information rather than the concrete details. For example in the context of testing and story grooming sessions, testers with the ability to think in an abstract way can come up with interesting test scenarios. Rather than just reading the acceptance criteria, testers will look at a user story and try to figure out how this could relate to or impact other parts of the system. Divergent Thinking: Divergent Thinking refers to the ability to generate creative ideas by exploring many possible solutions in an effort to find one that works. It involves bringing facts and data together from various sources and then applying logic and knowledge to make decisions. When doing exploratory testing, we apply oracles and heuristics and make judgments based on our previous experiences. Convergent Thinking: Convergent thinking is the ability to put a number of different pieces or perspectives of a topic together in some organized, logical manner to find a single answer. For example, when we try to find a root cause of a defect, we gather relevant information and extract necessary data. Sequential Thinking: Sequential (linear) thinking refers to the ability to process information in an orderly prescribed manner. It involves a step-by-step progression where a response to a step must be obtained before another step is taken. In the context of software testing, this correlates to when we follow a script with predefined steps and expected results. Holistic Thinking: Holistic (nonlinear) thinking is the ability to see the big picture and recognize how the components form the larger system. It involves expanding your thought process in multiple directions, rather than in just one direction. In the context of testing, this is when we perform integration or system testing. In Summary:: Software testing requires deep thinking. It is a process of constantly asking questions and analyzing the information we receive. Different test activities require different thinking processes. Understanding the different thinking types will help in asking the right questions. When interviewing testers, we should be asking scenario based questions which exercise the tester’s thinking ability in terms of the above thinking types. "
    }, {
    "id": 45,
    "url": "localhost:4000/soak-testing-gatling-example/",
    "title": "Soak Testing With Gatling Example",
    "body": "2018/11/29 - How to perform Soak Testing with Gatling? Soak Testing involves running one or more scenarios for a long duration, e. g. 24 hours, to find memory leaks in an application. Some applications, when subjected to a constant load for a long time, could exhibit performance degradation. This is usually due to consuming too much memory and over a long period, the application could crash. Gatling tool provides a number of ways we can configure scenarios to run for long durations to simulate soak testing. The Loop feature within Gatling has the following methods:  repeat during asLongAs foreach doWhile asLongAsDuring doWhileDuring foreverIn this tutorial, we will look at how to use the during method to perform a soak test with Gatling. Soak Testing With Gatling: Previously, we discussed the best way to organize and structure a Gatling project. In this example, we will modify the CreateUserScenario object to introduce a duration of 12 hours. 123456789101112import com. amido. gatling. demo. requests. {CreateUserRequest, GetTokenRequest}import io. gatling. core. Predef. _import scala. concurrent. duration. _object CreateUserScenario {  val createUserScenario = scenario( Create User Scenario Soak Test )  . during(12 hours,  Soak Test ) {    exec(GetTokenRequest. get_token)    . exec(CreateUserRequest. create_user)  }}We can then use the above scenario in our Simulation class. You can even parameterize the duration of the soak test. Further Reading:  Performance Testing Framework with Gatling and Maven How to Parameterize Gatling Variables Gatling - How to Save Response Body Gatling Quick Reference: Usage of Common Gatling Functions"
    }, {
    "id": 46,
    "url": "localhost:4000/sdet-hiring-software-developers-in-test/",
    "title": "SDET Unicorns - Why is it so Hard to Hire SDETs?",
    "body": "2018/11/22 - SDET, also known as Software Development Engineer in Test, is a job role within Software Testing and Quality Assurance Domain.  The term was originally used by Microsoft and then Google with a view of replacing mundane and repetitive manual testing task with automation. Over the years, more and more companies are hiring SDETs as it’s a pivotal role in Agile and DevOps. However, it’s a challenging role to fill. Technology changes very quickly and testers need to learn a lot to stay ahead of the game. In my previous post, Testing in a DevOps World, I explained how the role of a tester has changed in the last decade, hence creating the shortage of test unicorns. This post talks about the role of an SDET and why unicorn SDETs are difficult to find. What Does an SDET do?: An SDET is a technical software tester with a focus on developing automated test scripts. Typically, they are part of an agile team and work alongside developers to help automate Acceptance Criteria in user stories. As well as participating in typical QA activities, they can write anything from automated integration tests, API tests and/or UI automation tests. In addition, SDETs could help review unit tests which are written by the developers. Why SDETs are Needed?: In every product, there are some core features which must be functioning on every release of the product. This means that in every sprint, new features plus existing functionality must be tested. Agile development is fast-paced. With short sprints, which are typically 2-weeks long, testers don’t have the time to test everything manually. When testers in a team don’t have the required skills to write automated checks, all testing has to be done manually. Ultimately, testing becomes a bottleneck to the development and release of software because it will take longer and longer to complete. Therefore, hiring and placing SDETs in an agile team can alleviate the burdens by automating much of the manual tests and tasks. Interviewing and Hiring SDETs: So, why is it so hard to find and recruit good SDETs? Over the years, the majority of so-called SDETs that I have interviewed either lack the required technical skills or have no comprehension of QA and testing principles. They don’t fully understand the main reason for the role of SDET in a team. Most come across with the assumption that all they’re required to do is to automate acceptance criteria. Let’s be clear, an SDET is NOT an automation engineer. Having the right balance of testing aptitude and technical skills is the key thing. A great SDET is a software tester by trade, is passionate about software quality and at the same time is tech-savvy and has the right mix of technical skills. When interviewing for SDETs, I always look for QA Mindset and Technical Skills. SDET Profile - Full-stack Testers: What does the profile of a great SDET look like? What skills should SDETs have? Now, some of us have heard of full-stack developers, but can we have full-stack testers? In my opinion, an SDET should have at least the following skills and attributes:  Has a tester mindset, is curious and can come up with interesting test scenarios Has a solid understanding of testing principles and methodologies Knows that all testing is exploratory in nature and appreciates the difference between testing and checking.  Can apply appropriate test methods for a given scenario knows the difference between testing and QA Can code in at least one scripting or programming language (Java and Javascript happen to be the most popular) Understands HTTP and how modern web applications are built Can write UI as well as API automated tests. One or the other is not good enough! Knows Git, Pull Requests, Branching, etc… Is agile in nature and knows how testing fits in the agile model Can write performance test scripts (Gatling and/or JMeter) Thinks about security and is aware of OWASP Understands CI/CD and Build pipelines Knows the services offered by cloud platform providers such as AWS, Azure and Google CloudBecoming a great SDET: As can be seen, the range of skills expected of an SDET is quite broad. My advice to testers who want to become SDETs and remain relevant in the new age of QA is: Ensure you work towards having all of the above skills in the SDET profile_, but as a minimum:_ Know and understand the fundamentals of testing: First and foremost, know the foundations of software testing. It is all too well to be on par with developers and able to write beautiful code. But if you lack the QA mindset, if you can’t come up with enough scenarios to test user stories and features in depth, then you’re not adding any value. You might as well work harder and become a developer. Know and understand HTTP: Most modern web applications interact with APIs. It is essential to know and understand HTTP architecture and how the web works. If you can’t differentiate between a POST request and a GET request or don’t know how to parse JSON, then how can you effectively test an API? Invest time in learning API testing tools such as Karate. You can’t call yourself an SDET if all you want to do is automate tests and all you know is Java and Selenium and God forbid Cucumber! Further Reading: Problems with Test Automation and Modern QA "
    }, {
    "id": 47,
    "url": "localhost:4000/top-10-open-source-performance-testing-tools/",
    "title": "Top 10 Open Source Performance Testing Tools",
    "body": "2018/11/19 - Performance testing is becoming an integral part of the development process, so it is essential to know what tools are out there.  This post contains a list of top 10 open source performance testing tools. Open Source Performance Testing Tools: JMeter: The Apache JMeter application is open source software. It is a pure Java application designed to load test an application and measure its performance.  Read More » Gatling: Gatling is a highly capable load testing tool. It is designed for ease of use, maintainability and high performance.  Read More » Locust: Locust is an easy-to-use, distributed, user load testing tool. It is intended for load-testing websites (or other systems) and figuring out how many concurrent users a system can handle.  Read More » Tsung: Tsung is an open-source multi-protocol distributed load testing tool. It can be used to stress HTTP, WebDAV, SOAP, PostgreSQL, MySQL, LDAP, MQTT, and Jabber/XMPP servers.  Read More » Siege: Siege is an HTTP load testing and benchmarking utility. Siege supports basic authentication, cookies, HTTP, HTTPS and FTP protocols. It lets its user hit a server with a configurable number of simulated clients.  Read More » Httperf: Httperf is a tool for measuring web server performance. It provides a flexible facility for generating various HTTP workloads and for measuring server performance.  Read More » Taurus: Although not specifically related to Perf testing, Taurus provides an automation-friendly framework for continuous testing, including functional and performance.  Read More » Artillery: Artillery is a modern, powerful &amp; easy-to-use load testing and functional testing toolkit. Use it to ship scalable applications that stay performant &amp; resilient under high load.  Read More » Goad: Goad takes full advantage of the power of Amazon Lambdas for distributed load testing. You can use goad to launch HTTP loads from up to four AWS regions at once. Each lambda can handle hundreds of concurrent connections, able to achieve peak loads of up to 100,000 concurrent requests.  Read More » Apache Bench: ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs.  Read More » Further Reading:  Performance Testing Framework with Gatling and Maven How to Install JMeter on Mac OS Jmeter Tutorial: Testing REST Web Services"
    }, {
    "id": 48,
    "url": "localhost:4000/http-status-codes/",
    "title": "HTTP Status Codes With Explanations",
    "body": "2018/11/16 - HTTP Status Codes or Response Codes are grouped into five categories. 1×× Informational, 2×× Success, 3×× Redirection, 4×× Client Error, 5×× Server Error. This post contains the full list of HTTP status codes with a short description of the most common response codes. When we do API testing, usually the first thing that we check on the response from an API call is the status code. It is essential that we are familiar with at least the most common status codes so we can identify issues quicker. 1×× Informational: The 1xx (Informational) class of status code indicates an interim response for communicating connection status or request progress prior to completing the requested action and sending a final response.  100 Continue 101 Switching Protocols 102 Processing2×× Success: The 2xx (Successful) class of status code indicates that the client’s request was successfully received, understood, and accepted. Most Common 2×× Success HTTP Status Codes 200 OK: The 200 (OK) status code indicates that the request has succeeded. The payload sent in a 200 response depends on the request method. 201 Created: The 201 (Created) status code indicates that the request has been fulfilled and has resulted in one or more new resources being created. 204 No Content: The 204 (No Content) status code indicates that the server has successfully fulfilled the request and that there is no additional content to send in the response payload body. Other 2××  202 Accepted 203 Non-authoritative Information 205 Reset Content 206 Partial Content 207 Multi-Status 208 Already Reported 226 IM Used3×× Redirection: The 3xx (Redirection) class of status code indicates that further action needs to be taken by the user agent in order to fulfill the request. Most Common 3×× Redirection HTTP Status Codes 301 Moved Permanently: The 301 (Moved Permanently) status code indicates that the target resource has been assigned a new permanent URI and any future references to this resource ought to use one of the enclosed URIs. 302 Found: The 302 (Found) status code indicates that the target resource resides temporarily under a different URI. Other 3××  304 Not Modified 300 Multiple Choices 303 See Other 305 Use Proxy 307 Temporary Redirect 308 Permanent Redirect4×× Client Error: The 4xx (Client Error) class of status code indicates that the client seems to have erred. Most Common 4×× Client Error HTTP Status Codes 400 Bad Request: The 400 (Bad Request) status code indicates that the server cannot or will not process the request due to something that is perceived to be a client error (e. g. , malformed request syntax). 401 Unauthorized: The 401 (Unauthorized) status code indicates that the request has not been applied because it lacks valid authentication credentials for the target resource. 403 Forbidden: The 403 (Forbidden) status code indicates that the server understood the request but refuses to authorize it. 404 Not Found: The 404 (Not Found) status code indicates that the origin server did not find a current representation for the target resource or is not willing to disclose that one exists. 405 Method Not Allowed: The 405 (Method Not Allowed) status code indicates that the method received in the request-line is known by the origin server but not supported by the target resource. 415 Unsupported Media Type: The 415 (Unsupported Media Type) status code indicates that the origin server is refusing to service the request because the payload is in a format not supported by this method on the target resource. The format problem might be due to the request’s indicated Content-Type or Content-Encoding, or as a result of inspecting the data directly. Other 4××  402 Payment Required 406 Not Acceptable 407 Proxy Authentication Required 408 Request Timeout 409 Conflict 410 Gone 411 Length Required 412 Precondition Failed 413 Payload Too Large 414 Request-URI Too Long 416 Requested Range Not Satisfiable 417 Expectation Failed 418 I’m a teapot 421 Misdirected Request 422 Unprocessable Entity 423 Locked 424 Failed Dependency 426 Upgrade Required 428 Precondition Required 429 Too Many Requests 431 Request Header Fields Too Large 444 Connection Closed Without Response 451 Unavailable For Legal Reasons 499 Client Closed Request5×× Server Error: The 5xx (Server Error) class of status code indicates that the server is aware that it has erred or is incapable of performing the requested method. Most Common 5×× Server Errors HTTP Status Codes 500 Internal Server Error: The 500 (Internal Server Error) status code indicates that the server encountered an unexpected condition that prevented it from fulfilling the request. 502 Bad Gateway: The 502 (Bad Gateway) status code indicates that the server while acting as a gateway or proxy, received an invalid response from an inbound server it accessed while attempting to fulfill the request. 503 Service Unavailable: The 503 (Service Unavailable) status code indicates that the server is currently unable to handle the request due to a temporary overload or scheduled maintenance, which will likely be alleviated after some delay. 504 Gateway Timeout: The 504 (Gateway Timeout) status code indicates that the server while acting as a gateway or proxy, did not receive a timely response from an upstream server it needed to access in order to complete the request. Other 5××  501 Not Implemented 505 HTTP Version Not Supported 506 Variant Also Negotiates 507 Insufficient Storage 508 Loop Detected 510 Not Extended 511 Network Authentication Required 599 Network Connect Timeout ErrorRelated:  HTTP Basics for Software Testers Difference Between PUT and PATCH Requests How to get Response Status Code with Selenium WebDriverReference: Internet Engineering Task Force "
    }, {
    "id": 49,
    "url": "localhost:4000/gatling-save-response-body/",
    "title": "Gatling - How to Save Response Body",
    "body": "2018/11/15 - How to save response body in Gatling? When we do API performance testing, we may need to build a chain of requests. For example, we make a call to an API, save the response and pass the response to another API call. This is called request-response chaining and is a common activity when testing APIs. Gatling provides a way of saving the whole response or part of a response. The examples below illustrate how to save response data in Gatling. Gatling Save Response Body: Save the Whole Response Body: 12345val authRequest = exec(http( Auth Request )  . post(base_url +  /login/auth )  . body(ElFileBody( payload. json ))  . check(bodyString. saveAs( Auth_Response ))  . check(status is 200))We save the full response of the above API call in a variable called Auth_Response. Then we can use that variable, which contains the response, to pass as a body or payload to another request, such as: 123456val validateRequest = exec(http( Validate Request )  . post(base_url +  /login/validate )  . body(StringBody( ${Auth_Response} ))  . check(bodyString. saveAs( Validate_Response ))  . check(status is 200))Extract Element From Response Body and Save: In Gatling, we can also parse a response, for example with JsonPath, extract a value and save it as a variable. Like above, we can then pass that variable in the next API call. 1234567val loginRequest: HttpRequestBuilder = http( Login Request )  . post(base_url +  /login )  . header(ContentType, ApplicationJson)  . header(Accept, ApplicationJson)  . body(StringBody(  ))  . check(status is 200)  . check(jsonPath( $. tokenId ). saveAs( tokenId ))In the above request, we parse the JSON Response and extract the value for the parameter tokenId and save its value as tokenId. We can then reference the variable using ${tokenId} Further Reading:  Create Gatling Maven Project From Scratch How to Parameterize Gatling Variables Send Random Post Request in Gatling Soak Testing with Gatling"
    }, {
    "id": 50,
    "url": "localhost:4000/convert-string-to-int-java-examples/",
    "title": "Convert String to Int in Java With Examples",
    "body": "2018/11/15 - How to convert a String to an Int in Java? If the String contains only numbers, then the best way to convert the String to Int is by using Integer. parseInt() or Integer. valueOf(). If the String contains both numbers and characters, then we have to use regular expressions to extract numbers from the string and then convert the resulting String it to Int. One thing to note is that parseInt(String) returns a primitive int, whereas valueOf(String) returns an Integer() object. Convert String to Int in Java: Using Integer. parseInt(): 1234567891011121314package com. testingexcellence. tutorials;public class ConvertStringToInt {  public static void main(String[] args) {    String stringNumber =  1234 ;    int number = convertStringToInt(stringNumber);    System. out. println(number);  }  private static int convertStringToInt(String number) {    return Integer. parseInt(number);  }}Output: 11234Using Integer. valueOf(): 1234567891011121314package com. testingexcellence. tutorials;public class ConvertStringToInt {  public static void main(String[] args) {    String stringNumber =  1234 ;    int number = convertStringToInt(stringNumber);    System. out. println(number);  }  private static int convertStringToInt(String number) {    return Integer. valueOf(number);  }}Output: 11234It is important to note that if the String contains characters and numbers such as “1234abcd” then the Integer parser throws NumberFormatException as stated in Javadoc. Using Integer. decode(): We can also use Integer. decode(). An interesting feature of decode is that it can convert to other bases, such as base 10, base 16, etc… 1234567891011121314package com. testingexcellence. tutorials;public class ConvertStringToInt {  public static void main(String[] args) {    String stringNumber =  1234 ;    int number = convertStringToInt(stringNumber);    System. out. println(number);  }  private static int convertStringToInt(String number) {    return Integer. decode(number);  }}Output: 11234Apache Commons NumberUtils Class: Last but not least, we can use Apache Commons NumberUtils class to convert String to Int in Java. All you need to do is to have the following dependency in your pom. xml file 12345&lt;dependency&gt;  &lt;groupId&gt;commons-lang&lt;/groupId&gt;  &lt;artifactId&gt;commons-lang&lt;/artifactId&gt;  &lt;version&gt;2. 6&lt;/version&gt;&lt;/dependency&gt;Then, you can use: 12345678910111213141516package com. testingexcellence. tutorials;import org. apache. commons. lang. math. NumberUtils;public class ConvertStringToInt {  public static void main(String[] args) {    String stringNumber =  1234 ;    int number = convertStringToInt(stringNumber);    System. out. println(number);  }  private static int convertStringToInt(String number) {    return NumberUtils. toInt(number);  }}Output: 11234"
    }, {
    "id": 51,
    "url": "localhost:4000/extract-numbers-string-java-regular-expressions/",
    "title": "Extract Numbers From String Using Java Regular Expressions",
    "body": "2018/11/14 - The following are examples which show how to extract numbers from a string using regular expressions in Java. Being able to parse strings and extract information from it is a key skill that every tester should have. This is particularly useful when testing APIs and you need to parse a JSON or XML response. The following Java Regular Expression examples focus on extracting numbers or digits from a String. Extract All Numbers from a String: 1234567891011121314package com. testingexcellence. tutorials;import java. util. regex. Matcher;import java. util. regex. Pattern;public class RegexExamples {  public static void main(String[]args) {    Pattern p = Pattern. compile( \\d+ );    Matcher m = p. matcher( string1234more567string890 );    while(m. find()) {      System. out. println(m. group());    }  }}Output: 1231234567890Extract nth Digit from a String: If you want to extract only certain numbers from a string you can provide an index to the group() function. For example, if we wanted to only extract the second set of digits from the string string1234more567string890, i. e.  567 then we can use: 1234567891011121314151617package com. testingexcellence. tutorials;import java. util. regex. Matcher;import java. util. regex. Pattern;public class RegexExamples {  private static final Pattern p = Pattern. compile( [^\\d]*[\\d]+[^\\d]+([\\d]+) );  public static void main(String[] args) {    // create matcher for pattern p and given string    Matcher m = p. matcher( string1234more567string890 );    // if an occurrence if a pattern was found in a given string. . .     if (m. find()) {      System. out. println(m. group(1)); // second matched digits    }  }}Output: 1567Explanation of the Pattern [^\d]*[\d]+[^\d]+([\d]+)  ignore any non-digit ignore any digit (first number) again ignore any non-digit capture the second numberExtract Number from a Tag Attribute: When dealing with XML or HTML tags, sometimes there is a need to extract a value from an attribute. For example, consider the following tag &lt;result name= response  numFound= 9999  start= 0 &gt; To extract number 9999 we can use the following code: 123456789101112131415package com. testingexcellence. tutorials;import java. util. regex. Matcher;import java. util. regex. Pattern;public class RegexExamples {  public static void main(String[]args) {    Pattern pattern = Pattern. compile( numFound=\ ([0-9]+)\  );    Matcher matcher = pattern. matcher(  );    if (matcher. find()) {      System. out. println(matcher. group(1));    }  }}Output: 19999Extract a String Containing digits and Characters: You can use Java regular expressions to extract a part of a String which contains digits and characters. Suppose we have this string Sample_data = YOUR SET ADDRESS IS 6B1BC0 TEXT and we want to extract 6B1BC0 which is 6 characters long, we can use: 1234567891011121314package com. testingexcellence. tutorials;import java. util. regex. Matcher;import java. util. regex. Pattern;public class RegexExamples {  public static void main (String[] args) {    Pattern p = Pattern. compile( YOUR SET ADDRESS IS\\s+([A-Z0-9]{6}) );    Matcher n = p. matcher( YOUR SET ADDRESS IS 6B1BC0 TEXT );    if (n. find()) {      System. out. println(n. group(1)); // Prints 123456    }  }}Output: 16B1BC0Extract Key-Value Pairs With Regular Expressions: Let’s suppose we have a string of this formatbookname=testing&amp;bookid=123456&amp;bookprice=123. 45and we want to extract the key-value pair bookid=123456 we would use: 123456789101112131415package com. testingexcellence. tutorials;import java. util. regex. Matcher;import java. util. regex. Pattern;public class RegexExamples {  public static void main(String[] args) {    String s =  bookname=cooking&amp;bookid=123456&amp;bookprice=123. 45 ;    Pattern p = Pattern. compile( (?&lt;=bookid=)\\d+ );    Matcher m = p. matcher(s);    if (m. find()) {      System. out. println(m. group());    }  }}Output: 1123456"
    }, {
    "id": 52,
    "url": "localhost:4000/java-loop-arraylist/",
    "title": "How to Loop Over ArrayList in Java",
    "body": "2018/11/10 - Looping over an ArrayList in Java. In this tutorial, we look at five different ways we can iterate through an ArrayList in Java. As of Java 8, we can use the forEach method as well as the iterator class to loop over an ArrayList. Looping over an ArrayList: There are primarily 5 different ways to loop over an ArrayList  Classic For Loop Advanced For Loop Iterator While Loop ForEach (Java 8)First, let’s create an ArrayList to use in the loop examples: 12345678910111213141516package com. testingexcellence. tutorials;import java. util. ArrayList;import java. util. List;public class LoopOverArrayExamples {  private List fruitBasket = new ArrayList&lt;&gt;(0);  public void addFruitsToBasket() {    fruitBasket. add( Apple );    fruitBasket. add( Banana );    fruitBasket. add( Pear );    fruitBasket. add( Mango );  }}Using Classic For Loop: 123for (int i=0; i&lt;fruitBasket. size(); i++) {  System. out. println(fruitBasket. get(i));}Advanced For Loop: 123for(String fruit : fruitBasket) {  System. out. println(fruit);}Using Iterator: 1234Iterator fruitIterator = fruitBasket. iterator();while (fruitIterator. hasNext()) {  System. out. println(fruitIterator. next());}Using While Loop: 12345int i = 0;while (i &lt; fruitBasket. size()) {  System. out. println(fruitBasket. get(i));  i++;}ForEach (Java 8): 123fruitBasket. forEach( (fruit) -&gt;  System. out. println(fruit));"
    }, {
    "id": 53,
    "url": "localhost:4000/git-cheat-sheet-for-testers/",
    "title": "Git Commands Every Tester Should Know",
    "body": "2018/11/02 - This post is a Git Cheat Sheet with the most common Git commands you will likely use on a daily basis. If you are a technical tester working alongside developers, you should be familiar with the basic Git commands. This post contains enough Git knowledge to get you going on a day to day basis as a QA. If you haven’t got Git installed on your machine, you can follow the steps in How to Install Git on Mac and Generate SSH Keys. Initial Git Setup: Initialize a repo: Create an empty git repo or re-initialize an existing one 1$ git initClone a repo: Clone the foo repo into a new directory called foo: 1$ git clone https://github. com/&lt;username&gt;/foo. git fooGit Branch: How to Create a New Branch in Git: When you want to work on a new feature, you typically create a new branch in Git. As such, you generally want to stay off the master branch and work on your own feature branches so that master is always clean and you can create new branches from it. To create a new branch use: 1$ git checkout -b &lt;new_branch_name&gt;How to List Branches in Git: If you want to know what branches are available in your working directory, then use: 1$ git branchExample output 123developmy_featuremasterHow to Switch Branches in Git: When you create a new branch then Git automatically switches to the new branch. If you have multiple branches, then you can easily switch between branches with git checkout: 123$ git checkout master$ git checkout develop$ git checkout my_featureHow to Delete Branches in Git: To delete a local branch: 1$ git branch -d &lt;local_branch&gt;Use the -D option flag to force it. To delete a remote branch on origin: 1$ git push origin :&lt;remote_branch&gt;Git Staging: To stage a file is simply to prepare it for a commit. When you add or modify some files, you need to stage those changes into “the staging area. ” Think of staging as a box where you put things in before shoving it under your bed, where your bed is a repository of boxes you’ve previously have shoved in. Git Stage Files: To stage or simply add files, you need to use git add command. You can stage individual files: 1$ git add foo. jsor all files at once: 1$ git add . Git Unstage Changes: If you want to remove a certain file from the stage: 1$ git reset HEAD foo. jsOr remove all staged files: 1$ git reset HEAD . You can also create an alias for a command and then use it with Git: 12$ git config --global alias. unstage 'reset HEAD'$ git unstage . Git Status: If you want to see what files have been created, modified or deleted, Git status will show you a report. 1$ git statusGit Commits: It is a good practice to commit often. You can always squash down your commits before a push. Before you commit your changes, you need to stage them. The commit command requires a -m option which specifies the commit message. You can commit your changes like: 1$ git commit -m  Updated README Undoing Commits: The following command will undo your most recent commit and put those changes back into staging, so you don’t lose any work: 1$ git reset --soft HEAD~1To completely delete the commit and throw away any changes use: 1$ git reset --hard HEAD~1Squashing Commits: Let’s say you have 4 commits, but you haven’t pushed anything yet and you want to put everything into one commit, then you can use: 1$ git rebase -i HEAD~4The HEAD~4 refers to the last four commits. The -i option opens an interactive text file. You’ll see the word “pick” to the left of each commit. Leave the one at the top alone and replace all the others with “s” for squash, save and close the file. Then another interactive window opens where you can update your commit messages into one new commit message. Git Push: After you have committed your changes, next is to push to a remote repository. First Push: Push a local branch for the first time: 1$ git push --set-upstream origin &lt;branch&gt;After that, then you can just use 1$ git pushPush local branch to different remote branch: To push a local branch to a different remote branch, you can use: 1$ git push origin &lt;local_branch&gt;:&lt;remote_branch&gt;Undo Last Push: If you have to undo your last push, you can use: 1$ git reset --hard HEAD~1 &amp;&amp; git push -f origin masterGit Fetch: When you use git fetch, Git doesn’t merge other commits them with your current branch. This is particularly useful if you need to keep your repository up to date, but are working on something that might break if you update your files. To integrate the commits into your master branch, you use merge. Fetch changes from upstream:: 1$ git fetch upstreamGit Pull: Pulling is just doing a fetch followed by a merge. When you use git pull, Git automatically merges other commits without letting you review them first. If you don’t closely manage your branches, you may run into frequent conflicts. Pull a branch: If you have a branch called my_feature and you want to pull that branch, you can use: 1$ git pull origin/my_featurePull everything: Or, if you want to pull everything and all other branches 1$ git pullGit Merging and Rebasing: When you run git merge, your HEAD branch will generate a new commit, preserving the ancestry of each commit history. The rebase re-writes the changes of one branch onto another without creating a new commit. Merge Master Branch to Feature Branch: 12$ git checkout my_feature$ git merge masterOr with rebase option, you use: 12$ git checkout my_feature$ git rebase masterMerge Feature Branch to Master Branch: 12$ git checkout master$ git merge my_featureGit Stash: Sometimes you make changes on a branch, and you want to switch to another branch, but you don’t want to lose your changes. You can stash your changes. Here’s how you do a stash in Git: 1$ git stashNow, if you want to unstash those changes and bring them back into your working directory use: 1$ git stash pop"
    }, {
    "id": 54,
    "url": "localhost:4000/junit-5-annotations/",
    "title": "JUnit 5 Annotations With Examples",
    "body": "2018/10/25 - This tutorial explains the Junit 5’s most common annotations with examples. JUnit 5 is the next generation of JUnit. The goal is to create an up-to-date foundation for developer-side testing on the JVM. This includes focusing on Java 8 and above, as well as enabling many different styles of testing. You can use both Maven and Gradle. If you are using Maven, you need to add the following dependency to your pom. xml file: 1234567891011121314&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org. junit. jupiter&lt;/groupId&gt;    &lt;artifactId&gt;junit-jupiter-api&lt;/artifactId&gt;    &lt;version&gt;5. 3. 1&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;org. junit. jupiter&lt;/groupId&gt;    &lt;artifactId&gt;junit-jupiter-params&lt;/artifactId&gt;    &lt;version&gt;5. 3. 1&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;@JUnit 5 Annotations: You will notice that in Junit 5, one of the most obvious changes is that test classes and methods do not have to be public anymore. Now, let’s go through the list of most common JUnit 5 Annotations. @Test: This annotation denotes that a method is a test method. Note this annotation does not take any attributes. 12345678910import org. junit. jupiter. api. Test;import static org. junit. jupiter. api. Assertions. assertEquals;class JUnit5Test {      @Test  void helloJUnit5() {    assertEquals(10, 5+5);  }}@ParameterizedTest: Parameterized tests make it possible to run a test multiple times with different arguments. They are declared just like regular @Test methods but use the @ParameterizedTest annotation instead. In addition, you must declare at least one source that will provide the arguments for each invocation and then consume the arguments in the test method. For example, the following example demonstrates a parameterized test that uses the @ValueSource annotation to specify a String array as the source of arguments. Example: 12345678910111213import org. junit. jupiter. params. ParameterizedTest;import org. junit. jupiter. params. provider. ValueSource;import static org. junit. jupiter. api. Assertions. assertTrue;class JUnit5Test {  @ParameterizedTest  @ValueSource(strings = {  cali ,  bali ,  dani  })  void endsWithI(String str) {    assertTrue(str. endsWith( i ));  }}@RepeatedTest: JUnit 5 has the ability to repeat a test a specified number of times simply by annotating a method with @RepeatedTest and specifying the total number of repetitions desired. Each invocation of a repeated test behaves like the execution of a regular @Test method. This is particularly useful in UI testing with Selenium. 1234567891011121314151617181920import org. junit. jupiter. api. DisplayName;import org. junit. jupiter. api. RepeatedTest;import org. junit. jupiter. api. RepetitionInfo;import org. junit. jupiter. api. TestInfo;import static org. junit. jupiter. api. Assertions. assertEquals;class JUnit5Test {    @RepeatedTest(value = 5, name =  {displayName} {currentRepetition}/{totalRepetitions} )  @DisplayName( RepeatingTest )  void customDisplayName(RepetitionInfo repInfo, TestInfo testInfo) {    int i = 3;    System. out. println(testInfo. getDisplayName() +        --&gt;  + repInfo. getCurrentRepetition()    );        assertEquals(repInfo. getCurrentRepetition(), i);  }}: As you can see from the result of the test, when i==3, the test passes, otherwise it fails. @DisplayName: Test classes and test methods can declare custom display names that will be displayed by test runners and test reports. Example: 1234567891011121314151617import org. junit. jupiter. api. DisplayName;import org. junit. jupiter. api. Test;import org. junit. jupiter. api. TestInfo;@DisplayName( DisplayName Demo )class JUnit5Test {  @Test  @DisplayName( Custom test name )  void testWithDisplayName() {  }  @Test  @DisplayName( Print test name )  void printDisplayName(TestInfo testInfo) {    System. out. println(testInfo. getDisplayName());  }}@BeforeEach: The @BeforeEach annotation denotes that the annotated method should be executed before each test method, analogous to JUnit 4’s @Before. Example: 12345678910111213141516171819import org. junit. jupiter. api. *;class JUnit5Test {  @BeforeEach  void init(TestInfo testInfo) {    String callingTest = testInfo. getTestMethod(). get(). getName();    System. out. println(callingTest);  }  @Test  void firstTest() {    System. out. println(1);  }  @Test  void secondTest() {    System. out. println(2);  }}Output 1234firstTest1secondTest2@AfterEach: This annotation denotes that the annotated method should be executed after each test method, analogous to JUnit 4’s @After. For example, if the tests need to reset a property after each test, we can annotate a method with @AfterEach for that task. 12345678910111213141516171819import org. junit. jupiter. api. *;class JUnit5Test {  @Test  void firstTest() {    System. out. println(1);  }  @Test  void secondTest() {    System. out. println(2);  }  @AfterEach  void after(TestInfo testInfo) {    String callingTest = testInfo. getTestMethod(). get(). getName();    System. out. println(callingTest);  }}Output: 12341firstTest2secondTest@BeforeAll: This annotation executes a method before all tests. This is analogous to JUnit 4’s @BeforeClass. The @BeforeAll annotation is typically used to initialize various things for the tests. Example: 123456789101112131415161718import org. junit. jupiter. api. *;class JUnit5Test {  @BeforeAll  static void init() {    System. out. println( Only run once before all tests );  }  @Test  void firstTest() {    System. out. println(1);  }  @Test  void secondTest() {    System. out. println(2);  }}Output: 123Only run once before all tests12@AfterAll: The @AfterAll annotation is used to execute the annotated method, only after all tests have been executed. This is analogous to JUnit 4’s @AfterClass.  We use this annotation to tear down or terminate all processes at the end of all tests. Example: 123456789101112131415161718import org. junit. jupiter. api. *;class JUnit5Test {  @Test  void firstTest() {    System. out. println(1);  }  @Test  void secondTest() {    System. out. println(2);  }  @AfterAll  static void after() {    System. out. println( Only run once after all tests );  }}Output: 12312Only run once after all tests@Tag: We can use this annotation to declare tags for filtering tests, either at the class or method level. The @Tag annotation is useful when we want to create a test pack with selected tests. Example: 12345678910111213141516import org. junit. jupiter. api. Tag;import org. junit. jupiter. api. Test;@Tag( smoke )class JUnit5Test {  @Test  @Tag( login )  void validLoginTest() {  }  @Test  @Tag( search )  void searchTest() {  }}@Disabled: The @Disabled annotation is used to disable or skip tests at class or method level. This is analogous to JUnit 4’s @Ignore. When declared at class level, all @test methods are skipped. When we use @Disabled at the method level, only the annotated method is disabled. Example: @Disabled used to disable a test class: 12345678910import org. junit. jupiter. api. Disabled;import org. junit. jupiter. api. Test;@Disabledclass DisabledClassDemo {  @Test  void testWillBeSkipped() {  }}Example: @Disabled annotation used to disable test method: 1234567891011121314import org. junit. jupiter. api. Disabled;import org. junit. jupiter. api. Test;class DisabledTestsDemo {  @Disabled  @Test  void testWillBeSkipped() {  }  @Test  void testWillBeExecuted() {  }}Further reading: Run All Test Classes in a Package from testng. xml Suite "
    }, {
    "id": 55,
    "url": "localhost:4000/rest-assured-post-request/",
    "title": "How to Submit Form Data With REST-assured Post Request",
    "body": "2018/10/22 - How to send a POST request with REST-assured. HTML Forms use POST request to submit form data and in this tutorial, we use REST-assured to submit a form. A POST request has four elements: URL: This is the location of the resource we submit data to, e. g. www. example. com/login VERB: when submitting data, we use the POST request. HEADERS: these are request headers, such as Accept or Content-Type. BODY: body contains the data which we submit as a post request. For example, when submitting a form, form data are sent in the body of the request. REST-assured POST request: The sample code below shows how to submit form data as a POST request with REST-assured, version 3. 2. 0. 123456&lt;dependency&gt;  &lt;groupId&gt;io. rest-assured&lt;/groupId&gt;  &lt;artifactId&gt;rest-assured&lt;/artifactId&gt;  &lt;version&gt;3. 2. 0&lt;/version&gt;  &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;12345678910111213141516171819import io. restassured. RestAssured;import io. restassured. http. ContentType;import org. junit. Test;import static io. restassured. RestAssured. given;public class restAssuredPostRequest {  @Test  public void submitForm() {    RestAssured. baseURI =  https://www. example. com ;    given(). urlEncodingEnabled(true)      . param( username ,  user@site. com )      . param( password ,  Pas54321 )      . header( Accept , ContentType. JSON. getAcceptHeader())      . post( /login )      . then(). statusCode(200);  }}REST-assured POST JSON Payload: Other than submitting Form data, you can also use REST-assured POST request to send JSON payload to some resource. Here is an example: 1234567891011121314151617181920212223242526import io. restassured. http. ContentType;import io. restassured. response. Response;import static io. restassured. RestAssured. given;public class PostJsonPayload {  private static String payload =  {\n  +      \ description\ : \ Some Description\ ,\n  +      \ id\ : \ Some id\ ,\n  +      \ name\ : \ Some name\ \n  +     } ;  public static Response postJsonPayload() {    return      given()      . contentType(ContentType. JSON)      . body(payload)      . post( /some/resource )      . then()      . statusCode(200)      . extract()      . response();  }}Further Reading:  How to Parse JSON Response with REST-assured HTTP Basics for Software Testers"
    }, {
    "id": 56,
    "url": "localhost:4000/page-object-framework-java-webdriver/",
    "title": "Page Object Model Framework with Java and WebDriver",
    "body": "2018/10/18 - This tutorial is the second part of the Test Automation Framework development. In the first part, we learned how to create the structure of the framework from scratch. In this tutorial, we are going to create the base classes for the framework. If you haven’t read part 1 of this tutorial, please follow the instructions on How to Create a Test Automation Framework from Scratch. Alternatively, you can clone the base framework from my GitHub repo. Once you have followed the instructions on part 1 of this tutorial or cloned the repo, you should have these four Maven modules:  domain - classes that describe the business model framework - core classes that form the framework page-objects - components and locators of each webpage regression-tests - actual test classes that rely on page objectsOur framework will be based on the Page Object Model design pattern. We will also be using the WebDriver’s PageFactory class to initialize WebElements. Selenium Page Object Model: Ok, now that you have created the base structure, let’s start by adding the base classes. BasePage. java: In the framework module, we create a class called BasePage. java. All page object classes will extend the BasePage, thus inheriting all the base methods. Our BasePage class will have a constructor which takes a WebDriver object to initialize a WebDriverWait object. The constructor will also be responsible to initialize WebElements via PageFactory. In addition, we will also have some utility wait methods to handle the various waits such as WaitForElementToAppear. So, the BasePage class will look like: 1234567891011121314151617181920212223242526272829303132333435package rima. framework. core;import org. openqa. selenium. By;import org. openqa. selenium. WebDriver;import org. openqa. selenium. support. PageFactory;import org. openqa. selenium. support. pagefactory. AjaxElementLocatorFactory;import org. openqa. selenium. support. ui. ExpectedConditions;import org. openqa. selenium. support. ui. WebDriverWait;public class BasePage {  private static final int TIMEOUT = 5;  private static final int POLLING = 100;  protected WebDriver driver;  private WebDriverWait wait;  public BasePage(WebDriver driver) {    this. driver = driver;    wait = new WebDriverWait(driver, TIMEOUT, POLLING);    PageFactory. initElements(new AjaxElementLocatorFactory(driver, TIMEOUT), this);  }  protected void waitForElementToAppear(By locator) {    wait. until(ExpectedConditions. visibilityOfElementLocated(locator));  }  protected void waitForElementToDisappear(By locator) {    wait. until(ExpectedConditions. invisibilityOfElementLocated(locator));  }  protected void waitForTextToDisappear(By locator, String text) {    wait. until(ExpectedConditions. not(ExpectedConditions. textToBe(locator, text)));  }}Note that in BasePage class, we don’t initialize the WebDriver object. The initialization is done in BaseTest class. BaseTest. java: BaseTest class holds the methods to initialize and terminate the WebDriver object. Since all the Test classes will extend the BaseTest class, then the initialization is done implicitly. The Test classes will simply get the WebDriver object by calling the getDriver() method. Also, as we are using TestNG, we can use the @BeforeSuite and @AfterSuite annotations, such as: 12345678910111213141516171819202122232425262728293031323334353637383940package rima. framework. core;import io. github. bonigarcia. wdm. ChromeDriverManager;import org. openqa. selenium. WebDriver;import org. openqa. selenium. chrome. ChromeDriver;import org. openqa. selenium. chrome. ChromeOptions;import org. testng. annotations. AfterSuite;import org. testng. annotations. BeforeSuite;public class BaseTest {  private WebDriver driver;  @BeforeSuite  public void beforeSuite() {    System. setProperty( headless ,  false ); // You can set this property elsewhere    String headless = System. getProperty( headless );    ChromeDriverManager. chromedriver();    if( true . equals(headless)) {      ChromeOptions chromeOptions = new ChromeOptions();      chromeOptions. addArguments( --headless );      driver = new ChromeDriver(chromeOptions);    } else {      driver = new ChromeDriver();    }  }  @AfterSuite  public void afterSuite() {    if(null != driver) {      driver. close();      driver. quit();    }  }  public WebDriver getDriver() {    return driver;  }}Adding the Page Objects: Now, in the page-objects module, we create our first Page Object. For this tutorial, I will use the Google homepage. 1234567891011package rima. pageobjects. homepage;import org. openqa. selenium. WebDriver;import rima. framework. core. BasePage;public class GoogleHomepage extends BasePage {  public GoogleHomepage(WebDriver driver) {    super(driver);  }}As you can see, this page object doesn’t do much. It only has a constructor which takes a WebDriver object and passes it on to its superclass constructor. Again, note that none of the page objects nor the BasePage initialize the WebDriver Objects. In Part 3 of this tutorial, we will add the methods to handle the search function of the Google homepage. Adding the Tests: We add the tests in the regression-tests module. We create a test class called GoogleHomepageTests, with one test method which just instantiates our GoogleHomepage page object. For now, it doesn’t do any other action. In Part 3 of this tutorial, I will add the methods to search and verify the results. 12345678910111213package rima. tests. homepage;import org. testng. annotations. Test;import rima. framework. core. BaseTest;import rima. pageobjects. homepage. GoogleHomepage;public class GoogleHomepageTests extends BaseTest {  @Test  public void homepageTests() {    GoogleHomepage googleHomepage = new GoogleHomepage(getDriver());  }}When you run the above test in your IDE, you should see a Google Chrome browser open and close. Stay tuned for Part 3 of this tutorial where I will take the above example further by adding more components to extend the framework. You can get all the above source code from the GitHub repo. Hope you found the above WebDriver Framework tutorial useful. Further Reading:  How to Develop a Test Automation Framework From Scratch? Performance Testing Framework with Gatling and Maven Test Automation Tools for Testing ReactJS Applications"
    }, {
    "id": 57,
    "url": "localhost:4000/convert-list-to-array-in-java/",
    "title": "Convert List to Array in Java",
    "body": "2018/10/17 - Converting between List and Array is a very common operation in Java. The best and easiest way to convert a List into an Array in Java is to use the . toArray() method. Likewise, we can convert back a List to Array using the Arrays. asList() method. The examples below show how to convert List of String and List of Integers to their Array equivalents. Convert List to Array of String: 12345678910111213141516171819package com. testingexcellence. tutorials;import java. util. ArrayList;import java. util. List;public class ConvertArrayListToArray {  public static void main(String[] args) {    List&lt;String&gt; itemList = new ArrayList&lt;String&gt;();    itemList. add( item1 );    itemList. add( item2 );    itemList. add( item3 );    String[] itemsArray = new String[itemList. size()];    itemsArray = itemList. toArray(itemsArray);    for(String s : itemsArray)      System. out. println(s);  }}We can use the same approach to convert List of Integers to Array of Integers, for example: Convert List to Array of Integers: 12345678910111213141516171819package com. testingexcellence. tutorials;import java. util. ArrayList;import java. util. List;public class ConvertArrayListToArray {  public static void main(String[] args) {    List&lt;Integer&gt; intList = new ArrayList&lt;Integer&gt;();    intList. add(10);    intList. add(20);    intList. add(30);    Integer[] intArray = new Integer[intList. size()];    intArray = intList. toArray(intArray);    for(Integer i : intArray)      System. out. println(i);  }}Convert String Array to List: You can also convert an Array back to a List. To do this, we use Arrays. asList().  For example: 12345678910111213141516package com. testingexcellence. tutorials;import java. util. ArrayList;import java. util. Arrays;import java. util. List;public class ConvertArrayToList {  public static void main(String[] args) {    String[] stringArray = { item 1 ,  item 2 ,  item 3 ,  item 4 };    List&lt;String&gt; stringList = new ArrayList(Arrays. asList(stringArray));    for (String listItem : stringList) {      System. out. println(listItem);    }  }}Further Reading  How to Loop Over ArrayList in Java Different Ways to Iterate Through a Map in Java"
    }, {
    "id": 58,
    "url": "localhost:4000/gatling-maven-performance-test-framework/",
    "title": "Performance Testing Framework with Gatling and Maven",
    "body": "2018/10/15 - What is the best way to organize and structure a Gatling project for performance testing? When designing a framework, we should think about maintainability and extendability, thus how we organize the components is very important. In this tutorial, we will show how to create a performance testing framework from scratch using Gatling and maven. Gatling Maven Test Framework: Pre-requisites: For this tutorial you need to have the following installed:  Java 1. 8 Maven 3. 5 IntelliJ with Scala Plugin installedFirst, we create a base project by running the maven Gatling archetype: 1mvn archetype:generate -DarchetypeGroupId=io. gatling. highcharts -DarchetypeArtifactId=gatling-highcharts-maven-archetypeWhen you execute the above command, it will start downloading the dependencies. When prompted, provide values for ‘groupId’, ‘artifactId’, and ‘version’. My setup looks like the following:  When you open the project, you will notice there are some default files and folders. Under the resources, we have bodies this package holds the request payloads. For example, you can have requests templates for various requests. data this package holds the data you need to feed to your tests, such as CSVs. In addition to the above two folders, there are Gatling. conf, logback. xml and recorder. conf files. We won’t be discussing these in this tutorial. The Gatling maven archetype also creates three base Scala object, but we won’t be using them, so go ahead and delete the objects. In addition, we will create four packages, config, requests, scenarios, and simulations: Config Package: In the config package, create a Scala object called Config. This will hold various configurations for our project such as application URLs, default users, etc… 123456789package com. testingexcellence. configobject Config {  val app_url =  http://example-app. com   val users = Integer. getInteger( users , 10). toInt  val rampUp = Integer. getInteger( rampup , 1). toInt  val throughput = Integer. getInteger( throughput , 100). toInt}Requests Package: The requests package holds different operation requests. For example, we could have a request that gets an authorization token. Another request can use the token from the previous request to create a user and so on. These are individual and isolated requests sent to different endpoints. GetTokenRequest 1234567891011package com. testingexcellence. requestsimport io. gatling. core. Predef. _import io. gatling. http. Predef. _import com. testingexcellence. config. Config. app_urlobject GetTokenRequest {  val get_token = http( RequestName ). get(app_url +  /token )  . check(status is 200)  . check(jsonPath( $. . token ). saveAs( token ))}CreateUserRequest 123456789101112131415161718package com. testingexcellence. requestsimport com. testingexcellence. config. Config. app_urlimport io. gatling. core. Predef. _import io. gatling. http. Predef. _object CreateUserRequest {  val sentHeaders = Map( Authorization  -&gt;  bearer ${token} )  val create_user = exec(http( Create User Request )  . post(app_url +  /users )  . headers(sentHeaders)  . formParam( name ,  John )  . formParam( password ,  John5P4ss )  . check(status is 201)  . check(regex( Created ). exists))}Scenarios Package: The scenario package holds the business scenarios. For example, to create a user, we first have to get an auth token and then send the token as a header along with form parameters to create a user. i. e. we use the response of the first request to feed to the second request. This “chaining of requests” is quite common in API testing. CreateUserScenario 12345678910package com. testingexcellence. scenariosimport com. testingexcellence. requests. {CreateUserRequest, GetTokenRequest}import io. gatling. core. Predef. scenarioobject CreateUserScenario {  val createUserScenario = scenario( Create User Scenario )  . exec(GetTokenRequest. get_token)  . exec(CreateUserRequest. create_user)}Simulations Package: Finally, we have the Simulations in the simulations package. You can think of simulations as different load profiles. For example, we can have a normal load simulation or a spike simulation. The simulations need to be Scala classes and they must extend the Gatling Simulation class. 12345678910111213package com. testingexcellence. simulationsimport com. testingexcellence. scenarios. CreateUserScenarioimport io. gatling. core. Predef. Simulationimport io. gatling. core. Predef. _import com. testingexcellence. config. Config. _class CreateUserSimulation extends Simulation {  private val createUserExec = CreateUserScenario. createUserScenario  . inject(atOnceUsers(users))  setUp(createUserExec)}Your project should look like the following: We also need to modify our pom. xml file to be able to pass parameters, such as users and throughput to our performance tests at runtime. pom. xml file: The pom. xml file should look like: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version= 1. 0  encoding= UTF-8 ?&gt;&lt;project xmlns= http://maven. apache. org/POM/4. 0. 0  xmlns:xsi= http://www. w3. org/2001/XMLSchema-instance       xsi:schemaLocation= http://maven. apache. org/POM/4. 0. 0 http://maven. apache. org/xsd/maven-4. 0. 0. xsd &gt;  &lt;modelVersion&gt;4. 0. 0&lt;/modelVersion&gt;  &lt;groupId&gt;testing-excellence&lt;/groupId&gt;  &lt;artifactId&gt;gatling-framework&lt;/artifactId&gt;  &lt;version&gt;1. 0-SNAPSHOT&lt;/version&gt;  &lt;properties&gt;  &lt;maven. compiler. source&gt;1. 8&lt;/maven. compiler. source&gt;  &lt;maven. compiler. target&gt;1. 8&lt;/maven. compiler. target&gt;  &lt;encoding&gt;UTF-8&lt;/encoding&gt;  &lt;gatling. version&gt;2. 3. 0&lt;/gatling. version&gt;  &lt;gatling-plugin. version&gt;2. 2. 4&lt;/gatling-plugin. version&gt;  &lt;typesafe-config. version&gt;1. 3. 2&lt;/typesafe-config. version&gt;  &lt;simulation&gt;CreateUserSimulation&lt;/simulation&gt;  &lt;/properties&gt;  &lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;io. gatling. highcharts&lt;/groupId&gt;    &lt;artifactId&gt;gatling-charts-highcharts&lt;/artifactId&gt;    &lt;version&gt;${gatling. version}&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;com. typesafe&lt;/groupId&gt;    &lt;artifactId&gt;config&lt;/artifactId&gt;    &lt;version&gt;${typesafe-config. version}&lt;/version&gt;  &lt;/dependency&gt;  &lt;/dependencies&gt;  &lt;build&gt;  &lt;plugins&gt;    &lt;plugin&gt;    &lt;groupId&gt;io. gatling&lt;/groupId&gt;    &lt;artifactId&gt;gatling-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;${gatling-plugin. version}&lt;/version&gt;    &lt;configuration&gt;      &lt;simulationClass&gt;com. testingexcellence. simulations. ${simulation}&lt;/simulationClass&gt;      &lt;jvmArgs&gt;      &lt;jvmArg&gt;-Denv=${env}&lt;/jvmArg&gt;      &lt;jvmArg&gt;-Dusers=${users}&lt;/jvmArg&gt;      &lt;jvmArg&gt;-Drampup=${rampup}&lt;/jvmArg&gt;      &lt;jvmArg&gt;-Dduration=${duration}&lt;/jvmArg&gt;      &lt;jvmArg&gt;-Dthroughput=${throughput}&lt;/jvmArg&gt;      &lt;/jvmArgs&gt;      &lt;propagateSystemProperties&gt;true&lt;/propagateSystemProperties&gt;    &lt;/configuration&gt;    &lt;/plugin&gt;  &lt;/plugins&gt;  &lt;/build&gt;&lt;/project&gt;Finally, to execute the simulation class, we run the following command 1mvn clean gatling:execute -Dusers=1The above command will run the CreateUserSimulation with 1 user. Further Reading:  How to Parameterize Gatling Variables Develop a Test Automation Framework From Scratch How to Save Response Data in Gatling"
    }, {
    "id": 59,
    "url": "localhost:4000/problems-test-automation-modern-qa/",
    "title": "Problems with Test Automation and Modern QA",
    "body": "2018/10/12 - What are some common problems with test automation in agile and DevOps? Modern Software Development and QA focus too much on test automation and not enough on exploratory testing. Are we releasing better quality software with more automated tests? I think not! I recently came across a post on a social media network that said  What I see in most testing and QA events today is mostly DevOps, Continuous Integration and Test Automation.  Although that is all very nice, I see a lot of crappy test cases being automated.  I see few bugs reported during integration tests and functional tests although they are all automated.  In UAT the users are finding more and more bugs because the test teams fail to identify them in previous phases.  If we do not teach people how to write good test cases we will end up with fully automated … And my interpretation of … is “crap”. :-) Anyways, let’s see what is really happening in the world of Modern QA and Test Automation. Problems with Modern QA: Most of the “Test Automation” within the agile development is in a dire state. The software industry is pouring in huge sums of money to hire “Test Automation Experts” mostly to gain a sense of confidence that the software they’re building is of high quality. Yet, noticeable bugs and/or other issues are found during UAT or slip through into production environments. So, what’s going on? N. B. By Test Automation, I am mostly referring to UI Test Automation. Automated testing is now at the heart of any modern software development process. Its purpose is to help deliver high-quality software on a repeatable basis, but is it really? Do Testers Still Test?: The truth of the matter is that in most agile teams, testers are not testing anymore. Manual testing has lost its virtue, thanks to development practices and cultures such as agile and DevOps, which have created a divide in the QA space - those who can code and those who can’t. You’d often hear things like, “I’m a 100% automation engineer”, or “80% automation 20% manual”, or even worse, “I hate manual testing”. Shocking! In DevOps, we are led to believe that everything should be automated. There is no place for manual intervention, e. g. manual testing. Nowadays, most testers in an agile team struggle to keep up with the “Test Automation” demand.  There is pressure to automate every story in the sprint, and there is not enough time for thorough exploratory testing. The problem, especially in Agile development, is that QAs take a user story and automate its acceptance criteria. While doing so, their main and only focus is to wrestle with their limited coding skills just to get the test passing. Naturally, this creates a narrow focus when you’re only interested in automating the test and see it passing in the build pipeline. This only proves what was in the acceptance criteria - right or wrong - is working and you tend to forget about the big picture. The Decline in Manual Testing: More and more “traditional testers” are transitioning to “agile testing” by taking some coding lessons and becoming more technical. Don’t get me wrong; this is all good. I believe as testers, we should always strive to learn new and emerging technologies to stay resourceful. We should understand the tech stack if we want to test a system to a high degree of quality. However, the real reason why most manual testers take these initiatives is that there is a common belief that “automated testing” is superior to manual testing and hey, coding is fun, right? Note By manual testing, I am NOT referring to the old school way of following a script and executing the steps. I am referring to the so-called “exploratory testers” - those who do the real testing and are curious to examine the system’s behavior by exercising interesting and thoughtful scenarios. Unfortunately, there seems to be a big decline in the market for exploratory testers. This is quite evident. Just run a couple of search queries for “manual tester” and “automation tester” in any IT job site, and see the result for yourselves. Problems with Test Automation: Now, let’s see why most of the test automation effort is not delivering any value. Common mistakes I see happening repeatedly:  Having a wrong expectation of automated tests Automating tests at the wrong layer, at the wrong time and using wrong tools Automating useless tests Neglecting important areas Missing key scenariosWrong Expectations: A while back I wrote a blog post on why would you want to automate a test? If you haven’t read it, it’s worth a read. The summary of that article is that you automate tests which you want to run on a regular basis. By definition, these are your regression tests which confirm the system is still functioning. However, if automated checks do find a lot of regression issues, I would question the skills of the developers and the development process. UI Automated Tests should not be [held at the expense of] or [compensated] for lousy coding. Wrong Layer, Wrong Tools and Wrong Time: Majority of “Test Automation Engineers” in agile teams, look at a user story and automate it’s acceptance criteria. Most of the time this is done by a combination of Selenium and Cucumber. Modern web applications are now clearly divided between backend and frontend. The backend is mostly composed of a number of REST web services or APIs with easily accessible end-points. The application’s logic can be tested at the API layer. However, most test automation engineers resort to validating functionality at the UI layer which is at best cumbersome. There are testing tools out there, such as Karate and Rest-Assured, that simplify API testing. We should be making use of these tools during development. Sadly, some test automation engineers don’t even know the basics of HTTP, let alone be able to write API test scenarios. As for UI tests automation, Cypress is a great tool. It is more like a TDD tool for the front-end developers. The developers get a very quick feedback on the behavior of the new UI components. Both Karate and Cypress serve as “development test tools”, i. e. tools that guide and support development. Both are lightweight, easy to integrate and can provide confidence in development. We can then use Selenium or repurpose Cypress to design only a handful of scenarios that exercise the system end-to-end. These scenarios form our light-weight regression pack and provide confidence in business continuity. Quite often I hear things like, “we wait until the feature is fully developed and stable, before automating tests”. Any conscious tester knows that the new-feature bugs outnumber regression bugs. There is a higher chance of finding issues with the current developing feature, than a stable feature. If you are going to spend time automating tests, do them in parallel with development when they can provide more value. Automating Useless Tests: Don’t automate every “test” just for the sake of it. Put some thinking process into the game. Study the high-level and low-level architectural diagrams. Ask what can possibly go wrong. Examine the integration points and look for potential failure points. Take a risk-based approach in automation as you would (hopefully) do with your overall testing approach. What is the likelihood of something failing, and what is the impact of the failure? If the answer is high, then those scenarios should be automated and executed on every build. In each sprint, we often end up writing automated tests around user stories for that sprint and forget about integration with other features. There are either weak or no integration tests. Remember automating “tests” takes time. Do also bear in mind that by automating a test, you are not really testing, you’re only merely checking that the feature in question is satisfying some acceptance criteria. You cannot automate testing, but you can automate the checking of known facts. Therefore, every time you spend automating a “test”, think about the time you are wasting by not testing! Neglecting Important Areas: I see more and more of this negligence since the birth of the DevOps culture. In DevOps, the delivery pipeline, along with the deployment scripts are the spine of the software development and delivery, yet they hardly ever get tested. In the past few years, I could easily say, that I have seen a lot more “environmental issues” than functional bugs. Environment issues such as problems with the CI server, the deployment scripts, the test environments, and so on. Environment issues have a serious impact on the development and testing effort. They consume a lot of developer and DevOps time and massively slow down the deployment process, yet there is no consideration for testing and thus preventing these issues. We just accept them as part of the modern software delivery. We spend a lot of effort automating functional behavior and completely disregard the “things” that matter the most. Even worse is having to rely on Selenium tests to indicate if deployments are working or not! Missing Key Scenarios: Scenarios are king! After all, it is the scenarios that reveal bugs. Quite often, a serious issue leaks into production because no one thought about that particular scenario. The number of executed automated tests doesn’t matter. If a scenario was not thought of or tested, sod’s law tells us there is a bug in there. Unfortunately, in most agile development environments, not enough dedication is given to this all important “Scenario Workshop” activity. Problems with the Process: Let’s see how the above problems manifest themselves in a typical development scenario:  Product owner writes user stories with either no or minimum acceptance criteria.  Not enough time dedicated to story refinement sessions to discuss various scenarios for a user story.  Acceptance criteria are interpreted as acceptance tests - Yes, there is a difference between the two! Testers only automate the acceptance criteria in the user stories mostly using Selenium and/or Cucumber.  Automated testing is almost always the responsibility of “automation testers”.  Developers have no idea what is covered in the test packs or don’t even know how to execute the automated tests.  The automated tests are added to an ever-expanding “regression pack” therefore taking longer and longer to run each time.  The UI automated functional tests are integrated into the build pipeline, which is good but…A developer pushes a simple change and has to wait 30 minutes for the automated tests to go green before the new feature or bug fix can be deployed to production. The 30 minutes wait is only if the tests pass the first time. If they fail due to some test or environment issues, it can take longer. As the automated tests are running and the QA is investigating random failures, the developer and/or the product owner have verified the new implementation and are happy to release, but they can’t because the build is not green. After a while, either the build goes green or the management becomes frustrated with the failing tests and makes a decision to release anyway. Then, BOOM, after a few minutes in production, there is a spike in 500 server errors. Infrastructure Failures: The failures seem to show a similar pattern  Failure in integration points.  Failure in communicating with 3rd party apps.  Web services not being “up” and requests to the API endpoints failing.  A wrong configuration on one of the VMs or nodes, thus resulting in intermittent issues. And yet, there is no process in place for checking these issues as part of the development or delivery process. The focus of the test automation engineers is to automate functional tests. There is no focus on performance, security or resiliency. And there is certainly no testing of the infrastructure! Summary:: Time has come to shift our focus from automating functional tests that have little chance of catching functional issues to the more serious and common environmental issues that plague development. Test Automation, if done wrong or with no thought process, is a waste of time and provides no value to anyone. Crappy automated tests can incur huge maintenance costs and impede development. In the end, the only solution is to bin the tests. In the modern software development, most of the effort of the “Test Automation Engineers” is spent battling with automation code and getting the “tests” to work rather than focusing on proper testing and exploring the system. There is literally not enough time to write automation code and perform exploratory testing. We automate story after story and forget about integration tests, forget about the big picture. Often we end up executing tons of automated tests, yet exploratory testing finds the majority of bugs. Then retrospectively, we write an automated test for the bugs that were found by exploratory testing, to catch regression bugs. We should be selective on what to automate and judge our decision based on risk. What can go wrong, what is the likelihood of it going wrong and what will be the impact on the user or the business if it did go wrong? If you are in the business of “Test Automation” then please don’t use Selenium to test the functionality of APIs or UI components. Instead, use Selenium to automate only a handful of useful and business-critical scenarios to provide confidence in business continuity before each release. And lastly, every time you spend automating a “test”, think about the time you are wasting by not testing! Further Reading:  Common myths of test automation Where to start with test automation for an existing website? Test automation strategy for Agile projects Why is it so hard to hire SDETs"
    }, {
    "id": 60,
    "url": "localhost:4000/how-to-parse-json-in-java/",
    "title": "How to Parse JSON in Java",
    "body": "2018/10/10 - JSON stands for JavaScript Object Notation, and it is based on a subset of JavaScript. As a data-exchange format, it is widely used in web programming. Here we show how to parse JSON in Java using the org. json library. A JSON object is an unordered set of key/value pairs. A JSON array is an ordered collection of values. The values themselves could be objects or arrays. We will be parsing this JSON as an example to retrieve values for pageName, pagePic and post_id 12345678910111213141516{   pageInfo : {      pageName :  Homepage ,      logo :  https://www. example. com/logo. jpg   },   posts : [     {        post_id :  0123456789 ,        actor_id :  1001 ,        author_name :  Jane Doe ,        post_title :  How to parse JSON in Java ,        comments : [],        time_of_post :  1234567890      }  ]}Parse JSON Using org. json: To use org. json to parse JSON in Java, you need to add the library as a dependency. This can be fetched from http://mvnrepository. com/artifact/org. json/json 123456789101112131415161718import org. json. JSONArray;import org. json. JSONObject;public class ParseJSON {  static String json =  . . .  ;  public static void main(String[] args) {    JSONObject obj = new JSONObject(json);    String pageName = obj. getJSONObject( pageInfo ). getString( pageName );    System. out. println(pageName);    JSONArray arr = obj. getJSONArray( posts );    for (int i = 0; i &lt; arr. length(); i++) {      String post_id = arr. getJSONObject(i). getString( post_id );      System. out. println(post_id);    }  }}N. B. the . . .  needs to be replaced by the JSON string. This has been omitted from the code above for clarity. First, we need to convert the JSON string into a JSON Object, using JSONObject class. Also, note that “pageInfo” is a JSON Object, so we use the getJSONObject method. Likewise, “posts” is a JSON Array, so we need to use the getJSONArray method. Parse JSON Using Gson: In order to use Gson to parse JSON in Java, you need to add the library as a dependency. You can get the latest version from Maven repository: http://mvnrepository. com/artifact/com. google. code. gson/gson The below example shows how to Parse the above JSON with Gson. 12345678910111213141516171819import com. google. gson. JsonArray;import com. google. gson. JsonObject;import com. google. gson. JsonParser;public class ParseJSON {  static String json =  . . .  ;  public static void main(String[] args) {    JsonObject jsonObject = new JsonParser(). parse(json). getAsJsonObject();    String pageName = jsonObject. getAsJsonObject( pageInfo ). get( pageName ). getAsString();    System. out. println(pageName);    JsonArray arr = jsonObject. getAsJsonArray( posts );    for (int i = 0; i &lt; arr. size(); i++) {      String post_id = arr. get(i). getAsJsonObject(). get( post_id ). getAsString();      System. out. println(post_id);    }  }}Like the previous example, the . . .  needs to be replaced by the JSON string. Parse JSON Using JsonPATH: The above two examples require a full deserialization of the JSON into a Java object before accessing the value in the property of interest. Another alternative, which does not go this route is to use JsonPATH which is like XPath for JSON and allows traversing of JSON objects. Like before, you need to add JsonPATH as a dependency, which can be fetched from maven repository https://mvnrepository. com/artifact/com. jayway. jsonpath/json-path For example, to parse the above JSON we can use: 12345678910111213141516import com. jayway. jsonpath. JsonPath;public class ParseJSON {  static String json =  . . .  ;  public static void main(String[] args) {    String pageName = JsonPath. read(json,  $. pageInfo. pageName );    System. out. println(pageName);    Integer posts = JsonPath. read(json,  $. posts. length() );    for(int i=0; i &lt; posts; i++) {      String post_id = JsonPath. read(json,  $. posts[  + i +  ]. post_id );      System. out. println(post_id);    }  }}Related:  Purpose of overriding toString() method in Java Different ways to iterate through a map in Java How to get the current working directory in Java"
    }, {
    "id": 61,
    "url": "localhost:4000/jmeter-foreach-controller/",
    "title": "How to Use ForEach Controller in JMeter",
    "body": "2018/10/08 - ForEach Controller in Jmeter iterates through an array of variables. In this JMeter tutorial, we’ll use the ForEach Controller to loop through a JSON Array. There are times when we need to parse a response and extract certain information from it. For example, when testing an API, we could get a JSON response which could contain JSON Arrays. Then, we need to loop through the array and for each element perform an action. In JMeter, we can use the ForEach Controller to iterate through the JSON Array. How to Use JMeter ForEach Controller: In this example, we will be making a GET request to a resource which returns a JSON response.  The response contains an Array of JSON objects.  For each object, we need to extract the URL which we can do via JSONPath. The JSONPath to get all the URL’s in the above response is $. [*]. url.  Once we parse the JSON response and extract the URLs, we then have an array of Strings, basically the URLs. We save this array in a variable called url_array Now suppose that for each element of the String array, we want to make a request to the URL. In JMeter, this is done by using the ForEach Controller. To add the ForEach Controller to your test plan, right click on Thread Group &gt; Add &gt; Logic Controller &gt; ForEach Controller The ForEach Controller requires two parameters:  Input variable prefix Output variable nameThe Input variable prefix takes the name of the array variable, in this example, url_array .  For the Output variable name, we will assign a variable, in this example, url_index which we’re going to use in the subsequent request.  Then, in our subsequent requests, we can extract each value by using ${url_index} This will now loop through each entry in the JSON Array and make the HTTP requests to the URLs. Further Reading  Jmeter Tutorial: Testing REST Web Services How to Install JMeter With Extra Plugins on Mac OS Using HomeBrew How to Send a JSON File as Request in Body JMeter - Pass Variables Between Thread Groups Parsing a JSON Response in JMeter"
    }, {
    "id": 62,
    "url": "localhost:4000/testing-in-devops/",
    "title": "Testing in DevOps World",
    "body": "2018/10/06 - DevOps is an amalgamation of the Development and Operations practices for Software development and Delivery. Testers who are involved in the DevOps delivery model start asking questions like:  Where does testing fit in a DevOps model? How is testing and QA in DevOps different than testing in Agile and waterfall models? As a QA, what additional skills am I expected to know?This post discusses the tools, strategies, and practices we need to implement to test effectively in a DevOps world, embracing automation and continuous testing in DevOps. QA and Testing in DevOps: How has testing evolved from waterfall to agile to DevOps? Waterfall Model: Testing and Quality Assurance practices have seen a considerable shift from the days of the waterfall, Agile and now DevOps. In the waterfall model, testing was seen as a phase in the software development lifecycle. Testers and testing effort were very much siloed where testers used to be part of a testing team and often separate from the development team. Testers owned the testing strategy and were seen as the gatekeepers of quality. Testing was largely manual and used to happen after the software was fully developed and just before releasing to production. Likewise, software used to take a long time to deliver. A separate operations team were responsible for releasing the software to production which, at best, happened every few months. There was no or low level of communication/collaboration between the Ops team and the Dev team. Agile Model: Agile model created a shift in the development and testing space as well as the release frequency. Software was developed iteratively and incrementally. Scrum, which is a methodology in the Agile delivery model, quickly became very popular. https://www. testingexcellence. com/iterative-incremental-development-agile/ Development effort was broken down into a series of short iterations, typically lasting 2-4 weeks. Each iteration would create a potentially shippable software by adding new or enhancing existing features. Testers became part of the development team and testing became a parallel activity to software development, rather than a phase at the end of SDLC. The testing activity became a shared responsibility and quality was owned by the development team. The Agile model fused the development and testing practices and paved the way for a faster delivery of software, however, the actual deployment to production was still done by a separate TechOps team. While TechOps team would have knowledge of servers, networks, and deployment, they were normally oblivious to the details of each release. Feedback to the development team was slow. If a bug existed in the release, it would normally take few hours for the development team to become aware of the issue. DevOps Model: DevOps takes the Agile model a step further by bringing closer the release and deployment activities to those of development and testing. This means that an agile team on its own is responsible for the development, testing and release of the software they create. DevOps Testing Strategy: Testing in DevOps spans the whole software development and delivery lifecycle. Testers are no longer just focusing on functional testing and feature verification. As testers, we should also be involved in operations testing, performance testing, basic security testing, as well as being able to monitor and analyze production data and logs. Dan Ashby has an excellent post about testing in DevOps in which he describes  You can see why people struggle to understand where testing fits in a model that doesn’t mention it at all. For me, testing fits at each and every single point in this model.   Indeed, testing can and should happen at each stage in a DevOps model. In the Agile Test Strategy post, we described how testing fits into the Agile model. DevOps testing strategy can extend that by adding following sections: Test Automation and Continuous Testing in DevOps: Choice of tools and technologies become ever so important in the DevOps model. The choice of tools allows an organization’s ability to deliver applications and services at high velocity. There is a greater emphasis on automated testing in DevOps as we want to create a culture where we can push code down the systems quickly and with confidence. As well as automated functional tests, we should also have a set of performance tests as well as security/resilience tests in the delivery pipeline. Needless to say, before being able to implement any of the above automated tests, first and foremost is building an automated build and delivery pipeline in a Continuous Integration tool, such as Jenkins. Testing in Production: Testing in production doesn’t necessarily mean executing your functional / performance testing scripts against a live system where users are using the application. We can start by analyzing the trends in A/B or multivariant tests. We can also monitor servers for any strange behavior, such as memory leaks, high CPU usage, etc. Impact of DevOps on Testing: How has all of this changed the role of testers and testing in DevOps? Testers are now expected to have at least the following knowledge and skills to be able to effectively carry out testing activities  Basic networking knowledge Basic Unix/Shell scripting, e. g. bash, python Continous Integration/Continuous Delivery e. g. Jenkins, Performance testing tools such as JMeter or Gatling Ready for Operations and Resilience Testing Knowledge of containers, Docker, Kubernetes Querying monitoring tools such as Splunk Clouds services, e. g. AWS, Azure"
    }, {
    "id": 63,
    "url": "localhost:4000/capture-network-traffic-xhr-cypress/",
    "title": "How to Capture Browser Network Traffic (XHR) with Cypress",
    "body": "2018/05/31 - Cypress is a next generation front-end testing tool built for the modern web. Cypress has a lot of nice features to facilitate browser automation. One of those features is the ability to capture network traffic. This post gives an example of how to capture XHR network traffic while submitting a form. Capture Network Traffic (XHR) with Cypress: 1234567891011121314151617181920212223242526describe('Capture browser network traffic', function () { context('Login functionality', () =&gt; {  it('Dscro should be able to login', () =&gt; {   cy. server()   //This is the post call we are interested in capturing   cy. route('POST', 'https://loginservice. example. net/login/json/authenticate'). as('login')   cy. visit('https://example. net/login')   cy. get('#email'). type('tester@gmail. com')   cy. get('#password'). type('Passw0rd1')   cy. get('button[type=submit]'). click()   cy. wait('@login')   //Assert on XHR   cy. get('@login'). then(function (xhr) {    expect(xhr. status). to. eq(200)    expect(xhr. requestHeaders). to. have. property('Content-Type')    expect(xhr. requestHeaders). to. have. property('X-Password', 'Passw0rd1')    expect(xhr. method). to. eq('POST')    expect(xhr. responseBody). to. have. property('tokenId')   })  }) })})"
    }, {
    "id": 64,
    "url": "localhost:4000/karate-api-testing-tool-cheat-sheet/",
    "title": "Karate API Testing Tool Cheat Sheet",
    "body": "2018/05/30 - Karate is an opensource API testing tool developed by Peter Thomas from Intuit.  Karate is built on top of HttpClient and Cucumber and has its own DSL to make API testing very easy. Although been around for almost a year, it has matured very quickly and has all the capabilities expected from an API testing tool. Because Karate sits on top of cucumber, it inherits all the functionalities of cucumber, so you can write your API tests in simple Given When Then format and utilize all the cucumber keywords such as Feature, Scenario Outline, Scenario, Examples, Feature tagging. I’ve created this cheat sheet to help anyone who is involved in testing APIs, giving examples of how to use the Karate tool. Please note, this cheat sheet is just the tip of the iceberg. Karate has many other features that are not mentioned here. This list is just the most common operations typically used when testing APIs. Add the dependencies (pom. xml): 12345678910111213141516171819202122232425262728293031323334&lt;properties&gt;  &lt;project. build. sourceEncoding&gt;UTF-8&lt;/project. build. sourceEncoding&gt;  &lt;maven. compiler. plugin&gt;3. 7. 0&lt;/maven. compiler. plugin&gt;  &lt;maven. compiler. source&gt;1. 8&lt;/maven. compiler. source&gt;  &lt;maven. compiler. target&gt;1. 8&lt;/maven. compiler. target&gt;  &lt;java. version&gt;1. 8&lt;/java. version&gt;  &lt;karate. version&gt;0. 8. 0. RC4&lt;/karate. version&gt;  &lt;cucumber. reporting. version&gt;3. 13. 0&lt;/cucumber. reporting. version&gt;&lt;/properties&gt;&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;com. intuit. karate&lt;/groupId&gt;    &lt;artifactId&gt;karate-core&lt;/artifactId&gt;    &lt;version&gt;${karate. version}&lt;/version&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;com. intuit. karate&lt;/groupId&gt;    &lt;artifactId&gt;karate-apache&lt;/artifactId&gt;    &lt;version&gt;${karate. version}&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;com. intuit. karate&lt;/groupId&gt;    &lt;artifactId&gt;karate-testng&lt;/artifactId&gt;    &lt;version&gt;${karate. version}&lt;/version&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;net. masterthought&lt;/groupId&gt;    &lt;artifactId&gt;cucumber-reporting&lt;/artifactId&gt;    &lt;version&gt;${cucumber. reporting. version}&lt;/version&gt;    &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;Project Structure: You can organize and structure your maven project like this: karate-config. js: This is where you can create variables which have a global scope. Karate reads this file before executing any scenario. This comes in very handy when switching environments which specific variables are used for different environments 1234567891011121314151617181920212223242526272829303132333435363738394041function() { var env = karate. env; // get java system property 'karate. env' karate. log('karate. env selected environment was:', env); karate. configure( ssl , true) if (!env) {  env = 'dev'; //env can be anything: dev, qa, staging, etc.  } var config = {  env: env,  AM_USERNAME: 'devuser',  AM_PASSWORD: 'devpass',  AM_HOST: 'https://am. '+env+'. example. net',  AM_AUTHENTICATE_PATH: '/am/json/realms/root/authenticate',  IDM_USERNAME: 'devuser',  IDM_PASSWORD: 'devpass',  IDM_HOST: 'https://idm. '+env+'. example. net',  IDM_MANAGED_USER_PATH: '/idm/managed/user', }; if(env == 'qa') {  config. AM_USERNAME: 'myUserName'  config. AM_PASSWORD: 'myPa55word' } if(env == 'live') {   config. AM_USERNAME: 'admin'   config. AM_PASSWORD: 'secret' } karate. log('OpenAM Host:', config. AM_HOST); karate. configure('connectTimeout', 60000); karate. configure('readTimeout', 60000); return config;}How to send an HTTP Request (Get, Post, Put, Delete, Patch): 12345678910111213@FRFeature: AM Admin Login Scenario: Login as Admin to AM and get token  Given header X-OpenAM-Username = AM_USERNAME  Given header X-OpenAM-Password = AM_PASSWORD  Given url AM_HOST + AM_AUTHENTICATE_PATH  And request ''  When method POST  Then status 200  * assert response. tokenId != null  * def tokenId = response. tokenIdIn the above example, AM_USERNAME, AM_PASSWORD, AM_HOST, and AM_AUTHENTICATE_PATH come from the karate-config. js file. ‘****’ can be interpreted as any of Given, When, Then, And, but when an action doesn’t serve a context, we can use ‘’. ‘+’ acts as a concatenate operator The above example sends an empty post body request. We can just use ‘ ‘ The method can be any valid HTTP verb (Get, Post, Put, Patch, Delete) ‘def’ is used to store a value in a variable. header, url, request, method, status, response are all karate’s keywords forming the DSL. For the full list of keywords, visit Intuit. In the above example, the response is JSON format, so we can use karate’s builtin JsonPath notation to parse the response. Request Chaining with multiple API calls: 1234567891011121314151617181920212223242526272829303132Feature: request chaining with multiple api callsScenario: chain request demo  * json req = read('classpath:com/example/templates/idm/create-user-template. json')  * def user = req. givenName  Given header X-Username = 'anonymous'  Given header X-Password = 'anonymous'  Given url AM_HOST + '/some/endpoint  And request ''  When method POST  * def authId = response. authId  * def payload1 =       { authId : ${authId} , callbacks :[{ type : NameCallback , output :[{ name : prompt , value : Email Address }], input :[{ name : IDToken0 , value : ${user}@putsbox. com }]}]}       * replace payload1  | token   | value |  | ${authId} | authId |  | ${user}  | user  |  * json mypayload1 = payload1  Given header X-Username = 'anonymous'  Given header X-Password = 'anonymous'  Given url AM_HOST + '/openam/some-other-endpoint  And request mypayload1  When method POSTIn the above example, the first call is made and the authId is parsed from the response and saved in a variable called authId. We then replace the second payload with the authId retrieved in the first call. We then use the new payload to send to the next API call. How to read request templates and call other feature files: We can make our scenarios reusable and call them from other feature files. In this example, we can create a “generic” create-user. feature file where we can send the create user request but with a different request body 1234567891011Feature: Create User in IDM Scenario: Create user in IDM with given guid  Given header X-Requested-With = 'Swagger-UI'  Given header X-OpenIDM-Username = IDM_USERNAME  Given header X-OpenIDM-Password = IDM_PASSWORD  Given url IDM_HOST + IDM_MANAGED_USER_PATH  And request __arg  When method POST  Then status 201Note, in the above example, we are using ‘__arg’ as the post body request. We can then call the above feature file and pass in the required post body, which in turn we can read from a template 123456Feature: Create a user Scenario: Create user in IDM   * json myReq = read('classpath:com/example/templates/idm/idm-create-user-template. json')  * call read('classpath:com/example/idm/idm-create-user. feature') myReqThe above code reads a template which is in location com/example/templates/idm/idm-create-user-template. json and stores it as a JSON variable called myReq Then we can send the JSON variable to the other feature file using the call method. The template looks like 12345678{  mail  :  david@putsbox. com ,  givenName  :  david ,  sn  :  putsbox ,  jobRole  :  developer ,  telephoneNumber  :  91234567890 ,  dob  :  01/02/2010 ,}How to read other feature files - example 2: We can read a specific variable in the called feature file which is passed from a calling feature file 1234567891011Feature: Create User in IDM Scenario: Create user in IDM with given guid  Given header X-Requested-With = 'Swagger-UI'  Given header X-OpenIDM-Username = IDM_USERNAME  Given header X-OpenIDM-Password = IDM_PASSWORD  Given url IDM_HOST + IDM_MANAGED_USER_PATH  And request __arg. emailAddress  When method POST  Then status 201Note, in the above example, we are using ‘__arg. emailAddress’ as the post body request. We are only interested in sending the email address as the request We can then call the above feature file and pass in the required post body, which in turn we can read from a template 1234567Feature: Create a user Scenario: Create user in IDM   * json myReq = read('classpath:com/example/templates/idm/idm-create-user-template. json')  * json emailAddress = '{ emailAddress :  ' +myReq. mail+ ' }'  * call read('classpath:com/example/fr/idm/idm-create-user. feature') emailAddressThe above code extracts the mail field from the JSON template. When we pass a variable to another feature file, it must be of type JSON, so the variable emailAddress must be a valid JSON. Then we can send the JSON variable to the other feature file using the call method and be sending the JSON variable, in this case, emailAddress. Create a Test Runner class: We can execute the scenarios in the feature file using maven (which is useful to run the tests in a CI environment) 1234567891011121314151617181920212223242526272829303132333435363738import com. intuit. karate. cucumber. CucumberRunner;import com. intuit. karate. cucumber. KarateStats;import cucumber. api. CucumberOptions;import net. masterthought. cucumber. Configuration;import net. masterthought. cucumber. ReportBuilder;import org. apache. commons. io. FileUtils;import org. testng. annotations. Test;import java. io. File;import java. util. ArrayList;import java. util. Collection;import java. util. List;import static org. testng. AssertJUnit. assertTrue;@CucumberOptions(tags = { @FR ,  ~@ignore })public class TestRunner_FR {  @Test  public void testParallel() {    String karateOutputPath =  target/cucumber-html-reports ;    KarateStats stats = CucumberRunner. parallel(getClass(), 1, karateOutputPath);    generateReport(karateOutputPath);    assertTrue( there are scenario failures , stats. getFailCount() == 0);  }  private static void generateReport(String karateOutputPath) {    Collection jsonFiles = FileUtils. listFiles(new File(karateOutputPath), new String[] { json }, true);    List jsonPaths = new ArrayList(jsonFiles. size());    for (File file : jsonFiles) {      jsonPaths. add(file. getAbsolutePath());    }    Configuration config = new Configuration(new File( target ),  YOUR PROJECT NAME );    config. addClassifications( Environment , System. getProperty( karate. env ));    ReportBuilder reportBuilder = new ReportBuilder(jsonPaths, config);    reportBuilder. generateReports();  }}The above code runs all the feature files which are tagged as “@FR” but ignores all the tests which are tagged as “@ignore”. It also creates a cucumber report for visualizing the results of the test runs. Run the tests from a command line or CI: 1mvn clean test -DargLine= -Dkarate. env=staging  -Dtest=TestRunner_FRHere, we are running the TestRunner_FR class and setting the environment as staging. Execute JavaScript in the Feature file: In a feature file, we have the capability to execute javascript as well 1234567891011121314Feature: Generate a random session id Scenario: generate random session id  * def random_string =       function(s) {   var text =   ;   var possible =  ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz ;   for (var i = 0; i &lt; s; i++)    text += possible. charAt(Math. floor(Math. random() * possible. length));   return text;  }       * def sessionId = random_string(10)The above code generates a random string of length 10 and saves it in a variable called sessionId. Data Driven Tests: Since Karate sits on top of cucumber, data-driven testing comes as default 123456789101112131415161718Feature: Data driven testing exampleScenario Outline: An 'Invalid input request' error is returned if required parameters have incorrect values.   * def attribute_name = '&lt;name_attribute&gt;'  * xml malformed_request = &lt;method_call&gt;  * json activate_request = malformed_request  * def activate_response = call read('activate. feature') activate_request  * match activate_response. contentType == 'text/xml;charset=ISO-8859-1'  * match activate_response. gas_version == '5. 2. 7'  * match activate_response. error_code == '1000'  Examples:   | name_attribute | method_call                                    |   | auth_method   | Java. type('com. example. StringUtil'). removeNodeByAttribute(xml_req, attribute_name) |   | app_url     | Java. type('com. example. StringUtil'). removeNodeByAttribute(xml_req, attribute_name) |The example above utilizes Cucumber’s Scenario Outline and Examples keywords to create data-driven tests. To read each parameter, we use the angle brackets &lt;&gt; Call Java from a feature file: 123456789101112131415161718package com. example;public class StringUtil {  public static String getNumberFromString(String text) {    return text. replaceAll( \\D+ ,   );  }}Feature: Call java demoScenario: Get number from text  Given url 'https://preview. putsbox. com/p/david/last. json'  When method GET  * def emailText = response. text  * def otpCode = Java. type('com. example. StringUtil'). getNumberFromString(emailText)  * print otpCodeThe above feature file calls a Java method in the class called StringUtil. Then saves the response of that call to otpCode variable. https://www. testingexcellence. com/set-multiple-headers-http-request-karate/ "
    }, {
    "id": 65,
    "url": "localhost:4000/software-testing-interview-questions-answers/",
    "title": "Software Testing Interview Questions and Answers - Ultimate List",
    "body": "2018/04/08 - This post is a large collection of Software Testing Interview Questions and Answers. The list covers foundations of Software Testing, Technical Testing, Test Automation, API Testing, Agile Testing, Web Testing and Selenium WebDriver Interview Questions and Answers. You can click on the links below to read the interview questions and answers for your area of interest.  Selenium WebDriver Software Testing API Testing Agile Testing Test Automation Web TestingSoftware Testing Interview Questions and Answers: In this section, we will look at some common Software Testing Interview Questions that you may be asked when you attend a Software Testing Interview. The answers to these interview questions are for guidance only. You may want to expand on the answers at the interview if you are asked any of these Software Testing Interview Questions. If you are preparing for a Software Testing Interview, or you are interviewing candidates for QA roles, you will find this mind map very useful: 30+ Essential Software Testing Questions to Prepare for Interview What is Exploratory Testing and when should it be performed?: The definition of Exploratory Testing is “simultaneous test design and execution” against an application. This means that the tester uses her domain knowledge and testing experience to predict where and under what conditions the system might behave unexpectedly. As the tester starts exploring the system, new test design ideas are thought of on the fly and executed against the software under test. On an exploratory testing session, the tester executes a chain of actions against the system, each action depends on the result of the previous action, hence the outcome of the result of the actions could influence what the tester does next, therefore the test sessions are not identical. This is in contrast to Scripted Testing where tests are designed beforehand using the requirements or design documents, usually before the system is ready and execute those exact same steps against the system in another time. Exploratory Testing is usually performed as the product is evolving (agile) or as a final check before the software is released. It is a complementary activity to automated regression testing. What Test Techniques are there and what is their purpose?: Test Techniques are primarily used for two purposes: a) To help identify defects, b) To reduce the number of test cases.  Equivalence partitioning is mainly used to reduce the number of test cases by identifying different sets of data that are not the same and only executing one test from each set of data Boundary Value Analysis is used to check the behavior of the system at the boundaries of allowed data.  State Transition Testing is used to validate allowed and disallowed states and transitions from one state to another by various input data Pair-wise or All-Pairs Testing is a very powerful test technique and is mainly used to reduce the number of test cases while increasing the coverage of feature combinations. Why is Testing Necessary?: Testing is necessary in order to identify any defects that are present in software which can cause harm. Without proper testing, we could potentially release a software which could malfunction and cause serious injuries. Examples can be:  Software in a life support machine which can cause serious harm to a patient; Software in a nuclear plant which monitors nuclear activity can cause harm to the environment Banking or financial application which calculates exchange rates can cause financial loss to a businessWhat is the difference between a Bug, Defect, Error, Failure, Fault, and Mistake?: Error and Mistake are the same things.  Bug, Defect, and Fault are the same thing. In general, a human being can make a mistake (error) which produces a defect (bug, fault) in a software application which may cause a failure. Defects occur because human beings are prone to make mistakes, also a software application can be very complex so the integration of different components can cause odd behaviors. How much testing is enough?: There is no definitive answer to this question. Testing is not absolute and has no limits. However, we can use risk metrics (risk-based testing) to identify the likely scenarios that can cause the most harm or the sections of the software that is mostly used so that we focus our time and effort to the sections that are most important. Testing should provide enough information about the status or health of an application, so the stakeholders can make an informed decision on whether to release the software or spend more time on testing. The following questions contain short answers to provide quick hints to some ISTQB Interview Questions. What are the Seven Testing Principles?:  Testing shows the presence of defects Exhaustive testing is impossible Early testing Defect clustering Pesticide Paradox Testing is context dependentRead more on seven principles of testing What is the Fundamental Test Process?:  Test planning and control Test analysis and design Test implementation and execution Evaluating exit criteria and reporting Test closure activitiesRead more about fundamental test process What are the different Test Levels?:  Component Testing Integration Testing System Testing Acceptance TestingWhat are the different black box testing techniques?:  Equivalence Partitioning Boundary Value Analysis Decision Table Testing State Transition Testing Use Case TestingWhat are the different Test Planning activities?:  Determining the scope and objectives of testing Defining the overall approach of testing, defining entry and exit criteria Making decisions about what to test and who will test which part of the application Scheduling test design sessions Assigning resources for different testing activities Deciding which tools to use for testing Reporting on the progress of testing Producing exit reportsWhat information should be included in a defect or bug report?:  A brief summary of the defect A full description of the defect including steps to reproduce Screenshot attachments if required Date the defect was found and raised Who reported the defect Severity and/or Priority of the defect Which component is the defect assignedAgile Testing Interview Questions and Answers: Agile Testing Interview Questions are designed to test your knowledge of agile principles and testing practices. What is Agile Testing and how is it different to the traditional waterfall or the V model?: Agile Testing is testing practice that follows the principles of agile software development. Agile testing involves all members of an agile team with special skills and expertise to ensure business value is delivered at frequent intervals. The big difference is that in an agile environment, testing is not a phase, it is an activity parallel to development. In an agile environment, small features of the software are delivered frequently, so testing activity should be parallel to development activity. Testing time is short as we are only testing small features. In the waterfall model, there is a testing phase at the end of the development so, testing is a big effort done after the whole application is developed. Testing time is long as we have to test the whole application. What is your approach when requirements change continuously?: This question can be asked if you are interviewed for an agile QA position where requirements are likely to change frequently during development. Although a complete change in requirement is possible, most of the time, it is the technical details that are subject to change. e. g. the intent of the requirement or behavior of the feature is the same but implementation details can change Some possible answers can be:  Write generic test plans and test cases which focus on the intent of the requirement rather than its exact details Work very closely with the product owners or business analysts to understand the scope of change so testing can be updated Make sure the team understands the risks involved in changing requirements especially towards the end of the sprint If you’re going to automate this feature, it is best to wait until the feature is stable and requirements are finalized Negotiate to see if the changes can be kept to a minimum and/or implement the changes in next sprintWhat are good characteristics of an Agile Tester / QA?: When attending an Agile Testing Interview, questions can be asked to find out what you really understand from an Agile Tester or Agile QA role and how you will fit with the rest of the team. Some good characteristics of an Agile Tester are:  Good communicator – In agile teams, there is an increased level of communication with the Devs, QAs, and BAs Priorities change frequently in agile projects, so the Agile QA should be able to prioritize the tasks accordingly Should not be afraid of change Ideally, Agile Testers should be multi-skilled and technical or at least understand the technical terminology so that they don’t feel alienated from the rest of the team when developers talk in technical terms Should understand Agile concepts and principles Participate in daily sprint planning, stand-ups, retrospectives. Note the word Participate, meaning to actually talk and take part in discussions rather than just attending the meetingsWhat are the two key factors when working as a QA in an Agile team?: QAs can add a lot of value to an agile team because of the different mindset. Testers can and should think about the different possible scenarios to test a story. However, the most important asset that they can bring is:  To prevent defect.  QA should advocate best practices along the way to prevent defects from entering the system in the first place.  To provide fast feedback.  It is important for developers to know if the new functionality works as expected and if regression tests pass, and they need that feedback quite quickly. QA should provide the results of the tests to developers as soon as possible. What are the three main roles in Scrum?: The Scrum team consists of three main roles:  Product Owner: Manages the product backlog. PO is the voice of the business and creates new features to be developed for the application.  Scrum Master: Responsible for managing the sprint, remove any impediments and keeps track of the progress of the project.  Scrum Team itself: Composed of developers, designers, and QA. This forms the team which is responsible for delivering high-quality software. Test Automation Interview Questions and Answers: This section focuses on Test Automation Interview Questions and Answers. Rather than being tool specific, e. g. QTP or Selenium, WebDriver, the questions are more about the approach to test automation. What criteria do you consider for automating a test?: I would consider the following points to help me decide if a test should be automated:  How often does the test need to be executed? i. e. is that going to be a regression test? Sometimes the test will need to be executed once, but with a large set of data.  How much time does automating this test will save me so that I can use my time in exploratory testing.  How important is the test to the business; i. e. is the test scenario a typical user journey through the application.  How complex is it to automate the test and how likely is it that the complexity doesn’t cause many false positives which increases results analysis time? How likely is it that this test catches a defect? How likely is it that a feature or functionality will break and what is the impact of it on the business? If it is high impact, then it should be automated to ensure it passes from release to releaseWhat kind of tests should NOT be automated?: This interview question is similar to the previous question but focuses on which tests Not to be automated and left for manual testing. Possible answers can be:  Usability Testing – at times this can be an impossible task to perform by automation as the computer cannot efficiently judge if the system is of any use to its users.  Tests that only need to be executed once – unless the same test needs to be executed for a large dataset then it makes sense to automate.  Tests without predictable results – test automation should give us confidence in the results of the tests. If there are intermittent failures then the tests cannot be reliable and cannot be dependent on.  Tests that need to be verified visually.  Tests that need to be executed quickly. At first, writing an automated test takes longer. If we want a quick check, we should test manually, however, if that test is a good one which should be run regularly, then it should be automated in timeWhat are Pros and Cons of automating tests at UI layer?: Pros:  UI automated tests execute in a way that simulates a user interacting with the system. So it is very good for validating user journeys and flows Can cover end-to-end flows that communicate with 3rd party systems Because tests are run against the system, they can be shown to the customer who can understand what tests are run Can catch high severity or showstopper bugs Can check UI functionality where it is not possible to test otherwiseCons:  UI automated tests can be very brittle (i. e. fail due to UI changes even though functionality hasn’t changed).  Slow feedback to the team. Execution is slow as you have to wait for the system to launch and connections with 3rd party system can take a long time.  Limitation on what can be checked from the UI. There is some information that is not present from the UI.  Because tests are slow from UI, we can’t have a lot of tests running against the UI.  Can be time-consuming to construct automated test scripts for the UI.  Usually, have to depend on a 3rd party tool or vendor for UI testingWhy would you want to automate a test? Is it to::  Increase test coverage? Improve quality? Save time for exploratory testing? Find more bugs? Replace manual testers?This is a common test automation interview question and answer to this is quite straightforward. Although some of the above reasons seem plausible, the main reason why you would want to automate a test is that you want to repeat the same test many times. Web Testing Interview Questions: In this section, we discuss some common Web Testing Interview Questions and Answers. These questions are specific to web testing. How do you test the login feature of a web application?: This is a very common software testing interview question and the aim is to see how broad you can think about the feature. Most interviewees start with the obvious answer of checking input fields with positive and negative values, invalid email, valid email but incorrect password, SQL injection, etc. But most of these tests can be done and should be done by the developers as part of integration testing. Here the focus is on testing at the system level, tests which cannot be done without a fully integrated system. Possible answers to this testing interview question can be:  Sign in with valid login, Close browser and reopen and see whether you are still logged in or not.  Session management is important – how do we keep track of logged in users, is it via cookies or web sessions? Sign in, then log out and then go back to the login page to see if you are truly logged out.  Log in, then go back to the same page, do you see the login screen again? Sign in with one browser, then open another browser to see if you need to sign in again? Log in, change the password, and then log out, then see if you can log in again with the old password. What Types of Testing is Specifically Important for Web Testing?: This is also an important Software Testing interview question for web application testing roles.  Note, this question is asking about the types of testing. Although you would do functional testing, usability testing, accessibility testing, etc, these are all also applicable to desktop application testing. The question is asking specifically for web testing. Two types of testing which are very important for testing web applications are Performance Testing and Security Testing.  The difference between a web application and desktop application is that web applications are open to the world, with potentially many users accessing the application simultaneously at various times, so load testing and stress testing are important. Web applications are also vulnerable to all forms of attacks, mostly DDOS, so security testing is also very important to consider when testing web applications. How do You Verify the Results of Your Search on Search Results Page?: This is another common Software Testing Interview Question for e-commerce testing roles. This question refers to verifying the results are what we expect to see. Suppose you search for a product on Amazon. com website. On the search results page, you will see a list of items related to your search. How can you verify that the results that you see are really the ones that you are supposed to see? The answer to this question is rather simple. At first instance, we need to know where the data is coming from. Are they coming from a database? Or some XML files from 3rd party websites? Once we have this information, we can start comparing the results we see on the result page with the results from the source, e. g. database. Another option is to use mocks to generate the data that we need so we can fully control the data that we see on the search results page. How is Web Application Testing different to Desktop Application Testing?: Web Applications are typically hosted on a server which we can access via a web browser, whereas desktop applications are installed on the client’s machine. This setup opens a lot of new testing challenges: Performance and Security testing become important as the application is open to a wide audience. Good design and usability are also important. Other important factors that come to play are testing on multiple browsers, multiple devices, redirection, and responsiveness. Also, we should not forget about Javascript, CSS, Cookies, W3C standards, traffic monitoring, third-party tags testing, all of which are important in Web Application Testing. How would you Test a Service Oriented Architecture (SOA) Web Application?: The testing of web applications that communicate with a web service can be broken down into two parts:  Testing of the Web Service in isolation.  Each web service has one or more functions which can be tested by sending appropriate requests and analyzing the response and verifying correct data is returned in the response.  We can use tools such as SoapUI to test a Soap Service or Rest Client to test a RESTful web service.  Integration Testing of Web Service with the Front End.  The integration testing is also important as it can highlight issues with data in the request and display of the response. The reason for this separation is to be able to identify issues in the web service much quicker and easier to debug. There is a login form which is connected to an Authentication Web Service. What tests would you perform at which layer?:  All the input/output validation should be tested at the API layer calling the Authentication Web Service. Tests such as valid/invalid username/password combinations as well as verifying correct error messages.  The location of the display of error messages, their color and font should be tested at login web page. Also, if applicable, Javascript and Cookie tests needs to be tested at front-end login page. There are many ways to test a website and there could be lots of test cases to execute, how can you make sure the web application is fit for release?:  We can Automate majority of test cases, but most importantly we can use test techniques such as Pair-wise testing to reduce combinations and/or model-based testing to plan user journeys to ensure major functionality of web application works.  We can also use analytics to gain insight into what users do on the website, which page is most popular and which feature is most used by users. API Testing Interview Questions and Answers: Many of the new modern web applications are built using web-services, micro-services, and APIs. As testers, we should be knowledgeable and experienced in testing APIs and Web Services. Here are some fundamental API Testing Interview Questions mainly aimed at software testers. What is the difference between API Testing and Unit Testing?: API testing and unit testing are not the same things, although they are similar. Unit testing is done by the development team to make sure that a particular unit of software functions as required; since it is not black-box testing, it can’t accurately reflect the use of that software in the field. To put it bluntly, developers know their software too well, so they’re likely to miss something which may be blindingly obvious to a tester who is not acquainted with the software’s internal workings. The job of the API tester is to test the software knowing only what a user is likely to know. API testing also tests the unit as part of a system, while unit testing typically tests the unit in relative isolation from the rest of the system. Real web API testing requires an internet connection since communication to the Web API is done over the web. Unit testing is done on a local machine and requires no internet connection. Unit Testing:  Developers perform it Small units are tested in isolation The developer can access the source code Aims to find programmer errors and code coverage Limited in scope Usually ran before check-inAPI Testing:  Testers perform it Are a means of end-to-end testing Testers treat API as black-box Multiple functionalities can be checked Performance testing can also be done All functional issues are tested Broader in scope Ran after build is createdWhat’s the difference between UI level testing and API level testing?: With API testing, we can hit the API endpoint directly and have control of what data we send to the API for testing purposes. e. g. invalid data, malformed requests, etc. In UI level testing, we don’t have that level of flexibility because we are bound by the constraints of the UI. Also in terms of the response of API, there could be a lot of information which is not presented in the UI layer, but only available when analyzing the response body. UI level tests are inherently slow to execute, whereas API level tests are a lot quicker. As a result, API tests provide a much quicker feedback. How to perform API Testing? What to check for?: In API Testing, we make a request to the API with known data and we then analyze the response for validation. Typically, the things which we should check for are:  Data accuracy Data validations, data type, data order, data completeness Error codes if API returns Schema validation Authorization checks HTTP status codes Response timeout implementation Non-functional Testing such as Security and Performance TestingWhat tools are typically used for API Testing?: Postman is a rest client that started off as a Chrome browser plugin but recently came out with native versions for both Mac and Windows.  Can be used for both automated and exploratory testing Can be run on Mac, Windows, Linux &amp;Chrome Apps Has a bunch of integrations like support for Swagger &amp; RAML formats Has Run, Test, Document and Monitoring Features Doesn’t require learning a new languageSoapUI is a headless functional testing tool from SmartBear software. It comes in two flavors: Free open source version and Pro Version.  Can easily create custom code using Groovy Drag and Drop Test Creating Can create complex scenarios Asynchronous Testing SoapUI’s Mock Service lets you mimic web services before they are implementedRest-Assured is an open-source Java Domain-specific language (DSL) that makes testing REST service simple. It simplifies things by eliminating the need to use boiler-plate code to test and validate complex responses. It also supports XML and JSON Request/Responses.  Removes need to create boilerplate code required to interact with a rest service Support BDD Given/When/Then syntax Integrated seamlessly with Java projectsWhat are HTTP Request and HTTP Response?: An HTTP request method is made up of four components:  Request Method – Get, Post, Put, Delete (these are the common ones) Request URI – the URL of the resource Request Header – Accept-Language, Accept-Encoding, User-Agent, Host Request Body – this is the data to be sent to the resourceAn HTTP response method is made up of three components:  Response Status Code – 200, 301, 404, 500 (these are the most common ones) Response Header Fields – Date, Server, Last-Modified, Content-Type Response Body – this is the data that comes back to the client from the serverSelenium WebDriver Interview Questions and Answers: Here, we will cover some common selenium interview questions. Selenium WebDriver is a very popular browser automation testing tool and is used by many companies. When you apply for a job as an automation tester, you are most likely be expected to have experience working with Selenium WebDriver, so there will be questions at the interview to assess your knowledge of the selenium tool. Previously, we covered some Test Automation Interview Questions which are focused on the approach to test automation, here the main focus is on selenium tool and what questions you are likely to be asked at an interview. These selenium interview questions are based on the selenium tutorials. What is Selenium?: Selenium is a browser-based functional test automation tool. It is basically a library which you can use in your program to test a web application. It is important to note that selenium is mainly used for browser automation. It is NOT used for unit testing or API testing. Selenium Webdriver has many language bindings, which means you can write your tests in your favorite programming language and using the respective selenium bindings. In Selenium WebDriver, how do you select an item from a drop-down menu?: A: We can select an item from the drop-down menu by Value, by Index or by Visible Text. Example: 12345678910111213141516171819&lt;select id= cars &gt;  &lt;option value= vo &gt;Volvo&lt;/option&gt;  &lt;option value= sa &gt;Saab&lt;/option&gt;  &lt;option value= me &gt;Mercedes&lt;/option&gt;  &lt;option value= au &gt;Audi&lt;/option&gt;&lt;/select&gt;WebElement cars = driver. findElement(By. id( cars ));Select car = new Select(cars)//select by valuecar. selectByValue( vo ); //this will select Volvo from drop-down//select by indexcar. selectByIndex(2); //this will select Saab//select by visible textcar. selectByVisibleText( Audi ) //this will select AudiWhat is the difference between driver. get() and driver. navigate. to(): You can use both methods to navigate to a URL. Because navigating to a URL is very common, then driver. get() is a convenient way. However, it does the same function as the driver. navigate(). to(“url”) The driver. navigate() also has other functions, such as driver. navigate(). back()driver. navigate(). forward()driver. navigate(). refresh() What is the difference between implicit wait and explicit wait in Selenium WebDriver?: This question is asked in almost all selenium interview questions because many web applications use AJAX. Selenium Webdriver introduces the concept of waits for AJAX-based applications. There are two waiting methods, implicit wait, and explicit wait Implicit wait: When an implicit wait is implemented in tests, if WebDriver cannot find an element in the Document Object Model (DOM), it will wait for a defined amount of time for the element to appear in the DOM. In other terms, an implicit wait polls the DOM for a certain amount of time when trying to find an element or elements if they are not immediately available. Implicit waits can slow down your tests because once set, the implicit wait is set for the life of the WebDriver object’s instance. This means that when an application responds normally, it will still wait for each element to appear in the DOM which increases the overall execution time. Another downside is if for example you set the waiting limit to be 5 seconds and the elements appears in the DOM in 6 seconds, your tests will fail because you told it to wait a maximum of 5 seconds. An example of an implicit wait is: 1driver. manage(). timeouts(). implicitlyWait(10, TimeUnit. SECONDS);Explicit wait: Explicit waits are better than implicit wait. Unlike an implicit wait, you can write custom code or conditions for a wait before proceeding further in the code. An explicit wait can be used where synchronization is needed, for example, the page is loaded but we are still waiting for a call to complete and an element to appear. Selenium WebDriver provides WebDriverWait and ExpectedCondition classes for implementing an explicit wait. The ExpectedCondition class provides a set of predefined conditions to wait before proceeding further in the code. An example of an explicit wait is: 123WebDriverWait wait = new WebDriverWait(driver, 10);wait. until(ExpectedConditions. titleContains( selenium ));To summarize: Implicit wait time is applied to all elements in your script and Explicit wait time is applied only for a particular specified element. How would you count the number of elements on a page?: This is a common selenium interview question because in many cases you want to click on an item from a list. So it is important to know how to count the elements and select the correct one from the list. We first need to locate the node element where the items are listed. For example, in the HTML code below: 12345678&lt;ul id= movies &gt;  &lt;li&gt;movie title 1&lt;/li&gt;  &lt;li&gt;movie title 2&lt;/li&gt;  .   .   .   &lt;li&gt;movie title 50&lt;/li&gt;&lt;/ul&gt;The root element can be located using 1List&lt;WebElement&gt; movies = driver. findElements(By. cssSelector(ul#movies li));Then we can use the . size() to get the number of &lt;li&gt; elements 1int numberOfMovies = movies. size();How can you check if a checkbox or a radio button is selected?: We can use the . isSelected() method, e. g. 1driver. FindElement(By. id( id_of_checkbox )). isSelected();Is there a way to do drag and drop in Selenium WebDriver?: Yes, we can use the following code to do drag and drop 1234Actions action = new Actions(driver);WebElement start = driver. findElement(By. cssSelector(“div. source”));WebElement end = driver. findElement(By. cssSelector(“div. target”));action. dragAndDrop(start,end). perform();How would you check if an element is visible on the page?: We can use isDisplayed() method. The return type of the method is boolean. So if it returns true then the element is visible otherwise it is not. 1driver. findElement(By. id(“id_of_element”)). isDisplayed();How to check if a button is enabled page?: We can Use isEnabled() method. The return type of the method is boolean. So if it returns true then the button is enabled else not enabled. 1driver. findElement(By. id(“id_of_element”)). isEnabled();Now that you have gone through these selenium interview questions, it is time to take a short selenium WebDriver quiz. "
    }, {
    "id": 66,
    "url": "localhost:4000/parameterize-gatling-variables/",
    "title": "How to Parameterize Gatling Variables",
    "body": "2018/04/05 - How can we parameterize Gatling variables and pass parameters from the command line to Gatling? On most occasions, when you create a performance script, you want to run the simulation with a different set of parameters, such as users, ramp-up time and duration, or even different environment. In this Gatling tutorial, we will be using Maven as the build tool and show how to parameterize the test so that we can pass different values from command line or a CI tool such as Jenkins to our simulation class.  Create a Gatling project with Maven How to send post request in GatlingParameterize Gatling Variables: First, we have to have the following in the build section of the pom. xml file 123456789101112131415161718192021222324&lt;build&gt; &lt;plugins&gt;  &lt;!-- Gatling Maven plugin that runs the load-simulation. --&gt;  &lt;plugin&gt;   &lt;groupId&gt;io. gatling&lt;/groupId&gt;   &lt;artifactId&gt;gatling-maven-plugin&lt;/artifactId&gt;   &lt;version&gt;${gatling-plugin. version}&lt;/version&gt;   &lt;configuration&gt;    &lt;simulationClass&gt;simulations. LoginSimulation&lt;/simulationClass&gt;    &lt;jvmArgs&gt;     &lt;jvmArg&gt;-Denv=stable&lt;/jvmArg&gt;     &lt;jvmArg&gt;-Dusers=${users}&lt;/jvmArg&gt;     &lt;jvmArg&gt;-Drampup=${rampup}&lt;/jvmArg&gt;     &lt;jvmArg&gt;-Dduration=${duration}&lt;/jvmArg&gt;     &lt;jvmArg&gt;-Dthroughput=${throughput}&lt;/jvmArg&gt;     &lt;jvmArg&gt;-Xms2g&lt;/jvmArg&gt;     &lt;jvmArg&gt;-Xmx5g&lt;/jvmArg&gt;    &lt;/jvmArgs&gt;    &lt;!--&lt;fork&gt;true&lt;/fork&gt;--&gt;    &lt;propagateSystemProperties&gt;true&lt;/propagateSystemProperties&gt;   &lt;/configuration&gt;  &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;Then in a Configuration object, we can reference the above variables to inject values passed from the command line: 12345678object Configuration { val t_concurrency = Integer. getInteger( users , 10). toInt val t_rampUp = Integer. getInteger( rampup , 1). toInt val t_holdFor = Integer. getInteger( duration , 60). toInt val t_throughput = Integer. getInteger( throughput , 100). toInt}If the user doesn’t provide any value for the variables, then default values are used. For example, the default value for users is 10. Once we have the above setup, we can then use the command line or from a CI tool to pass in parameters to the pom. xml file which in turn injects them into the simulation class. 1mvn clean gatling:execute -Dusers=20 -Drampup=2 -Dduration=60 -Dthroughput=100"
    }, {
    "id": 67,
    "url": "localhost:4000/testing-quality-assurance-agile/",
    "title": "Testing and Quality Assurance in Agile",
    "body": "2018/04/04 - What does testing and quality assurance look like in an agile environment? How can we ensure that during the limited time that we have in a sprint we can deliver software that is functionally correct and fit for purpose and delivers value for customers? In this article, Liz Porritt shares her experience as a QA manager. Considering it has been 17 years since the Agile Manifesto was published it is surprising to me that we still haven’t quite got to grips with how we fit testers into the process.  Everywhere I have worked I have seen different attitudes to testing.  Some have the testers running a sprint behind, some have a testing story on the backlog, some have SDETs and some have manual only testers - and everything that fits in between.  All that I have seen have had quality issues - huge bug backlogs or, worse, just chaos.  Of course, I only see the not so great, otherwise, they wouldn’t be bringing me in.  How to Write an Agile Test Strategy How does Testing fit in an Agile Model?  Agile Tester vs. Traditional TesterTesting in an Agile World: Almost everyone agrees that quality plays an integral part in Agile, you just can’t be agile when you are dealing with bugs as often as you are building new features.  When quality is an accepted and supported part of the development process the team is free to play with new ideas, to roll out a new feature and see how it feels in the wild, and to know that the user response is to the feature and not clouded by bugs or performance. But how do we get to that utopia of clean, efficient code that doesn’t take weeks to write and test? We have all the pieces in place - we know the whole team is responsible for quality and that anyone who is able can test.  We know about TDD, BDD, peer reviews, automated functional, non-functional, system and system integration tests and we know that manual testing still plays a big role too.  And, we have DevOps - this is a big part of making sure we have quality code. So, who does all of this? SDETs, Developers, manual testers or just throw it out for the team to pick up? Technical Testing: Testing is a profession and a good, experienced tester should be the coordinator of all of the above, much like the senior developer is holding the development process together.  The two working closely together, with respect for each other’s work is a good place to start.  Building test frameworks takes time and experience that the development team don’t always have and that test code is as valuable, if not more valuable than the application source code. If the company loses the source code they can rewrite it using the tests, if the company loses the tests they have lost not just the tests but a lot of the documentation for the code. Someone must have responsibility for the creation, maintenance and the addition to the test framework and source code.  It is valuable stuff. Writing tests themselves should be easy, and yes, devs can do that alongside the testers, but it is only easy if the test framework is solid and the tests are run automatically in a good DevOps pipeline.  We need a test professional to work within the DevOps team to make sure the right tests get executed at the correct points of the pipeline.  The tester will be responsible for making sure that these tests are efficient and don’t hold up the process and have ideas of how to bring out the longer, more complicated test suites to run less often, overnight for example. There are usually many people in the team who have ideas, not just the testers, and these ideas are great, but if we try to coordinate everything without a tester and rely only on devs or ops then the work becomes too burdensome on top of everything else.  For something so high on the list of priorities, surely quality needs a dedicated professional? Automated and Manual Testing So far, I have only been thinking about the automated tests - manual testing can’t be forgotten.  Automated tests will not tell us if we have built the right thing (only that we built it right).  I am a big fan of Jonathan Bach’s session-based exploratory testing.  This is an excellent way for testers to really focus on what matters and to use their expertise to sniff out trouble.  I really don’t like formal script testing at all, I think that is such a terrible waste of time and resource.  Writing those tests is time spent away from the application and executing them is so mindless and demoralizing.  They are less likely to find issues than automated tests as we are basically turning our tester into a machine in the way we are expecting her to work and the point of manual testing is to look at the application from the eyes of a human being. Product Owners are great people to get involved in manual testing, in fact, I would argue that their job description should include it as standard.  The PO is going to see if their idea on paper really works as they expected.  The professional tester is going to see if unexpected user behavior will cause problems. The PO and tester relationship is also essential when designing the requirements themselves in order to ensure that they are testable. BDD is my personal favorite approach for this - but that is for another article. So, yes, the whole team is involved and committed to quality, but the Quality Assurance role is a vital one, we can’t expect to deliver efficiently without an excellent, well-designed testing platform and this requires expertise and as much investment as the product itself if we want that product to thrive. As a side note, while Googling for images for manual testing I saw a lot that were designed around Manual v Automated testing - this makes me so very sad. I hope it is just a legacy of a passing fad that has well and truly passed. There is not a competition here - both are vital. "
    }, {
    "id": 68,
    "url": "localhost:4000/http-basics/",
    "title": "HTTP Basics for Software Testers",
    "body": "2018/03/25 - If you are a technical tester or you are involved in testing APIs then you need to be familiar with the HTTP basics and terminologies. Without knowing the basics of HTTP, you cannot develop good API tests. In this article, we’ll examine some of the most common HTTP terminologies and their meanings for API testing. What is HTTP?: HTTP stands for Hypertext Transfer Protocol. It is a communications protocol and is used to send and receive web pages and files over the internet. HTTP works by using a user agent (e. g. a browser) to connect to a server. The server must be located using a URL or URI. This always contains http:// at the start. It normally connects to port 80 on a computer. What is HTTPS?: HTTPS stands for Hypertext Transfer Protocol Secure. This is a more secure version of HTTP and starts with https:// at the beginning of the URL. It encrypts all the information that is sent and received. This can stop malicious users such as hackers from stealing the information and is often used on payment websites. HTTPS uses port 443 for communication instead of port 80. What is an HTTP Request?: HTTP stands for Hypertext Transfer Protocol and is a way of sending messages from one computer to another computer over the internet. An HTTP request is sent to a specific URL and consists of a VERB, a set of HTTP Headers and a Body or Payload. An example HTTP request is: 123456GET https://www. testingexcellence. com/ HTTP/1. 1Accept-Encoding: gzip,deflateContent-Type: text/plainHost: testingexcellence. comUser-Agent: Apache-HttpClient/4. 5. 4 (Java/1. 8. 0_144)Accept: text/html,application/xhtml+xmlURL: URL is a Uniform Resource Locator and is the address we use to access websites and web applications.  URLs occur most commonly to reference web pages (http), but are also used for file transfer (ftp), email (mailto), and other applications. Most web browsers display the URL of a web page above the page in an address bar. A typical URL could have the form https://www. testingexcellence. com/index. html, which indicates a protocol http, a hostname www. testingexcellence. com, and a file name index. html. Request Verbs: Request VERB specifies the type of request e. g. GET, POST, PUT, DELETE. A Web Browser will usually make GET requests and POST requests, whereas when working with HTTP APIs the typical HTTP Verbs used are: GET, POST, PUT, DELETE. GET request, as the name suggests, asks for a resource or to read information from the server e. g. clicking on a link. GET requests are visible in the browser’s address bar. POST request, on the other hand, supply information to the server e. g. submitting a login or registration form. To create an entity, we would use POST requests. Also, POST requests are not visible in the browser’s address bar. PUT request is used to update information on the server. For example, an existing user wishes to update his password, then a PUT request is used. DELETE request deletes information on the server. Both POST and PUT requests would usually have a request body. GET and DELETE would not. Request Headers: Request headers specify information such as the type of Browser, type of content in the message, and what type of response is accepted in return. Example Request headers: 12Content-Type: text/plainUser-Agent: Apache-HttpClient/4. 5. 4 (Java/1. 8. 0_144)Request Body / Payload: A Payload is the body of the HTTP request or response. A request body can be plain text, HTML, XML, JSON, Javascript, or a set of key-value pairs as form-data. When browsing the Web, the Browser usually receives an HTML payload. This is the web page that you see rendered in the Browser. Typically when working with an HTTP API we will send and receive JSON or XML payloads. Not all HTTP messages can have payloads: POST and PUT can have payloads, GET and DELETE can not. What is an HTTP Response?: When a request is sent to a server, the server returns a response. The response from the server tells you if your request was successful, or if there was a problem. An HTTP response method is made up of three components: Response status code, response headers, response body. Example response: 12345HTTP/1. 1 200 OKContent-Length: 859Content-Type: text/html; charset=utf-8Date: Fri, 23 Feb 2018 14:38:21 GMTServer: Werkzeug/0. 14. 1 Python/3. 6. 3Line 1 is the status code and response message, lines 2-5 are response headers and the XML is the response body. Response Status Codes:  2xx for Success, the most common one is 200 which means “OK”.  3xx for Redirection, the most common ones are 301 and 303 which mean “Permanent Redirect” and “Redirect for Undefined Reason”, respectively.  4xx for Application Error, the most common ones are 403 and 404 which mean “Forbidden” and “Not Found”, respectively.  5xx for Server Error, the most common one is 500 which means “Server Error”. What is an API?: An API is an Application Programming Interface. This is an interface to an application designed for other computer systems to use. As opposed to a Graphical User Interface (GUI) which is designed for humans to use. Most modern APIs are HTTP based and are used to access Web Applications which are deployed to Servers accessible over the Internet. What is a Web Service?: Applications which are accessed via HTTP APIs are often called Web Services. In other words, a web service is a function that can be accessed by other programs over the web (HTTP). Read more on basics of Web Services What is JSON?: JSON stands for JavaScript Object Notation and is a text representation that is also valid JavaScript code. 123456789101112{   employers :{    employee :[     {       id :1,       name : Dan Brown ,       position : Director ,       status : active ,     }   ]  }}JSON can be thought of as a hierarchical set of key/value pairs where the value can be:  Object - delimited by { and } Array - delimited by [ and ] String - delimited by ” and ” IntegerAn array is a list of objects or key/value pairs. The keys are String values e. g. “employee”, “id”, “name”, etc. Further Reading:  HTTP Status Codes With Explanations How to get Response Status Code with Selenium WebDriver Difference Between PUT and PATCH Requests"
    }, {
    "id": 69,
    "url": "localhost:4000/subject7-saas-test-automation-platform/",
    "title": "Subject7 - A Cloud-Based SaaS Test Automation Platform",
    "body": "2018/03/20 - Two of the most common challenges QAs face in an agile team, is keeping up with the developers to automate new functionality, and the other is to have decent technical skills to be able to write good automation code. Majority of test automation engineers, including myself, are fond of being very hands-on and most of the time opt to code the automated scripts in their preferred programming language. This is yet another common problem, in that if the delivery team is mostly C# developers and automated tests are written in Java by the QAs, then only team members with Java knowledge can contribute and maintain the framework. Meet Subject7, a true script-free and cloud-based SaaS test automation platform which is designed to help non-technical testers as well as test automation engineers to expedite the creation of end-to-end automated tests. Using Subject7’s highly intuitive UI, you can create complex automated test scenarios in no time and most importantly it is language agnostic and anyone can contribute. Here is a quick overview of some of the useful features of this powerful test automation platform:  Test repository for all your automated and manual test cases.  Supports API Testing, Browser Testing, Native Mobile App Testing, Sikuli Tests and more.  On-the-fly test creation and execution Parameterization and Data Driven Testing Modularizing Test steps Cloud Run, Scheduled executions and Alerts Test Reporting and Archiving – Video recordingRelated:  Creating and Running Automated Tests with Subject7 Tips for Effective UI Test AutomationTest Library: You can organize your tests in a hierarchical manner, with folders to separate projects. In each folder, you can create test suites to hold a collection of related test scenarios, and in each test suite, you can create test cases. One of the cool features of the Subject7 tool is that it can also act as your test repository for your manual tests as well as automated tests. When you create a test case, you can choose if the test is manual or automated.  Wizard: At the heart of the Subject7 test automation platform is an intelligent wizard that assists you in creating all sorts of actions. With over 70 options, this wizard can create Selenium WebDriver tests, Appium Tests, API tests, and even Sikuli tests, conditional branches, loops, and database queries! All without writing any single line of code. The wizard can also create element locators automatically with their proprietary XPath generation algorithm. Very powerful indeed! On-the-fly Test Creation: Another powerful and indeed very useful feature of the tool is that you can add test steps as the test case is executing. You can imagine that when executing a long test case, if something fails, or you had coded a locator incorrectly, you have to start all over again. With this ability to create test step as the test is executing, you can cut down on debugging time and essentially test your step as you create them. This ensures that when you actually come to execute the tests as a set of large regression pack, then there are at least no script failures. Parameterizing and Data Driven Testing: A good practice in any automated test script is to externalize your test data so that you can easily modify them without having to change your scripts. Also, there are times when you need to run your test cases with a large set of data, also known as Data Driven Testing. Subject7 beautifully supports both of these features by its built-in Data Templates and Data Sets features, respectively. You can either upload a CSV format file for test data or create the test data directly on the tool itself. You can bind your test data to any test case. This feature is very handy when for example you want to run your tests on dev, staging and/or pre-prod environments. You can parameterize and define the environments in the Data Templates and then call them in the test steps.  Groupings of Test Steps: As you build up a test suite with many test cases, chances are some of the test steps are duplicates, where they are repeated in many test scenarios. Subject7 allows you to create functions by grouping a set of test steps which can be reused in other scripts, thus reducing rework and enhancing readability. Local Run and Cloud Run: When you develop your test scenarios, you typically choose the local run to test and debug your own test steps. This is limited to a single thread execution running on the local host machine and the chosen browser. Like most modern PaaS providers, Subject7 also supports cloud execution and this is where things get really exciting. Using the cloud run, you can parallelize multiple test executions and have your test cases executed on multiple VMs on multiple browsers. Test executions can be scheduled to run at a specific time, e. g. every day at 5 pm.  You have the ability to monitor live status as the tests are being executed and also get notified on any event (e. g. failures or timeouts). Cloud run does not mean that you don’t see the tests being executed! After a test case has finished, you can simply hit the video button on the test status row and see the execution of the tests as it happened on the VM. This is particularly usefulwhen a test fails and you want to include the evidence in a bug report.  There is a slight learning curve on using subject7 to create automated tests, however, once the initial hurdle is passed, large test packs can be created relatively quickly and are easy to maintain. "
    }, {
    "id": 70,
    "url": "localhost:4000/set-multiple-headers-http-request-karate/",
    "title": "How to Set Multiple Headers in HTTP Request With Karate",
    "body": "2018/01/23 - How to set HTTP headers in Karate? Karate is an API testing tool with a very comprehensive and easy to understand DSL. In this post, we show how to set multiple headers in the header part of a request. Examples include User-Agent, Content-Type, Accept-Encoding, Connection, etc. Related:  Automated testing of emails with Karate Automate your API testing with Karate What are request headers?There are a number of ways you can set request headers in Karate: Using header: You can use the header keyword multiple times in the request 1234567891011Given header Content-Type = 'text/xml;charset=ISO-8859-1'  And header Accept-Encoding = 'gzip,deflate'  And header Connection = 'Keep-Alive'  And header Expect = '100-continue'  And header User-Agent = 'Mozilla/4. 0(compatible;IE;GACv7\. 1\. 5192\. 22378)'  And header Host = 'localhost'  When url 'http://www. example. com'  And request { some: 'data' }  When method post  Then status 200Using headers: You can also define multiple headers all in a variable and then use it in the headers  keyword to send all the request headers 1234567* def req_headers = {Content-Type: 'text/xml;charset=ISO-8859-1', Connection: 'Keep-Alive', User-Agent: 'Mozilla/4. 0(compatible;IE;GACv7\. 1\. 5192\. 22378)'}Given headers req_headers  And url 'http://www. example. com'  And request { some: 'data' }  When method post  Then status 200Using configure headers: Another way of setting the request headers is to use configure headers 12345* configure headers = {Content-Type: 'text/xml;charset=ISO-8859-1', Connection: 'Keep-Alive', User-Agent: 'Mozilla/4. 0(compatible;IE;GACv7\. 1\. 5192\. 22378)'}  Given url 'http://www. example. com'  And request { some: 'data' }  When method post  Then status 200https://www. testingexcellence. com/karate-api-testing-tool-cheat-sheet/ Learn more about karate automated API testing tool. "
    }, {
    "id": 71,
    "url": "localhost:4000/gatling-set-ramp-max-duration/",
    "title": "Gatling - How to Set Ramp-up and Max Duration",
    "body": "2018/01/22 - In Gatling, you can set the ramp-up period and the maximum duration of the load testing. You can define the values in seconds or minutes. You might get a “Cannot resolve symbol minutes” or “Cannot resolve symbol seconds”. In order to resolve this issue, you need to import Gatling package scala. concurrent. duration. _. 12import scala. concurrent. duration. _setUp(scn. inject(rampUsers(10) over(2 seconds))). maxDuration(5 minutes). protocols(httpConf)Related:  Performance Testing with Gatling, Maven and Scala Gatling - How to Save Response Body Soak Testing With Gatling Example"
    }, {
    "id": 72,
    "url": "localhost:4000/gatling-random-post-request/",
    "title": "Gatling - How to Send Post Request in StringBody() With Random Data",
    "body": "2018/01/19 - In this Gatling tutorial, we show how to send post requests which contain random data in the StringBody(). In most performance testing scenarios, you want to randomize the data that is sent as post request to simulate different sessions. For this, we can make use of feeders which read data from CSV files or plain text. If you haven’t setup Gatling on your machine yet, you can read the post that explains how to setup Gatling as a Maven project. Scala Random String Generator: First, we need a method which generates a random string in Scala: 123object randomStringGenerator {  def randomString(length: Int) = scala. util. Random. alphanumeric. filter(_. isLetter). take(length). mkString}XML Request as Post Body: In this example, we are sending an XML post request. This contains a log_session_id parameter which needs to be different in each request: 12345678val req =  &lt;?xml version=\ 1. 0\  encoding=\ UTF-8\ ?&gt;\n  +        &lt;gpOBJECT&gt;\n  +         &lt;gpPARAM name=\ auth_method\ &gt;3&lt;/gpPARAM&gt;\n  +         &lt;gpPARAM name=\ app_url\ &gt;MY_APP&lt;/gpPARAM&gt;\n  +         &lt;gpPARAM name=\ log_session_id\ &gt;0000000000&lt;/gpPARAM&gt;\n  +         &lt;gpPARAM name=\ device_id\ &gt;b02edd23,ClientIP=10. 211. 55. 3&lt;/gpPARAM&gt;\n  +         &lt;gpPARAM name=\ service\ &gt;ACTIVATION&lt;/gpPARAM&gt;\n  +        &lt;/gpOBJECT&gt; We need to have a way of sending the above XML request as a post in the StringBody() in Gatling, but in each request, the log_session_id value should be a random string. For this, we need to make use of feeders. Feeder in StringBody(): 1234567var randomSession = Iterator. continually(Map( randsession  -&gt; ( req. replace( 0000000000 , randomStringGenerator. randomString(10)))))val scn = scenario( Activate )  . feed(randomSession)  . exec(http( activate request )  . post( /login/activate )  . body(StringBody(   ${randsession}   ))The full script to send random post request in StringBody() in Gatling: 1234567891011121314151617181920212223242526272829303132333435363738394041package com. testingexcellence. scala. examplesimport io. gatling. core. Predef. _import io. gatling. http. Predef. _import io. gatling. http. config. HttpProtocolBuilder. toHttpProtocolimport io. gatling. http. request. builder. HttpRequestBuilder. toActionBuilderclass Activate extends Simulation { object randomStringGenerator {  def randomString(length: Int) = scala. util. Random. alphanumeric. filter(_. isLetter). take(length). mkString } val req =  &lt;?xml version=\ 1. 0\  encoding=\ UTF-8\ ?&gt;\n  +        &lt;gpOBJECT&gt;\n  +         &lt;gpPARAM name=\ auth_method\ &gt;3&lt;/gpPARAM&gt;\n  +         &lt;gpPARAM name=\ app_url\ &gt;MY_APP&lt;/gpPARAM&gt;\n  +         &lt;gpPARAM name=\ log_session_id\ &gt;0000000000&lt;/gpPARAM&gt;\n  +         &lt;gpPARAM name=\ device_id\ &gt;b02edd23,ClientIP=10. 211. 55. 3&lt;/gpPARAM&gt;\n  +         &lt;gpPARAM name=\ service\ &gt;ACTIVATION&lt;/gpPARAM&gt;\n  +        &lt;/gpOBJECT&gt;  var randomSession = Iterator. continually(Map( randsession  -&gt; ( req. replace( 0000000000 , randomStringGenerator. randomString(10))))) val httpConf = http  . baseURL( http://localhost:5000 )  . acceptHeader( text/html,application/xhtml+xml,application/xml;q=0. 9,*/*;q=0. 8 )  . userAgentHeader( Mozilla/4. 0(compatible;IE;GACv10\. 0\. 0\. 1) ) val scn = scenario( Activate )  . feed(randomSession)  . exec(http( activate request )  . post( /login/activate )  . body(StringBody(   ${randsession}   ))  . check(status. is(200)))  . pause(5) setUp(  scn. inject(atOnceUsers(5)) ). protocols(httpConf)}"
    }, {
    "id": 73,
    "url": "localhost:4000/webdriver-headless-mode-chrome-driver/",
    "title": "How To Run WebDriver in Headless Mode",
    "body": "2018/01/18 - How to run WebDriver in headless mode? This might be needed if your CI tool, for example, Jenkins doesn’t support UI. Running WebDriver Automated Tests in headless mode provides advantages in terms of speed of execution of tests and easier integration into the CI pipeline. In this tutorial, we will use PhantomJS and ChromeDriver to run Selenium WebDriver tests in headless mode. https://www. testingexcellence. com/capture-network-traffic-xhr-cypress/ PhantomJS: To run WebDriver tests in headless mode using PhantomJS, you first need to download the PhantomJS executable file and save it in a location, e. g. your project’s resources folder. In the example below, I have put the PhantomJS executable in src/test/resources/phantomjs You will also need the ghost driver dependency as well: 12345&lt;dependency&gt;  &lt;groupId&gt;com. github. detro. ghostdriver&lt;/groupId&gt;  &lt;artifactId&gt;phantomjsdriver&lt;/artifactId&gt;  &lt;version&gt;1. 0. 1&lt;/version&gt;&lt;/dependency&gt;And your Java class: 12345678910111213141516171819202122package com. sdetworld. tutorials. seleniumimport org. openqa. selenium. phantomjs. PhantomJSDriver;import org. openqa. selenium. phantomjs. PhantomJSDriverService;import org. openqa. selenium. remote. DesiredCapabilities;public class WebDriverBase { static protected WebDriver driver; public static void setup() {  DesiredCapabilities caps = new DesiredCapabilities();  caps. setJavascriptEnabled(true); // not really needed: JS enabled by default  caps. setCapability(PhantomJSDriverService. PHANTOMJS_EXECUTABLE_PATH_PROPERTY,  src/test/resources/phantomjs );  driver = new PhantomJSDriver(caps); } public static void main(String[] args) {  WebDriverBase. setup();  driver. get( https://www. testingexcellence. com ); }}ChromeDriver: To run WebDriver tests in headless mode using ChromeDriver, you will need to add the relevant dependencies in your pom. xml file: 1234567891011121314151617181920&lt;dependency&gt;  &lt;groupId&gt;org. seleniumhq. selenium&lt;/groupId&gt;  &lt;artifactId&gt;selenium-chrome-driver&lt;/artifactId&gt;  &lt;version&gt;${selenium. version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;org. seleniumhq. selenium&lt;/groupId&gt;  &lt;artifactId&gt;selenium-server&lt;/artifactId&gt;  &lt;version&gt;${selenium. version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;org. seleniumhq. selenium&lt;/groupId&gt;  &lt;artifactId&gt;selenium-java&lt;/artifactId&gt;  &lt;version&gt;${selenium. version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;io. github. bonigarcia&lt;/groupId&gt;  &lt;artifactId&gt;webdrivermanager&lt;/artifactId&gt;  &lt;version&gt;${webdrivermanager. version}&lt;/version&gt;&lt;/dependency&gt;Next, we instruct the WebDriver manager to launch chrome driver in headless mode 1234567891011121314151617181920212223package com. sdetworld. tutorials. seleniumimport io. github. bonigarcia. wdm. ChromeDriverManager;import org. openqa. selenium. chrome. ChromeDriver;public class WebDriverBase { static protected WebDriver driver; public static void setup() {  ChromeDriverManager. getInstance(). setup();  ChromeOptions chromeOptions = new ChromeOptions();  chromeOptions. addArguments( --headless );  driver = new ChromeDriver(chromeOptions); } public static void main(String[] args) {  WebDriverBase. setup();  driver. get( https://www. testingexcellence. com ); }}"
    }, {
    "id": 74,
    "url": "localhost:4000/performance-testing-gatling-maven-scala/",
    "title": "Performance Testing with Gatling, Maven and Scala",
    "body": "2018/01/18 - This post shows how to set up a Gatling simulation test using Maven and Scala on IntelliJ IDE. If you don’t already have Scala plugin for IntelliJ IDE, you can install it from the plugins section under preference: Once the Scala plugin is installed, then you need to create a Maven project and choose a Scala archetype If the desired archetype is not listed, you can click the “Add archetype” button and add the following details 123&lt;groupId&gt;net. alchim31. maven&lt;/groupId&gt;&lt;artifactId&gt;scala-archetype-simple&lt;/artifactId&gt;&lt;version&gt;1. 6&lt;/version&gt;Next, add the following section to the pom file which indicates which version of libraries we will be using 1234567&lt;properties&gt;  &lt;maven. compiler. source&gt;1. 8&lt;/maven. compiler. source&gt;  &lt;maven. compiler. target&gt;1. 8&lt;/maven. compiler. target&gt;  &lt;encoding&gt;UTF-8&lt;/encoding&gt;  &lt;scala. version&gt;2. 11. 7&lt;/scala. version&gt;  &lt;scala. compat. version&gt;2. 11&lt;/scala. compat. version&gt;&lt;/properties&gt;Then, add the required Scala and Gatling dependencies in the pom file 12345678910111213&lt;dependencies&gt;  &lt;dependency&gt;   &lt;groupId&gt;org. scala-lang&lt;/groupId&gt;   &lt;artifactId&gt;scala-library&lt;/artifactId&gt;   &lt;version&gt;${scala. version}&lt;/version&gt;  &lt;/dependency&gt;  &lt;dependency&gt;   &lt;groupId&gt;io. gatling. highcharts&lt;/groupId&gt;   &lt;artifactId&gt;gatling-charts-highcharts&lt;/artifactId&gt;   &lt;version&gt;${gatling. version}&lt;/version&gt;   &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt; &lt;/dependencies&gt;And finally, add the build section in the pom file 123456789101112131415&lt;build&gt;  &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;  &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;  &lt;plugins&gt;   &lt;!-- Gatling Maven plugin that runs the load-simulation. --&gt;   &lt;plugin&gt;    &lt;groupId&gt;io. gatling&lt;/groupId&gt;    &lt;artifactId&gt;gatling-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;${gatling-plugin. version}&lt;/version&gt;    &lt;configuration&gt;     &lt;simulationClass&gt;com. example. perf. simulations. HttpSimulation&lt;/simulationClass&gt;    &lt;/configuration&gt;   &lt;/plugin&gt;  &lt;/plugins&gt; &lt;/build&gt;Once all the sections in the pom file have been updated, we are now ready to create a Gatling simulation class in Scala.  In src/test/scala, create a package named com. example. gatling. simulations.    In this package, create a Scala class named HttpSimulation with the following implementation.   package com. example. gatling. simulations   import io. gatling. core. Predef. _import io. gatling. http. Predef. _import io. gatling. http. config. HttpProtocolBuilder. toHttpProtocolimport io. gatling. http. request. builder. HttpRequestBuilder. toActionBuilder   /**          Example Gatling load test that sends two HTTP requests to the same URL.  */class HttpSimulation extends Simulation {     val theHttpProtocolBuilder = http  . baseURL(“https://computer-database. gatling. io”)     val theScenarioBuilder = scenario(“Scenario1”)  . exec(    http(“myRequest1”). get(“/”)  )     setUp(  theScenarioBuilder. inject(atOnceUsers(1))). protocols(theHttpProtocolBuilder)}       To execute your test, just run 1mvn gatling:execute"
    }, {
    "id": 75,
    "url": "localhost:4000/automated-api-testing-emails-karate/",
    "title": "Automated Testing of Emails Using Karate",
    "body": "2017/11/28 - Automated Testing of emails can be a bit daunting as the majority of email providers are not built for testing purposes. In the past, people have used Gmail and mailinator to create email addresses, send and read emails but they tend to have limitations and can block a user. There is a web application [qamail. ala. se](http://qamail. ala. se/) which is very lightweight and is specifically built for testing purposes. You can create email accounts (email addresses), list emails for an account, read an email and delete emails. One of the great things about this is that you can use both the UI and/or its API which comes very handy for UI and API automated testing. For example, you can either use Selenium WebDriver or Rest-Assured or Karate to fetch emails. In this page, I list examples of how to work with the API of the qamail application. The given examples are in **[Karate](https://www. testingexcellence. com/automated-api-testing-made-easy-karate/)**, but equally any API testing library can be used. ### Create Session#create-session-key. featureFeature: Create a session key to use for email fetching Background:  * def host = 'http://qamail. ala. se'  * configure followRedirects = false  Scenario: test session creation   Given url host   When method get   * def redirect_address = responseHeaders['Location'][0]   Given url redirect_address   When method get   * string cookies = responseHeaders['Set-Cookie']   * string session_cookie = Java. type('com. testingexcellence. StringUtil'). getCookieValue(cookies, 'session_key')The above feature file calls a Java method to parse the cookies and extract the session_key cookiepublic static String getCookieValue(String cookieString, String cookieKey) {  Pattern p = Pattern. compile( (\\w+)=\ *((?&lt;=\ )[^\ ]+(?=\ )|([^\\s]+))\ * );  Matcher m = p. matcher(cookieString);  String cookieValue =   ;  while(m. find()){    if(m. group(1). contains(cookieKey)) {      cookieValue = m. group(2);    }  }  return cookieValue. replaceAll( ; ,   );}Once we obtain a session key, we can use it for various operations### Create MailBox#create-mailbox. featureFeature: create mailbox feature Background:  * def create_session = callonce read('create-session-key. feature')  * def session = create_session. session_cookie  * def host = create_session. host Scenario: Create a mailbox  * def create_mailbox_path = '/api/create_mailbox'  Given url host + create_mailbox_path + '?session_key=' + session  And request ''  When method PUT  Then status 200  * def email_address = get response. mailbox. address**Response** zxe45oy@qamail. ala. se### List Email Boxes#list-mailboxes. featureFeature: list mailboxes Background:  * def create_session = callonce read('create-session-key. feature')  * def session = create_session. session_cookie  * def host = create_session. host Scenario: list mailoxes  * def list_mailboxes_path = '/api/list_mailboxes'  * def endpoint = host + list_mailboxes_path + '?session_key=' + session  Given url endpoint  When method GET  Then status 200  * def email_address = get response. session. mailbox. address**Response** 8ZFmjSmdI6tf496dGrsK5sN6 t971kzb@qamail. ala. se ### List Emails for an Email AddressN. B: (only works when you send an email to the address) Values hardcoded for demo#show-emails. featureFeature: show emails for an email address Background:  * def result = call read('list-mailboxes. feature')  * def email_address = result. email_address  * def session = result. response. session. session_key  * def host = result. host Scenario: show emails for a specific email address  * def show_emails_path = '/api/show_mailbox_content'  * def session = 'LFB2Ii0GT4NuZB7nqLljNT0W'  * def email_address = 'h0qr0xd@qamail. ala. se'  Given url host + show_emails_path + '?session_key=' + session + '&amp;address=' + email_address  When method GET  Then status 200  * def email_id = get response. mailbox. letter. id  * def subject = get response. mailbox. letter. subject  * def from = get response. mailbox. letter. from  * def date = response. mailbox. letter. date**Response** h0qr0xd@qamail. ala. se 38989 Test mail test@test. com 2017-11-27 18:07:52 UTC ### Show Email Content for a Specific EmailN. B: (only works when you send an email to the address) Values hardcoded for demo#read-email. featureFeature: read an email Background:  * def result = call read('show-emails. feature')  * def email_address = result. email_address  * def session = result. session  * def host = result. host  * def letter_id = result. letter_id Scenario: show emails for a specific email address  * def show_email_content_path = '/api/show_rendered_letter'  * def session = 'LFB2Ii0GT4NuZB7nqLljNT0W'  * def email_address = 'h0qr0xd@qamail. ala. se'  * def letter_id = 38989  Given url host + show_email_content_path + '?session_key=' + session + '&amp;address=' + email_address + '&amp;letter_id=' + letter_id  When method GET  Then status 200**Response**The response is a dump of the body of an email. You have to use Regexp to extract what you want from the text of the email. "
    }, {
    "id": 76,
    "url": "localhost:4000/parse-json-response-rest-assured/",
    "title": "How to Parse JSON Response with REST-assured",
    "body": "2017/10/30 - In this API Testing tutorial, we take a look at how to parse JSON response and extract information using the REST-assured library. When testing an API, you typically make a request to a resource, (e. g. via a GET or POST request). The server comes back with a response and then you do some assertions on the response. Related: How to send a POST request with REST-assured How to Parse JSON Response: For this tutorial, I will be using JSONPlaceholder which is a fake online REST API for Testing and Prototyping.  JSONPlaceholder is a free online REST service that you can use whenever you need some fake data. More specifically, I will be using the users endpoint https://jsonplaceholder. typicode. com/users  How to set multiple Headers in Karate HTTP Basics for Software Testers How to encode and decode JSON Byte ArrayRequest and Response: When we make a GET request to the above resource, we get a JSON response which contains a list of users. This list is represented as a JSON Array. Each array has a structure like this: 1234567891011121314151617181920212223{ id: 1, name:  Leanne Graham , username:  Bret , email:  Sincere@april. biz , address: {  street:  Kulas Light ,  suite:  Apt. 556 ,  city:  Gwenborough ,  zipcode:  92998-3874 ,  geo: {   lat:  -37. 3159 ,   lng:  81. 1496   } }, phone:  1-770-736-8031 x56442 , website:  hildegard. org , company: {  name:  Romaguera-Crona ,  catchPhrase:  Multi-layered client-server neural-net ,  bs:  harness real-time e-markets  }}Therefore, in the full response, there will be ten records in the array, each having the same JSON structure, but with different values. Now, let’s start by parsing and extracting some values from the JSON. The first test would typically be to count the number of records in the array, so let’s start with that. 1234567891011121314151617181920212223242526272829import io. restassured. RestAssured;import io. restassured. http. ContentType;import io. restassured. parsing. Parser;import io. restassured. response. Response;import java. util. List;import static io. restassured. RestAssured. given;public class RestTest {  public static Response doGetRequest(String endpoint) {    RestAssured. defaultParser = Parser. JSON;    return        given(). headers( Content-Type , ContentType. JSON,  Accept , ContentType. JSON).             when(). get(endpoint).             then(). contentType(ContentType. JSON). extract(). response();  }  public static void main(String[] args) {    Response response = doGetRequest( https://jsonplaceholder. typicode. com/users );    List&lt;String&gt; jsonResponse = response. jsonPath(). getList( $ );    System. out. println(jsonResponse. size());  }}The result of the above call would print 10. Note the $ notation which means the root element. Parsing JSON Arrays and Lists: In the above example, if we wanted to get the username of all entries, we could use 12String usernames = response. jsonPath(). getString( username );System. out. println(usernames);This would print the array like: 1[Bret, Antonette, Samantha, Karianne, Kamren, Leopoldo_Corkery, Elwyn. Skiles, Maxime_Nienow, Delphine, Moriah. Stanton]If we then want to get the username of the first entry we could use 1String usernames = response. jsonPath(). getString( username[0] );This would print the first username: Bret Using a List we can use 12List&lt;String&gt; jsonResponse = response. jsonPath(). getList( username );System. out. println(jsonResponse. get(0));This would print the first username: Bret Parsing JSON ArrayList and HashMap: Looking at the above JSON structure, the company is actually a map. If we only had one record, we could use 1234Response response = doGetRequest( https://jsonplaceholder. typicode. com/users/1 );    Map&lt;String, String&gt; company = response. jsonPath(). getMap( company );    System. out. println(company. get( name ));which would print Romaguera-Crona But if the response returns an array and we want to extract the first company name, we could use: 1234Response response = doGetRequest( https://jsonplaceholder. typicode. com/users/ );    Map&lt;String, String&gt; company = response. jsonPath(). getMap( company[0] );    System. out. println(company. get( name ));Alternatively, we could use: 1234Response response = doGetRequest( https://jsonplaceholder. typicode. com/users/ );    List&lt;Map&lt;String, String&gt;&gt; companies = response. jsonPath(). getList( company );    System. out. println(companies. get(0). get( name ));both of which will print Romaguera-Crona. "
    }, {
    "id": 77,
    "url": "localhost:4000/difference-put-patch-requests/",
    "title": "Difference Between PUT and PATCH Requests",
    "body": "2017/10/29 - What is the main difference between PUT and PATCH requests, and when should we use one over the other? PUT and PATCH are HTTP verbs and they both relate to updating a resource. Main Difference Between PUT and PATCH Requests: The main difference between PUT and PATCH requests are in the way the server processes the enclosed entity to modify the resource identified by the Request-URI. https://www. testingexcellence. com/http-basics/ In a PUT request, the enclosed entity is considered to be a modified version of the resource stored on the origin server, and the client is requesting that the stored version be replaced. With PATCH, however, the enclosed entity contains a set of instructions describing how a resource currently residing on the origin server should be modified to produce a new version. Also, another difference is that when you want to update a resource with PUT request, you have to send the full payload as the request whereas with PATCH, you only send the parameters which you want to update.  Gatling - How to send post requests with randomized dataSuppose we have a resource that holds the first name and last name of a person. If we want to change the first name then we send a put request for Update 1{  first :  Michael ,  last :  Angelo  }Here, although we are only changing the first name, with PUT request we have to send both parameters first and last. In other words, it is mandatory to send all values again, the full payload. When we send a PATCH request, however, we only send the data which we want to update.  In other words, we only send the first name to update, no need to send the last name. For this reason, PATCH request requires less bandwidth. "
    }, {
    "id": 78,
    "url": "localhost:4000/automated-ui-tests-run-ci-pipeline/",
    "title": "Should Automated UI Tests Run in CI Pipeline?",
    "body": "2017/10/26 - Should Automated UI Tests (e. g. Selenium Tests) be run as part of the continuous integration build pipeline? The problem with automated UI tests is that they are slow and brittle as they need to interact with a browser over HTTP. In this post, we examine a strategy for executing automated UI tests in CI/CD pipeline. Automated UI Tests in CI Pipeline: The reason for choosing to have automated UI tests is to ensure the application under test works correctly end-to-end. By running automated UI tests, we are effectively simulating user journeys through the system. However, the problem with automated UI tests is that they are slow as they need to interact with a browser, even when running in headless mode, as they need to send and receive data over HTTP. Hence, the feedback loop is very slow.  Test Automation Strategy for Agile Projects How to set up a QA function from scratchAnother issue with automated UI tests is that they are quite often brittle, meaning that they could fail for a variety of reasons, sometimes due to valid failures which is good, but often due to false positives which makes it hard to get a Green build consistently. Why not have only unit tests in CI?: Unit tests are quick and provide a fast feedback, but while necessary to catch issues early on, are not sufficient to gauge the quality of a build. Remember, unit tests catch programmer errors, they don’t reveal system failures. End-to-End UI automated tests provide value and are great at highlighting system failures. Not including them in the CI pipeline, we risk of releasing software with potential bugs. UI level tests validate the behavior of the system from the point of view of the user and ensure the application delivers the functionality promised in the user stories and user journeys. So what should be the strategy?: In an ideal case, we should have only a handful of end-to-end automated UI  tests and aim for verifying functionality at lower layers than the UI. If the main problem of running automated UI tests as part of a build is time, then one solution is to run the tests in parallel e. g. Selenium Grid. Another solution is to have only the main core user journey scenarios to run as part of the build pipeline, and then a bigger regression pack as a separate process. Also, regression testing doesn’t mean to run all the tests all the time. Running all your tests with every integration to main is not often the best solution. You can have different suites of “regression packs” for the different parts of the application and only run the set that is needed. This is nicely achieved by tagging different automated tests for various purposes. You can always mark automated tests as CI, nightly, hourly, pre-release etc if that works and run them accordingly. "
    }, {
    "id": 79,
    "url": "localhost:4000/automated-api-testing-made-easy-karate/",
    "title": "Automated API Testing Made Easy With Karate",
    "body": "2017/10/20 - If you would like to get involved in Automated API Testing, but don’t have the programming background, then you might want to give Karate a go! Karate was released as an open-source tool by Intuit. The tool is designed to be used for automated API testing and has all the required features to make API testing a breeze and actually enjoyable. Unlike other automated API testing tools which require a fair amount of coding, even just to do basic stuff, Karate works out of the box. You can construct the most complex request-response operations with no knowledge of any programming language. All you have to do is to write the feature file using plain text Gherkin style. Because Karate is a complete DSL and sits on top of Cucumber-JVM, you can run tests and generate reports like any standard Java project, but instead of writing Java code, you write the tests in a language designed to make dealing with HTTP, JSON or XML easy and simple. Although there are no pre-requisites to use Karate, it helps if you have the basic understanding of HTTP, JSON, XML, JsonPath and XPath and JavaScript. In this post, we take a look at some typical operations you would normally perform in Automated API Testing, but first, a quick guide on setting up your environment for Karate. Maven: If you are using Maven, you need the two following dependencies 123456789101112&lt;dependency&gt;  &lt;groupId&gt;com. intuit. karate&lt;/groupId&gt;  &lt;artifactId&gt;karate-apache&lt;/artifactId&gt;  &lt;version&gt;0. 6. 0&lt;/version&gt;  &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;com. intuit. karate&lt;/groupId&gt;  &lt;artifactId&gt;karate-junit4&lt;/artifactId&gt;  &lt;version&gt;0. 6. 0&lt;/version&gt;  &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;Gradle: Alternatively, if you are using Gradle, you need 12testCompile 'com. intuit. karate:karate-junit4:0. 6. 0'testCompile 'com. intuit. karate:karate-apache:0. 6. 0'Folder Structure: A Karate test script has the file extension . feature which is the standard followed by Cucumber. You are free to organize your files using regular Java package conventions. The Maven tradition is to have non-Java source files in a separate src/test/resources folder structure - but the creators of the Karate tool recommend that you keep them side-by-side with your *. java files.  Like Cucumber, you need to have a “Runner” class which runs the feature file(s). Unlike Cucumber, however, there are no step definitions! And this is the magic of Karate. To use the TestRunner. java class to execute the feature file, you need to have the build section in the pom. xml file. 1234567891011121314151617181920212223242526272829303132&lt;?xml version= 1. 0  encoding= UTF-8 ?&gt;&lt;project xmlns= http://maven. apache. org/POM/4. 0. 0      xmlns:xsi= http://www. w3. org/2001/XMLSchema-instance      xsi:schemaLocation= http://maven. apache. org/POM/4. 0. 0 http://maven. apache. org/xsd/maven-4. 0. 0. xsd &gt;  &lt;modelVersion&gt;4. 0. 0&lt;/modelVersion&gt;  &lt;groupId&gt;Tutorials&lt;/groupId&gt;  &lt;artifactId&gt;Karate&lt;/artifactId&gt;  &lt;version&gt;1. 0-SNAPSHOT&lt;/version&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;com. intuit. karate&lt;/groupId&gt;      &lt;artifactId&gt;karate-apache&lt;/artifactId&gt;      &lt;version&gt;0. 6. 0. 4&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;com. intuit. karate&lt;/groupId&gt;      &lt;artifactId&gt;karate-junit4&lt;/artifactId&gt;      &lt;version&gt;0. 6. 0. 4&lt;/version&gt;    &lt;/dependency&gt;  &lt;/dependencies&gt;  &lt;build&gt;    &lt;testResources&gt;      &lt;testResource&gt;        &lt;directory&gt;src/test/java&lt;/directory&gt;        &lt;excludes&gt;          &lt;exclude&gt;**/*. java&lt;/exclude&gt;        &lt;/excludes&gt;      &lt;/testResource&gt;    &lt;/testResources&gt;  &lt;/build&gt;&lt;/project&gt;And your TestRunner. java class would look like 123456789package com. tutorials. karate;import com. intuit. karate. junit4. Karate;import org. junit. runner. RunWith;@RunWith(Karate. class)public class TestRunner {}Simple Automated API Testing with Karate: Suppose you are testing an API (https://some-api. com/api/users) which returns a list of users in JSON format 123456789101112[  {  	 id : 1,  	 name :  FirstUser ,  	 password :  User1Pass   },  {    id : 2,  	 name :  SecondUser ,  	 password :  User2Pass   }]Your Karate feature file will look like: 1234567Feature: Test User API Scenario: Fetch all users  Given url 'https://some-api. com/api/users'  When method GET  Then status 200  And assert response. length == 2  And match response[0]. name == 'FirstUser'And that’s it - very concise and to the point and most importantly, no code! Karate comes with a very rich set of useful features which enables you to perform Automated API Testing very easily and quickly. In future posts, we delve more into this amazing tool and give examples on how to do just about anything you need when testing APIs! "
    }, {
    "id": 80,
    "url": "localhost:4000/appium-starter-project/",
    "title": "Appium Starter Project - Step By Step Guide",
    "body": "2017/10/05 - In this Appium tutorial, we take a look at how to create a sample maven project to use for Mobile Test Automation using Appium with Java. This is an Appium starter project for mobile automation testing for both native and web view. It uses a sample app (Wikipedia) on an android emulator to run a basic search test. The idea is to show how to write automated tests for a mobile app using Appium. The project will automatically install the Wikipedia app on the virtual device which you will create in the following steps and then runs two search tests on the Wikipedia app.  How to create Test Automation Framework from scratch Opensource Mobile Test Automation Tools Run Automated Mobile Tests on Multiple DevicesAppium Project Setup Requirements: As this is a Java-based starter project, you need to have Java 8 installed. You will also need to have Android SDK to be able to interact with the Android emulator. You can clone this project from my Github repo https://github. com/AmirGhahrai/appiumTests Appium Project Setup: The instructions given here are for OSX 1 - Install latest Android SDK: 1https://developer. android. com/studio/install. html2 - The installer will install Android SDK in the following location: 1/Users/&lt;YOUR-USERNAME&gt;/Library/Android/sdk3 - Edit your . bash_profile to have the following:: 12345678export ANDROID_HOME=/Users/&lt;YOUR-USERNAME&gt;/Library/Android/sdkexport ANDROID_SDK_ROOT=$ANDROID_HOMEexport JAVA_HOME=$(/usr/libexec/java_home)PATH=$PATH:$ANDROID_SDK_ROOT/tools/binPATH=$PATH:$ANDROID_SDK_ROOT/emulatorPATH=$PATH:$ANDROID_SDK_ROOT/platform-toolsPATH=$PATH:$JAVA_HOME/binN. B. Your . bash_profile should be in ~/. bash_profile If you don’t have a . bash_profile then run this command to create it: touch ~/. bash_profile To edit your . bash_profile run: sudo nano ~/. bash_profile 4 - Install the latest platform tools by running the following command in a terminal: 1sdkmanager  platform-tools   platforms;android-26 5 - Download necessary packages: 1sdkmanager  system-images;android-26;google_apis;x86 6 - Create an avd (Android Virtual Device) with a name TestAvd and device Nexus 5X: 1avdmanager create avd -n TestAvd -k  system-images;android-26;google_apis;x86  -d  Nexus 5X 7 - Launch the emulator to see if everything is working: 1emulator -avd TestAvd -skin 1440x25608 - Now install Appium: 1npm install -g appium9 - Start the Appium server by running the following command: 1appium10 - Run the tests from the project root (where pom. xml resides): 1mvn clean testN. B.  To run the tests you need to clone the project from https://github. com/AmirGhahrai/appiumTests "
    }, {
    "id": 81,
    "url": "localhost:4000/iterative-incremental-development-agile/",
    "title": "Difference Between Iterative and Incremental Development in Agile",
    "body": "2017/08/10 - In agile software development, what is the difference between iterative and incremental development? Are they the same thing? What is the distinction between these two words? First, let’s look at simple definitions of the two terms: Incremental - adding new functionality in small chunks Iterative - performing repeatedly, i. e. adding new functionality in a repetitive or cyclic manner From Wikipedia:  Iterative development was created as a response to inefficiencies and problems found in the waterfall model.  The basic idea behind this method is to develop a system through repeated cycles (iterative) and in smaller portions at a time (incremental), allowing software developers to take advantage of what was learned during the development of earlier parts or versions of the system. Learning comes from both the development and use of the system, where possible key steps in the process start with a simple implementation of a subset of the software requirements and iteratively enhance the evolving versions until the full system is implemented. At each iteration, design modifications are made and new functional capabilities are added.  In incremental development, system functionality is sliced into increments (portions), whereby in each increment, a slice of functionality is delivered. The whole idea is to deliver a “working” version of a feature (however minimal) to the users so we can get feedback early in the process. Compare that with having to build a fully functional feature for few months, only to find out that what has been built doesn’t meet the users’ needs. Iterative and Incremental Development Model Example: Let’s see an example of how iterative and incremental development and delivery works in an agile context. Suppose you want to add a new login functionality to a website, and you decide you want to develop this using agile methodology, working in two-week delivery cycles (iterations). First iteration: The minimum working version of the login functionality worth delivering to users would be  Create a web page where the users will see the login form Add a login form with just two fields (username and password) and a login button, i. e. just a normal HTML form with no styling or validation Create a “welcome” page so when a users log in, they will see a message. This is the first version (working but limited in functionality) of the software delivered in iteration one. This basic login feature went through design, development, and testing and delivered at the end of the iteration. Second iteration: In next iteration, we want to enhance the login functionality of what was built in the last iteration. We may decide to do  Build validation rules around input parameters Add some CSS so the login form looks pretty Display a message when user tries to login with invalid credentialsNow we have added new and enhanced existing functionality. In other words, we have incremented the existing login functionality, and we did so in this iteration. Third iteration: In iteration three, we can yet again increment our login functionality, by adding  Forgotten password functionality “Remember me” checkbox Redirection mechanism to redirect to appropriate pages when users log in (rather than just a “welcome” page developed in the first iteration)As you can see, in each iteration, we have incremented the login functionality by adding new useful features for the users. By doing so, we can get quick feedback from the users so we can add or enhance its functionality. Over a number of iterations, we finally deliver the full solution. "
    }, {
    "id": 82,
    "url": "localhost:4000/cookies-selenium-webdriver-rest-assured/",
    "title": "How To Pass Cookies From Selenium WebDriver To Rest-Assured",
    "body": "2017/08/10 - How to pass cookies from Selenium WebDriver to Rest-Assured? When you do automated testing at API and UI layer, there could be situations where you are doing both and that you need to pass properties from your API test to you UI test or vice versa. In this example, we show how to pass cookies from Selenium WebDriver to Rest-Assured using Java.  WebDriver - How to restore cookies in a new browser window WebDriver - How to create, update and delete cookiesPass Cookies from Selenium to Rest-Assured: 12345678910111213141516171819202122232425262728293031323334353637383940import io. restassured. RestAssured;import io. restassured. http. Cookies;import org. openqa. selenium. Cookie;import org. openqa. selenium. WebDriver;import org. openqa. selenium. chrome. ChromeDriver;import org. testng. annotations. Test;import java. util. ArrayList;import java. util. List;import java. util. Set;import static io. restassured. RestAssured. given;public class RestAssuredWebDriverCookie {  @Test  public void cookieTest() {    WebDriver driver = new ChromeDriver();    driver. navigate(). to( http://www. someurl. com );    Set&lt;Cookie&gt; seleniumCookies = driver. manage(). getCookies();    // This is where the Cookies will live going forward    List restAssuredCookies = new ArrayList();    // Simply pull all the cookies into Rest-Assured    for (org. openqa. selenium. Cookie cookie : seleniumCookies) {      restAssuredCookies. add(new io. restassured. http. Cookie. Builder(cookie. getName(), cookie. getValue()). build());    }    // Pass them into the Rest-Assured Call    given(). spec(RestAssured. requestSpecification)        . basePath( /some-path )        . cookies(new Cookies(restAssuredCookies))        . queryParam( id ,  1234 )        . get()        . then(). statusCode(200);  }}"
    }, {
    "id": 83,
    "url": "localhost:4000/how-does-testing-fit-within-agile-development/",
    "title": "How Does Testing Fit Within Agile Development?",
    "body": "2017/08/08 - Question:  I’m just wondering how you carry out testing activities in an agile environment? What processes, tools, and techniques are used in agile testing? Answer: Testing in agile is not just the testing activities typically carried out in the traditional model, but rather spans the full spectrum of quality assurance practices. In fact, this is why testers in agile are normally referred to as QAs. In agile, testing supports development in parallel. Testing in agile is embedded within the development work. i. e. we test as we build, rather than having a phase of testing activities. Testing in agile has two primary goals:  a – defect prevention rather than defect detection b – providing fast feedback to the team by means of automated testsTesting in agile differs from traditional methods in that there is no time to write test cases and test plans ahead of the sprint, therefore, exploratory testing (mind maps, heuristics, and oracles), risk based testing and automated regression testing prevail. Typically testers get involved from the very beginning of development, starting from reviewing user stories to ensure they adhere to the INVEST principle. Participate in 3-amigos session to flesh out the details of the stories and acceptance criteria. If the organization is implementing BDD, scenarios can be written in Gherkin language to then be hooked with step definitions (using cucumber or similar tool) which exercise the system under test. The automated tests (unit/api) are run in a CI/CD pipeline as part of every new build. UI automated tests can also be part of the build in CI/CD pipeline as long as they run relatively quick. "
    }, {
    "id": 84,
    "url": "localhost:4000/reactjs-test-automation-tools/",
    "title": "Test Automation Tools for Testing ReactJS Applications",
    "body": "2017/08/04 - I am planning to test a ReactJS application and wanted to find out what is the best tool out there in the market to carry out end-to-end tests? After doing a little research I found that there are many tools available to test ReactJS applications but what is the best one to use for end-to-end tests? Answer: There is no concept of “best tool” when it comes to automated testing. It all depends on the context of your project and what you want to achieve from the tool. I have tested both Angular and ReactJS applications and I only used Selenium WebDriver as the test automation tool to create end-to-end tests. However, there seems to be a growing number of JS based test automation tools and frameworks to test ReactJS applications. These tools seem to be very popular amongst “front-end” developers as they are based on the language developers are familiar with, JavaScript. That means that not only testers can write automated end-to-end tests, but developers can also help when there is not enough time or resource. Related:  Run automated mobile tests on multiple devices Useful tools to test websites on mobile devices Appium starter projectBelow is a list of test automation tools and frameworks to test ReactJS application: Test Automation Tools for ReactJS: WebDriver. io: WebdriverIO is an open source testing utility for Node. js. It makes it possible to write super easy selenium tests with Javascript in your favorite BDD or TDD test framework. Nightwatch. js: Nightwatch. js is an easy to use Node. js based End-to-End (E2E) testing solution for browser-based apps and websites. It uses the powerful W3C WebDriver API to perform commands and assertions on DOM elements. NightmareJS: Nightmare is a high-level browser automation library from Segment. Under the covers, it uses Electron, which is similar to PhantomJS but roughly twice as fast and more modern. Niffy is a perceptual diffing tool built on Nightmare. It helps you detect UI changes and bugs across releases of your web app. Daydream is a complimentary chrome extension built by @stevenmiller888 that generates Nightmare scripts for you while you browse. Jest: Jest is used by Facebook to test all JavaScript code including React applications. One of Jest’s philosophies is to provide an integrated “zero-configuration” experience. We observed that when engineers are provided with ready-to-use tools, they end up writing more tests, which in turn results in more stable and healthy code bases.  Jest also parallelizes test runs across workers to maximize performance. Mocha: While Jest is popular amongst Facebook developers to write automated tests for ReactJS applications, it has some issues (slow, mocking is confusing). Mocha has become a popular alternative. It’s more painful to set up but may be worth a look. I expect it to become more popular in the future unless Jest overcomes some of those main issues. See Testing React Web Apps with Mocha to get started. Protractor: For acceptance testing, you can consider Protector. It’s primarily an Angular tool built on top of Selenium and it comes with a nicer API. Fortunately, it’s possible to configure it to work with React. See Testing React apps with Protractor. The nice thing about this approach is that this will allow you to test your application against a wide variety of browsers. Enzyme: Enzyme is a JavaScript Testing utility for React that makes it easier to assert, manipulate, and traverse your React Components’ output. Originally developed by Airbnb, is getting more and more popular. You can use it with any test runner (mocha, jasmine,…) and there is a helpful chai-enzyme plugin. Enzyme + Mocha seems to be the best combination to test web applications written in ReactJS. It is relatively easy to learn, even for someone new to ReactJS and Mocha can easily cope with these tools in a short time. "
    }, {
    "id": 85,
    "url": "localhost:4000/what-is-the-difference-between-agile-testing-and-continuous-testing/",
    "title": "What is the Difference Between Agile Testing and Continuous Testing?",
    "body": "2017/08/02 - Question:  What is the main difference between Agile Testing and Continuous Testing?  In my opinion, Agile Testing ties into the Agile effort development teams are moving towards, and how testing teams can keep up with the increase in the speed and amount of code being developed. Whereas Continuous Testing talks about the continuous ability to test code being developed.  What are testing teams trying to achieve? Are Agile Testing and Continuous Testing one in the same thing, or are there differences between the two approaches? Answer: You are looking at two problems at the same time, how to test in agile teams and how to achieve continuous delivery and in effect continuous testing. For start, there is no testing team in agile! IMO, the main difference being Frequent Interval vs. Continuous Automation. Considering that in an Agile approach you aim to release your software on (usually) bi-weekly basis, I don’t see any difference among the two, being a constant and continuous testing a must have, at any testing level. In other words, the whole team (not only the Engineers) has to figure out a way to test the new code locally, the integration of it in the new branch, the non-regression of old functionalities and the definitely the new version itself. https://www. testingexcellence. com/difference-between-greenblue-deployments-ab-testing-and-canary-releases/ A best practice I recommend is to start testing even before starting coding (e. g. requirements analysis), with QA Engineers working very closely with Product Managers and User Designers. Agile testing may or may not be continuous as in nightly build validation but rather an overall paradigm. Agile testing is validating new deliveries while Continuous Automation for example on a nightly basis may also validate environment changes, etc. which may be outside the scope of the project. In similar terms, you can have continuous delivery/testing even if you don’t use Agile principles for software development. Continuous testing is more defined and more in focus as new “buzz word” in testing, as more people in the organization are interested to ensure testing happens – at a particular time, within a timeframe and with some expected quality of automation. Agile Testing:to ensure delivering the business value desired by the customer at frequent intervals, working at a sustainable pace. Continuous Testing:A process of executing automated tests as part of the software delivery pipeline to obtain immediate feedback on the business risks associated with a software release candidate. So, it’s more of what software development process you follow and how you want to deliver that’s going to impact your choice in “whether to have Agile testing?” i. e. “Do we need agile development?” And “Do we need Continuous Testing?” i. e. “Do we need continuous Delivery?” "
    }, {
    "id": 86,
    "url": "localhost:4000/difference-between-greenblue-deployments-ab-testing-and-canary-releases/",
    "title": "Difference Between Green/Blue Deployments, A/B Testing and Canary Releases",
    "body": "2017/07/28 - This article describes the differences between Green/Blue deployments, A/B testing and Canary releases. Article was originally written by Christian Posta Blue-green Deployments, A/B Testing, and Canary Releases: A lot of teams I talk to recently are very interested in “DevOps” (whatever that means… seems to mean different things to different people?) and when we sit down and talk about what that really means, the direction of the conversation can go down many interesting paths. And some times, the path it goes down makes people feel very uncomfortable. I was talking with a team a while back about deployment best practices, hot deployments, rollbacks etc and when I mentioned blue-green deployments, they became a bit queasy. Another team couldn’t understand why doing something they’ve always done was not such a very good thing. blue-green deployments have been practiced at places like Amazon for 10+ years. They’re a safe, proven, method. Now, blue-green deployments are not a silver bullet, but there’s an element of usefulness to them. But what about A/B testing then? Or even Canary testing? With all of the #microservices, DevOps, and cloud-native talk, there’s a lot of discussion about them, but I wanted to clarify their differences. https://www. testingexcellence. com/what-is-the-difference-between-agile-testing-and-continuous-testing/ Blue Green Deployments: Please see Martin Fowler’s link about blue-green deployments. It gives the overall gist. It’s basically a technique for releasing your application in a predictable manner with a goal of reducing any downtime associated with a release. It’s a quick way to prime your app before releasing, and also quickly roll back if you find issues. Simply, you have two identical environments (infrastructure) with the “green” environment hosting the current production apps (app1 version1, app2 version1, app3 version1 for example): Now, when you’re ready to make a change to app2 for example and upgrade it to v2, you’d do so in the “blue environment”. In that environment you deploy the new version of the app, run smoke tests, and any other tests (including those to exercise/prime the OS, cache, CPU, etc). When things look good, you change the load-balancer/reverse proxy/router to point to the blue environment: You monitor for any failures or exceptions because of the release. If everything looks good, you can eventually shut down the green environment and use it to stage any new releases. If not, you can quickly rollback to the green environment by pointing the loadbalancer back. Sounds good in theory. But there are things to watch out for.  Long running transactions in the green environment. When you switch over to blue, you have to gracefully handle those outstanding transactions as well as the new ones. This also can become troublesome if your DB backends cannot handle this (see below) Enterprise deployments are not typically amenable to “microservice” style deployments – that is, you may have a hybrid of microservice style apps, and some traditional, difficult-to-change-apps working together. Coordinating between the two for a blue-green deployment can still lead to downtime Database migrations can get really tricky and would have to be migrated/rolledback alongside the app deployments. There are good tools and techniques for doing this, but in an environment with traditional RDBMS, NoSQL, and file-system backed DBs, these things really need to be thought through ahead of time; blindly saying you’re doing Blue Green deployments doesn’t help anything – actually could hurt.  You need to have the infrastructure to do this If you try to do this on non-isolated infrastructure (VMs, Docker, etc), you run the risk of destroying your blue AND green environmentsAs I’ve said, there are good techniques to overcome these challenges and make this deployment style work out very nicely, including plugging into a continuous deployment pipeline, but don’t jump into it trivially. A/B Testing: A/B testing is NOT blue-green deployments. I’ve run into groups that mistake this. A/B testing is a way of testing features in your application for various reasons like usability, popularity, noticeability, etc, and how those factors influence the bottom line. It’s usually associated with UI parts of the app, but of course, the backend services need to be available to do this. You can implement this with application-level switches (ie, smart logic that knows when to display certain UI controls), static switches (in the application), and also use Canary releases (as discussed below).  The difference between blue-green deployments and A/B testing is A/B testing is for measuring functionality in the app. Blue-green deployments are about releasing new software safely and rolling back predictably. You can obviously combine them: use blue-green deployments to deploy new features in an app that can be used for A/B testing. Canary releases: Lastly, Canary releases are a way of sending out a new version of your app into production that plays the role of a “canary” to get an idea of how it will perform (integrate with other apps, CPU, memory, disk usage, etc). It’s another release strategy that can mitigate the fact that regardless of the immense level of testing you do in lower environments you will still have some bugs in production. Canary releases let you test the waters before pulling the trigger on a full release.  The faster feedback you get, the faster you can fail the deployment, or proceed cautiously. For some of the same reasons as the blue-green deployments, be careful of things above to watch out for; ie, database changes can still trip you up. Further information: Are there scenarios where canary release is preferred over blue/green deployments, and vice versa?: Blue-green releasing is simpler and faster. You can do a blue-green release if you’ve tested the new version in a testing environment and are very certain that the new version will function correctly in production. Always using feature toggles is a good way to increase your confidence in a new version, since the new version functions exactly like the old until someone flips a feature toggle. Breaking your application into small, independently releasable services is another since there is less to test and less that can break. You need to do a canary release if you’re not completely certain that the new version will function correctly in production. Even if you are a thorough tester, the Internet is a large and complex place and is always coming up with unexpected challenges. Even if you use feature toggles, one might be implemented incorrectly. Deployment automation takes effort, so most organizations will plan to use one strategy or the other every time. So do blue-green deployment if you’re committed to practices that allow you to be confident in doing so. Otherwise, send out the canary. The essence of blue-green is deploying all at once and the essence of canary deployment is deploying incrementally, so given a single pool of users I can’t think of a process that I would describe as doing both at the same time. If you had multiple independent pools of users, e. g. using different regional data centers, you could do blue-green within each data center and canary across data centers. Although if you didn’t need canary deployment within a data center, you probably wouldn’t need it across data centers. "
    }, {
    "id": 87,
    "url": "localhost:4000/what-are-scrum-ceremonies/",
    "title": "What Are Scrum Ceremonies?",
    "body": "2017/07/20 - Scrum has four main ceremonies that bring structure to each sprint:  Sprint planning: A team planning meeting that determines what to complete in the coming sprint.  Daily stand-up: Also known as a daily scrum, a 15-minute mini-meeting for the software team to sync.  Sprint demo: A sharing meeting where the team shows what they’ve shipped in that sprint.  Sprint retrospective: A review of what did and didn’t go well with actions to make the next sprint better. Sprint Planning: The purpose of the Sprint Planning ceremony is to set up the entire team for success throughout the sprint. The required participants are:  Development Team ScrumMaster Product OwnerThe sprint planning happens just before the sprint begins and usually lasts one to two hours. Coming into the meeting, the product owner will have a prioritized list of the product backlog items. The product owner discusses each item or user story with the development team, and the group collectively estimates the effort involved. The development team will then make a sprint forecast, normally based on the team’s velocity, outlining how much work the team can complete from the product backlog. That body of work then becomes the sprint backlog. https://www. testingexcellence. com/difference-between-scrum-kanban-xp-agile/ Does Kanban have a Sprint Planning Ceremony? Yes, Kanban teams also plan, but they are not on a fixed iteration schedule with formal sprint planning. Sprint Planning and Story Refinement Some organizations use the sprint planning meeting to flesh out the details of each user story. In fact, it is highly encouraged that all participants engage in effective discussions so as to ensure everyone understands the scope of the work. Other organizations have a separate Story Refinement sessions where they discuss the details of each story along with a rough estimate of how much work is involved in delivering the stories. Normally stories are broken down into a number of small tasks. By having these separate story refinement sessions, typically in advance of the next sprint, the sprint planning session becomes shorter in duration and is aimed at only accepting stories into the upcoming sprint. **Related:**https://www. testingexcellence. com/testing-quality-assurance-agile/Daily Stand-up: The daily stand-up meeting is designed to quickly inform everyone of what’s going on across the team. It is not supposed to be a detailed status meeting. The tone should be light and fun, but informative. Have each team member answer the following questions:  What did I complete yesterday? What will I work on today? Am I blocked by anything?The daily stand-up occurs once a day, normally in the morning and requires the development team, ScrumMaster, and Product Owner to attend. It is advised that the duration is no more than 15 minutes, hence the purpose of standing up to keep the meeting short. One of the advantages of the daily stand-up meeting is that it makes the individuals be true to themselves. There’s an implicit accountability in reporting what work you completed yesterday in front of your peers. No one wants to be the team member who is constantly doing the same thing and not making progress. Distributed teams typically use video conferencing or group chat to close the distance gap. ## Sprint DemoAt the end of the sprint, each team gets to demo or showcase their newly developed features or just generally what they worked on during the sprint. This is the time for the team to celebrate their accomplishments, demonstrate work finished within the iteration, and get immediate feedback from project stakeholders. The duration can vary on the number of items to showcase per team. The work is usually showcased to participants of the respective team, namely the development team, ScrumMaster, and Product Owner as well as other teams and project stakeholders. For the demo to be of any value and interest to others, the work should be _fully_ demonstrable and meet the team's quality bar to be considered complete and ready to showcase in the review. Is Product Demo applicable to Kanban?  Like planning, review for Kanban teams should be aligned with team milestones rather than on a fixed cadence. Sprint Retrospective: And finally on to the sprint retrospective which occurs at the end of the sprint, typically after the sprint demo and lasts about one hour. Participants are the development team, ScrumMaster, and Product Owner. Agile is about continuous improvement and getting rapid feedback to make the product and development culture better.  Retrospectives help the team understand what worked well–and what didn’t.  Continuous improvement is what sustains and drives development within an agile team, and retrospectives are a key part of that. Sprint retrospectives shouldn’t be just for making complaints without taking action. Retrospectives are a means to identify what’s working so the team can continue to focus on those areas and also what’s not working so the team can discuss and collaborate to find creative solutions to the problems. Does Kanban also have Sprint Retrospective? Scrum teams do sprint retrospective based on a fixed cadence. Nothing stops Kanban teams to benefit from occasional retrospectives, too. https://www. testingexcellence. com/can-testers-add-value-agile-projects/ "
    }, {
    "id": 88,
    "url": "localhost:4000/test-oracles-test-heuristics/",
    "title": "What are Test Oracles and Test Heuristics?",
    "body": "2017/07/10 - Within the world of testing and quality assurance, we often hear the words Test Oracles and Test Heuristics, but what are they and how we can implement them into our daily testing activities? Let’s see a very nice explanation of test oracles and test heuristics by Katrina Clokie Test Heuristics: Imagine that I want to eat a pickle. My pickles are stored in a large glass jar. In my household, the last person to eat a pickle was my husband. He has closed the jar tight. On my first attempt, I fail to open it. What do I do next? I check that I’m turning towards the left to loosen the lid and try again. Then I retrieve a tea towel to establish a better grip when twisting the lid of the jar. Finally, in some frustration, I go and locate my husband. He successfully opens the jar. When faced with a jar that will not open there are a number of things that I know are worth trying. These are my jar opening heuristics. When I am instructed to test a software application there are a number of things that I know are worth trying. These are my test heuristics. Heuristics are simply experience-based techniques for problem-solving, learning, and discovery. Where an exhaustive search is impractical, heuristic methods are used to speed up the process of finding a satisfactory solution. Examples of this method include using a rule of thumb, an educated guess, an intuitive judgment, or common sense. Example: Suppose you are testing an e-commerce website. Most e-commerce websites’ search results page contains filters and sort functionalities. Through years of experience testing e-commerce websites, I have come to learn that combining filters and sort options are likely to reveal interesting bugs, as this has been the case many times, therefore, on my next project, I intuitively will test some scenarios related to combining filters and sort options. Test Oracles: Imagine that I go to lunch with a friend. I enter a restaurant at 12 pm on Thursday. After an hour enjoying a meal, I leave the restaurant at 1 pm on Friday. Although I have experienced only one hour, the world around me has shifted by a day. How do I know there’s a problem here? I may have several notifications on my mobile phone from friends and family wondering where I am. I may have a parking ticket. I may spot somebody reading a Friday newspaper. There are a number of ways in which I might determine that I have skipped a day of my life. These are my time traveling oracles. There are a number of ways in which I might determine that I have discovered a bug in a software application. These are my test oracles. Oracles are simply the principle or mechanism by which we recognize a problem. Test Oracles are basically your expected results. Example: Suppose you are testing the login functionality of a website. First, you might check with a valid username and valid password and expect _to see either a redirect to my account page or redirect to the page prior to the login. However, after you attempt to login and you see an error 500 response, you _know that something has gone wrong. Oracles and Heuristics in Agile and Exploratory Testing: Both Test Oracles and Test Heuristics are vital when it comes to exploratory testing in an agile environment. When we don’t have enough time to construct test cases and the product is continuously evolving, we can’t just rely on pre-designed test scripts, we have to use our domain knowledge (Test Oracles) and previous testing experience (Test Heuristics) to be able to quickly design and execute tests simultaneously while also learning about the product. "
    }, {
    "id": 89,
    "url": "localhost:4000/make-testing-quality-everyones-responsibility/",
    "title": "How to Make Testing and Quality Everyone's Responsibility?",
    "body": "2017/06/21 - I want to work in a properly cross-functional team. I’ve heard they exist. I’ve never seen one, but I’ve heard that they exist. In my understanding, this cross-functional unicorn would see all members contributing to all aspects of the delivery, regardless of “speciality” or “discipline” . But that comes with some prerequisites. Before we all fall under the “developer” title, what must we be able to do? Well. Developers must understand how to test software, beyond unit testing. Testers must be able to contribute more than just testing. And testing, I realize encapsulates a huge amount of activities. But consider this; in Agile, we don’t usually consider something done until it’s coded, tested, integrated and deployed to a production-like, if not production environment (or a subset of those). So does it matter who does the work? What’s the point in segregating responsibility through explicitly defined roles? To be blunt, I don’t think it’s possible to contribute to delivery without contributing production code. Putting a plaster on the developer’s knee when they fall of their skateboard because no one taught them how to skate in the first place is reactive, rather pro-active. Automated Testing - Setting the Right Expectations I’m not one of those “do, do, do” guys. But testing is a negative activity. It doesn’t add tangible business value. And by that, I mean that the testing is what most businesses attempt to negotiate on when they want something done quickly. I accept that it’s possible to make testing more visible and valuable to a business owner. I don’t get the feeling that this is a practice in general use. I understand the value that good testing contributes to a project. I also understand the lack of value that bad testing contributes to a project. If we merged the roles, values, experiences, and mindsets of developer and tester, what would happen? Well, as I mentioned at the start, I haven’t worked with a team like this before, so I’m just kinda throwing some thoughts out there. It feels like we would catch more problems at the point of writing the code. It feels like when we forecast, we would be more inclined to build testing into our estimates. It feels like we would find better ways to test stuff. It seems like we would implement things with testing in mind, rather than an external “conscience” that testers often become for developers. It feels like testing would merge into development, rather than it being a separate practice. Does testing add value to a delivery cycle? Yes. Absolutely. At the very least it gives a safety net that allows me to confidently add or amend features if of course it’s done “right”. At most, it “proves” that my application works. Does a tester add value to a delivery cycle? It depends. It depends on two things. Firstly the developers that are involved in delivery. Secondly, the testers involved in delivery. Do the developers understand what it is to test something? If they do, what does the tester add? I’d argue not much if they can’t cut some production quality code. But then again I only know a handful of developers I’d trust with testing. Most just don’t think about testing beyond unit tests, because there’s a tester in the team doing the thinking for them. Do the testers contribute some production quality code, as well as testing? If they do, why aren’t they just a developer? If they don’t what do they add? The biggest two barriers I see to this happening, at least in the UK, is the general quality of testing done, and the lack of developers who get how and what to test outside of unit tests. My challenge is to developers; start understanding what the testers in your team do. What do they do that you don’t? Probably the big thing is the amount of context-specific analytical questioning they ask of requirements. They probably rarely accept that what was written is what was meant. They probably think of more than just the “happy path” through an application. They probably think of the “customers” that hold a stake in the User Story you’re building other than the one written on the front of the record card (the guys managing it in production, the training team, the help desk guys etc). What more could you do to get into a mindset of making testing part of development rather than a person in your team? Testers. A weird challenge. Coach yourselves out of a job? I don’t know. I’m still thinking about it. Pass on an approach, a mindset, not a role? Quality is everyone’s responsibility, will we really be in a position to build consistently high-quality software when we segregate responsibility for testing to a single specialist role, instead of a mindset adopted by all? Is having testing as a mindset rather than a person not quite enough? Are we only really successful in blending developer and tester roles when testing slips into the consciousness of the developer and it becomes a muscle memory of sorts? Article originally published by Steve Walton Source: https://www. linkedin. com/pulse/testing-mindset-person-steve-walton "
    }, {
    "id": 90,
    "url": "localhost:4000/parse-json-response-using-jmeters-json-extractor/",
    "title": "How to Parse a JSON Response Using JMeter's JSON Extractor",
    "body": "2017/06/14 - As of JMeter 3. 0, it’s far easier to extract data from JSON responses using the JSON variable extractor. JSON is an extremely simple data format which has taken over XML a few years ago. An increasing number of REST APIs and servers, are using JSON as their primary data exchange format. Here, we will use JMeter to parse the JSON response. If you don’t have JMeter installed, read this article which explains how to install JMeter on Mac OS. Related:  How to Pass Variables Between Thread Groups How to Send a JSON File as Request in BodySuppose we have a JSON response as follows: 1234567891011121314151617181920212223{   store : {     book : [      {         category :  reference ,         author :  Nigel Rees ,         title :  Sayings of the Century ,         price : 8. 95      },      {         category :  fiction ,         author :  Evelyn Waugh ,         title :  Sword of Honour ,         price : 12. 99      }    ],     bicycle : {       color :  red ,       price : 19. 95    }  },   expensive : 10}To parse the above JSON with JMeter, we need to add the JSON Extractor to our test plan. Right click on Test Plan –&gt; Add –&gt; Post Processors –&gt; JSON Extractor Now, we should see the following view: In the JSON Path expressions field, we can insert our JSON path to parse the JSON response Here are some example Json Path expressions that can be used to extract data from the Json document exposed above: JsonPathResult$. store. book[*]. authorThe authors of all books$. . authorAll authors$. store. *All things, both books and bicycles$. store. . priceThe price of everything$. . book[0,1]The first two books$. . book[:2]All books from index 0 (inclusive) until index 2 (exclusive)$. . book[2:]Book number two from tail$. . book[?(@. isbn)]All books with an ISBN number$. store. book[?(@. price &lt; 10)]All books in store cheaper than 10$. . book[?(@. price &lt;= $[‘expensive’])]All books in store that are not “expensive”$. . book[?(@. author =~ /. *REES/i)]All books matching regex (ignore case)$. . *Give me every thing$. . book. length()The number of books"
    }, {
    "id": 91,
    "url": "localhost:4000/install-jmeter-extra-plugins-mac-os-using-homebrew/",
    "title": "How to Install JMeter With Extra Plugins on Mac OS Using HomeBrew",
    "body": "2017/06/13 - There are multiple approaches to installing JMeter on Mac OS. You can either do it manually just like we do in windows (i. e. downloading the binaries and executing the installer) or you can follow a more simplistic method to install JMeter via HomeBrew. Install JMeter on Mac OS With HomeBrew: 1. Open a Mac Terminal, where we will be running all the commands. 2.  First, check to see if HomeBrew is installed on your Mac by executing this command. You can either run brew help or brew -v 3. If HomeBrew is not installed, run the following command to install HomeBrew on Mac 1ruby -e  $(curl -fsSL https://raw. githubusercontent. com/Homebrew/install/master/install) Once HomeBrew is installed, we can continue to install JMeter. 4. To install JMeter without the extra plugins, run the following command 1brew install jmeter5. To install JMeter with all the extra plugins, run the following command 1brew install jmeter --with-plugins6. Finally, verify the installation by executing JMeter -v 7. Run JMeter using JMeter which should load the JMeter GUI. "
    }, {
    "id": 92,
    "url": "localhost:4000/query-partition-keys-dynamodb/",
    "title": "How To Query For All Partition Keys in DynamoDB?",
    "body": "2017/06/12 - Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. With DynamoDB, you can create database tables that can store and retrieve any amount of data, and serve any level of request traffic. How to put data in AWS Kinesis Stream The following code shows how to query a DynamoDB to retrieve all partition keys. 123456789101112131415161718192021222324252627282930313233343536373839404142434445import com. amazonaws. client. builder. AwsClientBuilder;import com. amazonaws. services. dynamodbv2. AmazonDynamoDB;import com. amazonaws. services. dynamodbv2. AmazonDynamoDBClientBuilder;import com. amazonaws. services. dynamodbv2. model. AttributeValue;import com. amazonaws. services. dynamodbv2. model. ScanRequest;import com. amazonaws. services. dynamodbv2. model. ScanResult;import java. util. ArrayList;import java. util. List;import java. util. Map;public class PartitionKeys {  static String serviceEndpoint =  http://dynamodb. eu-west-1. amazonaws. com ;  static String region =  eu-west-1 ;  static AmazonDynamoDB client = AmazonDynamoDBClientBuilder. standard()      . withEndpointConfiguration(new AwsClientBuilder. EndpointConfiguration(serviceEndpoint, region))      . build();  public static List&lt;String&gt; getAllPartitionKeys() {    List&lt;String&gt; partitionKeys = new ArrayList&lt;&gt;(0);    // dynamo returns results in chunks -     // you'll need this to get the next one    Map&lt;String, AttributeValue&gt; lastKeyEvaluated = null;    do {      ScanRequest scanRequest = new ScanRequest()          . withTableName( YOUR_TABLE_NAME )          . withExclusiveStartKey(lastKeyEvaluated);      ScanResult result = client. scan(scanRequest);      for (Map&lt;String, AttributeValue&gt; item : result. getItems()){        // for each item in the result set, examine the partition key        // to determine if it's a match        String key = item. get( YOUR_PARTITION_KEY ). getS();        partitionKeys. add(key);      }      lastKeyEvaluated = result. getLastEvaluatedKey();    } while (lastKeyEvaluated != null);    return partitionKeys;  }}"
    }, {
    "id": 93,
    "url": "localhost:4000/get-current-working-directory-java/",
    "title": "How to Get the Current Working Directory in Java",
    "body": "2017/06/12 - The current working directory means the root folder of your current Java project. We can get the current working directory in Java using the following system property function: 1String cwd = System. getProperty( user. dir );Example: 123456789public class CurrentWorkingDirectory {  public static void main (String args[]) {    String cwd = System. getProperty( user. dir );    System. out. println( Current working directory :   + cwd);  }}Output:Current working directory: C:\workspace\Java4Testers Further reading  Convert List to Array in Java Extract Numbers From String Using Java Regular Expressions Convert String to Int in Java With Examples Purpose of Overriding toString() Method in Java"
    }, {
    "id": 94,
    "url": "localhost:4000/encode-decode-json-byte-array/",
    "title": "How to Encode and Decode JSON Byte Array",
    "body": "2017/06/12 - The typical way to send binary in JSON is to base64 encode it. Java provides different ways to Base64 encode and decode a byte[]. One of these is DatatypeConverter. Suppose we have a JSON Array as listed below: 1234567891011{ menu : {  id :  file ,  value :  File ,  popup : {   menuitem : [   { value :  New ,  onclick :  CreateNewDoc() },   { value :  Open ,  onclick :  OpenDoc() },   { value :  Close ,  onclick :  CloseDoc() }  ] }}}Encode JSON as Base64: To encode the above JSON, we would use 1String base64Encoded = DatatypeConverter. printBase64Binary(jsonBytes);Decode Base64 JSON: To decode a base64 encoded JSON, we would use 1byte[] base64Decoded = DatatypeConverter. parseBase64Binary(base64Encoded);Example code: 12345678910111213141516171819202122232425262728import javax. xml. bind. DatatypeConverter;public class JsonEncodeDecode {  public static void main(String[] args) {    String json =  {\ menu\ : {\n  +          \ id\ : \ file\ ,\n  +          \ value\ : \ File\ ,\n  +          \ popup\ : {\n  +           \ menuitem\ : [\n  +            {\ value\ : \ New\ , \ onclick\ : \ CreateNewDoc()\ },\n  +            {\ value\ : \ Open\ , \ onclick\ : \ OpenDoc()\ },\n  +            {\ value\ : \ Close\ , \ onclick\ : \ CloseDoc()\ }\n  +           ]\n  +          }\n  +         }} ;    byte[] bytes = json. getBytes();    String base64Encoded = DatatypeConverter. printBase64Binary(bytes);    System. out. println( Encoded Json:\n );    System. out. println(base64Encoded +  \n );    byte[] base64Decoded = DatatypeConverter. parseBase64Binary(base64Encoded);    System. out. println( Decoded Json:\n );    System. out. println(new String(base64Decoded));  }}Output:Encoded JSON eyJtZW51IjogewogICJpZCI6ICJmaWxlIiwKICAidmFsdW Decoded JSON 1234567891011{ menu : {  id :  file ,  value :  File ,  popup : {   menuitem : [   { value :  New ,  onclick :  CreateNewDoc() },   { value :  Open ,  onclick :  OpenDoc() },   { value :  Close ,  onclick :  CloseDoc() }  ] }}}Note: the encoded JSON_ is truncated for sake of neatness, otherwise it’s a very long string. _ https://www. testingexcellence. com/parse-json-response-rest-assured/ "
    }, {
    "id": 95,
    "url": "localhost:4000/easiest-way-read-properties-file-java-resourcebundle/",
    "title": "Easiest Way to Read Properties File in Java With ResourceBundle",
    "body": "2017/06/12 - There are a number of ways to load and read properties file from Java, but the easiest and most straightforward is using the ResourceBundle class. First, you need to create a properties file under resources folder. In a typical Maven project, this looks like the following  In this example, the properties file is called config. properties The content of the properties file is in the format of name=value Example: 1browser=chromeIn a Java class, we can use the ResourceBundle class to read from the properties file: 123456789public class ReadPropertiesFile {  private static ResourceBundle rb = ResourceBundle. getBundle( config );  public static void main(String[] args) {    String browser = rb. getString( browser );    System. out. println(browser);  }}Output: 1chromeFurther reading  How to Convert Java Map to JSON How to Generate Random Numbers in Java How to Loop Over ArrayList in Java"
    }, {
    "id": 96,
    "url": "localhost:4000/selenium-webdriver-java-8/",
    "title": "Selenium WebDriver With Java 8 - Lambda Expressions and Collections Stream",
    "body": "2017/06/10 - From Selenium 3. 0, minimum Java version is 8. In this article, we illustrate how to use Java 8 features like Lambda expression and Collections Stream to simplify Selenium WebDriver code. Lambda Expression: Java lambda expressions are Java’s first step into functional programming. A Java lambda expression is thus a function which can be created without belonging to any class. A lambda expression can be passed around as if it was an object and executed on demand.  How to read properties file in Java 4 different ways to iterate through a map in Java How to get the current working directory in JavaLet’s say you have an ArrayList and you want to print all its elements. Without lambda expressions, you would use: 123456789List&lt;String&gt; list=new ArrayList();list. add( Apple );list. add( Orange );list. add( Grape );for(String item:list){ System. out. println(item);}Using Lambda expression in Java 8, we can rewrite the same loop using forEach 1list. forEach(item -&gt; System. out. println(item));Collections Stream: Collections Stream is a new feature in Java 8. A stream represents a sequence of elements and supports different kind of operations from a collection. So, let’s say you want to check whether an option is available or not in a drop-down list: 1234Select select=new Select(driver. findElement(By. id( selectId )));//Validating drop-down option without For Loopselect. getOptions(). stream(). anyMatch(item-&gt;item. getText(). equals( Option1 ))Filtering WebElements Using Regular Expression: 12345List&lt;WebElement&gt; elements=driver. findElements( By. xpath( //input[@type='checkbox'] ));elements. stream()   . filter(element-&gt;Pattern. compile( check_(\\d+)_box ). matcher(element. getAttribute( id )). matches())   . forEach(element-&gt;element. click());https://www. testingexcellence. com/webdriver-explicit-implicit-fluent-wait/ "
    }, {
    "id": 97,
    "url": "localhost:4000/webdriver-explicit-implicit-fluent-wait/",
    "title": "WebDriver Implicit, Explicit and Fluent Wait Examples",
    "body": "2017/06/08 - WebDriver Waits: What are WebDriver waits? What is the difference between implicit wait, explicit wait and fluent wait in WebDriver? More specifically, what is the relation between WebDriverWait and FluentWait? Here are examples of using each wait method in WebDriver with Java. Implicit Wait: An implicit wait is to tell WebDriver to poll the DOM for a certain amount of time when trying to find an element or elements if they are not immediately available. The default setting is 0. Once set, the implicit wait is set for the life of the WebDriver object instance.  How to wait for a page to load in WebDriver WebDriver wait for AJAX call to complete WebDriver - open new browser window with JavascriptExample of using implicit wait 1234WebDriver driver = new FirefoxDriver();driver. manage(). timeouts(). implicitlyWait(10, TimeUnit. SECONDS);driver. get( http://somedomain/slow_loading_url );WebElement dynamicElement = driver. findElement(By. id( dynamicElement ));When should we use implicit waits? Normally, it is not recommended to use implicit waits, when we can use explicit waits or fluent waits. Explicit Wait: An explicit wait is a code that you define to wait for a certain condition to occur before proceeding further in the code. WebDriverWait by default calls the ExpectedCondition every 500 milliseconds until it returns successfully. Example of using explicit wait 1234WebDriver driver = new FirefoxDriver();driver. get( http://somedomain/someurl );WebElement dynamicElement = (new WebDriverWait(driver, 10)) . until(ExpectedConditions. presenceOfElementLocated(By. id( dynamicElement )));When should we use explicit waits? We would normally use explicit wait if an element takes a long time to load. We also used explicit wait to check CSS property of an element (presence, clickability. etc) which can change in Ajax applications. Fluent Wait: When using the FluentWait instance, we can specify:  The frequency with which FluentWait has to check the conditions defined.  Ignore specific types of exception waiting such as NoSuchElementExceptions while searching for an element on the page.  The maximum amount of time to wait for a conditionExample of using FluentWait 12345678910111213// Waiting 30 seconds for an element to be present on the page, checking// for its presence once every 5 seconds. Wait&lt;WebDriver&gt; wait = new FluentWait&lt;WebDriver&gt;(driver)  . withTimeout(30, SECONDS)  . pollingEvery(5, SECONDS)  . ignoring(NoSuchElementException. class);WebElement foo = wait. until(new Function&lt;WebDriver, WebElement&gt;() { public WebElement apply(WebDriver driver) { return driver. findElement(By. id( foo ));}});When should we use FluentWait? When you try to test the presence of an element that may appear after every x seconds/minutes. Difference Between WebDriverWait and FluentWait: WebDriverWait is a subclass of FluentWait. In FluentWait you have more options to configure, along with maximum wait time, like polling interval, exceptions to ignore etc. So, instead of waiting and then using findElement: 12345678910WebDriverWait wait = new WebDriverWait(driver, 18);wait. until(ExpectedConditions. elementToBeClickable(By. linkText( Account )));WebElement element = driver. findElement(By. linkText( Account ));element. sendKeys(Keys. CONTROL);element. click();we can use:WebElement element = wait. until(    ExpectedConditions. elementToBeClickable(By. linkText( Account )));"
    }, {
    "id": 98,
    "url": "localhost:4000/testing-microservices-beginners-guide/",
    "title": "Testing Microservices - A Beginner's Guide",
    "body": "2017/04/19 - Testing Microservices are becoming more and more important as many of the new applications are being built using Microservices architecture. Before we are able to see how to test microservices, we first need to understand what they are. What Are Microservices?: Microservice is defined as an architectural style, an approach to developing a single application as a suite of services.  Each service is defined by its characteristics some of which are:  Running in its process.  Communicating with a lightweight mechanism often with an HTTP resource API.  Independently deployable by a fully automated machinery.  Using different programming languages/technologies/DB.  Is using different data storage technologies. https://www. testingexcellence. com/http-basics/ The microservice architectural style involves developing single applications that can work together as a suite of small services, each running in its individual process and communicating with lightweight mechanisms such as an HTTP resource API. These services require bare minimum centralized management, use different data storage technologies, and can be written in different programming languages. These services, built around business capabilities, can also be deployed independently by machinery that supports fully automated deployment. Microservices characteristics:  Organized around business capability, Automated deployment, Intelligence in the endpoints rather than in service bus, Decentralized control of languages and data. How Are Microservices Different to SOA:  Service-oriented architecture(SOA): an architectural pattern in computer software design in which application components provide services to other components via a communications protocol, typically over a network.  Microservices:  a software architecture style in which complex applications are composed of small, independent processes communicating with each other using language-agnostic APIsExample: If Uber were built with an SOA, their services might be:  GetPaymentsAndDriverInformationAndMappingDataAPI AuthenticateUsersAndDriversAPIIf Uber were built with microservices, their APIs might be more like:  SubmitPaymentsService GetDriverInfoService GetMappingDataService AuthenticateUserService AuthenticateDriverServiceMore APIs, smaller sets of responsibilities. https://www. testingexcellence. com/automated-api-testing-made-easy-karate/ How to test Microservices: Unit Tests: Unit tests exercise the small pieces of software such as a function in the application to determine whether they produce the desired output given a set of known inputs. It is worth noting that unit testing alone doesn’t provide guarantees about the behavior of the system. We need other types of testing for microservices. Component Tests: Once we have carried out unit testing of all functions within a microservice, then we need to test the microservice itself in isolation. Typically, an application would be composed of a number of microservices, so in order to test in isolation, we need to mock the other microservices. Component tests will also test the interaction of microservice with its dependencies such as a database, all as one unit. Integration Tests: After we have verified the functionality of each microservice, then we need to test the inter-service communications. An integration test verifies the communication paths and interactions between components to detect interface defects Service calls must be made with integration to external services, which should include error and success cases, hence, integration testing validates that the system is working together seamlessly and that the dependencies between the services are present as expected. Contract Tests: Contract tests verify interactions at the boundary of an external service asserting that it meets the contract expected by a consuming service. This type of testing should treat each service as a black box and all the services must be called independently and their responses must be verified. A “contract” is how a service call (where a specific result or output is expected for certain inputs) is referred to by the consumer contract testing. Every consumer must receive the same results from a service over time, even if the service changes. There should be the flexibility to add more functionality as required to the Responses later on. However, these additions must not break the service functionality. End-To-End Tests: The role of end-to-end tests is to make sure everything ties together and there are no high-level disagreements between the microservices. End-to-end tests verify that a system meets external requirements and achieves its goals, testing the entire system, from end to end. The tests also verify that the entire process and user flows work correctly, including all service and DB integration. Thorough testing of operations that affect multiple services ensures that the system works together as a whole and satisfies all requirements. https://www. testingexcellence. com/automated-ui-testing-worth/ Example of Testing Microservices: Let’s take a microservice A that depends on two other services B &amp; C. You need to establish an isolated environment where the state of A, B and C is well defined and can be repeatedly set-up. For example, state/storage of B and C should be pre-initialised. After that, you just run a set of tests testing APIs of microservice A using usual REST/WebService set of test tools, e. g. SOAPUI or Chakram or simple xUnit alternative for your programming language. Mock any peer services the API depends on using restito. Other alternatives include rest-driver, WireMock, and Mochito. The obvious challenge is the mocking/faking 3rd party APIs when doing integration testing of microservices. You can use any of the mocking tools mentioned above, just treat the mocks as part of our test fixture and make sure you are up to date with new API releases. "
    }, {
    "id": 99,
    "url": "localhost:4000/install-git-mac-generate-ssh-keys/",
    "title": "How to Install Git on Mac and Generate SSH Keys",
    "body": "2017/04/05 - In this step-by-step Git Tutorial, we will go through how to install Git on a Mac machine, how to generate SSH keys and upload your public SSH key to your GitHub account for authorization. How to Install Git on Mac: Open a terminal and type 1$ brew install gitThis will install Git on your system. To confirm the installation, type 1$ git --versionThis will print the version of Git installed on your machine. How to generate SSH key for GitHub authorization:  Open a terminal Go to your home directory by typing cd ~/   Type the following command   1$ ssh-keygen -t rsa       This will prompt you to enter a filename to store the key   Just press enter to accept the default filename (/Users/you/. ssh/id_rsa)   Then it will ask you to create a passphrase. This is optional, either create a passphrase or press enter for no passphrase    When you press enter, two files will be created     ~/. ssh/id_rsa   ~/. ssh/id_rsa. pub    Your public key is stored in the file ending with . pub, i. e. ~/. ssh/id_rsa. pubHow to access and copy public SSH key: In order to authenticate yourself and your device with GitHub, you need to upload your public SSH key which you generated above to your GitHub account. Copy public SSH key Open a terminal and type 1$ pbcopy &lt; ~/. ssh/id_rsa. pubThis will copy the contents of the id_rsa. pub file to your clipboard. How to upload your public SSH key to GitHub:  Once you have copied your public SSH key, login to your GitHub account and go to https://github. com/settings/profile On the left-hand side menu, you will see a link “SSH and GPG keys” Click on that link which will take you to a page where you can enter your public SSH key that you copied earlier.  Click the button which says ‘New SSH key’ Then enter a title name - can be anything, e. g. newMac Paste the public SSH key in the key textbox Click “Add SSH key”Test your GitHub authorization: Open a terminal and type 1$ git clone git@github. com:AmirGhahrai/Rima. git It will ask you if you want to continue to connect, type yes If you created a passphrase when you were generating the public key, then it will ask you to enter it.  Enter your passphrase and press enter.  It will then start to clone the project to your directory. You are all now set up to use Git and GitHub. Further reading:  Git Cheatsheet - Common Git Commands How to uninstall IntelliJ from Mac OS How to install JMeter with Extra Plugins on Mac OS"
    }, {
    "id": 100,
    "url": "localhost:4000/develop-test-automation-framework-scratch/",
    "title": "How to Develop a Test Automation Framework From Scratch?",
    "body": "2017/03/15 - In this step-by-step guide, I will describe how to develop a modularized Test Automation Framework from scratch using Java, Selenium, TestNG and Maven. To begin with, let’s see what a Test Automation Framework is and what are the benefits of creating one. Test Automation Framework: What is the purpose of a Test Automation Framework? What challenges does it solve for the development team? In agile development, you might not have enough time to automate your new features in time, so you might be creating automated scripts, duplicating a lot of code in many places. Refactoring code is an inherent part of software development to avoid building up a huge tech debt. This also applies to test automation; by refactoring your automated scripts, you will improve readability and maintenance in the long run. In this Test Automation Framework tutorial, the end product is a result of many refactorings over time. Obviously, continuous improvement is essential if we are going to get a good return on investment from test automation. When creating a Test Automation Framework, we should consider the following main points:  To be able to create automated tests quickly by using appropriate abstraction layers The framework should have meaningful logging and reporting structure Should be easily maintainable and extendable Should be simple enough for testers to write automated tests A retry mechanism to rerun failed tests - this is especially useful for WebDriver UI testsIn this tutorial, I will be using:  Java as the programming language TestNG as the assertion framework Maven as the build tool WebDriver as the browser automation tool IntelliJ as the IDEThis Test Automation Framework tutorial is split into two parts: Part 1: Creating the base project and modules and the dependencies Part 2: Adding the code In part 1 of this tutorial I assume you already have Java and Maven installed on your machine. Steps to Create a Test Automation Framework From Scratch: Step #1 - Create new maven project Open IntelliJ IDE and select New Project from the menu. You are then presented with a screen to select the type of the project you are interested in.  Step #2 - Give your project a name Select Maven as the project type. Provide a name for GroupId and ArtifatId - I have decided to name this Test Automation Framework, Rima.  Step #3 - Choose the location of your project Now, choose a name for your project and select a directory for your workspace Step #4 - Base project is created You now have a base project created. We can start creating maven modules in this project to organize the structure of our Test Automation Framework.  And this is how our pom. xml looks like As this is going to be our base project with the parent pom. xml, we won’t have any code in this project. Instead, we will create maven modules for different parts of the Test Automation Framework. Go ahead and delete the src folder.  Step #5 - Create different modules Now we are in a position to create different maven modules for our framework. We will create the following modules: rima-framework - this module contains all the related classes and methods to facilitate creating automated tests. rima-domain - this module contains the domain specific language (DSL) classes. rima-page-objects - as the name suggests, this module contains the page objects. rima-regression-tests - and finally our automated regression tests. We will start by creating the rima-framework module. To do this, select File &gt; New &gt; Module Select Maven module and click Next In next screen, you can give the artifactId of the module you are creating, in this case, rima-framework Note the parent module and the groupId as Rima and click Next where we can give the name of the module and click Finish.  Once rima-framework module is created, it should look something like this We can then continue creating the rest of the modules in the same fashion. Once we have created all the modules, our project should look like below And finally, all the modules have been added to the root pom. xml Add Dependencies: Next, we need to add the dependencies between the modules in the framework as well as adding the libraries and other maven projects that our Test Automation Framework is dependent on. I have added the dependencies in the pom. xml files. You can take a look at the pom. xml files in my GitHub repo: https://github. com/AmirGhahrai/Rima In part 2 of this tutorial, we will go through the actual Test Automation Framework code written in Java, WebDriver and TestNG. And, here is the link to Part 2 of this tutorial: Page Object Model Framework with Java and WebDriver "
    }, {
    "id": 101,
    "url": "localhost:4000/how-do-we-measure-software-quality-in-agile-projects/",
    "title": "How do we Measure Software Quality in Agile Projects?",
    "body": "2017/02/26 - Question In agile, what metrics should be used to measure the quality of software? I know quality is largely subjective and can mean different things to different people, but what KPIs should be chosen if we want to measure quality? Of course, the ultimate indicator is the number of high priority defects leaked to production as a result of a release of new features and perhaps (if we are in an agile setup) the number of committed stories to actual delivered stories. But what other factors can be used to measure quality? Answer It’s important to measure software quality but it’s difficult to identify meaningful metrics. When no bugs have been identified does that mean the software is of the highest quality? On the other hand, when a large number of bugs have been created does that mean the QA team is doing a great job and the software is crap? The value is determined by the quality of the bugs and the QA process but how is that measured? I guess the closest we can come to a meaningful software quality metric is the number of bugs that make their way to the customer and the impact those bugs have on the users of the software. Another way of looking at it is that we develop software for a purpose, which is satisfying the need of a user. We deliver value, not quality, so the best thing to do it to make sure whatever you’re doing delivers something valuable to your user. What is important is how you deliver this value to your users and how quickly and how frequently. This is all related to the process and pipeline of software delivery. Rather than trying to measure software quality via some metrics, why not focus on trying to create a perfect delivery model? Within an agile context, you might want to take the following into account:  Ensure user stories have clear, concise and understandable acceptance criteria Before development begins, ensure everyone in the team (developers, designers, testers) has the same understanding of the need of the user stories Encourage 3 amigos meeting to flesh out the requirements and design decent scenarios Test the stories as they are being developed - Code reviews, Unit tests, pairing to provide early feedback Ensure you deliver what you commit to at the beginning of the sprint Ensure you don’t release high priority defects to production which have customer impact, easier said than done! No rollbacks - this is easy to measure - number of rollbacks could indicate a very broken processTo create a “quality product”, we need to have a quality process in place. By practising the above activities, it helps to create a smooth software delivery pipeline which provides value for the users. Other metrics to consider are  Measuring Velocity over time including how many Story Points was committed to vs. how many was actually completed in a sprint (see if we’re right sizing our stories/sprints and may show a scope issue).  Measuring the number of defects alongside velocity to see if there are any correlations with Velocity and number of defects per sprint. In ISO 25010 standards, there are 8 leading factors, each having certain attributes that can be tested with different kinds of tests. Generally, a high-quality software has great levels of  Maintainability (it is easy to maintain the code and add amendments) Portability (Easy to install, replace, adapt to new environments) Functionality (It does what it is intended to do) Performance (it works quickly without using too many resources, even when many people access the software at the same time, across the globe) Compatibility (the software is compatible with several components) Usability (easy to use without needing instructions, even for people with disabilities) Reliability (we can trust the software will work and overcome issues) Security (important information cannot be extracted by hackers)But, for each software, some of these will be more important than others, depending on for what and by whom the system will be used. "
    }, {
    "id": 102,
    "url": "localhost:4000/difference-acceptance-tests-requirements/",
    "title": "Difference Between Acceptance Tests and Requirements",
    "body": "2017/02/20 - Question Is there a difference between Acceptance Criteria (Agile) and Requirements (Waterfall)? I am a little confused and trying to understand the difference a little better as it seems like they are the same thing? I have worked in projects where everything was in the form of requirements, and other projects where everything was in the form of acceptance criteria, and on projects that have both. Can you please clarify the difference between Acceptance Criteria and Requirements? Answer The acceptance criteria could be one of the ways to judge if a user story is complete or even ready to be shipped. Acceptance criteria are a list of requirements that must be fulfilled to accept a user story as Done. This means that some requirements (usually “nice to have” requirements) may fall off, and be implemented in next version. As Microsoft Press states:  Acceptance Criteria as “Conditions that a software product must satisfy to be accepted by a user, customer or other stakeholder. ” Google defines them as “Pre-established standards or requirements a product or project must meet. and  Acceptance Criteria are a set of statements, each with a clear pass/fail result, that specify both functional (e. g. , minimal marketable functionality) and non-functional (e. g. , minimal quality) requirements applicable at the current stage of project integration. These requirements represent “conditions of satisfaction. ” There is no partial acceptance: either a criterion is met or it is not. A requirement describes a certain functionality of the application. A requirement is a singular documented physical and functional need that a particular design, product or process must be able to perform. It is most commonly used in a formal sense in systems engineering, software engineering, or enterprise engineering. It is a statement that identifies a necessary attribute, capability, characteristic, or quality of a system for it to have value and utility to a customer, organization, internal user, or other stakeholders. Requirements are often used in waterfall development and driven by the client as a list of expected results from the completion of a project. In it’s most basic description requirements are nothing more than a to-do list for a project. Acceptance criteria are often used in the agile world and are normally provided by the Product Owner or as a joint effort between various stakeholders. Unlike requirements, acceptance criteria is not a to-do list. It’s a list of conditions that must be met for the agreement to be considered finished. What is the difference between the acceptance criteria and the application requirements? With above definitions, the difference is quite clear. Acceptance Criteria vs Acceptance Tests might also be of interest. "
    }, {
    "id": 103,
    "url": "localhost:4000/continuous-testing-mean/",
    "title": "Continuous Testing - What Does it Mean?",
    "body": "2017/02/18 - What is Continuous Testing?: In a world of Agile Development where frequent releases are the norm, how can we ensure that we release to production with no major bugs and keep the business functioning? Continuous Testing is the answer - but what exactly is Continuous Testing and how do we go about attaining such a state in our development strategy? In the Agile Test Strategy, we based our model on two fundamental principles  Defect Prevention rather than Defect Detection Quick Feedback LoopLet’s explore these two points and see how they are related to Continuous Testing. If we assume that the end goal of software delivery is that of the Continuous Delivery model, then we cannot afford to make big mistakes. Our aim is to be able to release software continuously and smoothly without having to go back and forth multiple times to fix issues. We all know that the cost of fixing defects increases as we progress through the delivery pipeline. There will be a lot of time wasted investigating the issue(s) and trying to work out the root cause of a failure. Therefore, it is essential to ensure that we build the right product and _build it right _from the beginning. This means that when we pick up a user story or a sub-task to work on in a sprint, we should have a clear understanding of its intended benefit(s). The story should be well groomed with all the acceptance criteria and everyone should have the same understanding of how the feature should behave. We also need to have a quick feedback mechanism in place, so that if there are any issues with the new build, we get to know about it and fix it immediately. This is usually done via automated checks along the delivery pipeline. One thing to bear in mind is that Continuous Testing is NOT about test automation. Continuous Testing in Agile: Let’s break down the stages of developing a new feature and releasing it to production. We need this in order to see at which stage we need to test and what type of test is required. Story Grooming This is the first stage where defects can be introduced. As a minimum, we need to ensure user stories are testable and contain a good set of acceptance criteria. This is normally done via the Three Amigos (Dev, QA, PO) meeting where the details of the user stories are fleshed out. Design We can test the design/architecture and ask questions. Testing the design of the software is exploratory in nature. It can still be risk-based, as we use the risks as heuristics to focus our investigation. As we question the design, it will help us uncover more information. Information that will help us refactor the design (or plan) to make it better. You don’t want to build a feature and then later find out that it has serious performance issues! Branching When we start working on a new story, we typically create a new branch off the main master branch. This can get quite complex and easy to make serious mistakes when multiple developers create multiple branches and then all need to merge their branches to the master. Watch out for any merge conflicts. When several developers work together to deliver a feature, there is a risk of merge conflicts. We can test our branching strategy to ensure we don’t encounter any issues or merge conflicts. Code There are many ways we can check the code. TDD, pair programming, peer code reviews, unit tests are all activities with the aim of preventing defects getting into the system. Testing at this stage gives the highest ROI since unit tests are fast to execute and if there are any errors, they can be fixed immediately. It is interesting to note that defects which are found later in the development pipeline, are open for debate and most of the time, the not so serious issues will either get accepted and forgotten about or placed in the backlog to be fixed in future sprints. However, at the coding stage, even a single failed unit test, will cause the build to fail, so it has to be fixed there and then to be able to continue. Build When a new build is created, first we can check whether it was successfully built and deployed to a testing or staging environment. Automated functional regression checks of existing functionality should be part of the build process to give us the confidence that things are still in good order. Automated functional regression checks of existing functionality should be part of the build process to give us the confidence that things are still in good order. Integration testing, End-to-end testing and Exploratory testing of new features are all essential activities and all have different purposes. Continuous testing and Continuous Improvement go hand-in-hand. With the above activities, we start to understand the product better, to design better test cases and to learn about the risky areas of the application so that we can inform of potential risk in future developments, Release Release to production should be smooth and no new surprises should be seen, however, we can verify the release by running some sanity checks to ensure we actually released what we intended to release. Not only that, we should also monitor to see if there are any alerts in the monitoring tools and if there are any new errors reported since the release. Conclusion As you can see, in order to move fast and deliver continuously, we need to test alongside development. We need to ensure that we are building the right product from the onset. It is never enough to retrospectively test a finished product as bugs found later in the pipeline can be very costly to fix. Instead, we should embrace continuous testing. Continuous testing gives us confidence that at each stage, we are looking good. Testing at each stage serves a different purpose, so we can get a holistic view of the quality of the product. "
    }, {
    "id": 104,
    "url": "localhost:4000/common-agile-development-methodologies/",
    "title": "Most Common Agile Development Methodologies",
    "body": "2017/02/18 - What are the most common Agile Development Methodologies? There are various methodologies that are collectively known as Agile and they all promote the values of the agile manifesto. The most common agile development methodologies are DSDM, Scrum and XP. DSDM: DSDM which stands for Dynamic systems development methodis probably the original agile development method, way before the term ‘Agile’ was even invented. DSDM is an Agile project delivery framework, used as a software development method covering all aspects of change delivery from project initiation to benefits realisation. Although DSDM was used before what we currently know as Agile, it still has the same principles and practices to all other Agile methods i. e:  Breaking business requirements into small components – user stories Prioritising these components according to the business need Delivering, testing and accepting these components in small time frame Delivery through a collaborative team that includes the end users Regular and transparent feedback on both the solution and the processDSDM is Project focused. https://www. testingexcellence. com/what-are-scrum-ceremonies/ SCRUM: Scrum is also an agile development method, with great emphasis on how to manage tasks within a team-based development environment.  Scrum is the most popular and widely adopted agile method. The six Scrum principles are:  Empirical Process Control - This principle emphasizes the core philosophy of Scrum based on the three main ideas of transparency, inspection, and adaptation.  Self-organization - This principle focuses on today’s workers, who deliver significantly greater value when self-organized and this results in better team buy-in and shared ownership; and an innovative and creative environment which is more conducive for growth.  Collaboration - This principle focuses on the three core dimensions related to collaborative work: awareness, articulation, and appropriation. It also advocates project management as a shared value-creation process with teams working and interacting together to deliver the greatest value.  Value Based Prioritization - This principle highlights the focus of Scrum to deliver maximum business value, from beginning early in the project and continuing throughout.  Time-boxing - This principle describes how time is considered a limiting constraint in Scrum, and used to help effectively manage project planning and execution. Time-boxed elements in Scrum include Sprints, Daily Standup Meetings, Sprint Planning Meetings, and Sprint Review Meetings.  Iterative Development - This principle defines iterative development and emphasizes how to better manage changes and build products that satisfy customer needs. It also delineates the Product Owner’s and organization’s responsibilities related to iterative development. XP: XP(Extreme Programming) is a more radical agile methodology, focusing more on the software engineering process and addressing the analysis, development and test phases with novel approaches that make a substantial difference to the quality of the end product. XP can be applied when we may have a system whose functionality is expected to change every few weeks/months. Sometimes, our customers may not have a concrete idea of what the system should exactly do. In many software industries, the requirements are dynamically changing and this change is the only constant thing. This is when XP will work while other methodologies do not work. The main goal of XP is to deliver useful software to the customer as and when it is required. Here, we have to set expectations so that in a limited period of time, customers can receive a new build of the system with the most prioritized features. Then we can make new plans for the next release. "
    }, {
    "id": 105,
    "url": "localhost:4000/testing-agile-sprint-short/",
    "title": "Testing in Agile: The Sprint Is Too Short!",
    "body": "2017/02/16 - While many developers love Agile, testers… not so much. “It’s not possible to finish all the testing in one sprint”, “the sprint is too short, let’s add a week”, “we need two or three weeks to complete the regression”… Have you ever heard any of these? I hear them all the time. Agile changed our approach to development but testing sometimes still comes as an afterthought. In some ways testing became even more challenging. Here’s a short list, to mention just a few issues typically experienced by testers in Agile environment:  Testing in the midst of code changes makes it hard to establish a baseline.  Development drops late in the sprint cycle don’t leave enough time for testing.  Infrequent builds/deployments create delays and downtime.  Not enough testers to plan, document and execute the test cases.  Not enough time to go through functional, integration, regression, usability, security and other testing.  No time to review, fix and retest defects found late in the cycle.  Lack of knowledge and communication across testers, developers, SMEs and other specialists. But if we read this list carefully, we’ll notice that none of these issues are really caused by the length of the sprint. Three or even four weeks instead of two wouldn’t make a difference when it comes to the lack of communication or knowledge, amount of manual testing, delays caused by manual or infrequent builds, late drops, and defects found on the last day of the sprint.  The challenges of Agile testing are not caused by the sprint length. So what do we do? We split the testing into two parts: tests directly related to the user stories developed during the sprint, and everything else. Then we defer the “everything else” to the end of the release, which happens every several months. Here’s the truth: all we can do during the sprint is pretty much just the functional testing. We’re not doing much of the integration, regression or performance testing until right before the release. We call this final system test a “regression sprint” or “hardening sprint”. Sounds familiar? If you nod in agreement, don’t worry, you’re not alone. This is a very typical Agile implementation across the industry. Unfortunately, it’s a BAD idea. ![](https://media. licdn. com/mpr/mpr/AAEAAQAAAAAAAAjMAAAAJGY2ZjIzNGJmLTRmNjEtNGYyYi1iMjVjLWI1YzA1ZDU0MTU3Ng. jpg)We say we try to mitigate the issues and challenges of Agile testing, but we don’t really solve the problem. By pushing the major testing effort to the very end of the release we increase the risk, compromise quality and don’t use the main advantage of Agile - ability to deliver value to the customers often in small increments. So, adding the hardening sprint doesn’t really help with the problem of sprints being too short.  The sprint is too short only if you planned more than you could realistically deliver The real goal should be to eliminate the hardening sprint and to complete all types of testing during the sprint, however short or long it is. This way every sprint would end with a set of fully tested features that could potentially be deployed to Production or shipped to the customer. There would be no need for the context switch at the end of the release, no last minute defects and costly delays. ![](https://media. licdn. com/mpr/mpr/AAEAAQAAAAAAAAd_AAAAJGI5ZjQwMTUyLWQ5ZjItNGE1Ni04NWI4LTY2NTIzYmFlZDdkZQ. jpg)Do you still have hardening sprints? Do you feel like your sprint is too short? Then join me on this journey and make 2017 a year of high quality and true agility. : Let’s start the new year with some important decisions and pledge to make our solutions truly agile. Let’s improve our quality and deliver software updates to the customers when they need them. Let’s stop complaining about sprints being short and start being realistic about our planning. Let’s eliminate manual builds, deployments and tests where possible, automate regression tests and run them on daily basis during the sprint. Let’s update our definition of “Done” to include all types of testing. Let’s get rid of the “hardening” cycle. Let’s complete all of our tests within the sprint!: Here’s a practical guide to testing without feeling that the sprint is “too short”: ![](https://media. licdn. com/mpr/mpr/AAEAAQAAAAAAAAgzAAAAJGJhMGM1ODdmLWRjODgtNDQyNy04MWRmLWYzYTg1ZDNiNTE5Yw. jpg)Article published by [Katy Sherman](https://www. linkedin. com/in/katy-sherman-practical-agile)"
    }, {
    "id": 106,
    "url": "localhost:4000/testlodge-a-test-case-management-tool/",
    "title": "TestLodge - a Test Case Management Tool",
    "body": "2017/02/12 - Introduction TestLodge test case management tool is a relatively new hosted tool that is designed to be a lot simpler than traditional software by only providing the essentials to get the job done well. The system focuses on helping you create your test plans, input your requirements, create and manage your test suites and cases along with allowing you to easily perform multiple test runs and generate reports.  Main features TestLodge offers the following features to its users: 1. Test Plans - The ability to create and maintain test plans. These can be either be built from scratch or built from a pre-defined template that TestLodge offers 2. Requirements - The tool allows you to quickly enter your requirements which can later be associated with test cases. 3. Test cases - TestLodge allows you to enter your requirements into test suites with ease. The software allows you enter a title, description, test steps and expected result for each case along with easily being able to copy to other projects. 4. Test runs - Once you have created your test cases, its time to run them. TestLodge provides a clear interface that guides you through each test one by one. If you mark a test case as ‘failed’ it also allows you to create bug reports in 3rd party issue tracking tools such as FogBugz, Assembla, Redmine etc…   InterfaceMany existing test management systems have been around for years and over this time they have become bloated and hard to use. They host nearly every feature that you could require along with interfaces that take hours or even days to learn. TestLodge differs from these by keeping things simple and only providing the essentials to get the job done well and quickly. The interface is designed to be simple, easy to use and require no training to use it. ConclusionTestLodge is a great tool for people who want to easily manage their manual testing effort across a whole team, their pricing plans are reasonable and it takes people little effort in getting up to speed with the software. Watch a demo of the tool "
    }, {
    "id": 107,
    "url": "localhost:4000/choose-tests-automate/",
    "title": "TestLodge - a Test Case Management Tool",
    "body": "2017/02/08 - How do you choose which tests to automate and which tests to leave for manual testing? Before you start automating a test, you need to see what benefits you get by automating the test after you factor in the time, effort and resource invested in test automation. Below are some factors to consider to help identify which manual tests should or should not be automated. As the old saying goes, just because you can automate something doesn’t necessarily mean that you should. Here are some guidelines to help identify good candidates for test automation: Tests that should be automated::  Business critical paths - the features or user flows that if they fail, cause a considerable damage to the business.  Tests that need to be run against every build/release of the application, such as smoke test, sanity test and regression test.  Tests that need to run against multiple configurations — different OS &amp; Browser combinations.  Tests that execute the same workflow but use different data for its inputs for each test run e. g. data-driven.  Tests that involve inputting large volumes of data, such as filling up very long forms.  Tests that can be used for performance testing, like stress and load tests.  Tests that take a long time to perform and may need to be run during breaks or overnight.  Tests during which images must be captured to prove that the application behaved as expected, or to check that a multitude of web pages looks the same on multiple browsers. Generally speaking, the more repetitive the test run, the better it is for automation. Also remember that tests are not the only candidates for automation. Tasks such as setting up or creating test data for manual exploratory testing are also great candidates for automation. Tests that should not be automated::  Tests that you will only run only once. The only exception to this rule is that if you want to execute a test with a very large set of data, even if it’s only once, then it makes sense to automate it.  User experience tests for usability (tests that require a user to respond as to how easy the app is to use).  Tests that need to be run ASAP. Usually, a new feature which is developed requires a quick feedback so testing it manually at first Tests that require ad hoc/random testing based on domain knowledge/expertise - Exploratory Testing.  Intermittent tests. Tests without predictable results cause more noise that value. To get the best value out of automation the tests must produce predictable and reliable results in order to produce pass and fail conditions.  Tests that require visual confirmation, however, we can capture page images during automated testing and then have a manual check of the images.  Test that cannot be 100% automated should not be automated at all, unless doing so will save a considerable amount of time. Can you think of any other candidates for automating (or not automating) a test? "
    }, {
    "id": 108,
    "url": "localhost:4000/agile-killed-managers/",
    "title": "How Agile Killed Managers",
    "body": "2017/02/06 - Once upon a time in a land far away every few developers and every few testers had a manager. Everybody wanted to be managers because they had power and were paid better. But only the best engineers became managers. Then they hated their jobs because they really just wanted to be engineers and didn’t like dealing with people. Then Agile happened and POOF! the managers disappeared. What happened to them? Continue reading to learn about different ways managers can become an obstacle during Agile transformation, and what they should do instead to help the teams grow to their full potential and be successful. First of all, not all the managers are gone. Of course, scrum teams don’t need as much supervision and control as individuals did in the olden days, so companies don’t need as many managers as before. Some of the more technical managers return to what they do best: develop, test, design and create, establish standards and nurture innovation. In this new reality, they can create more value by being technical leads, subject matter experts, domain experts or architects.  You don’t need a title or direct reports to be a leader. Related:  Testing in Agile: The Sprint is too short! Head of QA Roles and ResponsibilitiesBut for the remaining few the rapid change sweeping the workplace can be brutal. Uncertainty leads to confusion and fear, stress and distrust. Managers who don’t understand the spirit of Agile, who cling to their titles and try to preserve the chain of command, can sabotage and hurt the Agile transformation. What Did The Managers Lose?: To understand what causes managers to be such a pain in the neck, let’s see what happened to their roles. Here’s what they lost:  Clear lines of responsibility. Cross-functional teams erased the boundaries between development and testing, but many organizations still operate in the shadow of the outdated functional silos, in which developers report up to development managers, and testers to QA managers. Unclear lines of responsibilities lead to conflict, power play and agendas, none of which is good. As part of agile transformation many organizations realign themselves to form engineering departments, in which all developers and testers report up the same chain on command. This eliminates the tension between development and QA groups, but can cause anxiety and insecurity for the managers, who now need to learn a new trade to support both functional areas.  Power over individuals and business value. In the traditional “command and control” model the manager decides what needs to be done, assigns tasks to individuals, monitors the execution and reports the status up the ladder. But today, the responsibility over the business value (what to do) belongs mostly to the product owner, whereas the knowledge about what needs to be done to achieve the goal (how to do it) lays within the team. The managers in this model can feel excluded and out of control.  Technical expertise. Today the managers are not expected to be domain experts or technical gurus. It is still great for a manager to have technical background, but it’s far more important to be a leader, have a vision, serve the teams and individual employees, as well as help them grow to their full potential. This transition can be hard for those who used to be a single point of decision making in all matters technical.  Metrics. This can be extremely painful for people who used to do what we call project management. In the traditional SDLC the project work is highly quantified through percent complete on each phase of the project, key performance indicators, scorecards, project plans and financial forecasts. It can be argued that these metrics give a false sense of visibility, but not having metrics at all causes a lot of anxiety. How Managers Can Abuse Agile: We all heard horror stories about managers destroying Agile. They do it because they try to preserve everything they had, which is now lost forever (control, power, influence, metrics) and are insecure about their own future. All management dysfunctions in agile environment stem from fear and distrust, and the only way to overcome them is through learning, coaching and cultural change.  First line managers need the same amount, perhaps even more agile coaching than the scrum teams. Here are some examples of management decisions and actions that are damaging and counterproductive. If you know a manager who does this, be patient and know: they need help.  Constantly move people in/out of teams. Being agile means accepting the uncertainty and being ready to adapt and adjust the course if needed. The team, however, is in the center of this process and should be kept as constant as possible. Moving people in and out, creating partial allocations and temporary team members will never allow the team to come together and start performing.  Give individuals assignments outside of their team role and scope. Treating people as resources that can be easily moved between projects is wrong. Planning projects around existing teams is a much better way of creating roadmaps.  Undermine or disrespect team’s decisions. Probably the most certain way to dis-empower and alienate the team.  Forcefully change the sprint scope during the sprint. Same as the above, only in this case the manager acts not only against the team, but also the product owner.  Measure velocity as an improvement target and compare velocity across teams. Focusing on numbers leads to inflation. Teams can easily game the system by creating bloated estimates or closing stories before they pass the definition of “done”.  Track the “estimated” hours vs “actual” hours. Another fool-proof technique to turn the team’s estimates into a completely meaningless numbers that only serve the purpose of being “on target” and nothing else.  Worry about people being underutilized. Remember, high utilization represents high risk. As utilization approaches 100%, the throughput time increases exponentially, which means that every simple task now takes forever to complete and nothing gets done.  Reward individuals who exhibit anti-team behavior. The classic article “On the folly of rewarding A, while hoping for B” was written in 1975 by Steven Kerr. 40 years later it’s still not uncommon to praise individuals who make decisions without discussing with their teams, hoard knowledge and generally refuse to collaborate. How Managers Can Boost Agile Transformation: The good news is, it’s not hard to be a great functional manager in agile environment. All it takes is to understand that some of the former manager’s responsibilities now belong to the team, but there’s so much more that can be done to reinforce agile principles, optimize processes, improve technology, create synergy within the team, and maximize business value. Here’s what a good manager could do to help the teams be successful:  Build teams wisely. It is still the manager’s responsibility to make hiring decisions and design teams. It might be a great idea to use team’s input during the hiring process to ensure acceptance and cultural fit.  Make sure the team gets all the training, mentorship and coaching they need. It’s great if the manager can act as a coach him/herself, but they can also hire experts, pay for courses, certifications, books and other materials.  Trust the team and stay away from their daily process. Trust is the biggest gift a manager can give to the employees. The only way to build self-organized team is to let the team to organize itself, establish its pace and master its processes.  Protect the team from disruptions during the sprint. This might sound as an unexpected suggestion, but sometimes the team needs protection from an over-eager product owner. Development is a creative process that requires focus and sometimes it’s just a matter of getting into the zone and not being distracted by phone calls and meetings.  Identify and eliminate waste, drive for lean processes and practices. Any manual process or step in the process is a waste. Every year a portion of the firm’s capital investment has to go towards automation, innovation and technology stack updates, and it’s the manager’s responsibility to identify gaps, facilitate and brainstorm the solution, allocate resources and follow through with the execution.  Reward teams and individuals wisely. Creating incentives, boosting morale and rewarding positive behavior can be tricky, but the secret of balanced approach is simple: managers should recognize both teams and individuals, depending on the situation and nature of the reward.  To learn more, see 5 Rules of Rewarding Teams and Individuals.  Create opportunities for growth. A rotating role of scrum master is a great opportunity for the team members to try themselves for a job that requires to facilitate, coordinate and help others to collaborate. Those who like it can one day become managers themselves. To learn more, read The Superpower of a Scrum Master.  Identify the team’s weak spots and come to the rescue. Read my next post to learn what telltale signs can alert on potential problems and dysfunctions within the teams and how each one can be addressed. Article published by Katy Sherman "
    }, {
    "id": 109,
    "url": "localhost:4000/performance-testing-terminologies/",
    "title": "Performance Testing Terminologies",
    "body": "2017/02/05 - Below are a list of common performance testing terminologies: Baselines: Creating a baseline is the process of running a set of tests to capture performance metric data for the purpose of evaluating the effectiveness of subsequent performance-improving changes to the system or application. Benchmarking: Benchmarking is the process of comparing your system’s performance against a baseline that you have created internally or against an industry standard endorsed by some other organization. Capacity Test: The capacity of a system is the total workload it can handle without violating predetermined key performance acceptance criteria. A capacity test complements load testing by determining your server’s ultimate failure point, whereas load testing monitors results at various levels of load and traffic patterns. You perform capacity testing in conjunction with capacity planning, which you use to plan for future growth, such as an increased user base or increased volume of data. For example, to accommodate future loads, you need to know how many additional resources (such as processor capacity, memory usage, disk capacity, or network bandwidth) are necessary to support future usage levels. Capacity testing helps you to identify a scaling strategy in order to determine whether you should scale up or scale out. Endurance Test: An endurance test is a type of performance test focused on determining or validating performance characteristics of the product under test when subjected to workload models and load volumes anticipated during production operations over an extended period of time. Endurance testing is a subset of load testing. Investigation: Investigation is an activity based on collecting information related to the speed, scalability, and/or stability characteristics of the product under test that may have value in determining or improving product quality. Investigation is frequently employed to prove or disprove hypotheses regarding the root cause of one or more observed performance issues. Latency: Latency is a measure of responsiveness that represents the time it takes to complete the execution of a request. Latency may also represent the sum of several latencies or subtasks. Metrics: Metrics are measurements obtained by running performance tests as expressed on a commonly understood scale. Some metrics commonly obtained through performance tests include processor utilization over time and memory usage by load. Performance Test: Performance refers to information regarding your application’s response times, throughput, and resource utilization levels. A performance test is a technical investigation done to determine or validate the speed, scalability, and/or stability characteristics of the product under test. Performance testing is the superset containing all other subcategories of performance testing described in this chapter. Performance Thresholds: Performance thresholds are the maximum acceptable values for the metrics identified for your project, usually specified in terms of response time, throughput (transactions per second), and resource-utilization levels. Resource-utilization levels include the amount of processor capacity, memory, disk I/O, and network I/O that your application consumes. Performance thresholds typically equate to requirements. Response Time: Response time is a measure of how responsive an application or subsystem is to a client request. Saturation: Saturation refers to the point at which a resource has reached full utilization. Scalability Testing: Scalability refers to an application’s ability to handle additional workload, without adversely affecting performance, by adding resources such as processor, memory, and storage capacity. Scenarios: In the context of performance testing, a scenario is a sequence of steps in your application. A scenario can represent a use case or a business function such as searching a product catalog, adding an item to a shopping cart, or placing an order. Smoke Test: A smoke test is the initial run of a performance test to see if your application can perform its operations under a normal load. Spike Test: A spike test is a type of performance test focused on determining or validating performance characteristics of the product under test when subjected to workload models and load volumes that repeatedly increase beyond anticipated production operations for short periods of time. Spike testing is a subset of stress testing. Stability: In the context of performance testing, stability refers to the overall reliability, robustness, functional and data integrity, availability, and/or consistency of responsiveness for your system under a variety conditions. Stress Test: A stress test is a type of performance test designed to evaluate an application’s behavior when it is pushed beyond normal or peak load conditions. The goal of stress testing is to reveal application bugs that surface only under high load conditions. These bugs can include such things as synchronization issues, race conditions, and memory leaks. Stress testing enables you to identify your application’s weak points, and shows how the application behaves under extreme load conditions. Throughput: Throughput is the number of units of work that can be handled per unit of time; for instance, requests per second, calls per day, hits per second, reports per year, etc. Workload: Workload is the stimulus applied to a system, application, or component to simulate a usage pattern, in regard to concurrency and/or data inputs. The workload includes the total number of users, concurrent active users, data volumes, and transaction volumes, along with the transaction mix. For performance modeling, you associate a workload with an individual scenario. What is the difference between Performance Testing, Load Testing and Stress Testing? Performance, load, and stress tests are subcategories of performance testing, each intended for a different purpose.    Performance testing. This type of testing determines or validates the speed, scalability, and/or stability characteristics of the system or application under test. Performance is concerned with achieving response times, throughput, and resource-utilization levels that meet the performance objectives for the project or product. In this guide, performance testing represents the superset of all of the other subcategories of performance-related testing.     Load testing. This subcategory of performance testing is focused on determining or validating performance characteristics of the system or application under test when subjected to workloads and load volumes anticipated during production operations.     Stress testing. This subcategory of performance testing is focused on determining or validating performance characteristics of the system or application under test when subjected to conditions beyond those anticipated during production operations. Stress tests may also include tests focused on determining or validating performance characteristics of the system or application under test when subjected to other stressful conditions, such as limited memory, insufficient disk space, or server failure. These tests are designed to determine under what conditions an application will fail, how it will fail, and what indicators can be monitored to warn of an impending failure.  "
    }, {
    "id": 110,
    "url": "localhost:4000/pros-cons-test-driven-development/",
    "title": "Pros and Cons of Test Driven Development",
    "body": "2017/02/03 -  What are pros and cons of Test Driven Development (TDD)? Test Driven Development is a software development methodology whereby you write and run a set of tests before you write code. The idea is that those tests will fail at first and then you start to write enough code to try to get all the tests to pass.  Having all the tests pass could be a measure of the done criteria (dev-done) and also increases confidence in the quality of the code. That said, like any other development methodologies there are some pros and cons associated with TDD. Here, we list some of them, but before that, best to clarify couple of points:  Doing unit tests doesn’t mean doing TDD. You can do the first without the second. In fact, you can do TDD without unit testings (but most people do), in this case, people complement generally unit testing with others flavors of tests. What you need for sure is automatic testing, whatever they are.  You can perform TDD for white box testing, to test your code. But you can also perform TDD for black box testing, something often called Behavior Driven Development. Traditionally, the process was to code a lot of modules and then write unit tests to verify the code. This is code-first, test later method. But if after coding there is no time or you’re pushed for release, then the whole exercise of unit testing gets skipped, or at best done retrospectively. Now, on to the pros and cons of TDD: Pros of Test Driven Development:  Because you are writing small tests at a time, it forces your code to be more modular (otherwise they’d be hard to test against).  TDD helps you learn, understand, and internalise the key principles of good modular design.  TDD also forces good architecture. In order to make your code unit-testable, it must be properly modularized. Writing the tests first, various architectural problems tend to surface earlier.  Documents your code better than documentation (it doesn’t go out of date since you’re running it all the time).  Makes code easier to maintain and refactor.  TDD helps to provide clarity during the implementation process and provides a safety-net when you want to refactor the code you’ve just written.  Makes collaboration easier and more efficient, team members can edit each others code with confidence because the tests will inform them if the changes are making the code behave in unexpected ways.  Because TDD essentially forces you to write unit tests before writing implementation code, refactoring of code becomes easier and faster. Refactoring code written two years ago is hard. If that code is backed up by a set of good unit tests, the process is made so much easier.  Helps prevents defects - well, at least it helps you find design or requirement issues right at the beginning. TDD provides early warning to design problems (when they are easier to fix).  Helps programmers really understand their code.  Creates an automated regression test suite, basically for free. i. e. you don’t need to spend time afterwards writing unit tests to test the implementation code.  It encourages small steps and improves the design because it makes you cut the unnecessary dependencies to facilitate the setup.  It helps to clarify requirements because you have to figure out concretely what inputs you have to feed and what outputs you expect.  Unit tests are especially valuable as a safety net when the code needs to be changed to either add new features or fix an existing bug. Since maintenance accounts for between 60 and 90% of the software life cycle, it’s hard to overstate how the time taken up front to create a decent set of unit tests can pay for itself over and over again over the lifetime of the project.  Testing while writing also forces you to try to make your interfaces clean enough to be tested. It’s sometimes hard to see the advantage of this until you work on a body of code where it wasn’t done, and the only way to exercise and focus on a given piece of code is to run the whole system and set a break-point.  “Stupid” mistakes are caught almost immediately. It helps developers find mistakes that would waste everyone’s time if they were found in QA. Cons of Test Driven Development:  The test suite itself has to be maintained; tests may not be completely deterministic (i. e. reliant on external dependencies).  The tests may be hard to write, esp. beyond the unit testing level.  Initially, it slows down development; for rapidly iterative startup environments the implementation code may not be ready for some time due to spending time writing tests first. (But in the long run, it actually speeds up development) Like any programming, there is a big difference between doing it and doing it well.   Writing good unit tests is an art form. This aspect of TDD is often not discussed, many managers tend to focus on metrics like code coverage; those metrics tell you nothing about the quality of the unit tests.  Unit testing is something the whole team has to buy into.  A challenge to learn.  It can be intimidating and not easy for anyone to learn at first, especially trying to learn it on your own.  It requires a lot of dedication (discipline, practice, persistence) and you have to have the goal that you want to continually get better at it.  Hard to apply to existing legacy code.  Lot’s of misconceptions that keep programmers from learning it.  Hard to start working this way. Especially if you have many many years of working the other way.  You sometimes have to mock a lot of things or things that are difficult to mock. It’s beneficial in the long term, but painful right now.  You have to perform housekeeping continually. Because booking more and more tests make your build longer and longer, it’s necessary to refine those tests to make them running more quickly or to remove redundant tests.  Like any good technique, unit testing can be carried to an extreme. The biggest benefits come from a moderate effort, with the tests always exercising the code in the simplest way possible.   If you find yourself frequently refactoring your tests, there’s a good chance you’re spending too much time on the test suite.  It can be easy to get distracted by “fluff” or fancy features in the unit testing framework. We should remember that simple tests are the fastest to create and the easiest to manage.  Although it is absolutely necessary, creating tests for failures can be tedious, but it pays off big time in the end.  Early stage refactoring requires refactoring test classes as well.  Unless everyone on the team correctly maintains their tests, the whole system can quickly degrade. "
    }, {
    "id": 111,
    "url": "localhost:4000/start-test-automation-existing-website/",
    "title": "Where to Start with Test Automation for an Existing Website?",
    "body": "2017/01/31 - Andrew asks:  I have recently joined a web based company as their first QA member. The website has been developed in the past five years and during this time, developers and other team members were doing the testing.  There is no formal QA or testing process in place, so all the testing has been largely ad-hoc.  Now my manager who is in charge of software delivery, wants me to create an automated regression testing pack which the team can execute whenever they develop new features.  My question is: where shall I start with test automation to build this regression pack for a website which has been in operation for more than five years?  Any ideas/suggestions would be highly appreciated. My response: Once a website has been functioning and serving live customers for a number of years, then it is in a mature state. By mature, I mean there are (hopefully) no obvious serious bugs in the system and if any, they will be the subtle or edge case issues that are not easily spotted by everyone. What we shouldn’t do, is to try to retrospectively write tests for all the stories that have already been developed and have become part of the system. However, what we want is a set of key scenarios that exercise the system end-to-end to ensure that future developments don’t jeopardize the existing functionality. Steps below are some guidelines that can be used for an existing and already established website in order to find the key scenarios and a method of expanding on these to create a functional regression pack. Related:  Should Test Automation be done by a separate dedicated team? Pros and Cons of Test Driven DevelopmentExplore: Step 1: First you need to familiarize yourself with the website and its features. Start with exploring the site and learn its behavior. While doing so, you can also create a mind map of the structure of the website, what pages there are and what features are there in each page. Mind maps are a great way of getting a high-level snapshot and overview of the whole website. We can always refer to the mind maps to get an understanding of how the pages are connected. Gather Metrics: Step 2: Gather site usage metrics from the marketing and/or analytics team.  Most businesses embed “tracking tags” such as Google Analytics on their website to be able to track how users use the site. There is a wealth of information about the user behavior and common user journeys that can be retrieved from these tracking systems. The reason why we need to gather this information is to be able to prioritize what test scenarios to automate first so that we get the most value in the shortest possible time. Key Scenarios: Step 3: Start with automating the core end-to-end scenarios through the web application. This will form the basis of our “smoke regression pack”. For example, for a typical e-commerce web application, the core end-to-end scenario is Homepage –&gt; Search results –&gt; Product details  –&gt; Customer login / Register –&gt; Payment details –&gt; Order confirmation It is important to note that, to start with, we only need to ensure that we can get through the pages, starting from Homepage and reaching the order confirmation page. The aim is to check that the purchase flow is not broken, rather than checking each page’s functionality in great detail. Once we have the simplest and most common user flow covered, we can then look into more variations. Despite the numerous combinations of features and pages, one would notice that there are really only a handful of user journeys through the system that need to be considered. Scrutinizing analytics data, you will probably find 80% of users would go through the same paths but with different data. Therefore, our smoke regression pack should be built based on these scenarios. Increase Coverage: A note about coverage, here I’m not talking about test coverage; the focus is on feature coverage. Step 4: Expand on the smoke regression pack to create a more extensive function regression pack by utilizing the mind maps and applying state transition testing technique to build the scenarios. Entry Points - To begin with, we first need to find the entry points into the system. These entry points could be a user landing on the home page, a product details page, or a SEM (Search Engine Marketing) specific page. Once we identify a particular landing page, we need to see what features there are on that page which the user can interact with. This is where mind maps become very useful. We have a high-level overview of the page and its features. Here, the meaning of feature is either a single component like a sort option drop-down box or filling up a user details form or as simple as clicking a link. Initial State - When we first land on an entry point in the application, there will be a state associated with that page. We record that as the initial state of the application. Whenever we interact with any of the features on that page, we are most likely going to alter its initial state. Trigger - Some features, when interacted with, will either load the same page (e. g. sort options will keep the same page, but data will be sorted) or transition to another page (e. g. submitting valid user credentials). The thing that causes this transition, either to the same page or to another page, is called the trigger, such as the submit button. Assertions - Then there are the assertions. Whenever the state of the application is changed, by interacting with a feature, we need to make assertions to check the status of the new state. For example, when we submit a login form with valid user data, we need to assert that the user is now logged in. We can continue with the same manner on the new transition, or go back to the initial state and interact with another feature until we cover all the important features of the mind maps. Over time, the level of confidence in deploying new code increases as more scenarios are automated and run on a regular basis. "
    }, {
    "id": 112,
    "url": "localhost:4000/error-fault-failure-software-testing/",
    "title": "Error, Fault and Failure in Software Testing",
    "body": "2017/01/29 - : Error, Fault, Failure: What is the difference between error, fault and failure in software testing? Error - a human action that produces an incorrect result. This is also sometimes referred to as Mistake. Fault - a manifestation of an error in software, also known as Defect or Bug. Failure - a deviation of the software from its expected delivery or service. An error is something that a human does, we all make mistakes and when we do whilst developing software, it is known as an error. The result of an error being made is a fault. It is something that is wrong in the software (source code or documentation - specifications, manuals, etc. ). Faults are also known as defects or bugs. When a system or piece of software produces an incorrect result or does not perform the correct action, this is known as a failure. Failures are caused by faults in the software. Note that software system can contain faults but still never fail (this can occur if the faults are in those parts of the system that are never used). In other words, failure is the manifestation of one or more faults (bugs). Reliability Another term that should be understood is reliability. A system is said to be reliable when it performs correctly for long periods of time. However, the same system used by two different people may appear reliable to one but not to the other. This is because the different people use the system in different ways. Reliability: the probability that the software will not cause the failure of the system for a specified time under specified conditions. The definition of reliability therefore includes the phrase ‘under specified conditions’. When reporting on the reliability of a system it is important to explain under what conditions the system will achieve the specified level of reliability. For example, a system may achieve a reliability of no more than one failure per month providing no more than 10 people use the system simultaneously. https://youtu. be/O-vliUERNNY "
    }, {
    "id": 113,
    "url": "localhost:4000/10-traits-agile-self-organizing-team/",
    "title": "10 Traits of an Agile Self Organizing Team",
    "body": "2017/01/28 -  One of the key important aspects of a successful Agile setup is having a self-organizing team. This is also mentioned in the Agile manifesto: “The best architectures, requirements, and designs emerge from self-organising teams” Self-organizing teams, as the name suggests, take responsibility and manage their own tasks and don’t rely on a manger to tell them what to do. 10 Traits of an Agile Self Organizing Team: Let’s see what a typical self-organizing Agile team looks like:    Ownership: Generally the team are a group of mature individuals which take initiatives and work for themselves and don’t wait for their leader to assign work. This ensures a greater sense of ownership and commitment.     Motivation: Team motivation is the key to success. Team members should be focused and interested in their work.     Teamwork: The team can manage their own work with regards to task allocation, task estimation, story development and testing and delivery of a successful sprint as a group.  They should work as a team rather than as a group of individuals. Teamwork is encouraged.     Coaching: The team is left to do what they’re best at - delivery of software - but they still require some level of mentoring and coaching and facilitation by their ScrumMaster, but they don’t require “command and control. ”     Trust and respect: Team members trust and respect each other. They believe in collective code ownership and testing and are ready to go the extra mile to help each other resolve issues.     Commitment: Communication and most importantly committed individuals are vital in a self-organizing Agile team. Team members communicate more with each other, and are fully committed to delivering their tasks individually and as a group. There are various Scrum ceremonies such as the daily stand-up meeting, story grooming and pairing, which encourages team discussions.     Collaboration: The team understands that to deliver software successfully, they should understand the requirements and aren’t afraid to ask questions to get their doubts clarified. Constant collaboration with the Product Owner is essential.     Competency: Individuals need to be competent for the job at hand. This will result in confidence in their work and will eliminate the need for direction from above.     Improvements: Continuously improving their own skills and recommend innovative ideas and improvements.     Continuity: A new team takes a while to mature and become self-organized. Overtime, they can understand their working habits as a team, so changing its composition every now and then doesn’t help. It is best to have the team members working together for a reasonable duration.  Creating a self-organizing team in Agile is not an easy task and takes a reasonable amount of time to form. Often, the ScrumMaster should coach and facilitate any of the above ingredients to help fast-track the formation of such self-organizing Agile teams. "
    }, {
    "id": 114,
    "url": "localhost:4000/transitioning-waterfall-agile-testing/",
    "title": "Transitioning from Waterfall to Agile Testing",
    "body": "2017/01/25 -  When a company decides to transition from Waterfall to Agile testing, what are the most important areas to concentrate on for effective Agile Testing? How does Testing in Agile compare to that of Waterfall model? What set of activities are important for testers to know and do? Testing Throughout the Development: The first thing to understand is that in agile development, testing is integrated throughout the lifecycle; testing the software continuously throughout its development. In traditional Waterfall model, testing is a large effort and is left towards the end of development, whereas in Agile, testing is small but more frequent and happens throughout the development. Testing throughout the development also means that the software is in releasable condition throughout the development, so it can be shipped whenever it’s appropriate. In Waterfall model, we are taught to think in phases, such as design phase, development phase and testing phase.  Agile development does not have a separate test phase as such. Developers are much more heavily engaged in testing, writing automated repeatable unit tests to validate their code. Developer Participation in Testing: With automated unit tests, testing can be done as part of the build, ensuring that all features are working correctly each time the build is produced. With a solid foundation of good unit test coverage, developers will feel more confident to refactor code as well. Testing in Agile also means starting early. That means the QA would have to be involved right from the design stage, understanding the features and stories and start preparing and even writing tests upfront. Another important aspect is Test Automation to be able to execute tests continuously as the product is being developed. This is not only unit automated tests, but API and UI automated tests as well. Integrated and Cross Functional Teams: Transitioning to Agile is cross-functional project team activity. This joint effort is not limited to the testing activities. The developers should assist with testing frameworks and create features, the business analysts assist with refining the story. Each team member works on a story until the entire story is done, that means developed and tested. Designers, Developers and Testers work together in parallel so achieve a common goal and they all should know what is necessary to get things done. Performing as a team is the main key point transitioning from Waterfall to Agile Testing. The Company can decide to change to Agile Testing but the people have to support this change to succeed. There is no test team in agile. Quality Mindset, Whole-Team Approach: Aim for defect prevention rather than defect detection. With early participation of testers in the project, they can assist in identifying key scenarios that are required to test a story. Quite often the acceptance criteria is written as a joint effort between a Product Owner, a Developer and a Tester - the Three Amigos. This ensures that whatever is being built is testable and understood by all stakeholders. Also, as more people are involved in defining the acceptance criteria and the “Definition of Done”, mistakes can be rectified earlier and ultimately the right product is built right. Everyone is involved and responsible for quality of the product. Less documentation, More collaboration: In Agile development, there is more emphasis on conversation and collaboration to clarify requirements more than the traditional approach of specifications and documentation. Although requirements can be clarified to some extent in agile development, it is still possible for requirements to be ambiguous and incomplete, and for team members to have different understanding of the requirements. So what does this mean for an Agile Tester? A common concern for testers transitioning to Agile development is that they don’t know precisely what they’re testing for. They don’t have a detailed spec to test against, so how can they possibly test it? You don’t need to have detailed documentation to get started with testing. Many times, decent testers can use their judgement and common sense to validate a product. Domain knowledge becomes crucially important. Testers should be confident to work more from their own knowledge of what good looks like. It’s certainly not just a case of following a test script, making sure the software does what it says in the spec. "
    }, {
    "id": 115,
    "url": "localhost:4000/test-automation-done-separate-dedicated-team/",
    "title": "Should Test Automation be Done by Separate Dedicated Team?",
    "body": "2017/01/22 - What are the advantages and disadvantages of having a dedicated team focusing only on test automation? When there are multiple agile teams in an organization, should each team take care of their own test automation efforts or should test automation be the responsibility of a separate team? As an Agile Tester in an Agile Team, you often don’t have enough time to test the new features and at the same time automate them. You might get time to either test the new features manually or spend time writing automated tests but it can be tricky to do both. So, wouldn’t it be ideal if test automation was done by a separate team? One of the roles I held during my career was a Test Automation Manager and was faced with a similar situation as described above. We had multiple Scrum Teams with each having a dedicated QA member who was not necessarily technical, so their tasks were mostly focused on testing new features manually. In addition to the Scrum Teams, we also had a separate team of “Test Automation Engineers” whose tasks were to automate stories for the multiple Scrum Teams. This team of Test Automation Engineers, were technically very strong, but not necessarily a strong testing mindset, quite the opposite to the “Manual QAs” in the Scrum Teams, so at each sprint the manual QAs would list down the stories that they wanted to be automated and hand them over to the Test Automation team for scripting. https://www. testingexcellence. com/there-is-no-qa-team-in-agile/ This setup did have some advantages, but at the same time had major drawbacks. I will list the advantages and disadvantages of the above team structure and what we did to resolve the issues, but first, let’s see why the test automation team was created in the first place.  The test automation engineers were initially embedded in the Scrum team and were seen as the QA resource but there were few problems with this setup: Test automation engineers embedded within the scrum teams had a narrow focus and only automated stories related to their area that they were working on. There was no one with a full knowledge of the system to be able to create scenario tests or end-to-end tests that exercised the whole application stack.  As it happens, it is quite a common trait amongst most test automation engineers, that they want to create their own little frameworks and build it from scratch. The downside to this is you will end up with many frameworks, each with different designs and a lot of duplications, both in terms of code and effort.  Because the test automation engineers were seen as a QA resource, they were also involved in manual testing particularly when the deadlines were tight, only to test the stories and get them out of the door. This meant that they would lose time to automate the tests during the sprint. After reviewing these problems, it was decided to liberate the test automation engineers from the Scrum teams and form a separate “Test Automation Team” to address the above issues. https://www. testingexcellence. com/can-testers-add-value-agile-projects/ Advantages of Separate Test Automation Team: Having a separate dedicated test automation team had the following advantages:  The team was able to share knowledge among themselves on updates to the framework code and review of new tools and libraries Because the team shared their knowledge, there was little duplicate code and many core modules were reused and shared for different tests The team used one single test automation framework which they all contributed to Team members were able to work in isolation without any of the daily clutter of the scrum teams and fully focused only on automation work Although each team member was assigned to a Scrum team, they were able to help each other out when there were complex stories to automate There were two senior members who focused on updating and refactoring the framework to facilitate and simplify the scripting of test codeDisadvantages of Separate Test Automation Team: In contrast to the above benefits, there were some clear disadvantages of separating test automation from the Scrum teams:  The team was disengaged from all the discussions and communications that were happening in the Scrum teams. This created a feeling of separation and isolation which had a negative impact.  Because the team was so focused on automating stories that were given to them by the Scrum teams, they rarely checked the quality of the tests or scenarios that was given to them.  Created a clear divide between “manual testers” and “automation testers”:     Test automation team members often felt inferior to the QAs in the Scrum teams with regards to testing knowledge and even domain knowledge.    Likewise, the QAs in the Scrum teams felt that the test automation team were superior because they had the technical knowledge.     The team was somewhat spoon-fed by manual QAs from the Scrum teams with little or no collaboration and discussion around what was deemed suitable and worthwhile for automation. Embedding Test Automation in Scrum Teams: There were both advantages and disadvantages in having a separate and dedicated test automation team responsible for automating tests and tasks for the Scrum teams. After letting the above setup to run for a number of months, we decided to reshuffle the test automation team members and once again embed them within the Scrum team, but this time, we also introduced another team called the “Test Architecture Group” to prevent the problems faced initially when the test automation engineers were part of the Scrum teams. This team had members with deep knowledge of the domain and members with technical expertise. While the test automation engineers and QAs worked side-by-side in each Scrum team, the domain experts from the test architecture group had a high-level overview across the Scrum teams so were able to digest each story and create end-to-end scenarios. The technical experts of the TAG group were responsible to review each test automation engineer’s code for compliance with standards and best practices and also contribute to the unified framework development. In other words, they facilitated tools and framework for the test automation engineers across the Scrum teams, so they could focus on delivering automated tests within the sprint. This setup worked quite well for the organization and over time there was a better quality of automated tests and more collaboration amongst all teams. "
    }, {
    "id": 116,
    "url": "localhost:4000/testers-quick-guide-exploratory-testing/",
    "title": "A Tester's Quick Guide to Exploratory Testing",
    "body": "2017/01/15 - : What is Exploratory Testing?: Exploratory testing is Simultaneous exploration, design and execution.  That means a tester is not referring to any pre-designed test cases during exploratory testing. There are two aims in exploratory testing: A - To learn about the system under test - Exploration. B - To apply existing knowledge about the system under test to find bugs - Design and Execution. Other characteristics of Exploratory Testing are:  It is an interactive test process Using information gained while testing to design new and better tests Formal, which means it is different from error-guessing and ad-hoc testing Testers have skills to listen, read, think and report rigorously and effectivelyWhen is Exploratory Testing Applicable?: Exploratory Testing is most applicable when:  There is little or no specification is available Investigating a particular defect Investigating a particular risk – to evaluate the need for scripted tests There is no time to specify and script tests We want to diversify testingHow to Prepare for Exploratory Testing?: For preparing and executing exploratory tests, test charters are used with items like:  What will be tested (scope) What will not be tested (out of scope) Why (questions to be answered) How (brainstorm) Expected problems ReferenceHow to Report Results of Exploratory Testing?: For describing the results of the exploratory tests, session sheets are used:  Test coverage outline Name of the tester who performed the exploratory testing session Test execution log Defects found Quality indicator (number of major defects per hour) New risks encountered Issues, questions, anomaliesThere will also be a debriefing at the end of the session for discussing priority of defects, risks mitigated, etc. "
    }, {
    "id": 117,
    "url": "localhost:4000/definitive-guide-writing-good-agile-user-stories/",
    "title": "Definitive Guide to Writing Good Agile User Stories",
    "body": "2017/01/13 - One of the first steps in delivering a quality product, is writing good user stories. A user story is a place to capture product functionality and as the name suggests, user stories describe how a customer or user will use the product. In this post, we describe how to write good user stories and what should be included. A user story represents a small piece of functionality which has a business value that a team can deliver in a sprint. The difference between a user story and a traditional requirement document is the level of detail. Requirement documents tend to contain a lot of text and are very detailed, whereas user stories are mainly based around conversations. We can break down the structure of a user story as:  The brief description of the need The conversations that happen during backlog grooming and sprint planning to solidify the details The acceptance tests that confirm the story’s satisfactory completionAn important point to bear in mind when writing user stories is that they are written from the perspective of the user who will ultimately use the product, hence it is important that we clearly identify who the user is when writing user stories. How to Write Good User Stories: As a rule of thumb, a good user story should adhere to the INVEST acronym: Independent - user stories should not depend on each other so they can be developed in any order. Negotiable - Avoid too much detail; keep them flexible so the team can adjust how much of the story to implement. Valuable - the story should provide some value to its users. Estimable - the team must be able to estimate the story. Small - user stories should be small enough to fit in a sprint; large stories are hard to estimate and plan. Testable - ensure what is being developed can be verified and tested adequately. What Format is Used to Write User Stories?: User stories generally have the following format: _As a , I want to so that . _ Example: As a customer of abc. com, I want a login functionality so that I can access my account details online. As mentioned earlier, pay particular attention to who the user of the product is and avoid the generic role of “User”.  If you don’t know who the users and customers are and why they would want to use the product, then you should not write any user stories. Narrative  The first part of the user story is the Narrative. 2-3 sentences used to describe the intent of the story. It is just a summary of the intent. Conversations  The most crucial aspect of a user story is the conversations that should happen continuously between the development team, customer, Product Owner and other stakeholders to solidify the details of the user story. Acceptance Criteria  Acceptance criteria represent the conditions of satisfaction which are written as scenarios, usually in Gherkin (Given, When, Then) format.  Acceptance criteria also provide the Definition of Done for the story. Who Should Write User Stories?: In most cases, user stories are written by a Product Owner or Business Analyst and prioritized in the product backlog. However, that’s not to say that it is the responsibility of only the Product Owner to write user stories. In fact, any team member can write user stories, but it is the Product Owner’s responsibility to ensure a backlog of user stories exist and are prioritized. What’s important, is that user stories should not be treated like requirements document which when written will get handed off to development team for implementation. User stories should be seen as a means of encouraging conversations between the Product Owner and the development team, and thus should be written collaboratively during the product backlog grooming sessions. An advantage of involving the development team in writing user stories is that if there are any technical constraints, they can be highlighted well in advance. Testers can particularly add value in constructing effective acceptance criteria and plan in advance on what needs to be tested and how. How Detailed Should User Stories Be?: User stories focus on customer value. The basic difference between user stories and other forms of requirements specification is the level of detail.  A user story is a metaphor for the work being done, not a full description of the work.   The actual work being done is fleshed out via collaboration revolving around the user story as system development progresses. If the description becomes too lengthy (more than what will fit on an index card), you should revisit the user story. It is likely that you are trying to include too much detail. Remember that the purpose of a user story is to encourage collaboration. It is not meant to document every aspect of the work, as it’s normally the case in traditional requirements statements. Moreover, too much information in the description can lead to missing information in acceptance criteria. Before agreeing to work on a story, the team must understand the acceptance criteria. These are essential for knowing what needs to be done in order to satisfy the user story. Acceptance criteria should be detailed enough to define when the user story is satisfied, yet not so detailed as to quash collaboration. Common Mistakes When Writing User Stories:    Too formal or too much detail. Product owners with good intentions often try to write extremely detailed user stories.  If a team sees a story at iteration planning that looks like an IEEE requirements document, they often assume that all the details are there and will skip the detailed conversation.     Writing user stories for Technical tasks. Much of the power of Agile comes from having a working increment of software at the end of each iteration.  If your stories are really just technical tasks, you often do not end up with working software at the end of each iteration, and you lose flexibility in prioritization.     Skipping the conversation. Stories are intentionally vague before iteration planning.  If you skip the acceptance criteria conversation, you risk moving in the wrong direction, missing edge cases or overlooking customer needs.  Do you have any tips that can be added to the above information for writing good user stories? Feel free to put them in comments. "
    }, {
    "id": 118,
    "url": "localhost:4000/difference-between-scrum-kanban-xp-agile/",
    "title": "What is the Difference Between Scrum, Kanban and XP?",
    "body": "2017/01/11 - In Agile Software Development Methodology, software is developed incrementally and iteratively and delivered bit by bit, rather than everything at once. Each iteration is time-boxed, around 2-4 weeks, and at the end of each iteration, a version of software is ready to be shipped. In Agile Methodology, projects are broken down into chunks or little bits of user functionality called user stories. A Product Owner is responsible for prioritizing these user stories in the backlog which are then continuously delivered in short two week cycles called Sprints or iterations. In this article, we review the differences between Scrum, Kanban and XP. At the high level, there are three flavours of Agile Methodology: https://www. testingexcellence. com/testing-in-devops/ Scrum:    A prioritized wish list called a product backlog is created. A placeholder for all the future development stories.     During the planning phase, the team selects a small chunk from the top of that wish list and create what is called a sprint backlog, and decides how to implement those pieces.     The team is given a certain amount of time, called a sprint, to complete its work.     The team meet each day on a stand-up meeting to assess the progress.     At the end of the sprint—usually two to four weeks—the work should be ready to hand to a customer.     The sprint ends with a sprint review and a retrospective.     The next sprint then begins.  Kanban: Kanban was first pioneered by Toyota engineers and the word Kanban in Japanese stands for “visual signal” or “card. ” Kanban is adaptable to software and non-software development projects and its  principles are:  **Visualize the workflow. **This can be done by using a card wall, or a Kanban Board, with the columns on the board representing the states or steps in the workflow and the cards representing the work items.  **Limit the works in progress. **Limiting work in progress or WIP is the cornerstone of Kanban. For example, If the team was working on five items at a time and not making progress, then we should reduce that number to two or three so work can be managed and progress made. Select the most important, most valuable work items. Always be working on the next most important thing.  **Manage flow. **The whole point of implementing a Kanban system is to create positive change. Before you can create that change you have to know what to change. You figure that out by looking at how value is currently flowing through the system, analyzing problem areas in which value flow is stalled and defining, then implementing, changes.  The flow of work through each state or step should be actively monitored, measured and reported in order to evaluate positive or negative effects of incremental and evolutionary changes.  **Make process policies explicit. **Ensure an explicit understanding of the mechanism of a process to achieve a rational, objective discussion of issues—and facilitate consensus around improvement suggestions.  An example of a policy that you can make explicit is a definition of done. In fact, you can have a definition of done for each step in your workflow, meaning that before an item can be ready to pull forward, it has to meet certain criteria.  **Improve collaboratively. **To truly leverage Kanban, teams must collaborate. We should not forget that Kanban is like any other agile method in that the team can meet as a team to plan, meet daily for a stand-up, and can choose to do retrospectives to inspect and adapt their process. Aim for constant collaboration and continuous improvement. If you are not continually improving, but you are doing all of the other parts of the Kanban method, you are missing the point. Its a little like the concept of “doing” Agile but not being agile. Extreme Programming (XP): XP has five values that can be emphasized in non-software development projects: simplicity, communication, feedback, respect and courage. It focuses on test-driven development (TDD), small releases and a team structure that includes the customer. Many of the rules for this agile methodology are designed specifically to address coding, designing and testing. Take planning, for example: A traditional project does planning up front; XP says to plan the release at a high level, but plan each iteration at its start (or every two weeks). Extreme Programming is based on 12 principles:  The Planning ProcessThe desired features of the software, which are communicated by the customer, are combined with cost estimates provided by the programmers to determine what the most important factors of the software are. This stage is sometimes called the Planning Game.  Small ReleasesThe software is developed in small stages that are updated frequently, typically every two weeks.  MetaphorAll members on an XP team use common names and descriptions to guide development and communicate on common terms.  Simple DesignThe software should include only the code that is necessary to achieve the desired results communicated by the customer at each stage in the process. The emphasis is not on building for future versions of the product.  TestingTesting is done consistently throughout the process. Programmers design the tests first and then write the software to fulfill the requirements of the test. The customer also provides acceptance tests at each stage to ensure the desired results are achieved.  RefactoringXP programmers improve the design of the software through every stage of development instead of waiting until the end of the development and going back to correct flaws.  Pair ProgrammingAll code is written by a pair of programmers working at the same machine.  Collective OwnershipEvery line of code belongs to every programmer working on the project, so there are no issues of proprietary authorship to slow the project down. Code is changed when it needs to be changed without delay.  Continuous IntegrationThe XP team integrates and builds the software system multiple times per day to keep all the programmers at the same stage of the development process at once.  40-Hour WeekThe XP team does not work excessive overtime to ensure that the team remains well-rested, alert and effective.  On-Site CustomerThe XP project is directed by the customer who is available all the time to answer questions, set priorities and determine requirements of the project.  Coding StandardThe programmers all write code in the same way. This allows them to work in pairs and to share ownership of the code. "
    }, {
    "id": 119,
    "url": "localhost:4000/can-testers-add-value-agile-projects/",
    "title": "How Can Testers Add Value in Agile Projects?",
    "body": "2017/01/10 - What do Agile Testers do and how can they add value in Agile projects? A tester on an Agile project will work differently than one working on a traditional project. Testers must understand the values and principles that underpin Agile projects, and how testers are an integral part of a whole-team approach together with developers and business representatives. The members in an Agile project communicate with each other early and frequently, which helps with removing defects early and developing a quality product. It is important to note that testers in Agile projects, don’t just focus on testing the product to find bugs, rather the focus should largely be on improving the processes to prevent defects, and testers play an important role in this. Here, we look at how Agile Testers can add value in each stages of the software delivery in an Agile setup. Agile Testers Adding Overall Value: Testers are involved in defining the overall quality and approach to testing and especially add value in the following activities:  Agile Test Strategy Agile Test Automation Strategy Delivery Pipeline Advocating Whole-team Approach Define Test EnvironmentsAgile Testers Adding Value in Pre-Planning: Testers are involved in Pre-planning and Story grooming sessions and especially add value in the following activities:  Defining testable user stories, including acceptance criteria Determining the testability of the user stories Creating acceptance tests for the user stories Participating in project and quality risk analysesAgile Testers Adding Value in Sprint Planning: Testers are involved in Sprint planning meetings and especially add value in the following activities:  Planning the testing for the release Participating in the detailed risk analysis of user stories Creating acceptance tests for the user stories Defining the necessary test levels Breaking down user stories into tasks (particularly testing tasks) Estimating testing effort associated with the user stories and all testing tasks Identifying functional and non-functional aspects of the system to be tested Supporting and participating in test automation at multiple levels of testingAgile Testers Adding Value During Sprint: Testers are involved during Sprint and especially add value in the following activities:  Performing Exploratory Testing of new Features Writing Automated Regression Tests for new and existing features Integrating and Executing Automated Tests on a CI server Feedback as soon as possible to the team in case of any issues Update Acceptance Tests when new scenarios are thought ofhttps://www. testingexcellence. com/agile-testing-challenges-qa-agile-projects/ "
    }, {
    "id": 120,
    "url": "localhost:4000/static-analysis-vs-dynamic-analysis-software-testing/",
    "title": "Static Analysis vs Dynamic Analysis in Software Testing",
    "body": "2017/01/08 - : What is Static Analysis?: Static analysis involves no dynamic execution of the software under test and can detect possible defects in an early stage, before running the program. Static analysis is done after coding and before executing unit tests. Static analysis can be done by a machine to automatically “walk through” the source code and detect noncomplying rules.  The classic example is a compiler which finds lexical, syntactic and even some semantic mistakes. Static analysis can also be performed by a person who would review the code to ensure proper coding standards and conventions are used to construct the program. This is often called Code Review and is done by a peer developer, someone other than the developer who wrote the code. Static analysis is also used to force developers to not use risky or buggy parts of the programming language by setting rules that must not be used. When developers performs code analysis, they usually look for  Lines of code Comment frequency Proper nesting Number of function calls Cyclomatic complexity Can also check for unit testsQuality attributes that can be the focus of static analysis:  Reliability Maintainability Testability Re-usability Portability EfficiencyWhat are the Advantages of Static Analysis?: The main advantage of static analysis is that it finds issues with the code before it is ready for integration and further testing. Static code analysis advantages:  It can find weaknesses in the code at the exact location.  It can be conducted by trained software assurance developers who fully understand the code.  Source code can be easily understood by other or future developers It allows a quicker turn around for fixes Weaknesses are found earlier in the development life cycle, reducing the cost to fix.  Less defects in later tests Unique defects are detected that cannot or hardly be detected using dynamic tests     Unreachable code   Variable use (undeclared, unused)   Uncalled functions   Boundary value violations   Static code analysis limitations:  It is time consuming if conducted manually.  Automated tools produce false positives and false negatives.  There are not enough trained personnel to thoroughly conduct static code analysis.  Automated tools can provide a false sense of security that everything is being addressed.  Automated tools only as good as the rules they are using to scan with.  It does not find vulnerabilities introduced in the runtime environment. What is Dynamic Analysis?: In contrast to Static Analysis, where code is not executed, dynamic analysis is based on the system execution, often using tools. From Wikipedia’s definition of dynamic program analysis:  Dynamic program analysis is the analysis of computer software that is performed with executing programs built from that software on a real or virtual processor (analysis performed without executing programs is known as static code analysis). Dynamic program analysis tools may require loading of special libraries or even recompilation of program code. The most common dynamic analysis practice is executing Unit Tests against the code to find any errors in code. Dynamic code analysis advantages:  It identifies vulnerabilities in a runtime environment.  It allows for analysis of applications in which you do not have access to the actual code.  It identifies vulnerabilities that might have been false negatives in the static code analysis.  It permits you to validate static code analysis findings.  It can be conducted against any application. Dynamic code analysis limitations:  Automated tools provide a false sense of security that everything is being addressed.  Cannot guarantee the full test coverage of the source code Automated tools produce false positives and false negatives.  Automated tools are only as good as the rules they are using to scan with.  It is more difficult to trace the vulnerability back to the exact location in the code, taking longer to fix the problem. "
    }, {
    "id": 121,
    "url": "localhost:4000/agile-testing-mindset-tester-role-agile-team/",
    "title": "Agile Testing Mindset and the Role of the Agile Tester",
    "body": "2017/01/06 - In an Agile team, testers must closely collaborate with all other team members and with business stakeholders. This has a number of implications in terms of the skills a tester must have and the activities they perform within an Agile team. Agile Testing Mindset: Agile Testers need to break away from the principles and working methodologies of traditional software development. In order to succeed as an Agile Tester, the right mindset is required. The Agile Testing Mindset, could be summed up in twelve principles:  Quality Assistance over Quality Assurance Continuous Testing over Testing at the End Team Responsibility for Quality over Tester’s Responsibility Whole Team Approach over Testing Departments and Independent Testing Automated Checking over Manual Regression Testing Technical and API Testing over Just GUI Testing Exploratory Testing over Scripted Testing User Stories and Customer Needs over Requirement Specifications Building the Best Software over Breaking the Software Early Involvement over Late Involvement Short Feedback Loop over Delayed Feedback Preventing Defects over Finding DefectsWhat Skills Should an Agile Tester Have?: In addition to the skills required for a tester working in a traditional waterfall project, a tester in an Agile team should be competent in test automation, test-driven development, acceptance test-driven development, white-box, black-box, and experience-based testing. As Agile methodologies depend heavily on collaboration, communication, and interaction between the team members as well as stakeholders outside the team, testers in an Agile team should have good interpersonal skills. Testers in Agile teams should:  Be positive and solution-oriented with team members and stakeholders Display critical, quality-oriented, skeptical thinking about the product Actively acquire information from stakeholders (rather than relying entirely on written specifications) Accurately evaluate and report test results, test progress, and product quality Work effectively to define testable user stories, especially acceptance criteria, with customer representatives and stakeholders Collaborate within the team, working in pairs with programmers and other team members Respond to change quickly, including changing, adding, or improving test cases Plan and organize their own workThe Role of a Tester in an Agile Team: The role of a tester in an Agile team includes activities that generate and provide feedback not only on test status, test progress, and product quality, but also on process quality. These activities include:  Understanding, implementing, and updating the Agile Test Strategy Work with Product Owners to define Acceptance Criteria and the Definition of Done.  Measuring and reporting test coverage across all applicable coverage dimensions Ensuring proper use of testing tools Configuring, using, and managing test environments and test data Writing and executing automated checks and reporting back to the team Reporting defects and working with the team to resolve them Coaching other team members in relevant aspects of testing Ensuring the appropriate testing tasks are scheduled during release and iteration planning Actively collaborating with developers and business stakeholders to clarify requirements, especially in terms of testability, consistency, and completeness Participating proactively in daily standup meetings, story grooming sessions, team retrospectives, suggesting and implementing improvementsWithin an Agile team, each team member is responsible for product quality and plays a role in performing test-related tasks. Agile organizations may encounter some test-related organizational risks:  Testers work so closely to developers that they lose the appropriate tester mindset Testers become tolerant of or silent about inefficient, ineffective, or low-quality practices within the team Testers cannot keep pace with the incoming changes in time-constrained iterations"
    }, {
    "id": 122,
    "url": "localhost:4000/roles-responsibilities-product-owner-agile/",
    "title": "Roles and Responsibilities of a Product Owner in Agile",
    "body": "2017/01/05 -  Product Owner Roles and Responsibilities: Product Owner is one of the main roles in Agile projects. But what does a Product Owner do? The Product Owner is the voice of the customer in the Scrum Team. The Product Owner is typically a product manager or a business analyst and has a vision of what the product should do and how it should behave. Here, we list some common responsibilities of a PO in Agile.  Single person responsible for maximizing the return on investment (ROI) of the development effort Responsible for product vision Constantly re-prioritizes the Product Backlog Clarifies questions on requirements Accepts or rejects each product increment Decides whether to ship Decides whether to continue development Considers stakeholder interests May contribute as a team memberThe Product Owner sits in between of the senior management team, such as the CEO and CIO, and the Scrum Teams and is responsible for ensuring business requirements are met efficiently and effectively. Through constant monitoring of the product backlog, the Product Owner can re-prioritize the items based on the business needs. During each Sprint, the Scrum Team feedback to the Product Owner who can then decide whether to ship the product to the customers or to make further refinements before the product goes out. By having a clear vision of the product, the Product Owner defines the Acceptance Criteria for each backlog item and is the best person to address any questions the Scrum team have about the backlog items. The Product Owner should also engage in User Acceptance Testing as the product is being developed to get an early insight of the product so that any amendments are done early in the development rather than later. Should the Product Owner be a technical person?: In reality, the term Technical Product Owner describes a person, not a role.  Specifically, it describes a person who has a technical background and works on a technology product.  It does not mean that the Product Owner will actually need to perform any technical tasks, such as software architecting and coding. They are not actually developing the product—they are performing a Product Management role in close coordination with a Software Development Team, the Scrum Team. For a company to get the most value from the role, Product Owner must focus on product management, not development. But some Product Owners need to understand the company’s technology at a deep level and interface with the Development Team in order to successfully lead the strategy for the product. "
    }, {
    "id": 123,
    "url": "localhost:4000/fundamental-test-process-software-testing/",
    "title": "Fundamental Test Process",
    "body": "2016/12/31 - What is the Fundamental Test Process?: In order to gain the most of the testing activities, a defined process must be followed. But before any testing activity begins, much of the effort should be spent on producing a good test plan. A good test plan goes a long way in ensuring that the testing activities are adhered to what the testing is trying to achieve. This is a test process that is documented in the standard BS7925-2 Software Component Testing. It therefore relates most closely to component testing but is considered general enough to apply to all levels of testing (i. e. component, integration in the small, system, integration in the large, and acceptance testing). It is perhaps most applicable to a fairly formal testing environment (such as mission critical). Most commercial organisations have less rigorous testing processes. However, any testing effort can use these steps in some form. The Fundamental Test Process comprises five activities:  Planning Specification Execution Recording Checking for Test CompletionThe test process always begins with Test Planning and ends with Checking for Test Completion. Any and all of the activities may be repeated (or at least revisited) since a number of iterations may be required before the completion criteria defined during the Test Planning activity are met. One activity does not have to be finished before another is started; later activities for one test case may occur before earlier activities for another. During this cycle of activities, all the while, the progress of activities need to be monitored and controlled so that we stay in line with the test plan. The five activities are described in more detail below. 1. Test Planning: The basic philosophy is to plan well. All good testing is based upon good test planning. There should already be an overall test strategy and possibly a project test plan in place. This Test Planning activity produces a test plan specific to a level of testing (e. g. system testing). These test level specific test plans should state how the test strategy and project test plan apply to that level of testing and state any exceptions to them. When producing a test plan, clearly define the scope of the testing and state all the assumptions being made. Identify any other software required before testing can commence (e. g. stubs &amp; drivers, word processor, spreadsheet package or other 3rd party software) and state the completion criteria to be used to determine when this level of testing is complete. Example completion criteria are (some are better than others and using a combination of criteria is usually better than using just one):  100% statement coverage; 100% requirement coverage; all screens I dialogue boxes I error messages seen; 100% of test cases have been run; 100% of high severity faults fixed; 80% of low &amp; medium severity faults fixed; maximum of 50 known faults remain; maximum of 10 high severity faults predicted; time has run out; testing budget is used up. 2. Test Specification: The fundamental test process describes this activity as designing the test cases using the techniques selected during planning. For each test case, specify its objective, the initial state of the software, the input sequence and the expected outcome. Since this is a little vague we have broken down the Test Specification activity into three distinct tasks to provide a more helpful explanation. (Note that this more detailed explanation of the Test Specification is not a part of the Foundation syllabus. ) Specification can be considered as three separate tasks:  Identify test conditions Design test cases - determine ‘how’ the identified test conditions are going to be exercised; Build test cases - implementation of the test cases (scripts, data, etc. ). 3. Test Execution: The purpose of this activity is to execute all of the test cases (though not necessarily all in one go). This can be done either manually or with the use of a test execution automation tool (providing the test cases have been designed and built as automated test cases in the previous stage). The order in which the test cases are executed is significant. The most important test cases should be executed first. In general, the most important test cases are the ones that are most likely to find the most serious faults but may also be those that concentrate on the most important parts of the system. There are a few situations in which we may not wish to execute all of the test cases. When testing just fault fixes we may select a subset of test cases that focus on the fix and any likely impacted areas (most likely all the test cases will have been run in a previous test effort). If too many faults are found by the first few tests we may decide that it is not worth executing the rest of them (at least until the faults found so far have been fixed). In practice time pressures may mean that there is time to execute only a subset of the specified test cases. In this case it is particularly important to have prioritised the test cases to ensure that at least the most important ones are executed. If any other ideas for test conditions or test cases occur they should be documented where they can be considered for inclusion. 4. Recording: In practice the Test Recording activity is done in parallel with Test Execution. To start with we need to record the versions of the software under test and the test specification being used. Then for each test case we should record the actual outcome and the test coverage levels achieved for those measures specified as test completion criteria in the test plan. In this way we will be marking off our progress. The test record is also referred to as the “test log”, but “test record” is the terminology in the syllabus. Note that this has nothing to do with the recording or capturing of test inputs that some test tools perform! The actual outcome should be compared against the expected outcome and any discrepancy found logged and analysed in order to establish where the fault lies. It may be that the test case was not executed correctly in which case it should be repeated. The fault may lie in the environment set-up or be the result of using the wrong version of software under test. The fault may also lie in the specification of the test case: for example, the expected outcome could be wrong. Of course the fault may also be in the software under test! In these cases the fault should be fixed and the test case executed again. The records made should be detailed enough to provide an unambiguous account of the testing carried out. They may be used to establish that the testing was carried out according to the plan. 5. Checking for Completion: This activity has the purpose of checking the records against the completion criteria specified in the test plan. If these criteria are not met, it will be necessary to go back to the specification stage to specify more test cases to meet the completion criteria. There are many different types of coverage measure and different coverage measures apply to different levels of testing. Comparison of the five activities: Comparing these five activities of the Fundamental Test Process it is easy to see that the first two activities (Test Planning and Test Specification) are intellectually challenging. Planning how much testing to do, determining appropriate completion criteria, etc. requires careful analysis and thought. Similarly, specifying test cases (identifying the most important test conditions and designing good test cases) requires a good understanding of all the issues involved and skill in balancing them. It is these intellectual tasks that govern the quality of test cases. The next two activities (Test Execution and Test Recording) involve predominantly clerical tasks. Furthermore, executing and recording are activities that are repeated many times whereas the first two activities, Test Planning and Test Specification are performed only once (they may be revisited if the completion criteria are not met the first time around but they are not repeated from scratch). The Test Execution and Test Recording activities can be largely automated and there are significant benefits in doing so. "
    }, {
    "id": 124,
    "url": "localhost:4000/why-we-test-software/",
    "title": "Why We Test Software",
    "body": "2016/12/30 - Why is software testing necessary?: Software Testing is necessary because the existence of faults in software is inevitable. Beyond fault-detection, the modern view of testing holds that fault-prevention (e. g. early fault detection/removal from requirements, designs etc. through static tests) is at least as important as detecting faults in software by executing dynamic tests. What are errors, faults and failures?: An error is a human action producing an incorrect result. The error is the activity undertaken by an analyst, designer, developer, or tester whose outcome is a fault in the deliverable being produced. When programmers make errors, they introduce faults to program code. We usually think of programmers when we mention errors, but any person involved in the development activities can make the error, which injects a fault into a deliverable. A fault is a manifestation of human error in software. A fault in software is caused by an unintentional action by someone building a deliverable. We normally think of programmers when we talk about software faults and human error. Human error causes faults in any project deliverable. Faults may be caused by requirements, design or coding errors. All software development activities are prone to error. Faults may occur in all software deliverables when they are first being written or when they are being maintained. A failure is a deviation of the software from its expected delivery or service. Software fails when it behaves in a different way that we expect or require. If we use the software properly and enter data correctly into the software but it behaves in an unexpected way, we say it fails. Software faults cause software failures when the program is executed with a set of inputs that expose the fault. It is very important to note that not all software faults cause failures and many faults in the software can go unnoticed for a long period of time and may never be found. On the other hand, defect clustering is a characteristic of testing a large software application. You cannot tell whether software fails unless you know how the software is meant to behave. This might be explicitly stated in requirements or you might have a sensible expectation that the software should not ‘crash’. "
    }, {
    "id": 125,
    "url": "localhost:4000/how-much-testing-is-enough/",
    "title": "How Much Testing Is Enough?",
    "body": "2016/12/29 - It is possible to do enough testing but determining the how much is enough is difficult. Simply doing what is planned is not sufficient since it leaves the question as to how much should be planned. What is enough testing can only be confirmed by assessing the results of testing. If lots of faults are found with a set of planned tests it is likely that more tests will be required to assure that the required level of software quality is achieved. On the other hand, if very few faults are found with the planned set of tests, then (providing the planned tests can be confirmed as being of good quality) no more tests will be required. Saying that enough testing is done when the customers or end-users are happy is a bit late, even though it is a good measure of the success of testing. However, this may not be the best test stopping criteria to use if you have very demanding end-users who are never happy! Why not stop testing when you have proved that the system works? It is not possible to prove that a system works without exhaustive testing (which is totally impractical for real systems). Have you tested enough when you are confident that the system works correctly? This may be a reasonable test stopping criterion, but we need to understand how well justified that confidence is. It is easy to give yourself false confidence in the quality of a system if you do not do good testing. It is not uncommon to have one Master Test Plan which is a common document for the test phases and each test phase have their own Test Plan documents. Ultimately, the answer to “How much testing is enough?” is “It depends!” (this was first pointed out by Bill Hetzel in his book “The Complete Guide to Software Testing”). It depends on risk, the risk of missing faults, of incurring high failure costs, of losing creditability and market share. All of these suggest that more testing is better. However, it also depends on the risk of missing a market window and the risk of over-testing (doing ineffective testing) which suggest that less testing may be better. We should use risk to determine where to place the emphasis when testing by prioritizing our test cases. Different criteria can be used to prioritize testing including complexity, criticality, visibility and reliability. "
    }, {
    "id": 126,
    "url": "localhost:4000/waterfall-model/",
    "title": "Waterfall Model in Software Testing",
    "body": "2016/12/28 - What is the Waterfall Model in Software Testing?: Once upon a time, software development consisted of a programmer writing code to solve a problem or automate a procedure. Nowadays, systems are so big and complex that teams of architects, analysts, programmers, testers and users must work together to create the millions of lines of custom-written code that drive our enterprises.  The oldest of these, and the best known, is the waterfall model: a sequence of stages in which the output of each stage becomes the input for the next. These stages can be characterized and divided up in different ways, including the following:  Requirement Specification Design Construction (AKA Implementation or Coding) Integration Testing (AKA Validation) Installation MaintenanceThe waterfall model is well understood, but it’s not as useful as it once was. The problem is that the waterfall model assumes that the only role for users is in specifying requirements, and that all requirements can be specified in advance. Unfortunately, requirements grow and change throughout the process and beyond, calling for considerable feedback and iterative consultation. Thus many other development models have been developed. Advantages of waterfall model:  Each phase has specific deliverables and a review process.  Phases are processed and completed one at a time.  Works well for smaller projects where requirements are very well understood.  It reinforces the notions of “define before design” and “design before code”. Disadvantages of waterfall model:  Adjusting scope during the life cycle can kill a project No working software is produced until late during the life cycle.  High amounts of risk and uncertainty.  Poor model for complex and object-oriented projects.  Poor model for long and ongoing projects.  Poor model where requirements are at a moderate to high risk of changing. When to use waterfall model:  Such model is highly used where requirements are clear and there will be no changes in the development time. We can find such scenarios in defense projects, where requirements will be clear since before they write requirements they will analyses well.  We can also name this kind of life cycle model for migration projects, where requirements will be same only platform or languages may vary / change.  Also can use for projects where sponsor themselves will do testing activities, since till the completion of the coding we will not deliver the project. "
    }, {
    "id": 127,
    "url": "localhost:4000/v-model-in-software-testing/",
    "title": "V Model",
    "body": "2016/12/28 - V Model in Software Testing: V Model is an enhanced version of the classic waterfall model whereby each level of the development life-cycle is verified before moving on to the next level. With this model, software testing explicitly starts at the very beginning, i. e. as soon as the requirements are written. Here, by testing we mean verification by means of reviews and inspections, i. e. static testing. This helps in identifying errors very early in the life-cycle and minimizes potential future defects appearing in the code later in the life-cycle. Each level of the development life-cycle has a corresponding test plan. i. e. as each phase is being worked on, a test plan is developed to prepare for the testing of the products of that phase. Be developing the test plans, we can also define the expected results for testing of the products for that level as well as defining the entry and exit criteria for each level. In the V Model the test activities are spelled out to the same level of detail as the design activities. Software is designed on the left-hand (downhill) part of the model, and built and tested on the right-hand (uphill) part of the model. Note that different organizations may have different names for the development and testing phases. The correspondences between the left and right hand activities are shown by the lines across the middle of the V, showing the test levels from component testing at the bottom, integration and system testing, and acceptance testing at the top level. V Model - Advantages:  in V Model, Each phase has specific deliverables.  Higher chance of success over the waterfall model due to the development of test plans early on during the life cycle.  Time concern in comparison with the waterfall model is low or even we can say 50% less.  Works well for small projects where requirements are easily understood.  Utility of the resources is high. V Model - Disadvantages:  Very rigid, like the waterfall model.  Little flexibility and adjusting scope is difficult and expensive.  Software is developed during the implementation phase, so no early prototypes of the software are produced.  V Model doesn’t provide a clear path for problems found during testing phases. When to use the V model:  As per my knowledge I personally think / feel where time and cost is the constraints of the project then we can use such models for quick and cost effective delivery.  In comparison with waterfall model, V Model is more or less the same but the activity of testing starts very early, which leads to less time, and cost of the project. "
    }, {
    "id": 128,
    "url": "localhost:4000/system-testing/",
    "title": "Prototyping",
    "body": "2016/12/28 - What is System Testing?: System testing has two important aspects, which are distinguished in the syllabus: functional system testing and non-functional system testing. The non-functional aspects are often as important as the functional, but are generally less well specified and may therefore be more difficult to test (but not impossible). If an organization has an independent test group, it is usually at this level, i. e. it performs system testing. Functional System Testing: Functional system testing gives us the first opportunity to test the system as a whole and is in a sense the final baseline of integration testing in the small. Typically we are looking at end to end functionality from two perspectives. One of these perspectives is based on the functional requirements and is called requirement-based testing. The other perspective is based on the business process and is called business process-based testing. Requirements-based Testing: Requirements-based testing uses a specification of the functional requirements for the system as the basis for designing tests. A good way to start is to use the table of contents of the requirement specification as an initial test inventory or list of items to test (or not to test). We should also prioritize the requirements based on risk criteria (if this is not already done in the specification) and use this to prioritize the tests. This will ensure that the most important and most critical tests are included in the system testing effort. Business process-based Testing: Business process-based testing uses knowledge of the business profiles (or expected business profiles). Business profiles describe the birth to death situations involved in the day to day business use of the system. For example, a personnel and payroll system may have a business profile along the lines of: Someone joins company, he or she is paid on a regular basis, he or she leaves the company. Another business process-based view is given by user profiles. User profiles describe how much time users spend in different parts of the system. For example, consider a simple bank system that has just three functions: account maintenance, account queries and report generation. Users of this system might spend 50% of their time using this system performing account queries, 40% of their time performing account maintenance and 10% of their time generating reports. User profile testing would require that 50% of the testing effort is spent testing account queries, 40% is spent testing account maintenance and 10% is spent testing report generation. Use cases are popular in object-oriented development. These are not the same as test cases, since they tend to be a bit “woolly” but they form a useful basis for test cases from a business perspective. Note that we are still looking for faults in system testing, this time in end-to-end functionality and in things that the system as a whole can do that could not be done by only a partial baseline. "
    }, {
    "id": 129,
    "url": "localhost:4000/spiral-model-sdlc/",
    "title": "Prototyping",
    "body": "2016/12/28 - What is the Spiral Model SDLC?: The spiral model starts with an initial pass through a standard waterfall life cycle, using a subset of the total requirements to develop a robust prototype. After an evaluation period, the cycle is initiated again, adding new functionality and releasing the next prototype. This process continues, with the prototype becoming larger and larger with each iteration. Hence, the “Spiral Model. ” The theory is that the set of requirements is hierarchical in nature, with additional functionality building on the first efforts. This is a sound practice for systems where the entire problem is well defined from the start, such as modeling and simulating software. Business-oriented database projects do not enjoy this advantage. Most of the functions in a database solution are essentially independent of one another, although they may make use of common data. As a result, the prototype suffers from the same flaws as the prototyping life cycle described below. For this reason, the software development team has decided against the use of the spiral lifecycle for database projects. Advantages of Spiral Model:    High amount of risk analysis     Good for large and mission-critical projects.     Software is produced early in the software life cycle.  Disadvantages of Spiral Model:    Can be a costly model to use.     Risk analysis requires highly specific expertise.     Project’s success is highly dependent on the risk analysis phase.     Doesn’t work well for smaller projects.  When to use Spiral Model:    For a typical shrink-wrap application, the spiral model might mean that you have a rough-cut of user elements (without the polished / pretty graphics) as an operable application, add features in phases, and, at some point, add the final graphics.     The spiral model is used most often in large projects.     The US military has adopted the spiral model for its Future Combat Systems program.  "
    }, {
    "id": 130,
    "url": "localhost:4000/rapid-application-development-rad/",
    "title": "Rapid Application Development (RAD)",
    "body": "2016/12/28 - What is the RAD Model?: Rapid Application Development Model or RAD for short, is a “try before you buy” approach to software development. The theory is that end users can produce better feedback when examining a live system, as opposed to working strictly with documentation. RAD-based development cycles have resulted in a lower level of rejection when the application is placed into production, but this success most often comes at the expense of a dramatic overruns in project costs and schedule. The RAD approach was made possible with significant advances in software development environments to allow rapid generation and change of screens and other user interface features. The end user is allowed to work with the screens online, as if in a production environment. This leaves little to the imagination, and a significant number of errors are caught using this process. The down side to RAD is the propensity of the end user to force scope creep into the development effort. Since it seems so easy for the developer to produce the basic screen, it must be just as easy to add a widget or two. In most RAD lifecycle failures, the end users and developers were caught in an unending cycle of enhancements, with the users asking for more and more and the developers trying to satisfy them. The participants lost sight of the goal of producing a basic, useful system in favor of the siren song of glittering perfection. For this reason, the software development team does not use a pure RAD approach, but instead blends limited prototyping in with requirements and design development during a conventional waterfall lifecycle. The prototypes developed are specifically focused on a subset of the application, and do not provide an integrated interface. The prototypes are used to validate requirements and design elements, and the development of additional requirements or the addition of user interface options not readily supported by the development environment is actively discouraged. Advantages of RAD:    RAD reduces the development time and reusability of components help to speed up development.     All functions are modularized so it is easy to work with.     For large projects RAD require highly skilled engineers in the team.  Disadvantages of RAD:    Both end customer and developer should be committed to complete the system in a much abbreviated time frame.     If commitment is lacking RAD will fail.     RAD is based on Object Oriented approach and if it is difficult to modularize the project the RAD may not work well.  "
    }, {
    "id": 131,
    "url": "localhost:4000/prototyping-model-software-development/",
    "title": "Prototyping",
    "body": "2016/12/28 - What is Prototyping Model?: [caption id=”attachment_10214” align=”aligncenter” width=”455”] prototype-model[/caption] During Prototyping model, the software development team, clarify requirements and/or design elements, that generate mockups and prototypes of screens, reports, and processes. Although some of the prototypes may appear to be very substantial, they’re generally similar to a movie set: everything looks good from the front but there’s nothing in the back. When a prototype is generated, the developer produces the minimum amount of code necessary to clarify the requirements or design elements under consideration. No effort is made to comply with coding standards, provide robust error management, or integrate with other database tables or modules. As a result, it is generally more expensive to retrofit a prototype with the necessary elements to produce a production module then it is to develop the module from scratchusing the final system design document. For these reasons, prototypes are never intended for business use, and are generally crippled in one way or another to prevent them from being mistakenly used as production modules by end-users. Advantages of Prototyping:  The software designer and implementer can obtain feedback from the users early in the project.  The client and the contractor can compare if the software made matches the software specification, according to which the software program is built.  It also allows the software engineer some insight into the accuracy of initial project estimates and whether the deadlines and milestones proposed can be successfully met. Disadvantages of Prototyping:  Often clients expect that a few minor changes to the prototype will more than suffice their needs. They fail to realise that no consideration was given to the overall quality of the software in the rush to develop the prototype.  The developers may lose focus on the real purpose of the prototype and compromise the quality of the product. For example, they may employ some of the inefficient algorithms or inappropriate programming languages used in developing the prototype. This mainly due to laziness and an over reliance on familiarity with seemingly easier methods.  A prototype will hardly be acceptable in court in the event that the client does not agree that the developer has discharged his/her obligations. For this reason using the prototype as the software specification is normally reserved for software development within an organisation. When to use Prototyping Model?:  Prototyping is very effective in the analysis and design of on-line systems.  Systems with little user interaction, such as batch processing or systems that mostly do calculations, benefit little from prototyping. Sometimes, the coding needed to perform the system functions may be too intensive and the potential gains that prototyping could provide are too small.  Prototyping is especially good for designing good human-computer interfaces. “One of the most productive uses of rapid prototyping to date has been as a tool for iterative user requirements engineering and human-computer interface design. ”"
    }, {
    "id": 132,
    "url": "localhost:4000/iterative-model/",
    "title": "Iterative Model",
    "body": "2016/12/28 - What is the Iterative Model?: [caption id=”attachment_10210” align=”aligncenter” width=”600”] iterative-model[/caption] An iterative life cycle model does not attempt to start with a full specification of requirements. Instead, development begins by specifying and implementing just part of the software, which can then be reviewed in order to identify further requirements. This process is then repeated, producing a new version of the software for each cycle of the model. Consider an iterative life cycle model which consists of repeating the following four phases in sequence: A Requirements phase, in which the requirements for the software are gathered and analysed. Iteration should eventually result in a requirements phase that produces a complete and final specification of requirements. A Design phase, in which a software solution to meet the requirements is designed. This may be a new design, or an extension of an earlier design. An Implementation and Test phase, when the software is coded, integrated and tested. A Review phase, in which the software is evaluated, the current requirements are reviewed, and changes and additions to requirements proposed. For each cycle of the model, a decision has to be made as to whether the software produced by the cycle will be discarded, or kept as a starting point for the next cycle (sometimes referred to as incremental prototyping). Eventually a point will be reached where the requirements are complete and the software can be delivered, or it becomes impossible to enhance the software as required, and a fresh start has to be made. The iterative life cycle model can be likened to producing software by successive approximation. Drawing an analogy with mathematical methods that use successive approximation to arrive at a final solution, the benefit of such methods depends on how rapidly they converge on a solution. The key to successful use of an iterative software development life cycle is rigorous validation of requirements, and verification (including testing) of each version of the software against those requirements within each cycle of the model. The first three phases of the example iterative model is in fact an abbreviated form of a sequential V Model or waterfall Model of development. Each cycle of the model produces software that requires testing at the unit level, for software integration, for system integration and for acceptance. As the software evolves through successive cycles, tests have to be repeated and extended to verify each version of the software. Advantages of Iterative Model:  Generates working software quickly and early during the software life cycle.  More flexible – less costly to change scope and requirements.  Easier to test and debug during a smaller iteration.  Easier to manage risk because risky pieces are identified and handled during its iteration.  Each iteration is an easily managed milestone. Disadvantages of Iterative Model:  Each phase of an iteration is rigid and do not overlap each other.  Problems may arise pertaining to system architecture because not all requirements are gathered up front for the entire software life cycle. "
    }, {
    "id": 133,
    "url": "localhost:4000/integration-testing-in-small/",
    "title": "Integration Testing in Small",
    "body": "2016/12/28 - What is Integration Testing in Small?: Integration testing in small is bringing together individual components (modules/units) that have already been tested in isolation. The objective is to test that the ‘set’ of components function together correctly by concentrating on the interfaces between the components. We are trying to find faults that couldn’t be found at an individual component testing level. Although the interfaces should have been tested in component testing, integration testing in the small makes sure that the things that are communicated are correct from both sides, not just from one side of the interface. This is an important level of testing but one that is sadly often overlooked. As more and more components are combined together then a subsystem may be formed which has more system-like functionality that can be tested. At this stage it may also be useful to test non­functional aspects such as performance. For integration testing in the small there are two choices that have to be made: How many components to combine in one go?In what order to combine components. The decision over which choices to make are what is called the ‘integration strategy’. There are two main integration strategies: Big Bang and incremental. These are described in separate sections below. Big Bang Integration: “Big Bang” integration means putting together all of the components in one go. The philosophy is that we have already tested all of the components so why not just throw them all in together and test the lot? The reason normally given for this approach is that it saves time - or does it? If we encounter a problem it tends to be harder to locate and fix the faults. If the fault is found and fixed then re-testing usually takes a lot longer. In the end, the Big Bang strategy does not work - it actually takes longer this way. This approach is based on the [mistaken] assumption that there will be no faults. Incremental Integration: Incremental integration is where a small number of components are combined at once. At a minimum, only one new component would be added to the baseline at each integration step. This has the advantage of much easier fault location and fixing, as well as faster and easier recovery if things do go badly wrong. (The finger of suspicion would point to the most recent addition to the baseline. ) However, having decided to use an incremental approach to integration testing we have to make a second choice: in what order to combine the components. This decision leads to three different incremental integration strategies: top-down, bottom-up and functional incrementation. Top-down Integration and Stubs: As its name implies, top-down integration combines components starting with the highest levels of a hierarchy. Applying this strategy strictly, all components at a given level would be integrated before any at the next level down would be added. Because it starts from the top, there will be missing pieces of the hierarchy that have not yet been integrated into a baseline. In order to test the partial system that comprises the baseline, stubs are used to substitute for the missing components. A stub replaces a called component in integration testing in the small. It is a small self-contained program that may do no more than display its own name and then return. It is a good idea to keep stubs as simple as possible; otherwise they may end up being as complex as the components they are replacing. As with all integration in the small strategies, there are advantages and disadvantages to the approach. One advantage is that we are working to the same structure as the overall system and this will be tested most often as we build each baseline. Senior Managers tend to like this approach because the system can be demonstrated early (but beware that this can often paint a false impression of the system’s readiness). There are some disadvantages. Stubs are needed (as in all incremental integration strategies but this perhaps needs more of them). Creating stubs means extra work though it should save more effort in the long run. The details of the system are not tested until last and yet these may be the most important parts of the software. Bottom-up Integration and Drivers: Bottom-up integration is the opposite of top-down. Applying it strictly, all components at the lowest levels of the hierarchy would be integrated before any of the higher level ones. Because the calling structure is missing, this strategy requires a way of activating the baseline, e. g. by calling the component at the top of a baseline. These small programs are called “drivers” because they drive the baseline. Drivers are also known as test harnesses or scaffolding. They are usually specifically written for each baseline though there are a few tools on the market which provide some ‘general purpose’ support. Bottom-up integration may still need stubs as well though it is likely to use fewer of them. Integration Guidelines: You will need to balance the advantages gained from adding small increments to your baselines with the effort needed to make that approach work well. For example, if you are spending more time writing stubs and drivers than you would have spent locating faults in a larger baseline, and then you should consider having larger increments. However, for critical components, adding only one component at a time would probably be best. Keep stubs and drivers as simple as possible. If they are not written correctly they could invalidate the testing performed. If the planning for integration testing in the small is done at the right place in the life cycle, i. e. on the left-hand side of the V-model before any code has been written, then the integration order determines the order in which the components should be written by developers. This can save significant time. "
    }, {
    "id": 134,
    "url": "localhost:4000/incremental-model/",
    "title": "Incremental Model",
    "body": "2016/12/28 - What is the Incremental Model?: [caption id=”attachment_10207” align=”aligncenter” width=”507”] incremental-model[/caption] The incremental build model is a method of software development where the model is designed, implemented and tested incrementally (a little more is added each time) until the product is finished. It involves both development and maintenance. The product is defined as finished when it satisfies all of its requirements. This model combines the elements of the waterfall model with the iterative philosophy of prototyping. The product is decomposed into a number of components, each of which are designed and built separately (termed as builds). Each component is delivered to the client when it is complete. This allows partial utilisation of product and avoids a long development time. It also creates a large initial capital outlay with the subsequent long wait avoided. This model of development also helps ease the traumatic effect of introducing completely new system all at once. There are some problems with this model. One is that each new build must be integrated with previous builds and any existing systems. The task of decomposing product into builds not trivial either. If there are too few few builds and each build degenerates this turns into Build-And-Fix model. However if there are too many builds then there is little added utility from each build. What is the difference between Incremental Model and Iterative Model?: The Incremental Approach uses a set number of steps and development goes from start to finish in a linear path of progression. Incremental development is done in steps from design, implementation, testing/verification, maintenance. These can be broken down further into sub-steps but most incremental models follow that same pattern. The Waterfall Model is a traditional incremental development approach. The Iterative Approach has no set number of steps, rather development is done in cycles. Iterative development is less concerned with tracking the progress of individual features. Instead, focus is put on creating a working prototype first and adding features in development cycles where the Increment Development steps are done for every cycle. Agile Modeling is a typical iterative approach. Advantages of Incremental Model:  Generates working software quickly and early during the software life cycle.  More flexible – less costly to change scope and requirements.  Easier to test and debug during a smaller iteration.  Easier to manage risk because risky pieces are identified and handled during its iteration.  Each iteration is an easily managed milestone. Disadvantages of Incremental Model:  Each phase of an iteration is rigid and do not overlap each other.  Problems may arise pertaining to system architecture because not all requirements are gathered up front for the entire software life cycle. When to use Incremental Model:  Such models are used where requirements are clear and can implement by phase wise. From the figure it’s clear that the requirements ® is divided into R1, R2………. Rn and delivered accordingly.  Mostly such model is used in web applications and product based companies. "
    }, {
    "id": 135,
    "url": "localhost:4000/component-testing/",
    "title": "Component Testing",
    "body": "2016/12/28 - Component Testing: Component Testing as defined by BS7925-1 is “A minimal software item for which a separate specification is available”. Components are relatively small pieces of software that are, in effect the building blocks from which the system is formed. They may also be referred to as modules, units or programs and so this level of testing may also be known as module, unit or program testing. For some organizations a component can be just a few lines of source code while for others it can be a small program. Component testing then is the lowest level of testing (i. e. it is at the bottom on the V-Model software development life cycle). It is the first level of testing to start executing test cases (but should be the last to specify test cases). It is the opportunity to test the software in isolation and therefore in the greatest detail, looking at its functionality and structure, error handling and interfaces. In component testing, because it is just a component being tested, it is often necessary to have a test harness or driver to form an executable program that can be executed. This will usually have to be developed in parallel with the component or may be created by adapting a driver for another component. This should be kept as simple as possible to reduce the risk of faults in the driver obscuring faults in the component being tested. Typically, drivers need to provide a means of taking test input from the tester or a file, passing it on to the component, receiving the output from the component and presenting it to the tester for comparison with the expected outcome. The programmer who wrote the code most often performs component testing. This is sensible because it is the most economic approach. A programmer who executes test cases on his or her own code can usually track down and fix any faults that may be revealed by the tests relatively quickly. If someone else were to execute the test cases they may have to document each failure. Eventually the programmer would come to investigate each of the fault reports, perhaps having to reproduce them in order to determine their causes. Once fixed, the fixed software would then be re-tested by this other person to confirm each fault had indeed been fixed. This amounts to more effort and yet the same outcome: faults fixed. Of course it is important that some independence is brought into the test specification activity. The programmer should not be the only person to specify test cases. Both functional and structural test case design techniques are appropriate in component testing, though the extent to which they are used should be defined during the test planning activity. This will depend on the risks involved, for example, how important, critical or complex they are. "
    }, {
    "id": 136,
    "url": "localhost:4000/5-reasons-why-software-have-bugs/",
    "title": "5 Reasons Why There Are Bugs in Software",
    "body": "2016/12/28 - There are many reasons for which a software contains bugs, but the root causes of the defects can normally be classed into the following ##1 - Miscommunication or no communication## Quite often, the requirements from the business is not communicated to the development team. Product owners have an idea of what the feature should look like and how it should behave, but if not communicated properly to developers and testers, the finished product might not be as expected.  The requirements should be communicated clearly to all stakeholders so everyone has the same understanding. ##2 - Software complexity## The complexity of current software applications can be difficult to comprehend for anyone without experience in modern-day software development. Multi-tiered applications, client-server and distributed applications, data communications, enormous relational databases, and sheer size of applications have all contributed to the exponential growth in software/system complexity. programming errors - programmers, like anyone else, can make mistakes. ##3 - Changing requirements## The end-user may not understand the effects of changes, or may understand and request them anyway - redesign, rescheduling of engineers, effects on other projects, work already completed that may have to be redone or thrown out, hardware requirements that may be affected, etc. If there are many minor changes or any major changes, known and unknown dependencies among parts of the project are likely to interact and cause problems, and the complexity of coordinating changes may result in errors. Enthusiasm of engineering staff may be affected. In some fast-changing business environments, continuously modified requirements may be a fact of life. In this case, management must understand the resulting risks, and QA and test engineers must adapt and plan for continuous extensive testing to keep the inevitable bugs from running out of control. ##4 - Poorly documented code## It’s tough to maintain and modify code that is badly written or poorly documented; the result is bugs. In many organizations management provides no incentive for programmers to document their code or write clear, understandable, maintainable code. In fact, it’s usually the opposite: they get points mostly for quickly turning out code, and there’s job security if nobody else can understand it (‘if it was hard to write, it should be hard to read’). ##5 - Software development tools## Visual tools, class libraries, compilers, scripting tools, etc. often introduce their own bugs or are poorly documented, resulting in added bugs. "
    }, {
    "id": 137,
    "url": "localhost:4000/integration-testing-in-large/",
    "title": "Integration Testing in Large",
    "body": "2016/12/27 - What is Integration Testing in Large?: This stage of testing is concerned with the testing of the system with other systems and networks. There is an analogy of building a house - our finished house (system) now needs to talk with the outside world:Our house needs electricity, gas, water, communications, TV etc to function properly. So too does our system - it needs to interface with different networks and operating systems and communications middleware. Our house needs to co-exist with other houses and blend in with the community - so too does our system - it needs to sit alongside other systems such as billing, stock, personnel systems etc; Our new system may need information from outside the organization such as interest rates, foreign exchange etc and this is obtained via external data interchange (EDI). A good example of EDI is the way in which our wages are transferred to our Bank Accounts. Our house receives things from outside organizations such as the Post Office or delivery trucks; Our new system may be required to work with different 3rd Party Packages - not directly involved with the System under Test. Different faults will be found during this level of testing and we must be prepared to plan and execute such tests if they are considered vital for the success of our business. In reality this level of testing will probably be done in conjunction with system testing rather than as a separate testing stage. However it is now a visible testing stage and integration testing in the large is an explicit testing phase in the syllabus. In terms of planning - it should be planned the same way as Integration testing in the small (i. e. testing interfaces/connections one at a time). This will reduce the risk of not being able to locate the faults quickly. Like all testing stages we must identify the risks during the planning phase - which areas would cause most severity if they were not to work? Perhaps we are developing a piece of software that is to be used at a number of different locations throughout the world - then testing the system within a Local Area Network (LAN) and comparing with the response over a Wide Area Network (WAN) is essential. When we plan Integration Testing in the Large there are a number of resources we might need, such as different operating systems, different machine configurations and different network configurations. These must all be thought through before the testing actually commences. We must consider what machines we will need and it might be worthwhile talking to some of the hardware manufacturers as they sometimes offer test sites with different machine configurations set up. "
    }, {
    "id": 138,
    "url": "localhost:4000/acceptance-testing/",
    "title": "Acceptance Testing",
    "body": "2016/12/26 - User Acceptance TestingUser Acceptance Testing is the final stage of validation. This is the time that customers get their hands on the system (or should do) and the end product of this is usually a sign-off from the users. One of the problems is that this is rather late in the project for users to be involved - any problems found now are too late to do anything about them. This is one reason why Rapid Application Development (RAD) has become popular. Users are involved earlier and testing is done earlier. However, the users should have been involved in the test specification of the Acceptance Tests at the start of the project. They should also have been involved in reviews throughout the project, and there is nothing to say that they cannot be involved in helping to design System and Integration tests. So there really should be no surprises! The approach in this stage is a mixture of scripted and unscripted and the model office concept is sometimes used. This is where a replica of the real environment is set up, for example a branch office for a bank or building society. Why should users be involvedIt is the end users’ responsibility to perform acceptance testing. Sometimes the users are tempted to say to the technical staff: “You know more about computers than we do, so you do the acceptance testing for us”. This is like asking the used car salesman to take a test drive for you! The users bring the business perspective to the testing. They understand how the business actually functions in all of its complexity. They will know of the special cases that always seem to cause problems. They can also help to identify sensible work-arounds, and they gain a detailed understanding of the system if they are involved in the acceptance testing. The differences between system testing and acceptance testing are: Done by users, not technical staff;Focuses on building confidence rather than finding faults;Focuses on business-related cases rather than obscure error handling. Contract Acceptance TestingIf a system is the subject of a legally binding contract, there may be aspects directly related to the contract that need to be tested. It is important to ensure that the contractual documents are kept up to date; otherwise you may be in breach of a contract while delivering what the users want (instead of what they specified two years ago). However, it is not fair for users to expect that the contract can be ignored, so the testing must be against the contract and any agreed changes. Alpha and Beta TestingBoth alpha and beta testing are normally used by software houses that produce mass-market shrink-wrapped software packages. This stage of testing is after system testing; it may include elements of integration testing in the large. The alpha or beta testers are given a pre-release version of the software and are asked to give feedback on the product. Alpha and beta testing is done where there are no identifiable “end users” other than the general public. The difference between alpha and beta testing is where they are carried out. Alpha testing is done on the development site - potential customers would be invited in to their offices. Beta testing is done on customer sites - the software is sent out to them. "
    }, {
    "id": 139,
    "url": "localhost:4000/equivalence-partitioning/",
    "title": "Equivalence Partitioning",
    "body": "2016/12/25 - Equivalence Partitioning Test Technique: The Equivalence Partitioning is a Black Box Test Technique. The idea behind the equivalence partitioning test technique is to eliminate the set of input data that make the system behave the same and yield the same result when testing a program. Equivalence Partitioning is a common black box testing technique and aims to reduce the number of redundant test cases by eliminating those that generate the same output and do not necessarily reveal defects in a program functionality. As the aim of testing is to find defects, then a successful test case is the one that does find a defect. The process of equivalence partitioning technique involves identifying the set of data as an input condition that give the same result when executing a program and classifying them as a set of equivalent data (because they make the program behave in the same way and generate the same output) and partitioning them from another equivalent set of data. Consider the example below:An application accepting integer values (that is whole number values) between -10,000 to +10,000 can be expected to be able to handle negative integers, zero and positive integers. Therefore, the set of input values can be divided into three partitions: From -10,000 to -1, 0 and from 1 to 10,000 Moreover, it is expected that the system to behave the same for values inside each partition. i. e. the way the system handles -6391 will be the same as -9. Likewise, positive integers, 5 and 3567 will be treated the same by the system. In this particular example, the value 0 is a single value partition. It is normally a good practice to have a special case for number zero. It is important to note that this technique does not only apply to numbers. The technique can apply to any set of data that can be considered as an equivalent. E. g. an application that reads in images of only three types, . jpeg, . gif and . png, then three sets of valid equivalent classes can be identified. An image with a . jpeg extensionAn image with a . gif extensionAn image with a . png extension Now, opening a . jpeg file which is an image of the moon, will behave the same as a file with an image of a dog. Therefore, opening only one file of type . jpeg, will suffice the purpose of the test case. The assumption is that the system will behave the same for all jpeg files. The same scenario applies to files with . gif and . png files. Likewise, if the application cannot open files other than the allowed and valid types, then trying to open a word document, the result will be the same as trying to open an excel spreadsheet or a text file. (Hopefully, the application has been designed well to cope with other file types and generates an appropriate message when attempting to open non-acceptable file types). These would be classed as set of invalid equivalent data. Trying to open the application with non-acceptable or invalid file types is an example of negative testing, which is useful when combined with equivalence partitioning technique which partitions the set of equivalent acceptable and valid data. "
    }, {
    "id": 140,
    "url": "localhost:4000/boundary-value-analysis/",
    "title": "Boundary Value Analysis",
    "body": "2016/12/24 - Boundary Value Analysis Test Technique: [caption id=”attachment_10165” align=”aligncenter” width=”532”] boundary-value-analysis-test-technique[/caption] Boundary value analysis, BVA, tests the behavior of a program at the boundaries. When checking a range of values, after selecting the set of data that lie in the valid partitions, next is to check how the program behaves at the boundary values of the valid partitions. Boundary value analysis is most common when checking a range of numbers. For each range, there are two boundaries, the lower boundary (start of the range) and the upper boundary (end of the range) and the boundaries are the beginning and end of each valid partition. We should design test cases which exercises the program functionality at the boundaries, and with values just inside and just outside the boundaries. Here, the assumption is that if the program works correctly for these extreme cases, then it will work correctly for all values in between the valid partition. Testing has shown that defects that arise when checking a range of values the most defects are near or at the boundaries. Boundary Value Analysis Example: A program which accepts an integer in the range -100 to +100, there would be three sets of valid equivalent partitions: these are -10 to -1, the negative range0, Zero and 1 to 10, the positive range. For each range, there are minimum and maximum values at each boundary. For the negative range the lower boundary is -10 and the upper boundary is -1. At each boundary, three conditions should be checked. -101, -100, -99 … … … … … … -2, -1, 0, -1, 0, +1 0, 1, 2 … … … … … … 99, 100, 101 You might have noticed that by selecting values at the boundaries for each partition there are some values that overlap. That is they would appear in our test conditions when we check the boundaries. We should of course make redundant those values that overlap to eliminate unnecessary test cases. Another worthy note to consider is that because the range goes from -100 to +100, then effectively, the “boundary values” -2, -1 and -99 are considered as equivalent. That is, the behavior of the system is the same (or should be the same) when testing with values -99, -2 and -1. However, because -99 is close to the upper limit boundary, and is most likely to reveal defects, we keep the value -99 in our test case and scrap conditions for -2 and -1. The same applies to the positive range boundaries, that is, +1, +2 and +99 are expected to give the same behavior. However, because 99 is close to the upper range boundary, we keep 99 in our list of data to test and get rid of values 1 and 2. Therefore, our list of data to check at the boundaries become -101, -100, -99 … … … … … … 0 … … … … … … 99, 100, 101 If our range of data was from 0 to +10 then the boundary value analysis would give us the following values to test: -1, 0, 1 … … … … … …9, 10, 11 Here, 1 and 9 are both part of the test condition because each are at the boundary of the whole range and can reveal defects. It is important to note that that boundary values analysis can be applied to float numbers as well as integers. The only difference is that when analyzing boundaries for float numbers, we should test to the closest decimal point. Example, if we have a range from 5. 5 to 9. 9, then the set of data at boundaries becomes 5. 4, 5. 5, 5. 6 … … … … … … 9. 8, 9. 9, 10. 0 Like Equivalence Partitioning Test Technique, Boundary Value Analysis is a common black box testing technique and is one which must be applied when checking a range of values. Together with equivalence partitioning and negative testing, it can be a very powerful black box testing technique to find defects when testing a range of values. "
    }, {
    "id": 141,
    "url": "localhost:4000/state-transition-testing/",
    "title": "State Transition Testing",
    "body": "2016/12/23 - State Transition Testing Technique: [caption id=”attachment_10168” align=”aligncenter” width=”682”] state-transition-digram[/caption] State transition testing is a black box testing technique and is used where some aspect of the system can be described in what is called a “finite state machine”. This simply means that the system can be in a (finite) number of different states, and the transitions from one state to another are determined by the rules of the “machine”. This is the model on which the system and the tests are based. Any system where you get a different output for the same input, depending on what has happened before, is a finite state system. State Transition Testing Examples: If you request to withdraw £100 from a bank ATM, you may be given cash. Later you may make exactly the same request but be refused the money (because your balance is insufficient). This later refusal is because the state of your bank account had changed from having sufficient funds to cover the withdrawal to having insufficient funds. The transaction that caused your account to change its state was probably the earlier withdrawal. Another example is a word processor. If a document is open, you are able to Close it. If no document is open, then “Close” is not available. After you choose “Close” once, you cannot choose it again for the same document unless you open that document. A document thus has two states: open and closed. A state transition model has four basic parts:    The states that the software may occupy (open/closed or funded/insufficient funds);     The transitions from one state to another (not all transitions are allowed);     The events that cause a transition (withdrawing money, closing a file);     The actions that result from a transition (an error message, or being given your cash).  Note that a transition does not need to change to a different state; it could stay in the same state. In fact, trying to input an invalid input would be likely to produce an error message as the action, but the transition would be back to the same state the system was in before. Deriving test cases from the state transition model is a black box approach. Measuring how much you have tested (covered) is getting close to a white box perspective. However, state transition testing is generally regarded as a black box technique. You can design tests to test every transition shown in the model. If every (valid) transition is tested, this is known as “0-switch” coverage. You could also test a series of transitions through more than one state. If you covered all of the pairs of two valid transitions, you would have “1-switch” coverage, covering the sets of 3 transitions would give “2-switch” coverage, etc. However, deriving tests only from the model may omit the negative tests, where we could try to generate invalid transitions. In order to see the total number of combinations of states and transitions, both valid and invalid, a state table can be used. "
    }, {
    "id": 142,
    "url": "localhost:4000/exploratory-testing/",
    "title": "Exploratory Testing",
    "body": "2016/12/22 - What is Exploratory Testing?: [caption id=”attachment_10175” align=”aligncenter” width=”454”] exploratory-testing-technique[/caption] Have you ever tested a piece of software that you were not very familiar with? Also, you might not have had the luxury of ready-made test cases at hand and could not afford spending time to write them. Nevertheless you went ahead to test the product and did a quite a good job. If you remember, it required a lot of logical thinking, formulating your thoughts into test cases in real time and concurrently executing them. The all-important question that arises here is- “Is this sort of testing justified and is it productive?” Both these queries were quite well answered when I stumbled on the form of testing called- exploratory testing. According to Cem Kaner who has coined the term “exploratory testing”, “most testers spend 25% of their time doing exploratory testing, with 25% creating and documenting new test cases and 50% doing regression testing (i. e. running old tests). ” Let us delve a little further into what exploratory testing is all about. Over the last few years exploratory testing has been recognized as a very powerful and interesting form of testing. Here a test case is designed and executed concurrently, unlike scripted testing (manual or automated), where you have your test cases created prior to actual testing. This from of testing does not really adhere to a pre-defined plan. Please don’t confuse this with “ad-hoc” testing, which is looking for defects randomly. The most important distinction between “ad-hoc” testing and exploratory testing is that the former can be carried out by anyone but exploratory testing is a thoughtful approach to testing and driven by logic. It is an intellectually challenging process where one is limited only by ones own imagination and understanding of the software being tested. It provides enough scope to extend the reach of testing to certain areas that cannot be easily accommodated in a scripted test case. James Bach, whose contributions and research works have been instrumental in establishing exploratory testing as a useful test methodology, has identified five key elements that an exploratory tester should focus on: Product ExplorationAs you discover a product, make a note of its functions, their purpose, types of data processed, and areas of potential instability. How well you comprehend the product, the underlying technologies and the time available will determine the effectiveness with which you perform exploration. As you explore, you should construct a mental-model of how the product works. Test DesignYou should decide on strategies related to the way you will test the product, observe results, and make inferences. Test ExecutionThis involves testing the product and observing its behavior. The information gathered should be used to formulate hypotheses about the functionality of the product. It’s also beneficial to document test ideas that occur to you while testing. HeuristicsThese are a set of rules that help you define what is to be tested and how. Reviewable ResultsThe intention of exploratory testing is to produce results. Once you have produced deliverables that meet the specified requirements you can say that it is complete. From a QA perspective, the deliverables must be reviewable and defensible for certification. A good point to start exploratory testing is when we come across a new or unstable product or software that has not been tested. It is also useful if you are aiming for fast results, trying to reproduce a bug, simplify defect reports. As the stability of a product increases, it can be complemented by scripted testing- manual or automated. While scripted tests give you a more detailed idea of the test coverage, especially during regression test cycles, exploratory can unearth new defects and extend your existing test cases. The knowledge gained during exploratory testing can be used to augment scripted testing by setting up a feedback mechanism to update existing test cases or create new ones. Despite the differences in the approaches both these forms of testing are perfectly compatible and go hand-in-hand. "
    }, {
    "id": 143,
    "url": "localhost:4000/black-box-testing/",
    "title": "Black Box Testing",
    "body": "2016/12/21 - What is Black Box Testing?: In Black Box Testing, the tester tests an application without knowledge of the internal workings of the application being tested. Data are entered into the application and the outcome is compared with the expected results; what the program does with the input data or how the program arrives at the output data is not a concern for the tester performing black box testing. All that is tested is the behavior of the functions being tested. This is why black box testing is also known as functional testing which tests the functionality of a program. Note we can also have non-functional black box testing, such as performance testing which is a type of black box testing but instead of verifying the behavior of the system, it tests how long it takes for a function to respond to user’s inputs and how long it takes to process the data and generate outputs. Because black box testing is not concerned with the underlying code, then the techniques can be derived from the requirement documents or design specifications and hence testing can start as soon as the requirements are written. Some Black Box Testing Techniques are:    Equivalence Partitioning     Boundary Value Analysis     State Transition Testing     Cause / Effect Graphing     Classification Tree Method  Advantages of Black Box Testing are:    The test is unbiased because the designer and the tester are independent of each other     The tester does not need knowledge of any specific programming languages     The test is done from the point of view of the user, not the designer     Test cases can be designed as soon as the specifications are complete  Disadvantages of Black Box Testing are:    The test can be redundant if the software designer has already run a test case     The test cases are difficult to design     Testing every possible input stream is unrealistic because it would take a inordinate amount of time; therefore, many program paths will go untested  "
    }, {
    "id": 144,
    "url": "localhost:4000/retesting-and-regression-testing/",
    "title": "Retesting and Regression Testing",
    "body": "2016/12/20 - Difference Between Retesting and Regression Testing: : What is Retesting: When a test fails and we determine the cause of the failure is a software fault, the fault is reported, we can expect a new version of the software that has had the fault fixed. In this case we will need to execute the test again to confirm that the fault has indeed been fixed. This is known as re-testing. Some people also refer to this as confirmation testing. When retesting, it is important to ensure that the test is executed in exactly the same way as it was the first time, using the same inputs, data and environment. If the test now passes does this mean that the software is now correct? Well, we now know that at least one part of the software is correct — where the fault was. But this is not enough. The fix may have introduced a different fault elsewhere in the software. The way to detect these “unexpected side-effects” of fixes is to do regression testing. What is Regression Testing: Like retesting, regression testing involves executing test cases that have been executed before. The difference is that for regression testing the test cases probably passed the last time they were executed (compare this with the test cases executed when re-testing - they failed the last time). In other words, we are executing tests with the intent of checking that the system has not regressed (that is, it does not now have more faults in it as a result of some change). More specifically, the purpose of regression testing is to verify that modifications in the software or the environment have not caused unintended adverse side effects and that the system still meets it requirements. It is common for organizations to have what is usually called a regression test suite or regression test pack. This is a set of test cases that is specifically used for regression testing. They are designed to collectively exercise most functions (certainly the most important ones) in a system but not test any one in detail. It is appropriate to have a regression test suite at every level of testing (component testing, integration testing, system testing, etc. ). All of the test cases in a regression test suite would be executed every time a new version of software is produced and this makes them ideal candidates for automation. If the regression test suite is very large it may be more appropriate to select a subset for execution. Regression tests are executed whenever the software changes, either as a result of fault fixes or new or changed functionality. It is also a good idea to execute them when some aspect of the environment changes, for example when a new version of a database management system is introduced or a new version of a source code compiler is used. Maintenance of a regression test suite should be carried out so it evolves over time in line with the software. As new functionality is added to a system new regression tests should be added and as old functionality is changed or removed so too should regression tests be changed or removed. As new tests are added a regression test suite may become very large. If all the tests have to be executed manually it may not be possible to execute them all every time the regression suite is used. In this case a subset of the test cases has to be chosen. This selection should be made in light of the latest changes that have been made to the software. Sometimes a regression test suite of automated tests can become so large that it is not always possible to execute them all. It may be possible and desirable to eliminate some test cases from a large regression test suite for example if they are repetitive (tests which exercise the same conditions) or can be combined (if they are always run together). Another approach is to eliminate test cases that have not found a fault for a long time (though this approach should be used with some care!). "
    }, {
    "id": 145,
    "url": "localhost:4000/defect-life-cycle-software-testing/",
    "title": "Defect Life Cycle in Software Testing",
    "body": "2016/12/19 - Defect Life Cycle is the stages that the defect or bug goes through from when it is first reported until it is fixed and confirmed. Introduction: Finding and reporting defects are core activities of the testing team. In this article I explain the Software Defect Life Cycle and the Defect Process in general. I will list all the activities for each stage of the process that are commonly performed in a typical software testing environment. Also, in this article, I have assumed that the development team have developed a software application and is at least to a stage that is ready for testing. The process is not leaning to any particular development model as I believe this generic process is suitable for any development model. In other words, the process in itself is generic for all development models; however, the amount of activities, required inputs and produced outputs will depend on the type and complexity of the application, organisation’s view on testing and the structure of the project. Defect Life cycle: Generally speaking, the defect life cycle is made up of four stages: Stage 1, defects are found and reported. Stage 2, defects are reviewed and delegated. Stage 3, defects are debugged and removed. Stage 4, removed defects are confirmed. Stage 1: Defects are found and reported by the testing team: After the development team have developed the software and is ready for testing, the software is then released to the testing team. Items released to testing generally include Software Requirement Specification (SRS), Software Design Specification (SDS), executable application and any third party libraries that may be required to make the application work. Once the application is available to testing team, testing of the application starts based on the Test Procedures. The activities may include Functional Testing, Non-Functional Testing, Performance Testing, etc. During testing, testers may find defects either in the application or in the documents e. g. test procedure. If a defect is found, either in the application (source code) or in the document, a defect report form is filled and passed on to the test team lead or test manager for review. Defect Status is: Open and Not Reviewed. This is the first stage of defect life cycle. Stage 2: Defects are reviewed and delegated: Defects get reviewed first by test team lead for any obvious mistakes by the testers, such as missing information on the defect form (see Defect Reporting) and then reported to software development manager for further review. A meeting is scheduled which includes members of the development team and testing team to discuss the validity, severity and priority of the defects. At this stage, defects are categorised into three different states:    Not a defect     Defect will be fixed     Defect won’t be fixed in this release  Defect Status is: Reviewed and Assigned. This is the second stage of defect life cycle. Stage 3: Defects are debugged and removed: After the meeting and agreed actions, the software development manager delegates defects to different developers in the team. For defects that are not going to be fixed in the current version of the software, an impact analysis must be performed to identify any potential failures that may occur as a result of the existing defects in the system. Developers will analyse the source code to identify the root cause and ultimately remove the defect. Defect Status is: Being Debugged. This is the third stage of defect life cycle Stage 4: Removed defects are confirmed: The “Fixed” version of the software will be released to the testing team and testers will start to test the “fixed” software. At this stage, two types of testing are performed by the testers: confirmation testing and regression testing. Based on the outcome of the confirmation testing, the “fixed” defects are either confirmed as fixed (defect is removed) or not fixed (defect still exists). For defects that are fixed, their status is changed to fixed and can be closed. For defects that are not fixed, i. e. they still exist in the system, they go round the cycle again, i. e. are reported to the development team, gets reviewed by the development team, faults are removed, a new version of software is released to testing for confirmation + regression testing and so on. This cycle is repeated until all the defects (that were decided to be fixed in the current version) are fixed and verified by testers. Defect Status is Fixed &amp; Closed. This is the fourth and last stage of defect life cycle. The model explained above is a generic model explaining the defect life cycle. Defect management is an important aspect of software testing and if managed properly it should reduce a lot of overheads. Following a defined lifecycle can help in managing the defect process and increase the productivity of the testing team. "
    }, {
    "id": 146,
    "url": "localhost:4000/defect-clustering-in-software-testing/",
    "title": "Defect Clustering in Software Testing",
    "body": "2016/12/18 - [caption id=”attachment_10047” align=”aligncenter” width=”493”] defect-clustering-istqb[/caption] What is Defect Clustering in Software Testing?: Defect Clustering in Software Testing is one of the seven principles of ISEB Software Testing. During software testing, as defects are found, analysis of defects can give surprising results! Defect Clustering in Software Testing means that the majority of the defects are caused by a small number of modules, i. e. the distribution of defects are not across the application but rather centralized in limited sections of the application. This is particularly true for large systems where the complexity, size, change and developer mistakes can impact the quality of the system and affect particular modules. Defect Clustering in Software Testing is based on the Pareto principle, also known as the 80-20 rule, where it is stated that approximately 80% of the problems are caused by 20% of the modules. In this image the principle of defect clustering in software testing can be seen that most of the defects are clustered in particular sections of the application of an application e. g. Product Details, Reviews and Search Results Page for an e-commerce website and the remaining defects in other areas. This can give a good indication that when a defect is found in one area of the application, chances are there are more defects in that particular area, so it is worth investing more time to test that particular area of the application to find as many defects as possible. However, testers should not ignore to test the rest of application as well as there may be other defects scattered around. Defect aggregation or defect clustering in software testing can also indicate which area of the application needs more regression testing to ensure related features are not broken. Analysis of test execution reports and grouping of the defects by features of the application produces a histogram which proves the principle of defect clustering in software testing. This helps with understanding of the defects better and also help with test case prioritization when there is not enough time to execute all the tests. "
    }, {
    "id": 147,
    "url": "localhost:4000/elements-of-a-bug-report/",
    "title": "Elements of a Bug Report",
    "body": "2016/12/17 - How to Write a Good Bug Report: Writing a good defect or bug report goes a long way in identifying and resolving the problems quickly. In here, I list the elements that are normally included in a bug report. In no particular order: Defect Identifier, ID: The identifier is very important in being able to refer to the defect in the reports. If a defect reporting tool is used to log defects, the ID is normally a program generated unique number which increments per defect log. Summary: The summary is an overall high level description of the defect and the observed failure. This short summary should be a highlight of the defect as this is what the developers or reviewers first see in the bug report. Description: The nature of the defect must be clearly written. If a developer reviewing the defect cannot understand and cannot follow the details of the defect, then most probably the report will be bounced back to the tester asking for more explanation and more detail which causes delays in fixing the issue. The description should explain exactly the steps to take to reproduce the defect, along with what the expected results were and what the outcome of the test step was. The report should say at what step the failure was observed. Severity: The severity of the defect shows how sever the defect is in terms of damaging to other systems, businesses, environment and lives of people, depending on the nature of the application system. The severities are normally ranked and categorized in 4 or 5 levels, depending on organization’s definition.    S1 - Critical: This means the defect is a show stopper with high potential damages and has no workaround to avoid the defect. An example could be the application does not launch at all and causes the operating system to shut down. This requires immediate attention and action and fix.     S2 - Serious: This means that some major functionalities of the applications are either missing or do not work and there is no workaround. Example, an image viewing application cannot read some common image formats.     S3 - Normal: This means that some major functionality do not work, but, a workaround exists to be used as a temporary solution.     S4 - Cosmetic / Enhancement: This means that the failure causes inconvenience and annoyance. Example can be that there is a pop-up message every 15 minutes, or you always have to click twice on a GUI button to perform the action.     S5 - Suggestion: This is not normally a defect and a suggestion to improve a functionality. This can be GUI or viewing preferences.  Priority: Once the severity is determine, next is to see how to prioritize the resolution. The priority determines how quickly the defect should be fixed. The priority normally concerns the business importance such as impact on the project and the likely success of the product in the marketplace. Like severity, priority is also categorized in to 4 or 5 levels.    P1 - Urgent: Means extremely urgent and requires immediate resolution     P2 - High: Resolution requirement for next external release     P3 - Medium: Resolution required for the first deployment (rather than all deployments)     P4 - Low: Resolution desired for the first deployment or subsequent future releases     P4 - Low: Resolution desired for the first deployment or subsequent future releases  Read more on Severity versus Priority It is important to note that a defect which has a high severity also bears a high priority, i. e. a severe defect will require a high priority to resolve the issue as quick as possible. There can never be a high severity and low priority defect. However, a defect can have a low severity but have a high priority. An example might be a company name is misspelled on the splash screen as the application launches. This does not cause a severe damage to the environment or people’s lives, but can have potential damages to company’s reputation and can harm business profits. Date and Time: The date and time that the defect occurred or reported is also essential. This is normally useful when you want to search for defects that were identified for a particular release of software or from when the testing phase started. Version and Build of the Software Under Test: This is very important too. In most cases, there are many versions of software; each version has many fixes and more functionality and enhancements to the previous versions. Therefore, it is essential to note which version of the software exhibited the failure that we are reporting. We may always refer to that version of software to reproduce the failure. Reported by: Again, this is important, because if we may need to refer to the person who raised the defect, we have to know who to contact. Related requirement: Essentially, all features of a software application can be traced to respective requirements. Hence, when a failure is observed, we can see what requirements have been impacted. This can help in reducing duplicate defect reports in that if we can identify the source requirement, then if another defect is logged with the same requirement number, we may not need report it again, if the defects are of similar nature. Attachments / Evidence: Any evidence of the failure should be captured and submitted with the defect report. This is a visual explanation of the description of the defect and helps the reviewer, developer to better understand the defect. "
    }, {
    "id": 148,
    "url": "localhost:4000/moscow-prioritization/",
    "title": "MoSCoW Prioritization in Software Testing",
    "body": "2016/12/16 - Prioritization of Requirements: An important factor for the success of any project is ensuring that the requirements, are prioritized. In many cases this is not done leading to sure project failure. Sometimes it is the customers’ fault who want the entire system to be delivered now. Other times it is the project manager’s fault because they do not discuss the project with the customer. In either case prayers for miracles are often required if the project is to have any chance of being successful. In my experience miracles rarely happen on projects. However prioritizing is not an easy process, and even less so when done using a number system. The trouble with number systems is that it appears logically to give the features a priority of 1, 2, 3 etc. However who wants a requirement to be a “2” or even a “3”? As a result all requirements become a “1”, which is useless. This can lead to having to resort to additional systems such as giving “1*” and “1**” ratings to try to sort out what is really important. Even this is subject to prioritization drift - upwards. Even more damaging with number systems is that features that will not be developed this time are left off the list, and are ultimately lost. This means that designers and developers are unaware of these future needs, and therefore cannot select solutions which will make it easier to accommodate them at a later date. So effective prioritization is important but how can it be done if number systems are not effective? MoSCoW: A more successful method is to prioritize requirements by using words that have meaning. Several schemes exist but a method popularized by the DSDM community is the acronym MoSCoW. This stands for: M - MUST have this. S - SHOULD have this if at all possible. C - COULD have this if it does not effect anything else. W - WON’T have this time but would like in the future. The two lower case “o” are there just to make the acronym work. The importance of this method is that when prioritising the words mean something and can be used to discuss what is important. The “Must” requirements are non-negotiable, if they are not delivered then the project is a failure, therefore it is in everybody’s interest to agree what can be delivered and will be useful. Nice to have features are classified in the other categories of “Should” and “Could. “Must” requirements must form a coherent set. They cannot just be “cherry picked” from all the others. If they are then what happens is that by default all the other requirements automatically become “Must”, and the entire exercise is wasted. Requirements marked as “Won’t” are potentially as important as the “Must” category. It is not immediately obvious why this is so, but it is one of the characteristics that makes MoSCoW such a powerful technique. Classifying something as “Won’t” acknowledges that it is important, but can be left for a future release. In fact a great deal of time might be spent in trying to produce a good “Won’t” list. This has three important effects:    Users do not have to fight to get something onto a requirements list     In thinking about what will be required later, affects what is asked for now.     The designers seeing the future trend can produce solutions that can accommodate these requirements in a future release.  "
    }, {
    "id": 149,
    "url": "localhost:4000/test-strategy-and-test-plan/",
    "title": "Test Strategy and Test Plan",
    "body": "2016/12/15 - Test Strategy: [caption id=”attachment_10182” align=”aligncenter” width=”600”] test-strategy-vs-test-plan[/caption] A Test Strategy document is a high level document and normally developed by project manager. This document defines “Software Testing Approach” to achieve testing objectives. The Test Strategy is normally derived from the Business Requirement Specification document. The Test Strategy document is a static document meaning that it is not updated too often. It sets the standards for testing processes and activities and other documents such as the Test Plan draws its contents from those standards set in the Test Strategy Document. Some companies include the “Test Approach” or “Strategy” inside the Test Plan, which is fine and it is usually the case for small projects. However, for larger projects, there is one Test Strategy document and different number of Test Plans for each phase or level of testing. Components of the Test Strategy document:  Scope and Objectives Business issues Roles and responsibilities Communication and status reporting Test deliverables Industry standards to follow Test automation and tools Testing measurements and metrices Risks and mitigation Defect reporting and tracking Change and configuration management Training planHere is an example of an Agile Test Strategy Document Template Test Plan: The Test Plan document on the other hand, is derived from the Product Description, Software Requirement Specification SRS, or Use Case Documents. The Test Plan document is usually prepared by the Test Lead or Test Manager and the focus of the document is to describe what to test, how to test, when to test and who will do what test. It is not uncommon to have one Master Test Plan which is a common document for the test phases and each test phase have their own Test Plan documents. There is much debate, as to whether the Test Plan document should also be a static document like the Test Strategy document mentioned above or should it be updated every often to reflect changes according to the direction of the project and activities. My own personal view is that when a testing phase starts and the Test Manager is “controlling” the activities, the test plan should be updated to reflect any deviation from the original plan. After all, Planning and Control are continuous activities in the formal test process. Components of the Test Plan document:  Test Plan id Introduction Test items Features to be tested Features not to be tested Test techniques Testing tasks Suspension criteria Features pass or fail criteria Test environment (Entry criteria, Exit criteria) Test deliverables Staff and training needs Responsibilities ScheduleThis is a standard approach to prepare test plan and test strategy documents, but things can vary company-to-company. Next: Agile Test Plan - Do We Really Need One? "
    }, {
    "id": 150,
    "url": "localhost:4000/software-testing-how-to-log-a-bug/",
    "title": "MoSCoW Prioritization in Software Testing",
    "body": "2016/12/14 -  As we already have discussed importance of Software Testing in any software development project (Just to summarize: Software testing helps in improving quality of software and deliver a cost effective solution which meet customer requirements), it becomes necessary to log a defect in a proper way, track the defect, and keep a log of defects for future reference etc. As a tester tests an application and if he/she finds any defect, the life cycle of the defect starts and it becomes very important to communicate the defect to the developers in order to get it fixed, keep track of current status of the defect, find out if any such defect (similar defect) was ever found in last attempts of testing etc. For this purpose, previously manually created documents were used, which were circulated to everyone associated with the software project (developers and testers), now a days many Bug Reporting Tools are available, which help in tracking and managing bugs in an effective way. How to write an effective bug report: It’s a good practice to take screen shots of execution of every step during software testing. If any test case fails during execution, it needs to be failed in the bug-reporting tool and a bug has to be reported/logged for the same. The tester can choose to first report a bug and then fail the test case in the bug-reporting tool or fail a test case and report a bug. In any case, the Bug ID that is generated for the reported bug should be attached to the test case that is failed. At the time of reporting a bug, all the mandatory fields from the contents of bug (such as Project, Summary, Description, Status, Detected By, Assigned To, Date Detected, Test Lead, Detected in Version, Closed in Version, Expected Date of Closure, Actual Date of Closure, Severity, Priority and Bug ID etc. ) are filled and detailed description of the bug is given along with the expected and actual results. The screen-shots taken at the time of execution of test case are attached to the bug for reference by the developer. After reporting a bug, a unique Bug ID is generated by the bug-reporting tool, which is then associated with the failed test case. This Bug ID helps in associating the bug with the failed test case. After the bug is reported, it is assigned a status of ‘New’, which goes on changing as the bug fixing process progresses. If more than one tester are testing the software application, it becomes a possibility that some other tester might already have reported a bug for the same defect found in the application. In such situation, it becomes very important for the tester to find out if any bug has been reported for similar type of defect. If yes, then the test case has to be blocked with the previously raised bug (in this case, the test case has to be executed once the bug is fixed). And if there is no such bug reported previously, the tester can report a new bug and fail the test case for the newly raised bug. If no bug-reporting tool is used, then in that case, the test case is written in a tabular manner in a file with four columns containing Test Step No, Test Step Description, Expected Result and Actual Result. The expected and actual results are written for each step and the test case is failed for the step at which the test case fails. This file containing test case and the screen shots taken are sent to the developers for reference. As the tracking process is not automated, it becomes important keep updated information of the bug that was raised till the time it is closed. "
    }, {
    "id": 151,
    "url": "localhost:4000/seven-principles-of-software-testing/",
    "title": "Seven Principles of Software Testing",
    "body": "2016/12/13 - Software testing is an extremely creative and intellectually challenging task. When testing follows the principles given below, the creative element of test design and execution rivals any of the preceding software development steps. 1. Testing shows the presence of bugs: Testing an application can only reveal that one or more defects exist in the application, however, testing alone cannot prove that the application is error free. Therefore, it is important to design test cases which find as many defects as possible. 2. Exhaustive testing is impossible: Unless the application under test (AUT) has a very simple logical structure and limited input, it is not possible to test all possible combinations of data and scenarios. For this reason, risk and priorities are used to concentrate on the most important aspects to test. 3. Early testing: The sooner we start the testing activities the better we can utilize the available time. As soon as the initial products, such the requirement or design documents are available, we can start testing. It is common for the testing phase to get squeezed at the end of the development lifecycle, i. e. when development has finished, so by starting testing early, we can prepare testing for each level of the development lifecycle. Another important point about early testing is that when defects are found earlier in the lifecycle, they are much easier and cheaper to fix. It is much cheaper to change an incorrect requirement than having to change a functionality in a large system that is not working as requested or as designed! 4. Defect clustering: During testing, it can be observed that most of the reported defects are related to small number of modules within a system. i. e. small number of modules contain most of the defects in the system. This is the application of the Pareto Principle to software testing: approximately 80% of the problems are found in 20% of the modules. 5. The pesticide paradox: If you keep running the same set of tests over and over again, chances are no more new defects will be discovered by those test cases. Because as the system evolves, many of the previously reported defects will have been fixed and the old test cases do not apply anymore. Anytime a fault is fixed or a new functionality added, we need to do regression testing to make sure the new changed software has not broken any other part of the software. However, those regression test cases also need to change to reflect the changes made in the software to be applicable and hopefully fine new defects. 6. Testing is context dependent: Different methodologies, techniques and types of testing is related to the type and nature of the application. For example, a software application in a medical device needs more testing than a games software. More importantly a medical device software requires risk based testing, be compliant with medical industry regulators and possibly specific test design techniques. By the same token, a very popular website, needs to go through rigorous performance testing as well as functionality testing to make sure the performance is not affected by the load on the servers. 7. Absence of errors fallacy: Just because testing didn’t find any defects in the software, it doesn’t mean that the software is ready to be shipped. Were the executed tests really designed to catch the most defects? or where they designed to see if the software matched the user’s requirements? There are many other factors to be considered before making a decision to ship the software. Other principles to note are:       Testing must be done by an independent party.    Testing should not be performed by the person or team that developed the software since they tend to defend the correctness of the program.       Assign best personnel to the task.    Because testing requires high creativity and responsibility only the best personnel must be assigned to design, implement, and analyze test cases, test data and test results.       Test for invalid and unexpected input conditions as well as valid conditions.    The program should generate correct messages when an invalid test is encountered and should generate correct results when the test is valid.       Keep software static during test.    The program must not be modified during the implementation of the set of designed test cases.       Provide expected test results if possible.    A necessary part of test documentation is the specification of expected results, even if providing such results is impractical. "
    }, {
    "id": 152,
    "url": "localhost:4000/top-10-negative-test-cases/",
    "title": "Top 10 Negative Test Cases",
    "body": "2016/12/12 - Negative test cases are designed to test the software in ways it was not intended to be used, and should be a part of your testing effort. Below are the top 10 negative test cases you should consider when designing your test effort:  1. Embedded Single QuoteMost SQL based database systems have issues when users store information that contain a single quote (e. g. John’s car). For each screen that accepts alphanumeric data entry, try entering text that contains one or more single quotes.  2. Required Data EntryYour functional specification should clearly indicate fields that require data entry on screens. Test each field on the screen that has been indicated as being required to ensure it forces you to enter data in the field.  3. Field Type TestYour functional specification should clearly indicate fields that require specific data entry requirements (date fields, numeric fields, phone numbers, zip codes, etc). Test each field on the screen that has been indicated as having special types to ensure it forces you to enter data in the correct format based on the field type (numeric fields should not allow alphabetic or special characters, date fields should require a valid date, etc).  4. Field Size TestYour functional specification should clearly indicate the number of characters you can enter into a field (for example, the first name must be 50 or less characters). Write test cases to ensure that you can only enter the specified number of characters. Preventing the user from entering more characters than is allowed is more elegant than giving an error message after they have already entered too many characters.  5. Numeric Bounds TestFor numeric fields, it is important to test for lower and upper bounds. For example, if you are calculating interest charged to an account, you would never have a negative interest amount applied to an account that earns interest, therefore, you should try testing it with a negative number. Likewise, if your functional specification requires that a field be in a specific range (e. g. from 10 to 50), you should try entering 9 or 51, it should fail with a graceful message.  6. Numeric Limits TestMost database systems and programming languages allow numeric items to be identified as integers or long integers. Normally, an integer has a range of -32,767 to 32,767 and long integers can range from -2,147,483,648 to 2,147,483,647. For numeric data entry that do not have specified bounds limits, work with these limits to ensure that it does not get an numeric overflow error.  7. Date Bounds TestFor date fields, it is important to test for lower and upper bounds. For example, if you are checking a birth date field, it is probably a good bet that the person’s birth date is no older than 150 years ago. Likewise, their birth date should not be a date in the future.  8. Date ValidityFor date fields, it is important to ensure that invalid dates are not allowed (04/31/2007 is an invalid date). Your test cases should also check for leap years (every 4th and 400th year is a leap year).  9. Web Session TestingMany web applications rely on the browser session to keep track of the person logged in, settings for the application, etc. Most screens in a web application are not designed to be launched without first logging in. Create test cases to launch web pages within the application without first logging in. The web application should ensure it has a valid logged in session before rendering pages within the application.  10. Performance ChangesAs you release new versions of your product, you should have a set of performance tests that you run that identify the speed of your screens (screens that list information, screens that add/update/delete data, etc). Your test suite should include test cases that compare the prior release performance statistics to the current release. This can aid in identifying potential performance problems that will be manifested with code changes to the current release. "
    }, {
    "id": 153,
    "url": "localhost:4000/white-box-testing/",
    "title": "White Box Testing",
    "body": "2016/12/11 - What is a White Box Testing Strategy?: White box testing strategy deals with the internal logic and structure of the code. White box testing is also called as glass, structural, open box or clear box testing. The tests written based on the white box testing strategy incorporate coverage of the code written, branches, paths, statements and internal logic of the code etc. In order to implement white box testing, the tester has to deal with the code and hence is needed to possess knowledge of coding and logic i. e. internal working of the code. White box test also needs the tester to look into the code and find out which unit/statement/chunk of the code is malfunctioning. Types of White Box testing: Unit Testing:The developer carries out unit testing in order to check if the particular module or unit of code is working fine. The Unit Testing comes at the very basic level as it is carried out as and when the unit of the code is developed or a particular functionality is built. Static and dynamic Analysis:Static analysis involves going through the code in order to find out any possible defect in the code. Dynamic analysis involves executing the code and analyzing the output. Statement Coverage:In this type of testing the code is executed in such a manner that every statement of the application is executed at least once. It helps in assuring that all the statements execute without any side effect. Branch Coverage:No software application can be written in a continuous mode of coding, at some point we need to branch out the code in order to perform a particular functionality. Branch coverage testing helps in validating of all the branches in the code and making sure that no branching leads to abnormal behavior of the application. Security Testing:Security Testing is carried out in order to find out how well the system can protect itself from unauthorized access, hacking – cracking, any code damage etc. which deals with the code of application. This type of testing needs sophisticated testing techniques. Mutation Testing:A kind of testing in which, the application is tested for the code that was modified after fixing a particular bug/defect. It also helps in finding out which code and which strategy of coding can help in developing the functionality effectively. Besides all the testing types given above, there are some more types which fall under both Black box and White box testing strategies such as: Functional testing (which deals with the code in order to check its functional performance), Incremental integration testing (which deals with the testing of newly added code in the application), Performance and Load testing (which helps in finding out how the particular code manages resources and give performance etc. ) etc. Advantages of White box testing are:    As the knowledge of internal coding structure is prerequisite, it becomes very easy to find out which type of input/data can help in testing the application effectively.     The other advantage of white box testing is that it helps in optimizing the code     It helps in removing the extra lines of code, which can bring in hidden defects.  Disadvantages of white box testing are:    As knowledge of code and internal structure is a prerequisite, a skilled tester is needed to carry out this type of testing, which increases the cost.     And it is nearly impossible to look into every bit of code to find out hidden errors, which may create problems, resulting in failure of the application.  "
    }, {
    "id": 154,
    "url": "localhost:4000/test-policy-document/",
    "title": "Test Policy Document",
    "body": "2016/12/10 - What is a Test Policy Document?: [caption id=”attachment_10178” align=”aligncenter” width=”472”] test-policy-document[/caption] A Test Policy is a high level document and is at the top of the hierarchy of the Test Documentation structure. The purpose of the Test Policy document is to represent the testing philosophy of the company as a whole and to provide a direction which the testing department should adhere to and follow. It should apply to both new projects and maintenance work. Setting an appropriate test policy by senior managers, provides a robust framework within which testing practitioners can then operate. This will help to ensure the maximisation of the strategic value inherent in every project. Contents of a Test Policy Document: 1. Definition of TestingOrganisations need to be clear why they are testing. This will influence the remainder of the policy document and also the detailed testing techniques that are selected by test managers at the programme and project level. From the understanding of why testing is required it is possible to specify what the purpose of testing is within the organisation. Without this fundamental linkage the test effort is destined to fail. Example: “ensuring the software fulfills its requirements” 2. Description of the test processIt is vital to establish a solid view towards the test process. We should address questions like, which phases and subtasks will the test process include. Which roles will be involved and the document structure associated with each tasks, as well as what test levels need to be considered. Example: “all test plans are written in accordance with company policy” 3. Test Evaluation:How are we going to evaluate the results of testing, what measures will we use to ensure test effectiveness in the project? Example: “effect on business of finding a fault after its release” 4. Quality Level to be achieved:Which quality criteria are going to be tested and which quality level is the system required to achieve prior to its release with regards to these criteria? Example: “no outstanding high severity faults prior to products release” 5. Approach to Test Process ImprovementHow often and when are we going to assess the usefulness of the current processes in place and what elements need improving and techniques that shall be used to improve the processes. Example: “project review meetings to be held after project completion” "
    }, {
    "id": 155,
    "url": "localhost:4000/best-practices-for-regression-testing/",
    "title": "Regression Testing Best Practices",
    "body": "2016/12/09 - Regression Testing Best Practices: Maintenance of Regression Testing can be a very daunting exercise. These Regression Testing Best Practices and tips can help you create maintainable and useful regression pack. It is a common practice that when a defect is fixed, two forms of testing are done on the fixed code. The first is confirmation testing to verify that the fix has actually fixed the defect and the second is regression testing to ensure that the fix hasn’t broken existing functionality. It is important to note that the same principle applies when a new feature or functionality is added to the existing application. In the case of new functionality being added, tests can verify that the new features work as per the requirement and design specifications while regression testing can show that the new code hasn’t broken any existing functionality. It is possible that a new version of the application will have fixed previously reported defects as well as having new functionality. For the ‘fixes’ we would normally have a set of Defect Test Scripts (DTS) which are run to confirm the fixes, while for the new functionalities we would have a set of Release Specific Test Scripts that test the Change Control Notices (CCNs). Overtime, as the software application becomes bigger and bigger in terms of new functionality and more components added, a regression pack, which is a bank of test cases, is developed to be run as each new version of the application is released. Selecting Tests for Regression Testing: As explained earlier, for each new release of software application, three sets of test suites are executed; Regression Tests, Release Specific Tests and Defect Test Scripts. Choosing test cases for regression packs is not a trivial exercise. Careful thoughts and attention need to be paid on choosing the sets of tests to include in the regression packs. One would expect that as each new test case written for Release Specific Tests, they will become part of the regression pack to be executed after the next version of the code is arrived. So, in other words, the regression pack becomes bigger and bigger as more and more new versions of the code is developed. If we automate regression testing, this should not be a problem, but for a manual execution of large regression packs, this can cause time constraints and the new functionalities may not be tested due to lack of time. These regression packs often contain tests that cover the core functionality that will stay the same throughout the evolution of the application. Having said that, some of the old test cases may not be applicable anymore as those functionalities may have been removed and replaced by new functionality. Therefore, the regression test packs need to be updated regularly to reflect changes to the application. The regression packs are a combination of scripted tests that have been derived from the requirement specifications for previous versions of the software as well as random or ad-hoc tests. A regression test pack should, at a minimum, cover the basic workflow of typical use case scenarios. “Most Important Tests” i. e. tests which are important to the application domain should always be included in the regression packs. For example, a banking application should contain tests which exercise the application’s security robustness while a web application for a high traffic website should most definitely contain performance related test cases. Successful test cases, i. e. tests which have revealed defects in the previous versions of the application are also a good candidate to be included in the regression packs. Automated Regression Testing: Where possible, regression tests must be automated. Running the same tests over and over again, with the same variables and conditions would not yield any new defects. Repetitive work causes a loss of interest and a lack of concentration for the person executing the tests who may potentially miss any new defects while executing the regression tests. Also another advantage of automating the regression tests is that more test cases can be added to the regression packs without much impact on the time. An automated regression pack can be run overnight or in parallel with the manual tests and would free up the resource. "
    }, {
    "id": 156,
    "url": "localhost:4000/should-you-prioritise-your-software-testing/",
    "title": "Should You Prioritise Your Software Testing?",
    "body": "2016/12/08 - Prioritize Your Software Testing: How often do you feel overwhelmed with the amount of software testing you need to complete for your next product release? Twice a week? Four times a week? Every day? It is a frustrating fact of testing that there is never enough time to complete all the testing. Rather than finding a way to deal with this, most software test teams simply hope that they’ve done enough. If that is what you’re doing why not consider prioritizing your software testing? When you prioritize your software testing you:    Find the serious bugs sooner     Deliver the results needed by the team faster     Don’t waste time on irrelevant tests  It would be great if we had more testers and realistic deadlines but in the real world we often get little influence over those variables. You have the resources you have, and you need to make the most of them. We can’t help you decide on the precise priorities for each of your tests, as you need knowledge of the product to do that. However, the following 6 points will help guide you : 1. Review defect trends from previous product releases 2. Identify areas where bugs have been fixed or new functionality added 3. Balance test priorities across early and later builds for the product 4. Make sure you have well defined meanings for each priority you use 5. Ensure you have consistent priorities across all your tests 6. Review test results from previous test runs The solution is not just to hope that you’ve done enough software testing. The solution is to find a system that enables you to prioritise software tests and focus on what matters most. "
    }, {
    "id": 157,
    "url": "localhost:4000/why-do-we-need-software-testing/",
    "title": "Why Do We Need Software Testing?",
    "body": "2016/12/07 - Why Do We Test Software: For any company developing software, at some point pressure to reach the deadline in order to release the product on time will come into play. Additional pressure from project stakeholders, such as ‘Marketing’ will not want to delay the release date as significant effort and money may have already been spent on an expected release date. Quite often, planned time to test the software (e. g. ascertain its quality - QA) will become reduced so as not to impact the release date. From a pure business perspective, this can be seen as a positive step as the product is reaching the intended customers on time. Careful consideration should be taken though as to the overall impact of a customer finding a ‘bug’ in the released product. Maybe the bug is buried deep within a very obscure functional area of the software product, and as the impact only results in a typo within a seldom-used report, the level of impact is very low. In this case, the effect on the business for this software company would probably be insignificant. But what if the bug resulted in the program crashing and losing data? Maybe this software product is used within an air traffic control system? As you can imagine, the impact of this type of bug could be incredibly high and may result in loss of life and destroying the entire company responsible. So basically, the level of risk of a bug being found (likelihood) and what is the effect of the bug (impact) prove to be critical in how much software testing is performed prior to a products release. Too Many Combinations to Test: Due to the complexity of modern software it is impossible to ensure that software is bug-free……. it really is! Imagine a simple form on a software application that was designed to accept one of ten specific values, in order to test this completely, you would need to create a test case for each and every permutation of the entries that could be entered by the user, for example: 10(inputs) to the 10(values)th power 10 to the 10th power Result = 10,000,000,000 test cases So, if you were the tester hired to perform the testing, and it only took you one second to perform each test case, it would take around 317 years to complete. Therefore, the test planning should take into consideration what is actually ‘achievable. ’ Test Techniques such as Equivalence Partitioning and Pairwise Testing can help reduce this number of combinations. Software testing (synonymous with the term Quality Assurance) itself can have many different purposes (quality assurance, validation, performance etc). This is a key decision when planning the QA /software testing, as not testing enough or testing in the wrong areas will inevitably result in missed bugs. The aim should be first ascertaining ‘why’ we are going to test and not simply ‘what’ we are going to test. Software testing and or Quality Assurance is still a kind of art, mainly due to a limited understanding of the complexities of modern software. Recent years has seen the development of software testing certification such as ISEB and ISTQB. This is good news for the software industry as a whole, as the more experienced a software tester is then the level of quality of the software they are testing can only increase. Software testing cannot ensure software is bug-free, but it CAN increase software quality. If we aim for perfection, we may just achieve excellence! http://www. testing4success. com is a professional consultancy providing highly cost-effective outsource software testing solutions to companies around the globe. We can provide outsource software testing services to supplement your existing project, or provide dedicated outsource software testing for entire projects, all delivered on-time and with outstanding results. Please contact us with any questions you may have, or for a free quote. "
    }, {
    "id": 158,
    "url": "localhost:4000/what-software-testing-methodology/",
    "title": "What is Software Testing Methodology?",
    "body": "2016/12/06 - Choosing a Testing Methodology: [caption id=”attachment_10195” align=”aligncenter” width=”517”] testing-methodology[/caption] Testing methodologies are approaches to testing, from unit testing through system testing and beyond. There is no formally recognized body of testing methodologies, and very rarely will you ever find a unified set of definitions. But here are some common methodologies: Unit testing: The act of testing software at the most basic (object) level. Generally performed by developers, run in “friend classes” with code-level access to read and manipulate objects. Acceptance testing: Also known as acceptance tests, build verification tests, basic verification tests, these are rudimentary tests which prove whether or not a given build is worth deeper testing. The term “smoke test” is a colloquial term – when machines are built, engineers will power them up and just let them run, looking for smoke as a sign of serious problems. Functional testing: Functional testing takes a user story or a product feature and tests all of the functionality contained within that feature. For example, in a photo application like Photoshop, functional testing would cover all the functionality contained within a feature like opening files (resolving file paths, determining appropriate format filters, passing the file path off to the filter) as well as handling errors within that functionality. System testing: Testing the project as a collective system. For the Photoshop application, an example would be to open a file in a given format, manipulate that file in various ways, and then output the file. System testing generally combines multiple features into an end-to-end process or scenario. Performance testing: Tests an application’s performance characteristics, be it file size, concurrent users, or mean-time-to-failure. Performance Testing can give us a measure of how the application responds to requests and how the application behaves under load. Security testing: A collection of tests focused on probing an application’s security, or its ability to protect user assets. Other people consider approaches to testing to be testing methodologies. For instance, boundary testing (finding the limits of a feature, then testing at that limit, below the limit, and above the limit); pairwise or combinatorial testing, wherein a tester takes a very scientific approach to testing combinations of input variables, etc. Two fantastic sources for learning more about testing methodologies are Cem Kaner’s Testing Computer Software (very formal, organized approach to testing) and Lessons Learned in Software Testing by Kaner, Bach, Pettichord, which is less formal, but full of interesting tips on software testing technique. "
    }, {
    "id": 159,
    "url": "localhost:4000/web-application-testing-techniques/",
    "title": "Web Application Testing Techniques",
    "body": "2016/12/05 - Web Application Testing: In today’s ever-changing and competitive web-based business scenario, organizations always need to test their web based applications before the launch of their website. By web application testing, any organization can be sure that the web application will work perfectly and will be easily accepted by the end-users. The web application testing techniques also check the web application’s browser compatibility; load testing, scalability testing, stress testing and resolution testing. Testing Methods for Web Application Testing: Here are few of the basic testing techniques for web application testing: 1. Functional Testing: This testing is used for checking all the links of the web pages; form testing, cookie testing and database connection. 2. Usability Testing: This testing checks the navigation and user friendliness of the web pages. Through this testing it is ensured whether the content is properly checked and is easily understandable to the users. It also checks whether the anchor text links are working properly, whether sitemaps and help files are having proper information and all the links are working. 3. Interface Testing: This checks if the web server and application server interface, application server and database server interface have proper interaction or not. This test ensures that the users do not see any error messages. 4. Compatibility Testing: Compatibility Testing is very important as it checks browser compatibility, operating system compatibility, mobile browsing and printing options. 5. Performance Testing: Performance testing includes web load testing and web stress testing. Web load testing technique checks if many users can access the same page at the same time and whether a web page can handle heavy load on any specific page. Web stress testing is done on the site to see that how will the site react and recover during the stress time. 6. Security Testing: This checks the security of the web applications. For security purposes, internal pages should not open if you are not logged into the website. Other statistics should not be seen even if the user is logged in. The files should only be given the option for downloading and it should not be accessed without downloading. CAPTCHA for automates scripts logins should be tested. SSL should be tested for security measures. After completing all the web application testing, a live testing is necessary for web based applications and web sites. Then upload the site and complete testing should be done. These days, web applications are accessed from different kinds of devices like desktops, PDAs, iPhones, etc. It is very important to check whether the web application is compatible to these devices. Web applications can be provided to a large and diverse audience but there is a risk of being exposed to a large set of probable loopholes as far as successful software testing results is concerned:    Numerous Application Usage (Entry – Exit) Paths are possible     People with varying backgrounds &amp; technical skills may use the application. Also, differences may rise from cross-platform issues to difference in browsers, network types or network speeds, Intranet and Internet application differences, etc. – resulting in issues concerning the software.     Even on the same browser, applications may be executed differently based on local issues such as screen resolution/ hardware/ software configuration of the system     The applications may require testing for disability compliance and usability     Firewalls or allied security threats  To conclude, the entire process of Web Application testing includes some really important and critical steps so as to ensure that end users are satisfied with the applications. "
    }, {
    "id": 160,
    "url": "localhost:4000/software-testing-jokes/",
    "title": "Software Testing Jokes",
    "body": "2016/12/04 - The field of Software Testing can be boring at times and a bit of humor is always nice. Software Testing Jokes is a collection of jokes, anecdotes, quotes, related to software testing and testers. Software testing is not a very glamorous job and not very dignified too. However, software testing is a crucial phase in any software development life cycle and whoever underestimates its benefits has lost much. Developers (well, not all) crack a lot of jokes about software testers, upfront and at the back, and sometimes they can hurt but a true software tester is undaunted and moves on with his work and life. The collection of jokes exemplifies the perspectives people have about software testers and the perspectives software testers, some exaggerated and some no t so true. But a hearty laugh does one good, always. One classical Joke: Question: How many testers does it take to change a light bulb?Answer: None. Testers do not fix problems; they just find them. Signs That You’re Dating A Tester  Your love letters get returned to you marked up with red ink, highlighting your grammar and spelling mistakes.  When you tell him that you won’t change something he has asked you to change, he’ll offer to allow you two other flaws in exchange for correcting this one.  When you ask him how you look in a dress, he’ll actually tell you.  When you give him the “It’s not you, it’s me” breakup line, he’ll agree with you and give the specifics.  He won’t help you change a broken light bulb because his job is simply to report and not to fix.  He’ll keep bringing up old problems that you’ve since resolved just to make sure that they’re truly gone.  In the bedroom, he keeps “probing” the incorrect “inputs”. You will relate to these jokes better if you are a Software Tester. "
    }, {
    "id": 161,
    "url": "localhost:4000/100-open-sourcefree-functional-testing-tools/",
    "title": "100+ Open Source/Free Functional Testing Tools",
    "body": "2016/12/03 - It is very important to make sure that your application functions as expected. There may be times that you add one little piece of code and all of a sudden other parts of the application no longer works. You may not have time/capacity to manually go back and regression test all the pieces of your application to make sure they are up to par. Companies use a variety of different testing tools for regression testing. There are lots of tools out there from very expensive to open source. Below is a list of some open source/free tools that may come in handy. Please keep in mind that every application is different so the tool you pick from one application may not be the same tool that you pick for another. My advice would be to pick a tool that can meet most of your current and near future needs.    Abbot Java GUI Test Framework: The Abbot framework provides automated event generation and validation of Java GUI components, improving upon the very rudimentary functions provided by the java. awt. Robot class (A Better ‘Bot). The framework may be invoked directly from Java code or accessed without programming through the use of scripts. It is suitable for use both by developers for unit tests and QA for functional testing   Anteater: A testing framework designed around Ant, from the Apache Jakarta Project. It provides an easy way to write tests for checking the functionality of a Web application or of an XML Web service.  Autonet:Autonet is a GUI networktest platform, internally it’s based on CLI to communicate with devices. It can help you to arrange test cases, setup commands to devices,run commands to check results and record test results. Requirement: windows, linux and any other platform which support tcl Avignon: An acceptance test system that allows you to write executable tests in a language that you define. It uses XML to define the syntax of the language but, if you choose to extend the language, leaves the semantics of the tests up to you. Avignon includes modules for testing HTML applications (through either IE or FireFox), Swing and . NET WinForm applications. Requirement: Java (MS Windows only for . NET testing) Canoo WebTest: Used for functional testing of web pages, WebTest is an open source testing framework built on top of HttpUnit. It allows tests to be defined in XML as Ant targets. Requirement: JDK 1. 2 and ANT v1. 3 Celerity: a JRuby wrapper around HtmlUnit – a headless Java browser with JavaScript support. It provides a simple API for programmatic navigation through web applications. Celerity aims at being API compatible with Watir.  Concordion: Framework for Java that lets you turn a plain English description of a requirement into an automated test. Concordion specifications are active. Behind the scenes, they are linked to the system under test and therefore do not go out-of-date. If a change is made to the system’s behaviour then the tests associated with the relevant specification will fail and let you know. Requirement: Java 1. 5 or above DbFit: Extension to FIT/FitNesse for test-driven database development. Enables developers to manipulate database objects in a relational/ tabular form, making database testing and management much easier then with xUnit-style tools. Requirement: Java/. NET Doit: Simple Web Application Testing: Scripting tool and language for testing web applications that use forms. Doit can generate random or sequenced form fill-in information, report results (into a database, file, or stdout), filter HTML results, and compare results to previous results, without having to manually use a web browser. It uses a console-based web client tool (like Curl or Wget) to send and receive HTTP requests and responses respectively. Requirement: You must have Perl 5 or greater and the appropriate Perl modules (detailed in Doit manual) installed on your system before you can use SPL.  EMOS Framework: A simple yet powerful environment for development of automated WinRunner? tests. Like most frameworks of this sort EMOS Framework separates test data from the test code in order to simplify and speed up test development, increase robustness of the produced solution, and empower non-programmers towards test automation. It is almost completely written in WinRunner’s own scripting language, TSL. Requirement: Mercury WinRunner, All 32-bit MS Windows (95/98/NT/2000/XP) Enterprise Web Test: Allows Java programmers to write re-usable tests for web applications that, unlike HttpUnit, “drive” the actual web browser on the actual platform they intend to support. Tests can be leveraged for functional, stress, reliability. Requirement: Microsoft, OS Independent, Linux Funkload: Web functional testing and load testing tool written in Python and distributed as free software under the GNU GPL. Emulates a web browser (single-threaded) using webunit; https support; produces detailed reports in ReST, HTML, or PDF. Functional tests are pure Python scripts using the pyUnit framework.  FWPTT: is a web application tester program for load testing web applications which can record normal and Ajax requests Harness: An open source Java API for creating Java test software HtmlUnit: Java unit testing framework for testing web based applications. (Similar in concept to httpunit but is very different in implementation) HtmlUnit models the returned document so that you can deal with pages, forms and tables.  httest: Scriptable HTTP Test Tool for testing and benchmarking web application and HTTP server development. Can act as client (requesting) and server (back-end for reverse proxys). Pattern matching answers (both server(s)and client(s)) to test validity. Has a very simple but powerful syntax. Can execute and stream shell commands into the HTTP stream and vice versa. Requirement: linux, solaris HTTPUnit: Java API for testing web sites without a browser.  IdMUnit: Leading xUnit automated testing framework for Identity Management that simplifies and accelerates the functional testing of the solution. Test cases are defined and implemented in spreadsheet format. This product plugs into Eclipse. Requirement: Cross-platform IeUnit: A simple framework to test logical behaviors of web pages, released under IBM’s Common Public License. It helps users to create, organize and execute functional unit tests. Includes a test runner with GUI interface. Implemented in JavaScript for the Windows XP platform with Internet Explorer.  iMacros for Firefox: Free Firefox add-on to record and automate web interactions. Can use variables inside the macros, and import data from CSV files. Includes user agent switcher, PDF download and Flash, ad and image blocking functions. The recorded macros can be combined and controlled with Javascript, so complex tasks can be scripted. The EXTRACT command enables reading of data from a website and exporting it to CSV files. Full Unicode support and works with all languages including multi-byte languages such as Chinese. STOPWATCH command enables capturing of web page response times ITP: Lightweight, yet powerful web application test harness. Test scripts written in XML. No programming required and no changes required to your web application. Supports sessions/cookies, POST form data. Command line based for integration into other tools. Also useful for regression and smoke testing.  ItsNat, Natural AJAX: A Java AJAX web framework with functional web test built-in. Simulates a Universal Java W3C Browser in the server, the client DOM tree is basically a clone of the server and is updated automatically when the server changes usually as the response of an AJAX event. The server can fire W3C DOM events and send them to the browser simulating user actions. These are received again by the server as in a normal AJAX app. As the test code is in the server too, can check the expected GUI changes (checking the server DOM tree) or the expected business behavior (added/removed/updated data). Requirement: Any supported platform by Java VM 1. 4 or upper ivalidator: Regression testing framework written in java but by no means restricted to java testing. Test suites are declared in XML. Especially designed for complex testing scenarios and integration testing. Requirement: JDK 1. 3 Jacobie: A Java API for use with Internet Explorer. Based on the JACOB project (Java to Com Bridge) and the IE COM Object, it directly controls IE from java. This API can be used as a true end-user web browser test with IE and not a Http-Based test such as HttpUnit. Requirement: All 32-bit MS Windows (95/98/NT/2000/XP) Jameleon: A plug-in driven automated testing tool that separates applications into features and allows those features to be tied together independently, creating test cases. Test cases can be data-driven and executed against different environments and test case docs are generated from the test cases. The goal is to create an automated testing tool that can be used for the enterprise. A UI that ties a series of features to a test case, generating both the test script and the test case documentation is in the works. Requirement: OS Independent, JDK 1. 4 or higher jDiffChaser: A GUI comparison tool that automates diffs detection between versions. You can record and play scenarios on two different releases of the same Swing application (in sequential or parallel mode); jDiffChaser compares both screens, shows you the differences and list them in a report with images highlighting the diffs. Requirement: Linux, OS X, WinXP JFunc: JUnit Functional Testing Extension: An extension to the JUnit testing framework to make it easier for use with functional tests. Functional testing (also called integration testing) significantly differs from unit testing in a number of respects. Part of this project is dedicated towards putting together code to address these differences; the other part of this project is putting together methodologies for functional testing. Requirement: JUnit jWebUnit: A Java framework that facilitates creation of acceptance tests for web applications. jWebUnit provides a high-level API for navigating a web application combined with a set of assertions to verify the application’s correctness. This includes navigation via links, form entry and submission, validation of table contents, and other typical business web application features. This code utilizes HttpUnit behind the scenes. The simple navigation methods and ready-to-use assertions allow for more rapid test creation than using only JUnit and HttpUnit. Requirement: OS Independent Linux Test Project: A collection of tools for testing the Linux kernel and related features. Our goal is to improve the Linux kernel by bringing test automation to the kernel testing effort. Requirement: Linux LogiTest: The core application in the LogiTest suite. The LogiTest application provides a simple graphical user interface for creating and playing back tests for testing Internet-based applications. Requirement:JDK 1. 2 or higher LReport: Command line tools for comparing csv files and databases (on the level of particular selects). The tools also support test documentation by nice formatting of selects’ results. Requirement: Tested on Win32 but should work on other platforms Mactor: An extensible tool for system integration testing. It can facilitate tests of any XML-based integration regardless of the type of message transfer protocol used (HTTP, SOAP, file-system and IBM MQ series are currently supplied with the tool) MaxQ: A free web functional testing tool. It includes an HTTP proxy that records your test script, and a command line utility that can be used to playback tests. The paradigm of MaxQ is similar to commercial web testing tools like Astra QuickTest or Empirix e-Test. These products are quite expensive. MaxQ hopes to provide the essential features: HTTP test recording, scripting, and playback without the huge cost. Requirement: Java 1. 2 or later Mockito: Java mocking is dominated by expect-run-verify libraries like EasyMock or jMock. Mockito offers simpler and more intuitive approach: you ask questions about interactions after execution. Using mockito, you can verify what you want. Using expect-run-verify libraries you are often forced to look after irrelevant interactions. Mockito has very slim API, almost no time is needed to start mocking. There is only one kind of mock, there is only one way of creating mocks. Just remember that stubbing goes before execution, verifications of interactions go afterwards. Requirement: Java MozUnit: Develop test-first style or just test against regressions: MozUnit provides framework, test runner, source browser, and API hooks for personalized reports. MozUnit is part of MozLab, a suite of tools and libraries for developers of AJAX and Mozilla applications, packaged as a Firefox extension. Requirement: Firefox OLVER – Open Linux VERification: A test suite for automated conformance and functional testing of various Linux distributions against LSB standard requirements on base system interfaces behavior. The tests are being developed at the Linux Verification Center of Russia. Requirement:Linux org. tigris. mbt: An implementation of Model-based testing built in Java. It allows you to generate test sequences from a finite-state machine (graph). The test sequences can be created statically, or run dynamically. Requirement: Any platform that runs Java 1. 4. 2 Ottomate: Suite of six Mac OS X Automator Actions that contains everything needed to graphically configure automated, repeatable user-acceptance tests for web-based applications. Requirement: Safari PAMIE: ‘Python Automated Module For Internet Explorer’ Allows control of an instance of MSIE and access to it’s methods though OLE automation . Utilizes Collections, Methods, Events and Properties exposed by the DHTML Object Mode Requirement:Windows NT/2000 Pounder: A utility for testing Java GUIs. It allows developers to dynamically load components, record scripts, and then use those scripts in JUnit. It supports custom components, drag and drop, and the examination of test runs in source. This project is no longer being actively developed. For similar tools under active development, the Pounder team recommend considering Abbot, Marathon, jfcunit and others. Requirement: OS Independent pywinauto: A python package that allows you to automate the windows GUI. Very easy to get started, and quite powerful. Requirement:Windows 2000, XP, + QAT (Quality Assurance Tests): Developed to ease the issues encountered by having to perform Quality Assurance tests across a variety of hardware and software combinations. The QAT tool can be divided into two main sections, the Agent, responsible for actually running each test or group of tests, and the Harness, which is responsible for test selection, management, result and agent co-ordination. Requirement:Java 2 QMTest: CodeSourcery’s QMTest provides a cost-effective general purpose testing solution that allows an organization to implement a robust, easy-to-use testing program tailored to its needs. QMTest’s extensible architecture allows it to handle a wide range of application domains: everything from compilers to graphical user interfaces to web-based applications. Requirement: QMTest works with most varieties of UNIX, including GNU/Linux, and with Microsoft Windows.  Rasta: A keyword-driven test framework using spreadsheets to drive testing. It’s loosely based on FIT, where data tables define parameters and expected results. The spreadsheet can then be parsed using your test fixtures. Requirement:Windows, Ruby Robot Framework: Robot Framework is a Python-based keyword-driven test automation framework for acceptance level testing and acceptance test-driven development (ATDD). It has an easy-to-use tabular syntax for creating test cases and its testing capabilities can be extended by test libraries implemented either with Python or Java. Users can also create new keywords from existing ones using the same simple syntax that is used for creating test cases.  Sahi: An automation and testing tool for web applications, with the facility to record and playback scripts. Developed in Java and JavaScript, it uses simple JavaScript to execute events on the browser. Features include in-browser controls, text based scripts, Ant support for playback of suites of tests, and multi-threaded playback. It supports HTTP and HTTPS. Sahi runs as a proxy server and the browser needs to use the Sahi server as its proxy. Sahi then injects JavaScript so that it can access elements in the webpage. This makes the tool independant of the website/ web application. Requirement:Needs Java 1. 4+ Samie: S. A. M. for I. E. is a Perl module (SAM. pm) that allows a user to run automated tests for their browser applications. Requirement: Windows NT/2000 Siege: http regression testing and benchmarking utility. It was designed to let web developers measure the performance of their code under duress, to see how it will stand up to load on the internet. Siege supports basic authentication, cookies, HTTP and HTTPS protocols. It allows the user hit a web server with a configurable number of concurrent simulated users. Those users place the webserver “under siege. ” Selenium: Testing tool for browser-based testing of web applications. It can be used both for functional, compatability (it has extensive cross-browser support) and regression testing Requirement: Windows, Linux or Mac Selenium Grid: An open source web functional testing tool that can transparently distribute your tests on multiple machines to enable running tests in parallel, cutting down the time required for running in-browser test suites. This enables speed-up of in-browser web testing. Selenium tests interact with a ‘Selenium Hub’ instead of Selenium Remote Control. The Hub allocates Selenium Remote Controls to each test. The Hub is also in charge of routing the Selenium requests from the tests to the appropriate Remote Control as well as keeping track of testing sessions. Requires Java 5+ JDK, Ant 1. 7. x SharpRobo: A Functional Testing and Recording tool for WinForm applications written in C#. It supports all the standard WinForm controls. SharpRobo records the tests in FIT format which can be played back using Fit (File or Directory Runner). Requirement:Windows NT/2000/XP SimpleTest: Unit testing framework which aims to be a complete PHP developer test solution. Includes all of the typical functions that would be expected from JUnit and the PHPUnit ports, but also adds mock objects; has some JWebUnit functionality as well. This includes web page navigation, cookie testing and form submission.  soapui: A java-swing based desktop application for inspecting, invoking and functional testing of webservices over HTTP. It is mainly aimed at developers/testers providing and/or consuming webservices (java, . net, etc). Functional testing can be done interactively in soapui or within a CI-process using the soapui maven plugin. Requirement: Java 1. 5 Software Automation Framework Support (SAFS): Provides for the implementation of compatible keyword-driven test automation frameworks. Currently, developing independent, multi-platform, Java-based Driver. Will be followed by independent, multi-platform Engines. Requirement: All 32-bit MS Windows (95/98/NT/2000/XP) Software Testing Automation Framework (STAF): An open source, multi-platform, multi-language framework designed around the idea of reusable components, called services (such as process invocation, resource management, logging, and monitoring). STAF removes the tedium of building an automation infrastructure, thus enabling you to focus on building your automation solution. STAX is an execution engine which can help you thoroughly automate the distribution, execution, and results analysis of your testcases. STAX builds on top of three existing technologies, STAF, XML, and Python, to place great automation power in the hands of testers. STAX also provides a powerful GUI monitoring application which allows you to interact with and monitor the progress of your jobs. Requirement:Windows, Linux, Solaris, AS/400, AIX, HP-UX, Irix Solex: This project is a set of Eclipse plugins providing non regression and stress tests of Web application servers. Test scripts are recorded from internet browser thanks to a built in web proxy. Requirement: Eclipse 2. 1 or above SWAT (Simple Web Automation Toolkit): A library written in C# designed to provide an interface to interact with several different web browsers. SWAT also includes components to integrate with Fitnesse allowing Q/A engineers to automate web application testing. Requirement: Windows (IE and FireFox) SWTBot: A functional testing tool for SWT and Eclipse applications. The focus of SWTBot is to provide a simple, readable and fast way to write tests. The API is simple which means that everyone on a team can use SWTBot to write functional tests. It is also very flexible when it comes to extensibility. Requirement: SWT/Eclipse Systin: Systin stands for System Testing in . Net and allows you to write system-level tests in a “domain language”. This is a port of the popular Systir program. Systin will allow for an abstraction of Test Case specification and Test Case automation execution. Requirement: . Net Windows tclwebtest: A tool for writing automated tests on web applications in tcl. It implements some basic html parsing functionality to provide comfortable commands for operations on the html elements (most importantly forms) of the result pages.  TextTest: An application-independent tool for text-based functional testing. This means running a batch-mode binary in lots of different ways, and using the text output produced as a means of controlling the behaviour of that application. Requirement: Most UNIX flavours + Windows XP (not Windows 9x) Tomato: (the Automation Tool Abstraction Project) An abstraction layer for automation engines. Its design allows automation scripts or tests to be written in one language, against one library, and remain portable across different architectures, OS platforms, and even widely different automation engines (e. g. HP Mercury Interactive WinRunner or the Linux Desktop Test Project). Requirement: Windows/Linux Toster – The Object-oriented Sofware Testing Environment: A system for sharing a set of tools that allow you to implement methods for object-oriented testing. Any method based on UML diagrams and on the software source code can easily be implemented as a TOSTER module. The environment itself makes a number of mechanisms available, such as information transfer from UML diagrams, mapping this information to source code, introducing modifications to the source code, launching the tested application, or presenting the results.  Watij: (pronounced wattage) stands for Web Application Testing in Java. Based on the simplicity of Watir and enhanced by the power of Java, Watij automates funtional testing of web applications through the real browser. There is a Google group at http://groups. google. com/group/watij Requirement:Windows WatiN: WatiN stands for Web Application Testing in dotNet. Inspired by Watir, WatiN enables web application testing, through Internet Explorer on a Windows platform, expressed in any . Net language. Requirement: Windows Watir: Watir (Web Application Testing in Ruby) is a functional testing tool for web applications. It supports tests executed at the web browser layer by driving a web browser and interacting with objects on a web page. It uses the Ruby scripting language. Requirement: Windows (currently only supports Internet Explorer) WebCorder: Free GUI web testing tool from Crimson Solutions, developed in VB. Designed for end users who are doing web based software testing, as a simple tool to record test scenarios, and play them back and generate log files. The user may also check for text or images on the screen or save screenshots.  Web Form Flooder: A Java console utility that will analyze a Web page, complete any forms present on the page with reasonable data, and submit the data. The utility will also crawl links within the site in order to identify and flood additional forms that may be present.  WebDriver: A developer focused tool for automated testing of webapps: WebDriver has a simple API designed to be easy to work with and can drive both real browsers, for testing javascript heavy applications, and a pure “in memory” solution for faster testing of simpler applications. Requirement: Any java-compatible platform WebInject: A free tool for automated testing of web applications and services. It can be used to test any individual system component with an HTTP interface, and as a test harness to create a suite of automated functional and regression tests. Requirement: Windows, OS Independent, Linux Webrat: Ruby-based utility to enable quick development of web app acceptance tests. Open source by Bryan Helmkamp. Leverages the DOM to run tests similarly to in-browser test tools like Watir or Selenium without the associated performance hit and browser dependency. Best for web apps that do NOT utilize Javascript; apps using Javascript in-browser tools may be more appropriate.  WebTst: AWeb development test infrastructure. It aims to simplify testing by implementing a capture engine: a Web proxy which records a tester’s actions using a real browser, and then replays them during testing. It comes with support for digital certificates, and a number of simple tests, such as cookie setting, pattern matching, response status, and many others. It features an extensible plug-in system. Requirement: POSIX, Linux WET: An opensource web automation testing tool which uses Watir as the library to drive web pages. You don’t have to download / install Watir separately or know anything about Watir. WET drives an IE Browser directly and so the automated testing done using WET is equivalent to how a user would drive the web pages. WET allows you to perform various checks as a part of the testing process by using Checkpoints. Requirement: Windows 98/ME/2000 SP3/XP SP2/Server 2003 Win32::IEAutomation: A Perl module which automates functional testing of web applications. It can be used to automate any complex web application including dynamic frames and popup windows. It is an object oriented module and all methods are like user actions on web browser. Requirement: Windows (only Internet Explorer is supported) XML Test Suite: Provides a powerful way to test web applications. Writing tests requires only a knowledge of HTML and XML. We want XmlTestSuite to be adopted by testers, business analysts, and web developers who don’t have a java background. Requirement: Windows 95/98/2000, Windows NT/2000, Linux, SunOS/Solaris"
    }, {
    "id": 162,
    "url": "localhost:4000/9-open-source-link-checking-tools/",
    "title": "9 Open Source Link Checking Tools",
    "body": "2016/12/02 - It is very important to make sure that there are no broken links on your site. A link may be active when your first added it but as the days, months, years go by the link may end up being broken. Below are some open source tools that can help you find those broken links. Bugkilla: Bugkilla will be a set of java tools for the functional test of J2EE Web Applications. Specification and execution of tests will be automated for web front end and business logic layer. DLC (Dead Link Check): It can generate an HTML output for easy checking of the results, and can process a link cache file to hasten multiple requests (links life is time stamp enforced). Written in Perl ht-Check: Outputs a simple report. It can retrieve information through HTTP/1. 1 and store them in a MySQL database. Most of the information is given by the PHP interface which comes with the package and that is able to query the database built by the htcheck program. Requirement: You need a Web server to use it, and PHP with the MySQL connectivity module. Jenu: A multithreaded, Java 1. 3 (swing) based Web site URL Link checker. It’s a copy of a nice multi-threaded link checker for the PC called Xenu. Requirement: Java 2 (1. 3) runtime. JSpider: A Web spider engine. It is a robot that will generate web traffic, just like you would do when you are browsing the internet. You can control and configure the robot’s behaviour to adapt it to your needs. LinkChecker: LinkChecker is a free, GPL licensed website validator. LinkChecker checks links in web documents or full websites. It runs on Python 2 systems, requiring Python 2. 7. 2 or later. Python 3 is not yet supported. Link Page Generator: Automatic link management program with -check option for marking/eliminating bad links (in cron job). Written in Perl. LinkVerify: Checks a set of hypertext files whether all references to external resources are valid. In HTML this applies mostly to hyperlinks and embedded images. Style sheets will be checked too. Requirement: Java 1. 1 is required Xenu’s Link Sleuth: checks Web sites for broken links. Link verification is done on “normal” links, images, frames, plug-ins, backgrounds, local image maps, style sheets, scripts and java applets. NOTE: This one is free but NOT Open Source "
    }, {
    "id": 163,
    "url": "localhost:4000/3-main-types-of-software-testing/",
    "title": "3 Main Types of Software Testing",
    "body": "2016/12/01 - Main Types of Software Testing: Software test cases are software codes that are executed based on the input provided by the clients. Once the required output is got, the module is said to be compliant with client requirements. Software developers follow three main types of testing – the black box testing, grey box and white box testing. Black Box Testing: 1. Here the user is not aware of the internal implementation of the testing software. 2. Some of the commonly used testing methods are equivalence partitioning, boundary value analysis, all-pairs testing, fuzz testing, model-based testing, etc. 3. It is common for black box testers to find bugs that were not traced during program execution. 4. The primary disadvantage with this testing is that the tester will not be aware even if some part of the code has not been tested. White Box Testing: On the other hand, in white box testing the tester is aware of the algorithm of the test software and is able to structure the test cases accordingly. The most commonly used testing methods here are static testing, API or Application Programming Interface testing, mutation testing methods etc. With this testing the tester can be assured of completely testing the module or code which is of prime importance. Grey Box Testing: In grey box testing methodology, the tester has access to internal data structures and algorithms to for purposes of designing test cases, the testing as such is done similar to black box testing. Grey box testing is commonly used by testers in case of integration testing, which is conducted to test the joint output of two modules. Today there are many test automation tools available in the market to carry out such kinds of software tests. There is also a growing trend in software development to use testing platforms that allow users to execute the test cases by scheduling the test case execution. Today test automation tools are also available as a SaaS service, making it simpler to deal with test execution, test metrics and test documentation. "
    }, {
    "id": 164,
    "url": "localhost:4000/why-do-we-test-what-is-the-purpose-of-software-testing/",
    "title": "Why do we Test? What is the Purpose of Software Testing?",
    "body": "2016/11/30 - Why We Test Software?: To answer the above question(s), let us look at the nature of software testing. The software testing group is a service provider. Software testers provide valuable information and insights into the state of the system. This information contributes towards reducing the ambiguity about the system. For example, when deciding whether to release a product, the decision makers would need to know the state of the product including aspects such as the conformance of the product to requirements, the usability of the product, any known risks, the product’s compliance to any applicable regulations, etc. Software testing enables making objective assessments regarding the degree of conformance of the system to stated requirements and specifications. Testing verifies that the system meets the different requirements including, functional, performance, reliability, security, usability and so on. This verification is done to ensure that we are building the system right. In addition, testing validates that the system being developed is what the user needs. In essence, validation is performed to ensure that we are building the right system. Apart from helping make decisions, the information from software testing helps with risk management. Software testing contributes to improving the quality of the product. You would notice that we have not mentioned anything about defects/bugs up until now. While finding defects / bugs is one of the purposes of software testing, it is not the sole purpose. It is important for software testing to verify and validate that the product meets the stated requirements / specifications. Quality improvements help the organization to reduce post release costs of support and service, while generating customer good will that could translate into greater revenue opportunities. Also, in situations where products need to ensure compliance with regulatory requirements, software testing can safeguard the organization from legal liabilities by verifying compliance. "
    }, {
    "id": 165,
    "url": "localhost:4000/how-to-start-selenium-server-with-java-code/",
    "title": "How to Start Selenium Server with Java Code",
    "body": "2016/11/29 - When test automating a web application using Selenium, we have to start the Selenium server first, so that a new Selenium session is created to talk to the web browser. This can be either done manually, i. e. user running a command line to start the Selenium server, or to get the pure automation effect of Selenium, it is best to start the Selenium server via a program code. The code below is written in Java and starts the Selenium server when called. Normally this would be the first action within your main() function. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com. company;import org. openqa. selenium. server. RemoteControlConfiguration;import org. openqa. selenium. server. SeleniumServer;import com. thoughtworks. selenium. Selenium;import java. net. BindException;import java. net. ServerSocket;public class Server {  public static SeleniumServer server;  public static void startSeleniumServer() throws Exception {    try {      ServerSocket serverSocket = new ServerSocket(RemoteControlConfiguration. DEFAULT_PORT);      serverSocket. close();//Server not up, start it      try {        RemoteControlConfiguration rcc = new RemoteControlConfiguration();        rcc. setPort(RemoteControlConfiguration. DEFAULT_PORT);        server = new SeleniumServer(false, rcc);      } catch (Exception e) {        System. err. println( Could not create Selenium Server because of:              + e. getMessage());        e. printStackTrace();      }      try {        server. start();        System. out. println( Server started );      } catch (Exception e) {        System. err. println( Could not start Selenium Server because of:              + e. getMessage());        e. printStackTrace();      }    } catch (BindException e) {      System. out. println( Selenium server already up, will reuse. . .  );    }  }  public static void stopSeleniumServer(Selenium selenium){    selenium. stop();    if (server != null)    {      try      {        selenium. shutDownSeleniumServer();        server. stop();        server = null;      }      catch (Exception e)      {        e. printStackTrace();      }    }  }}Another very simple and easy way to start selenium server inside the program, and if you are not bothered about setting specific port, just call these few lines in your program (before starting selenium session): 1234SeleniumServer _server = new SeleniumServer();_server. boot();_server. start();_server. stop();"
    }, {
    "id": 166,
    "url": "localhost:4000/severity-and-priority-difference/",
    "title": "Severity and Priority - What is the Difference?",
    "body": "2016/11/28 - Severity and Priority: [caption id=”attachment_10100” align=”aligncenter” width=”467”] severity-vs-priority-testing[/caption] Both Severity and Priority are attributes of a defect and should be provided in the bug report. This information is used to determine how quickly a bug should be fixed. Severity of a defect is related to how severe a bug is. Usually the severity is defined in terms of financial loss, damage to environment, company’s reputation and loss of life. Priority of a defect is related to how quickly a bug should be fixed and deployed to live servers. When a defect is of high severity, most likely it will also have a high priority. Likewise, a low severity defect will normally have a low priority as well. Although it is recommended to provide both Severity and Priority when submitting a defect report, many companies will use just one, normally priority. In the bug report, Severity and Priority are normally filled in by the person writing the bug report, but should be reviewed by the whole team. High Severity - High Priority bug: This is when major path through the application is broken, for example, on an eCommerce website, every customers get error message on the booking form and cannot place orders, or the product page throws a Error 500 response. High Severity - Low Priority bug: This happens when the bug causes major problems, but it only happens in very rare conditions or situations, for example, customers who use very old browsers cannot continue with their purchase of a product. Because the number of customers with very old browsers is very low, it is not a high priority to fix the issue. High Priority - Low Severity bug: This could happen when, for example, the logo or name of the company is not displayed on the website. It is important to fix the issue as soon as possible, although it may not cause a lot of damage. Low Priority - Low Severity bug: For cases where the bug doesn’t cause disaster and only affects very small number of customers, both Severity and Priority are assigned low, for example, the privacy policy page take a long time to load. Not many people view the privacy policy page and slow loading doesn’t affect the customers much. The above are just examples. It is the team who should decide the Severity and Priority for each bug. More information on Software Defects "
    }, {
    "id": 167,
    "url": "localhost:4000/how-to-download-and-save-images-with-selenium-rc/",
    "title": "How to Download and Save Images with Selenium RC",
    "body": "2016/11/27 - In this tutorial we will take a look at how we can download and save images from a website using Selenium RC and Java. If you want to know how to upload files and images to remote server, then please read How to Upload and Submit Files Using Selenium While Selenium is an excellent tool to run automated tests, it can also be used for information gathering from other websites and to download available materials. Normally when you want to download an image from a website, you right click on the image and from the context menu choose the ‘Save As’ option. With Selenium the right click functionality is a bit difficult to implement. The trick is to get Selenium to read the location of the image and then open another browser pointing to the full URL path of the image and then get Selenium to save the image by using the CTRL+S keys combination. Please note, this will only work in FireFox and Google Chrome browsers. Internet Explorer does not call the ‘Save As’ dialog box by the CTRL+S keys combination. Once the ‘Save As’ dialog box is opened, a simple AutoIt script can be called to deal with the dialog. This simple script contains 2 lines: 123WinWaitActive( Save As )Send( {ENTER} ) //this will just hit the enter key_please read documentation on AutoIt website to learn how to save the scripts as an executable file. _Sine the default selected button on the ‘Save As’ dialog box is ‘Save’ then we only need to “hit” the Enter key and the above AutoIt script sending an ‘ENTER’ command will hit the Enter key on the ‘Save’ button. Once we have the executable of the above AutoIt script we can call it within the Java program. In the below program, I have assumed that the selenium server is already running. If you want to see how to start selenium server in Java, then read How to Start Selenium Server With Java Code/ 12345678910111213141516171819202122232425262728import java. awt. Robot;import java. awt. event. KeyEvent;import com. thoughtworks. selenium. DefaultSelenium;import com. thoughtworks. selenium. Selenium;public class DownloadImage {  public void getImage() throws Exception{   String[] commands = new String[]{};   String AutoItScriptpath =  c:testsaveImage. exe ;   commands = new String[]{AutoItScriptpath };   Runtime. getRuntime(). exec(commands);   selenium = new DefaultSelenium( localhost , 4444,    googlechrome ,  http://www. testingexcellence. com );   selenium. start();   selenium. open( /images/logo. jpg );   selenium. windowMaximize();   //native key strokes for CTRL and S keys   Robot robot = new Robot();   robot. keyPress(KeyEvent. VK_CONTROL);   robot. keyPress(KeyEvent. VK_S);   robot. keyRelease(KeyEvent. VK_S);   robot. keyRelease(KeyEvent. VK_CONTROL);   //once the dialog box is displayed, the autoIt script   //will fire off and send an Enter command.  }}The location of the download is usually the default folder that is used by the browser. Of course you can modify the AutoIt script to first type the desired location for the file to be saved before sending the Enter command. "
    }, {
    "id": 168,
    "url": "localhost:4000/10-best-open-source-web-testing-tool/",
    "title": "10 Best Open Source Web Testing Tool",
    "body": "2016/11/26 -  JMeter - Load and Performance testerJMeter is a pure Java desktop application designed to load test functional behavior and measure performance. It may be used to test performance both on static and dynamic resources (files, Servlets, Perl scripts, Java Objects, Data Bases and Queries, FTP Servers and more). It can be used to simulate a heavy load on a server, network or object to test its strength or to analyze overall performance under different load types. Grinder - Java Load Testing FrameworkThe Grinder is a Java load testing framework that makes it easy to run a distributed test using many load injector machines. Load test anything that has a Java API. This includes common cases such as HTTP web servers, SOAP and REST web services, and application servers (CORBA, RMI, JMS, EJBs), as well as custom protocols. Multi-Mechanize - web performance and load testing frameworkMulti-Mechanize is an framework for web performance and load testing. It allows you to run simultaneous python scripts to generate load (synthetic transactions) against a web site or web service. You programmatically create test scripts to simulate virtual user activity. Your scripts will then generate HTTP requests to intelligently navigate a web site or send requests to a web service. Selenium - Web app testing toolSelenium is a suite of tools such as Selenium IDE, Selenium Remote Control and Selenium Grid to test the web application. Selenium IDE is an integrated development environment for Selenium scripts. It is implemented as a Firefox extension, and allows you to record, edit, and debug tests. It supports record and playback. Capybara - Acceptance test framework for web applicationsCapybara aims to simplify the process of integration testing Rack applications such as Rails, Sinatra or Merb. Capybara simulates how a real user would interact with a web application. It is agnostic about the driver running your tests and currently comes with Rack::Test and Selenium support built in. HtmlUnit and env. js are supported through external gems. OpenSTA - Open Systems Testing ArchitectureOpenSTA is a distributed software testing architecture designed around CORBA. The current toolset has the capability of performing scripted HTTP and HTTPS heavy load tests with performance measurements from Win32 platforms. Results and statistics are collected during test runs by a variety of automatic and user controlled mechanisms. These can include scripted timers, SNMP data, Windows Performance Monitor stats and HTTP results &amp; timings. Pylot - Performance &amp; Scalability Testing of Web ServicesPylot is a free open source tool for testing performance and scalability of web services. It runs HTTP load tests, which are useful for capacity planning, benchmarking, analysis, and system tuning. Pylot generates concurrent load (HTTP Requests), verifies server responses, and produces reports with metrics. Tests suites are executed and monitored from a GUI or shell/console. It supports HTTP and HTTPS. It is multi-threaded and generates real time stats. Response is verified with regular expressions. GUI and Console mode support available. WebLoad - The best LoadRunner AlternativeThe WebLOAD Open Source Load Generation Engine is an open source project sponsored by RadView Software. This project is intended for ISVs, SIs and software developers who need to integrate a professional load generation engine into their applications. Webrat - Ruby Acceptance Testing for Web applicationsWebrat helps to write expressive and robust acceptance tests for a Ruby web application. It supports multiple Ruby web frameworks like Rails, Merb and Sinatra. It also supports popular test frameworks like RSpec, Cucumber, Test::Unit and Shoulda. Windmill - Web Testing ToolWindmill is a web testing tool designed to automate and debug your web application. It provides cross-browser test recorder. It has built-in shell to interact with WIndmill server. Write and run tests from Python, Ruby and Javascript. "
    }, {
    "id": 169,
    "url": "localhost:4000/how-to-capture-screenshots-using-webdriver-in-java/",
    "title": "How to Capture Screenshots Using WebDriver in Java",
    "body": "2016/11/25 - Selenium 2 (or WebDriver) has come up with some great new functionality that makes website testing much easier. This is because of the webdriver architecture allows interaction outside of javascript sandbox. One of the new useful functionality is being able to take screenshots from WebDriver. You can take screenshots at any stage of the test, but mostly, it is used for when a test fails and taking screenshots helps the analysis so we can see what went wrong during a test failure. To take a screenshot in WebDriver, you would use the following code 12345678910111213141516171819202122232425262728293031323334File scrFile = ((TakesScreenshot)driver). getScreenshotAs(OutputType. FILE);import org. openqa. selenium. WebDriver;import org. openqa. selenium. firefox. FirefoxDriver;import org. openqa. selenium. By;import org. openqa. selenium. OutputType;import org. openqa. selenium. TakesScreenshot;import java. io. File;import org. apache. commons. io. FileUtils;import org. testng. annotations. Test;         public class webDriverTakeScreenshot {  public WebDriver driver;                 @Test  public void runDummyTest() throws Exception {    driver = new FirefoxDriver();    driver. get( http://www. testingexcellence. com );    try {      driver. findElement(By. id( dummyId )). click();    }    catch(Exception e) {      System. out. println( Element Not Found );      takeScreenshot();    }  }  public void takeScreenshot() throws Exception {    File scrFile = ((TakesScreenshot)driver). getScreenshotAs(OutputType. FILE);    FileUtils. copyFile(scrFile, new File( C:\testresults\failed-test. png ));  }}"
    }, {
    "id": 170,
    "url": "localhost:4000/agile-test-plan-do-we-really-need-one/",
    "title": "Agile Test Plan - Do We Really Need One?",
    "body": "2016/11/24 - Agile Test Plan Document: Do we need an Agile Test Plan Document? Test Planning is an important activity of a testing process and one that requires careful thoughts and decisions from not just the test manager (who is usually responsible for creating the test plan) but all members of the testing team and product development manager. Some people believe that it is the most important part of the testing process (I personally think test designing and abstract thinking is the most important) and spend many hours and effort coming up with a great test plan. Text books dedicate a whole section related to test planning, how to write one and what to include in a test plan while some governing bodies and regulatory organizations such as FDA require a comprehensive test plan in order to approve a product. In the real world, in a waterfall environment, quite often the test plan document is one that is hardly ever looked at during the life-cycle of the product. The activity of “Test Planning and Monitoring” should be an ongoing activity during the project life-cycle, it should be updated as per changes to the project, but in most cases this is not the case; test plan is either not updated or changes are retrospective, making the test plan document the least valuable by-product. Whilst test planning is almost always considered as a must-have product in a waterfall project, do we really need a test plan for an agile project? i. e. does it really add any value to what the whole team is trying to achieve? The agile manifesto clearly favours working software over comprehensive documentation and responding to change over following a plan. In an agile environment, the contents of a release (the items) are discussed before the sprint so the testing team know in advance what is the scope and what should be tested. In the “planning poker game” the estimates are discussed through so the testing team know how long it will take to test a feature (this is inclusive of environment setup, scenarios, automation, exploratory, performance, etc). In “story writing session” where details of each feature is thought through, the test team are already beginning to write scenarios to cover the many ways stories can be tested - this is the most valuable activity of the team. During the sprint, QA are continuously testing new code/feature. Test planning becomes a dynamic activity as the priorities for the day change. Testing is based on what is the activity for the day and the outcome of the day before. It is clearly evident that test plan doesn’t reveal defects but test scenarios will. The effort needs to be shifted on creating better scenarios than creating a test plan. What is really needed is a short agile test strategy document outlining the processes applicable across sprints, i. e. sections about Sprint Planning, Specifications Workshops, Manual QA, Automation, Test Coverage, Test Reporting, Test Environments, Staging, etc… These are processes and activities applicable to every sprint but of course derived by the company’s vision. So, with all this in mind, is the Test Plan document or extensive Test Strategies really a thing of the past? Do we really need an Agile Test Plan? "
    }, {
    "id": 171,
    "url": "localhost:4000/when-should-stories-be-automated/",
    "title": "When to Automate User Stories",
    "body": "2016/11/23 - If you have worked in an agile environment as a QA role, most probably you would have come across some sort of test automation. I don’t mean unit test automation which is typically a developer centric activity, but functional acceptance test automation which is normally done by QA or the new fancy role of Software Developer in Test. First, lets take a look at some criteria and reasons for having test automation which should answer the question of “Why Tests Should/Should Not be Automated” Repeatability:the automated tests should be repeatable and the output should be consistent in each run so that developers can rely on the outcome of the tests. This also means that we would not normally automate a test if it’s going to be run only once; the only exception to this is if you are running a test against a very large number of data, such as checking a link redirection script with many links. Reliability:the automated tests should really be checking verifications correctly and be able to determine actual results against valid expected results. This also means that if the results cannot be determined easily or automated tests are subject to environment issues which can cause false positives in the test results, then the tests cannot be reliable. Time:the automated tests should also save us time. If a simple test takes 10 minutes to complete but the same result can be determined in 1 minute manually, then it is best to not automate such tests. Safety net:the automated tests should provide a safety net for developers so that any deviation from a good working code, as a result of changes to the code base, is quickly highlighted and reported to the developers. When Should Stories be Automated?In a typical sprint, say there are 7 stories that are committed to a sprint out of which 5 are good candidates to be automated based on the above criteria. But when is the best time to automate these stories? Should we write the automated tests as the features are being developed? Should we wait till a feature is developed and then write the automated tests? Shall we wait till the end of the sprint and then automate the stories? In some cases when stories are bug fixes or slight modification or enhancement to an existing feature, then it makes all the sense to write the automated tests as the feature is being modified by developers. There may even be an existing automated test for the feature being modified in which you just need to tweak the script to accommodate the new changes. In other cases, when the story is about implementing a new feature to the application, how do we know what the end product will look like to be able to write tests in advance? Here, I’m not talking about feature files which describe the acceptance tests in advance, but the actual fixtures or selenium tests (the implementation of tests) that run against the delivered code. The bottom line is - any test which is going to be done more than once should be automated. And which tests are we going to execute more than once? Regression Tests. And what are regression tests? Tests that determine whether the application has regressed in functionality as a result of the new modifications and features. But, you can only write good automated regression tests against a system which is stable, well understood and deterministic in terms of behaviour with known inputs and outputs. The problem with trying to write automated tests against a feature as it is being developed is you could potentially spend a long time and a lot of effort writing automated scripts against something which is volatile and subject to constant change during the sprint. Moreover, how many times have we seen a story being committed to a sprint and then later being pulled out of sprint? Then we have wasted time scripting something which didn’t make it into the system. Some organizations even impose a strict rule that a story is not “done” until it is fully automated! Are we going to stop an important feature to be released because the QA didn’t or couldn’t provide automation in time due to various reasons? Or a story is not “done” because we don’t have an automated script to check the existence of a button on a page. Seriously? The best purpose of automation testing is regression testing and regression tests are always run against a known state and deterministic system to be able to detect changes in the baseline, and to get a meaningful result from an automated test, is only when the test has run and passed manually at least once, so you can compare the results of the automated run against the manual execution. By this definition, the stories should be automated (the implementation) within sprint and only when the feature is fully verified manually. Once the story is complete and it is verified manually first, then it is a reliable feature and a stable system which you can then design and write automate tests against. Once the automated test is implemented, it is then added to the regression test suite to monitor and detect regression defects as next features are being developed. "
    }, {
    "id": 172,
    "url": "localhost:4000/how-to-capture-network-traffic-and-http-requests-from-webdriver/",
    "title": "How to Capture Network Traffic and Http Requests From WebDriver",
    "body": "2016/11/22 - Selenium 1 has a built-in mechanism to record network traffic and http requests by setting the selenium. start(“captureNetworkTraffic=true”); Unfortunately, this solution is not available “out of the box” in Selenium 2 or WebDriver. You can capture network traffic using a proxy, such as the BrowserMob Proxy (http://proxy. browsermob. com) To configure the use of the proxy with a webdriver instance, set the CapabilityName. PROXY value to a org. openqa. selenium. Proxy instance: 12345678910public void proxy {    Proxy proxy = new Proxy();    // The URL here is the URL that the browsermob proxy is using    proxy. setHttpProxy( localhost:9100 );    DesiredCapabilities capabilities = DesiredCapabilities. firefox();    capabilities. setCapability(CapabilityType. PROXY, proxy);    WebDriver driver = new FirefoxDriver(capabilities);  }Once the test is finished, you can extract the data from the browsermob proxy using the mechanisms it provides. Note: “new Proxy()” - Needs org. openqa. selenium. Proxy "
    }, {
    "id": 173,
    "url": "localhost:4000/reasons-automated-tests-fail-to-find-regression-bugs/",
    "title": "5 Reasons Why Automated Tests Fail to Find Regression Bugs",
    "body": "2016/11/21 - It is widely believed that the purpose of automated tests is not to find new defects but rather find regression bugs as new features are developed. But even so, there are many occasions where regression bugs slip through that end up in production and really should have been caught by the automated regression tests. Let’s examine the reasons why automated tests failed to find the regression bugs: 1 - The Scenario Was Not Though OfAutomated Tests are as good as the person who designed the tests. Automated Tests are a set of instructions that are executed against the target application. First, test analysts design test cases and come up with a list of scenarios. The scenarios are then scripted in a programming language to execute the scenarios automatically. Therefore, if a particular scenario was not thought of, it wouldn’t have been scripted to run as automated test. 2 - The Scenario Was Thought Of But Was Not ScriptedIt takes time to automate tests. Depending on the complexity of the tests, test engineers coding skills, flexibility of test automation tools and frameworks, some tests take a long time to automate and hence miss the chance to find regression bugs as new features are developed. 3 - There is a Bug in the Test Code ItselfThere are situations where the automated tests do not really run against the tester’s intentions or assumptions. In other words the automation engineers made a mistake in coding the tests or did not insert verification points in correct places. 4 - The Automated Tests Couldn’t Execute due to Environment IssuesThis is particularly true when running System Tests via application UI, e. g. launching the application in browser. In such cases there are many dependencies on other applications, 3rd party or downstream systems, and if any of these are down or not responding or respond intermittently, the automated tests could not execute successfully and hence could not verify correctness of a particular test. 5 - Poor Analysis of Test ReportsAfter automated tests have executed, when there are failed tests, analysis is required to see the reason for the failed cases. This can take quite some time to analyze all the failed cases (many of which can be false positive). The analysis part is normally done manually and if the analysis is not done correctly, there could be genuine failures that are overlooked or masked by other issues. Can you think of other issues why automated tests miss defects? "
    }, {
    "id": 174,
    "url": "localhost:4000/acceptance-testing-agile/",
    "title": "What is Acceptance Testing in Agile",
    "body": "2016/11/20 - Acceptance testing: is a term used in agile methodologies, such as Extreme Programming, referring to the functional testing of a user story by the software development team during the implementation phase. The customer specifies acceptance criteria for a given story to be implemented. A story can have a number of acceptance criteria. QA then create acceptance tests or scenarios based on the acceptance criteria (each test criteria can have multiple acceptance tests), to ensure sufficient test coverage. As you can appreciate, this is a very important activity, because at the end of the day, it’s the scenarios that find the defects. Acceptance tests are black-box system tests. Each acceptance test represents some expected result from the system. Customers are responsible for verifying the correctness of the acceptance tests and reviewing test scores to decide which failed tests are of highest priority. Acceptance tests are also used as regression tests prior to a production release. A user story is not considered complete until it has passed its acceptance tests. This means that new acceptance tests must be created for each iteration or the development team will report zero progress. Quality assurance (QA) is an essential part of the XP process as well as agile method. On some projects QA is done by a separate group, while on others QA will be an integrated into the development team. The acceptance phase may also act as the final quality gateway, where any quality defects not previously detected may be uncovered. A principal purpose of acceptance testing is that, once completed successfully, and provided certain additional (contractually agreed) acceptance criteria are met. Acceptance testing occurs much earlier and more frequently in an agile methods with respect to traditional approach. You may also be interested in reading the difference between Acceptance Tests and Acceptance Criteria. "
    }, {
    "id": 175,
    "url": "localhost:4000/agile-testing-process-overview/",
    "title": "What is Acceptance Testing in Agile",
    "body": "2016/11/19 - AGILE is a methodology that enables continuous iteration of development and testing throughout the software development life cycle of the project. Iteration is defined as a small release of software. Agile Testing starts at the beginning of the project with rapid integration between development and testing. We can define the term “Agile” as “moving quickly and easily”. In agile testing, the testers are closely working with the development team and testing is done in parallel as and when a piece of code has been developed. Daily team meetings and discussions is an essential part of agile projects. It helps to find out the issues in advance and work on those accordingly. Management can be aware of the gaps in requirements or technology with the help of quick development and testing. Then it is possible to find out the workaround for the problem. Read the full article… "
    }, {
    "id": 176,
    "url": "localhost:4000/click-link-href-value-webdriver/",
    "title": "How to Click a Link by href value in WebDriver",
    "body": "2016/11/18 - In Selenium WebDriver, there are a number of ways we can interact with web elements, such as by element’s ID, XPath, CSS, etc… We can also click links by linkText or partialLinkText. These methods are good if we know the expected text between the tags. However when we do localization or internationalization testing, the text is translated accordingly and we are no longer able to use linkText or partialLinkText, especially if the anchor tags don’t contain any ID or class. Suppose we want to click a link which points to profile. html, e. g. 1&lt;a href= http://www. abc. com/account/profile. html &gt;View Profile&lt;/a&gt;As mentioned earlier, we can use 1driver. findElement(By. linkText( View Profile )). click()and that will work, as long as we are on a page with English language. When we change the language to German, for example, our link now displays 1&lt;a href= http://www. abc. com/account/profile. html &gt;Profil ansehen&lt;/a&gt;Now, the line 1driver. findElement(By. linkText( View Profile )). click()would fail because there is no link on the profile page with that text. One way to overcome this is to click a link by its href value, because even when the language of the site changes the href link should still point to the same location. In other words, internationalization shouldn’t impact the href of the links. WebDriver doesn’t have a standalone and direct way of clicking a link by its href value. Instead, we need to get all the links in the page, extract the href attribute and then compare the href values with what we expect. https://www. testingexcellence. com/webdriver-explicit-implicit-fluent-wait/ Click Link By href: Suppose we have the following links and we want to click on the profile link 12345678910111213141516&lt;a href= http://abc. com/account/profile. html &gt;View Profile&lt;/a&gt;&lt;a href= http://abc. com/account/transactions. html &gt;Transactions&lt;/a&gt;public void clickLinkByHref(String href) {    List&lt;WebElement&gt; anchors = driver. findElements(By. tagName( a );    Iterator&lt;WebElement&gt; i = anchors. iterator();    while(i. hasNext()) {      WebElement anchor = i. next();      if(anchor. getAttribute( href ). contains(href)) {        anchor. click();        break;      }    }  }Then we can use clickLinkByHref( Profile ) and then the above function will get all the links on the page and iterate through them and when it finds a link which contains profile, WebDriver will click the link. Note, if we have several links with the word profile in them, the above function will always click the first link containing the word profile. We can modify the above code to include which of the links we want to click: 12345678910111213141516171819public void clickLinkByHref(String href, int position) {    List&lt;WebElement&gt; anchors = driver. findElements(By. tagName( a );    Iterator&lt;WebElement&gt; i = anchors. iterator();    int j = 0;    while(i. hasNext()) {      WebElement anchor = i. next();      if(anchor. getAttribute( href ). contains(href)) {        j++;      }      if(anchor. getAttribute( href ). contains(href)          &amp;&amp; j == position) {        anchor. click();        break;      }    }  }"
    }, {
    "id": 177,
    "url": "localhost:4000/webdriver-wait-for-ajax-complete/",
    "title": "WebDriver Wait for AJAX Call to Complete",
    "body": "2016/11/17 - How to wait for an AJAX call to complete in WebDriver: Many web applications built on Web 2. 0 technology, contain AJAX calls. AJAX calls don’t refresh the whole page, only a certain part of a page is refreshed. When an AJAX call is made, while the page is waiting for a response from the server, a waiting icon appears on the page to inform the user, the page is waiting for information, this could be either a rotating circle, or a loading horizontal bar, etc… WebDriver is clever enough to wait for the whole page to load before doing any action and without the user having to specify a wait for page to load. However, in case of AJAX calls, because the whole page is not refreshed, WebDriver has no way of knowing something is happening. In normal cases, the waiting icon has a css style attribute such as 1&lt;div class= rotating-icon ; style= display: none &gt;&lt;/div&gt;for when the AJAX call is not started or already completed, and 1&lt;div class= rotating-icon ; style= display: block &gt;&lt;/div&gt;when the section is waiting for response from the server. When the display is block the user sees the waiting icon on the page. The css attribute changes dynamically when the user sends a request and when the request-response is completed. Luckily in WebDriver we can get the value of a tag attribute and check against an expected value. e. g. 1driver. findElement(By. cssSelector( . rotating-icon )). getAttribute();This would either output “block” or “none” depending on the state of the request. Before we can verify an automated check, we have to wait for the AJAX call to complete, therefore we need to have a waiting mechanism to check when the css attribute of a web element changes, before we start our verifications, otherwise the checks would fail. The code snippets below shows how to Wait while the element contains a certain attribute value 123456789101112131415public void waitWhileElementHasAttributeValue(String locator,                         String attribute, String value) {    while(driver. findElement(LocatorStrategy. getLocatorMethod(locator)). getAttribute(attribute). contains(value)) {      int timeout = 10;      if(timeout &gt; 0) {        timeout--;        try {          System. out. println(attribute +  t  + value);          Thread. sleep(1000);        } catch(Exception e) {        }      }    }  }The above function will wait while the element contains the attribute value. It checks the page every second and once the value of the attribute changes, it breaks out of the while loop or throws an exception if it times out, in this case 10 seconds. The LocatorStrategy class is a custom class that determines the By type of an element when we send the locator as string: 1234567891011121314151617181920212223242526public final class LocatorStrategy {  public static By getLocatorMethod(String locatorMethod) {    String locator = locatorMethod. split( = )[1];    if (locatorMethod. startsWith( id )) {      return By. id(locator);    } else if (locatorMethod. startsWith( name )) {      return By. name(locator);    } else if (locatorMethod. startsWith( css )) {      return By. cssSelector(locator);    } else if (locatorMethod. startsWith( xpath )) {      return By. xpath(locator);    } else if (locatorMethod. startsWith( class )) {      return By. className(locator);    } else if (locatorMethod. startsWith( linkText )) {      return By. linkText(locator);    } else if (locatorMethod. startsWith( partialLinkText )) {      return By. partialLinkText(locator);    } else if (locatorMethod. startsWith( tagName )) {      return By. tagName(locator);    } else {      return null;    }  }}When we send an AJAX request, the attribute value of style changes from “none” to “block”, therefore we have to wait while the element contains the attribute value “block” and then continue with our verification. Using the above methods, we can simply call 1waitWhileElementHasAttributeValue( css=div. rotating-icon ,  style ,  block )"
    }, {
    "id": 178,
    "url": "localhost:4000/test-automation-tips-best-practices/",
    "title": "Test Automation Tips and Best Practices",
    "body": "2016/11/16 - Top Tips for Test Automation: Automated Testing is an important testing activity during the software development lifecycle because it can provide quick feedback to the team when a new feature has been developed. It also removes the burden from QA to repeatedly run regression tests which saves time for QA to focus on other testing activities. Test Automation, when done right, can be very beneficial to the team. The tips below will help you get the most value from your automated testing process and activity and highlights pitfalls to avoid when starting to automate your tests. Manual vs Automated - Testing vs Checking: Avoid comparison between manual and automated testing. They are both needed as each serves a different purpose. Automated tests are a set of instructions written by a person to do a specific task. Every time an automated test is run, it will follow exactly the same steps as instructed and only check for things that are being asked to check. On the other hand, during manual testing, tester’s brain is engaged and can spot other failures in the system. The test steps may not necessarily be the same every time, as the tester can alter the flows during the testing; this is especially true in case of exploratory testing. Automate Regression Tests: The main reason you want to automate a test is that you want to execute the test repeatedly on every new release. If the test is required to be executed only once, then the effort to automate the test can outweigh the benefits. Regression tests are required to be executed repeatedly as the software under test evolves. This can be very time consuming and a boring task for QA to have to run regression tests every day. Regression tests are good candidates for test automation. Design Tests Before Automating Them: It is always a good practice to create the test cases and scenarios before starting to automate the tests. It is the good test design that can help in identifying defects, automated tests only execute the test design. The danger in jumping straight to automation is that you’re only interested in making the script to work and usually only automate positive and happy flow scenarios rather than thinking about the other possible scenarios that can be tested. Also, don’t reduce the scope of testing just to make the test work or pass. Remove Uncertainty from Automated Tests: One of the key points of automated testing is the ability to give consistent results so that we can be certain that something has actually gone wrong when a test fails. If an automated test passes in one run and fails in the next run, without any changes on the software under test, we cannot be certain if the failure is due to the application or due to other factors, such as test environment issues or problems in the test code itself. When there are failures, we have to analyze the results to see what had gone wrong, and when we have lots of inconsistent or false positive results, it increases analysis time. Don’t be afraid to remove unstable tests from regression packs; instead, aim for consistent clean results that you can rely on. Review Automated Tests for Validity: You will be alarmed by the sheer number of automated tests that are outdated, just don’t check for anything or are not checking the most important verifications! This could be a symptom of jumping straight to automation without spending enough time beforehand planning on what needs to be done and designing good test scenarios. Always have a colleague to review the automated tests for validity and sanity. Make sure tests are up to date. Don’t Automate Unstable Functionality: As a new feature or functionality is being developed, many things can go wrong and even the feature may no longer be applicable because the business have changed their mind. If you started automating tests as the feature was being developed, the tests need to be updated many times as the feature evolves and can be quite daunting trying to keep up with all the changes. And if the feature is no longer applicable, all that effort on test automation is wasted. Therefore, it is always best to automate a feature once it has been stabilized and less subject to change. Don’t Expect Magic From Test Automation: The primary reason for test automation is to free up QA time for interesting exploratory testing and to give confidence to the team that the application is still in good order as new changes are delivered. Don’t expect automation to find lots of bugs. In fact, the number of bugs found by automation is always much less than manual and exploratory testing. Don’t Rely Solely on Automation - Beware of Passing Tests: Automated regression tests can give a sense of confidence for the team because regression tests should still pass as new functionality is delivered. The team starts relying on the tests and having a good set of regression tests can act as a safety net. However, note that not all tests are automated or can be automated, therefore always accompany automated tests with exploratory testing. Sometimes a change in the software should fail a test; however, if all tests are passing that means the defect is missed and because there was no call to action, the defect went unnoticed. Aim for Fast Feedback: Quick feedback is one of the objectives of automated tests because developers are keen to know if what they have developed works and hasn’t broken current functionality. In order to get this quick feedback loop, the tests need to be automated at component or API layer without relying on the UI. Tests run on UI are much slower and prone to error due to GUI changes. In other words, the functionality still works as expected but the tests fail due to changes in the UI. Therefore the tests can become unreliable. Understand the Context: Tests can be automated at any layer, Unit, API, Service, GUI. Each layer serves a different purpose for testing. Unit Tests ensure that the code works at the class level, that it compiles and the logic is as expected. Tests at this layer are more verification than validation. API Tests or Integration Tests ensure a set of functions and classes can work together and data can be passed from one class to another. GUI Tests on the other hand test user flows and journeys. Generally, we would not test for functionality from the UI. This should be done at lower layers. The main purpose of UI tests is to ensure the whole system works as per some common user scenarios and use cases. Testing at this layer is more Validation rather than Verification At UI level, we automate scenarios rather than stories. Don’t Automate Every Test: 100% Test Coverage is not possible since there can be millions of combinations. We always execute a subset of possible tests. The same principle applies to automated testing. To create an automated script, it requires time and effort, and aiming for “Automating Every Test”, we require a lot of resource and time, which in many cases is not possible. Instead, use a Risk-based approach to determine which tests should be automated. To get the most value out of automation, only automate the most important business cases and scenarios. Also, a high number of automated tests adds maintenance cost and difficult to maintain. Another note to bear in mind is that not all tests can be automated. Some tests are very complex in nature and require many downstream system checking and can be inconsistent. In these cases, it is best to leave these checks for manual testing. Use Test Techniques in Test Automation: The test techniques that you learned in ISTQB, are not just for manual testing. They are also applicable to automated testing. Techniques such as Boundary Value Analysis, Equivalence Partitioning, State Transition Testing, Pairwise Testing can provide a lot of benefits in automated testing. Don’t Automate Chaos: In order to get the most out of your automated testing, a good QA process should be in place. If the QA process is chaotic and we add automated testing to that chaos, all we get is faster chaos. Try to answer questions like, What to automate, When to automate, When to execute the automated tests, Who shall automate the tests, What tools should be used for test automation, etc… These tips are gathered mostly from experience as an Automation Tester and some good practices followed by others. Do you have any Test Automation Tips to be added to this list? "
    }, {
    "id": 179,
    "url": "localhost:4000/open-new-tab-browser-using-selenium-webdriver-java/",
    "title": "How to Open a New Tab in Browser Using Selenium WebDriver with Java",
    "body": "2016/11/15 - Quite often you may want to open a new tab in the same browser window that is running your Selenium WebDriver tests. Instead of opening a new browser, you can simply use the code below to open a new tab in the same browser: 1driver. findElement(By. cssSelector( body )). sendKeys(Keys. CONTROL + t );Then when you open a new tab, you have to switch to it to be able to work with the newly opened tab: 12ArrayList&lt;String&gt; tabs = new ArrayList&lt;String&gt; (driver. getWindowHandles());driver. switchTo(). window(tabs. get(0));The above code works for Firefox Browser. "
    }, {
    "id": 180,
    "url": "localhost:4000/open-source-mobile-test-automation-tools/",
    "title": "10+ Open Source Mobile Test Automation Tools",
    "body": "2016/11/14 - Mobile Test Tools - A collection of the best open source mobile test automation tools than you can use to test mobile apps and websites on mobile devices Some of these open source mobile test tools can be used for both Android and iOS as well as Native, Web and Hybrid. Appium (Android and iOS): Appium is an open-source tool for automating native, mobile web, and hybrid applications on iOS and Android platforms. Native apps are those written using the iOS or Android SDKs. Mobile web apps are web apps accessed using a mobile browser (Appium supports Safari on iOS and Chrome or the built-in ‘Browser’ app on Android). Hybrid apps have a wrapper around a “webview” – a native control that enables interaction with web content. Download Appium Calabash (Android and iOS): Calabash is an automated acceptance testing framework for mobile apps. Calabash could be compared to Selenium WebDriver. However, it is important to realize that interacting with a web app from a desktop computer is vastly different than interacting with a native app using a touch screen. Calabash provides APIs that are specialized to native apps running on touch screen devices. Download Calabash Frank (iOS): Frank allows you to write structured text test/acceptance tests/requirements (using Cucumber) and have them execute against your iOS application. Frank also includes a powerful “app inspector” (called Symbiote) that you can use to get detailed information on your running app. Download Frank MonkeyTalk (Android and iOS): MonkeyTalk automates real, functional interactive tests for iOS and Android apps - everything from simple “smoke tests” to sophisticated data-driven test suites. Native, mobile, and hybrid app, real devices or simulators. Download MonkeyTalk iOS UI Automation (iOS): Use the Automation instrument to automate user interface tests for your iOS app through test scripts that you write. These scripts simulate user actions by calling UI Automation, a JavaScript programming interface that specifies actions to be performed in your app as it runs. During the tests, the system returns log information to you. When you automate tests of UI interactions, you free critical staff and resources for other work. In this way you minimize procedural errors and shorten the amount of time needed to develop product updates. More information Robotium (Android): Robotium is an Android test automation framework that has full support for native and hybrid applications. Robotium makes it easy to write powerful and robust automatic black-box UI tests for Android applications. With the support of Robotium, test case developers can write function, system and user acceptance test scenarios, spanning multiple Android activities. Download Robotium iOS-driver (iOS): Automate any IOS native, hybrid, or mobile web application using the Selenium / WebDriver API. ios-driver is fully compatible with the Selenium / Webdriver API. IOS automation is therefore as easy as automation for a browser. ios-driver fully integrates with Selenium Grid so you can reuse your existing web automation infrastructure including your helper and utility classes (i. e. data creation, page objects etc. ) Download iOS-driver Ui Automator (Android): The UI Automator testing framework lets you test your user interface (UI) efficiently by creating automated functional UI testcases that can be run against your app on one or more devices. The UI Automator API is bundled in the UI Automator. jar file under the /platforms/ directory. The API includes these key classes, interfaces, and exceptions that allow you to capture and manipulate UI components on the target app. More information KeepItFunctional (iOS): KIF, which stands for Keep It Functional, is an iOS integration test framework. It allows for easy automation of iOS apps by leveraging the accessibility attributes that the OS makes available for those with visual disabilities. KIF builds and performs the tests using a standard XCTest testing target. Testing is conducted synchronously in the main thread (running the run loop to force the passage of time) allowing for more complex logic and composition. Download KIF Selendroid (Android): Selendroid is a test automation framework which drives off the UI of Android native and hybrid applications (apps) and the mobile web. Tests are written using the Selenium 2 client API. Download Selendroid EarlGrey: EarlGrey is a native iOS UI automation test framework that enables you to write clear, concise tests. It integrates with Xcode’s Test Navigator so you can run tests directly from Xcode or the command line. Read more on EralGrey "
    }, {
    "id": 181,
    "url": "localhost:4000/common-myths-test-automation/",
    "title": "Common Myths of Test Automation",
    "body": "2016/11/13 -  It is not difficult to imagine the benefits of having automated testing alongside product development – faster releases, increased test coverage, frequent test execution, faster feedback to the development team, just to name a few, yet many organizations have not made the move or are resistant in investing in test automation. In this article, we shall examine some of the most common myths of test automation and how these prevent organizations from succeeding in test automation. Setting Realistic Expectations: Possibly the most difficult and challenging aspect of any test automation endeavor is to understand the limitations of automated testing and setting realistic goals and expectations to avoid disappointments. With that in mind, let’s see some of the most common misunderstandings and myths about test automation: Automated Testing is Better than Manual Testing: Referring to Michael Bolton’s blog post “Testing vs. Checking”, automated testing is not really testing. It is checking of facts. When we have an understanding of the system, we can enforce that understanding in forms of checks and then by running the automated checks, we confirm our understanding. Testing, on the other hand, is an investigation exercise where we aim to obtain new information about the system under test through exploration. Testing requires a human to make a sound judgment on the usability of the system. We can spot anomalies when we were not anticipating. We should not be lenient towards one or the other, as both methods are required to get insight into the quality of the application. Achieving 100% Automated Testing: Just as there is no practical way of achieving 100% test coverage (due to endless possible permutations), the same applies to test automation. We can increase test coverage by running automated tests with more data, more configurations, covering a whole variety of operating systems, browsers, but achieving 100% is still an unrealistic goal. When it comes to automated testing, more tests do not necessarily mean better quality or better confidence. It all depends on how good a test is designed. Rather than aiming for full coverage instead, focus on the most important area of functionality which is crucial to the business. Quick ROI: When implementing a test automation solution, there are other interrelated development activities than just scripting test cases. Normally a framework needs to be developed that can support bespoke operations which are useful and meaningful for the business, such as test case selection, reporting, data-driven, etc. The development of the framework is a project on its own and requires skilled developers and takes time to build. Even when a fully functional framework is in place, scripting automated checks initially takes longer than executing the same test manually. Therefore when we require quick feedback on the new feature that’s just developed, checking it manually is usually quicker than automating the test. However, the ROI is returned in the long run when we need to execute the same tests at regular intervals. Higher Rate of Defect Detection through Automated Checks: Although many of the vendor-supplied and home-brewed test automation solutions are very sophisticated and highly capable in performing complex operations, they will never be able to compete with the intelligence of a human tester who can spot unexpected anomalies in the application while exploring or executing a set of scripted tests against the system under test. Ironically, people expect automated testing to find lots of bugs because of allegedly increased test coverage, but in reality, this is not the case. True, automated tests are good at catching regression issues – after a new feature has been added to existing code base, we need to ensure that we haven’t broken current functionality and we need that information fast – but, the number of regression issues, in most cases, tends to be far less than new functionality that’s being developed. Another point to bear in mind is that the automated checks only check what they have been programmed to check by the person who wrote the script. The scripts are as good as the person who wrote them. All automated checks could happily pass but major flaws can go unnoticed which can give a false impression of the quality of the product. In essence, checking can prove the existence of defects, but it cannot prove their absence. We Only Require Unit Test Automation: So, if the likelihood of finding defects is greater in testing new features, why aren’t we running our automated tests against the new functionality as it is being developed? Well, this is somewhat the case for teams that practice TDD. The developers write a unit test first, watch it fail and then write enough code to get the unit test pass and the cycle is repeated until the intended functionality is delivered. In essence, these automated unit tests are checking new functionality and over time they form the unit regression pack which is executed repeatedly as new functionality is delivered. But, there is a caveat to this. While TDD is highly encouraged and is a strong development practice in building quality from the grounds up, unit tests are only good at finding programmer errors, not failures. There is a much larger aspect of testing that happens when all the components are tied together and form a system. In fact, many organizations have the majority of their automated checks at the system UI layer. However, scripting automated checks for the UI or system, while the features are being developed is at best a daunting task, as the new functionality tends to be volatile (subject to many changes) during development. Also, the expected functionality might not be known until later, so spending time automating a changing functionality is not encouraged. We only Require System UI Automation: There are values in running automated checks at the UI and system level. We get to see what the user experiences when interacting with the application; we can test end-to-end flows and 3rd party integration when we could not test otherwise; we can also demo the tests to clients and end-users so they can get a feel of test coverage. However, relying solely on the automated checks at the UI layer has its own problems. UI is constantly changing to enhance visual design and usability and having automated checks failing due to the UI changes and not changes in the functionality can give a false impression of the state of the application. UI automated checks are also much slower in the speed of execution than at unit or API layer and because of this, the feedback loop to the team is slow. It might take a few hours before a defect is spotted and reported back to the developers. And when something does go wrong, the root cause analysis takes longer because it is not easily apparent where the bug is. Understanding the context of each test and at which layer the test should be automated is important. Test automation should be part of the development activity, so the whole team is responsible for test automation, with developers writing executing unit tests, Software Developers in Test writing executing and maintaining acceptance tests at API and/or UI. Losing Faith and Trust in Test Automation: This last one is not a myth about test automation, but a side effect when test automation goes wrong. You spend many hours developing a perfect test automation solution, using the best tools and best practices, but if the automated checks do not help the team it is worthless. If the team has no visibility or knowledge on what is automated and executing, they either release with fear of unknown or duplicate their regression testing efforts. If the automated checks are flaky, slow, give intermittent results then it can confuse the team more than providing a safety net and a confidence booster. Don’t be afraid of removing automated checks that are always failing or give inconsistent results. Instead, aim for a clean and reliable suite of tests that can give correct indications of the health of the application. Conclusion: Test Automation is a long term investment. It will take time and expertise in developing and maintaining test automation frameworks and automated scripts. Test automation is not a one-off effort where you deliver a solution and let it run. It needs constant monitoring and updating. Rather than aiming to replace manual QAs or expecting the automated checks to find lots of defects, we should instead embrace the advantages it brings to the team, such as liberating QA’s time for more exploratory testing where chances of revealing defects is maximized, or using automated scripts to create test data that can be used for manual testing. Understanding the limitations and setting realistic expectations is important in overcoming these myths of test automation. Related:  Why is it so hard to hire SDETs? Modern QA - Problems with test automation How to choose which tests to automate?"
    }, {
    "id": 182,
    "url": "localhost:4000/best-software-testing-quotes/",
    "title": "Best Software Testing Quotes",
    "body": "2016/11/12 - Here are some of the best interesting quotes on software testing and quality assurance: 1 - “No amount of testing can prove a software right, a single test can prove a software wrong. ” - Amir Ghahrai 2 - “Testing is about defect detection, Quality Assurance is about defect prevention. ” - Amir Ghahrai 3 - “Testing is an infinite process of comparing the invisible to the ambiguous in order to avoid the unthinkable happening to the anonymous. ” - James Bach 4 - “I don’t care if it works on your machine! We are not shipping your machine!” — Vidiu Platon. 5 - “Discovering the unexpected is more important than confirming the known. ” - Pranav D 6 - “If you don’t care about quality, you can meet any other requirement” – Gerald M. Weinberg 7 - “Testers don’t break software, software is already broken” - Amir Ghahrai 8 - “Software testing proves the existing of bugs not their absence. ” – Edsger W. Dijkstra 9 - “More than the act of testing, the act of designing tests is one of the best bug preventers known. ” – Boris Beizer 10 - “Why do we never have time to do it right, but always have time to do it over?” - Anonymous 11 - “The principle objective of software testing is to give confidence in the software. ” – Anonymous 12 - “If you automate chaos, all you get is faster chaos. ” - Not known 13 - “Quality means doing it right even when no one is looking. ” - Henry Ford 14 - “Software testers do not make software; they only make them better. ” - Anonymous 15 - “The bitterness of poor quality remains long after the sweetness of low price is forgotten” – Benjamin Franklin 16 - “Testing is Questioning a system in order to evaluate it” - James Bach 17 - “Quality is not an act, it is a habit” - Aristotle Do you have a favorite software testing quote you would like to share? Put it in the comment below. "
    }, {
    "id": 183,
    "url": "localhost:4000/software-testing-definitions/",
    "title": "Software Testing Definitions",
    "body": "2016/11/11 - [caption id=”attachment_10031” align=”aligncenter” width=”472”] software-testing-definitions[/caption] Software Testing definitions from famous people in the field of testing::    Testing is the process of establishing confidence that a program or system does what it is supposed to (Hetzel, 1973).     Testing is the process of executing a program or system with the intent of finding errors (Myers, 1979).     Software Testing is the process of exercising or evaluating a system by manual or automatic means to verify that it satisfies specified requirements or to identify differences between actual and expected results (IEEE 610. 12, 1990)     Testing is any activity aimed at evaluating an attribute or capability of a program or system. Testing is the measurement of software quality (Hetzel, 1984)     Testing is demonstrating that a system is fit for purpose (Evans, et al, 1996)     Testing is a process of planning, preparation and execution to establish the characteristics of a software product and to determine the difference between the actual and required status (Pol and Van Veenendaal, 1996)     Software Testing is a process consisting of all life cycle activities concerned with checking software and software-related work products (Gelperin and Hetzel, 1988)     Testing is the process of exercising software to verify that it satisfies specified requirements and to detect errors (BS7925-1, 1998)     As the objective of a test should be to detect faults, a “successful” test is one that does detect a fault (ISEB, 1999)  Read the beginner’s guide to Software Testing "
    }, {
    "id": 184,
    "url": "localhost:4000/testers-role-agile-environment/",
    "title": "Tester's Role in Agile Environment",
    "body": "2016/11/10 - There are many diverse ideas about what being a tester means in agile development environments. This leads to confusion between how agile testers “fit” into development teams and what their role is. John Stevenson explains why there appears to be some fear and a little distrust of agile among some testers, then offers suggestions for dealing with their confusion. Historically, testing activities have happened at the end of the development (coding) effort because a tester’s responsibilities included proving the requirements were met, ensuring the software worked, and finding bugs in the mostly finished product. The Agile Manifesto flips around titles and roles and says to focus on individuals and interactions over processes and tools. This means that as testers, there is a need to work as members of the team and to engage with others within the team, regardless of titles. If you see a task that needs doing and you have the skills to do that task, then just do it. Agile processes mean testers are part of the delivery team and should try to be involved from the beginning of the project. Testers should have the ability to “switch hats” and be involved to support and assist the team. The purpose of a tester in agile environments is about getting things done rather than roles. As a tester, you should try to act as a service to the project and ask yourself, “What can I do that is best for the team or for the project?” There are many other roles a tester carries out during testing, such as a coach or mentor, a service provider, a sage, a confidant, and a person who is willing to listen as well as challenge others for the benefit of the team. Read the full article… "
    }, {
    "id": 185,
    "url": "localhost:4000/bdd-guidelines-best-practices/",
    "title": "BDD Guidelines and Best Practices",
    "body": "2016/11/09 - BDD Best Practices: BDD Introduction: BDD (Behaviour Driven Development) is a methodology for developing software through continuous example-based communication between developers, QAs and BAs. In this article we discuss some BDD Best Practices to get the most benefit. More than anything else, the primary purpose of BDD methodology is to encourage communication amongst the stakeholders of the project so that the context of each feature is correctly understood by all members of the team (i. e. shared understanding), before development work starts. This helps in identifying key scenarios for each story and also eradicate ambiguities from requirements. In BDD, Examples are called Scenarios. Scenarios are structured around the Context-Action-Outcome pattern and are written in a special format called Gherkin. The scenarios are a way of explaining (in plain english) how a given feature should behave in different situations or with different input parameters. Because Gherkin is structural, it serves both as a specification and input into automated tests, hence the name “Executable Specifications”. What is a feature file and what does it contain: Feature files are text files with . feature extension, which can be opened by any text editor as well as readable by any BDD-aware tool, such as Cucumber, JBehave or Behat. Feature files should start with the context of the feature (which is essentially the story), followed by at least one scenario in the following format Feature: Some terse yet descriptive text of what is desired In order to realize a named business valueAs an explicit system actorI want to gain some beneficial outcome which furthers the goal Scenario: Some determinable business situation Given some preconditionAnd some other preconditionWhen some action by the actorAnd some other actionAnd yet another actionThen some testable outcome is achievedAnd something else we can check happens too Scenarios in feature files should focus on the “what” rather than the “how”. The scenarios should be concise and to the point, so that the reader can quickly grasp the intent of the test without having to read a lot of irrelevant steps. Why should we write feature files: As mentioned before, the primary aim of the BDD methodology is to encourage communication amongst the delivery team. The aim of the feature files is to document the scenarios talked through in order to give an indication of how much work is involved in delivering the feature. The feature files are also the drivers for the automated tests. Feature files also serve as a definition of done (DoD), meaning that when all the scenarios have been implemented and tested successfully, we can mark the story as done. Who should write feature files: It doesn’t really matter who actually writes/types the feature files, it could be any member of the delivery team, however, the contents (scenarios) which are discussed by a trio of Dev-QA-BA are the essential part of feature files. Getting the shared common understanding of the feature is the key element. When should feature files be written: Feature files should be written during the story grooming sessions where the details of each story is discussed. Feature files containing scenarios should be written before development starts so that developers as well as QA have a clear understanding of the intent of the story. There should be a shared understanding of the story. The scenarios serve as requirements to development. Where should feature files be kept: There should be one source of truth serving both as specification and automated execution, therefore should be kept somewhere where every member of the team has easy access. Having said that, because the feature files are the drivers of the automated tests, they should ideally be kept in source control system (GitHub) so that any updates to the feature files is immediately reflected on to the tests. For non-technical members who have no experience with Git, we can always execute a dry-run of the feature files which will then output the list of all existing scenarios without actually exercising the feature files. How should we write feature files: There are generally two ways of writing feature files - Imperative and Declarative Imperative style of writing a feature file, is very verbose, contains low level details and too much information. Pros: person reading the feature file can follow the step-by-step Cons: Because of too much detail, the reader can lose the point of the story and the tests. The feature file becomes too big, difficult to maintain and likely to fail due to UI updates. Declarative style of writing a feature file is concise and to the point, contains only relevant information about the story. Pros: The declarative style is more readable as it contains less steps in the scenario. The reader can easily understand the scope of the test and quickly identify if any key elements are missing. "
    }, {
    "id": 186,
    "url": "localhost:4000/exploratory-testing-important-agile-projects/",
    "title": "Why Exploratory Testing is Important in Agile Projects",
    "body": "2016/11/08 - Exploratory Testing is an important activity in an agile environment as it can help software testers to keep up with the rapid development pace of agile software projects. First, a brief intro on agile methodology and exploratory testing: In agile methodology, software is released in small iterations. Each iteration goes through planning, estimation, development, integration, testing and release. Because of frequent releases, test automation becomes ever so important as developers need to get quick feedback on the status of the application. The automated checks serve as regression tests to ensure that with each release the software has not regressed. Exploratory Testing is defined as simultaneous learning, test design and test execution. It is an approach to testing that values the tester as an integral part of the test process and shares the same values as the Agile Manifesto:  Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a planExploratory Testing is also complementary to test automation; that is while automated checks are checking for regression issues, Exploratory Testing focuses on new features which have been developed. This is important because each sprint typically lasts only couple of weeks, which doesn’t allow sufficient time for scripting tests cases and executing them later against the application. On the other hand, exploratory testing in agile environment allows testers to get familiar with the domain and the application and on each iteration, that understanding is enhanced and hence testers become more efficient. [caption id=”attachment_9092” align=”aligncenter” width=”431”] agile-exploratory-testing[/caption] According to Brian Marick’s testing quadrant, there are two sides to testing, ones which support programming, i. e. support writing code (unit tests) or provide an indication of when the programmer might be finished (acceptance tests) and the ones which critique the product, i. e. “look at a finished product with the intent of discovering inadequacies. ” It’s here, in the area of critiquing the product, where exploratory testing can play a major role in agile project. In agile projects, the tests that support programming are mostly done by developers and are almost always automated and is an indication of done from a programmer’s point of view, whereas exploratory tests aim to find possible issues which are beyond automated programmer tests. The exploratory testers focus on areas where existing automated tests might come up short. Effective exploratory testers working on agile projects use the tactics of exploratory testing to help inform the project team about possible issues with the product. Their testing can be unstructured and freestyle or be managed using charters and test sessions. Also due to the short intervals of development, testing inherently becomes risk based, and exploratory testing can focus on high risk areas to find potential problems. Agile methodologies and exploratory testing are complimentary methods which, when employed together, can create excellent synergy within the testing experience. "
    }, {
    "id": 187,
    "url": "localhost:4000/software-development-life-cycle-sdlc-phases/",
    "title": "Software Development Life Cycle - SDLC Phases",
    "body": "2016/11/07 - SDLC Phases Explained: What are the SDLC Phases? Software Development Life Cycle, or SDLC is a process used to develop software. There are different stages or phases within the Software Development Life Cycle and in each phase, different activities take place. SDLC creates a structure for the development teams to be able to design, create and deliver high quality software by defining various tasks that need to happen The life cycle defines a methodology for improving the quality of software and the overall development process. The methodology within the SDLC process can vary across organizations, but standards such as ISO/IEC 12207 represent processes that establish a life cycle for software, and provide a standard for building and maintaining software. The intent of a SDLC process it to help produce a product that is cost-efficient, effective, and of high quality. SDLC Phases: 1. Requirement Analysis: Software Development Life Cycle begins with Requirement Analysis phase, where the stakeholders discuss the requirements of the software that needs to be developed to achieve a goal. The aim of the requirement analysis phase is to capture the detail of each requirement and to make sure everyone understands the scope of the work and how each requirement is going to be fulfilled. It is a normal practice to also discuss how each requirement will be tested and so testers can add great value in participating in requirement analysis meetings. Depending on which software development methodology is used, different approaches are taken in moving from one phase to another. For example, in the waterfall or V model, the requirement analysis phase are saved in a SRS (Software Requirement Specification) document and needs to be finalized before the next phase can take place. 2. Design: The next stage of Software Development Life Cycle is the Design phase. During the design phase, developers and technical architects start the high-level design of the software and system to be able to deliver each requirement. The technical details of the design is discussed with the stakeholders and various parameters such as risks, technologies to be used, capability of the team, project constraints, time and budget are reviewed and then the best design approach is selected for the product. The selected architectural design, defines all the components that needs to be developed, communications with third party services, user flows and database communications as well as front-end representations and behaviour of each components. The design is usually kept in the Design Specification Document (DSD) 3. Implementation: After the requirements and design activity is completed, the next phase of the Software Development Life Cycle is the implementation or development of the software. In this phase, developers start coding according to the requirements and the design discussed in previous phases. Database admins create the necessary data in the database, front-end developers create the necessary interfaces and GUI to interact with the back-end all based on guidelines and procedures defined by the company. Developers also write unit tests for each component to test the new code that they have written, review each other’s code, create builds and deploy software to an environment. This cycle of development is repeated until the requirements are met. 4. Testing: Testing is the last phase of the Software Development Life Cycle before the software is delivered to customers. During testing, experienced testers start to test the system against the requirements. The testers aim to find defects within the system as well as verifying whether the application behaves as expected and according to what was documented in the requirements analysis phase. Testers can either use a test script to execute each test and verify the results, or use exploratory testing which is more of an experience based approach. It is possible that defects are identified in the testing phase. Once a defect is found, testers inform the developers about the details of the issue and if it is a valid defect, developers will fix and create a new version of the software which needs to be verified again. This cycle is repeated until all requirements have been tested and all the defects have been fixed and the software is ready to be shipped. 5. Deployment and Maintenance: Once the software has been fully tested and no high priority issues remain in the software, it is time to deploy to production where customers can use the system. Once a version of the software is released to production, there is usually a maintenance team that look after any post-production issues. If an issue is encountered in the production the development team is informed and depending on how severe the issue is, it might either require a hot-fix which is created and shipped in a short period of time or if not very severe, it can wait until the next version of the software. Conclusion: All the stages in the Software Development Life Cycle defined above are applicable to any software development methodology, but the duration and the activities in each phase depend on whether you follow the V Model development methodology or Agile. In Agile, the duration to deliver a working software is typically between 2 to 4 weeks and so each of the above phases are shortened. Also in agile, it is a whole team approach where the developers and testers are involved and work together to make a high quality product. "
    }, {
    "id": 188,
    "url": "localhost:4000/acceptance-criteria-vs-acceptance-tests/",
    "title": "Acceptance Criteria vs. Acceptance Tests",
    "body": "2016/11/06 - What is the difference between acceptance criteria and acceptance tests? Many organizations that follow agile methodology, especially in Behaviour Driven Development (BDD) use these two terms interchangeably. When discussing the details of a story people tend to quickly jump in writing “Tests” in gherkin language to express their intent in terms of Given-When-Then scenarios when they should be focusing on the set of conditions that govern the behaviour of the story. In fact, Mike Cohn refers to these acceptance criteria as “Conditions of Satisfaction”. There is a subtle difference between acceptance criteria and acceptance tests. Acceptance criteria are a set of conditions that need to be met in order to accept the story as complete. Acceptance tests, on the other hand, are scenarios which are derived from acceptance criteria. In other words, each acceptance criteria can have one or more acceptance tests. Acceptance tests can be written in gherkin language which can be used by BDD tools such as cucumber to automate the tests. Acceptance criteria can be thought of as “what needs to be done” and acceptance tests as “how they should be done”. You can use acceptance criteria to clarify the scope of each story, so the team is clear on what is expected to be done to deliver the story. For this reason, it is best NOT to write acceptance criteria as gherkin for clarity and to separate the “what” from the “how”. Acceptance criteria can be written as bullet points to highlight the intent of the story where each bullet point is a condition. It is by means of conversations with stakeholders, developers and QA that the details of each acceptance criteria is fleshed out, e. g. in story workshops or story grooming sessions where different members of the team with different skills and knowledge and experience sit together and think about the scenarios to fulfil each criteria. Acceptance criteria are usually initiated by Product Owner or BA but other team members can also participate in defining the acceptance criteria for each story. These obviously need to be written and agreed upon before development work starts. The acceptance tests in gherkin format or otherwise can be written before or in parallel to development. New acceptance tests can be added at any time. Further reading… BDD Guidelines and Best Practices When to write story tests Acceptance criteria vs. scenarios "
    }, {
    "id": 189,
    "url": "localhost:4000/exploratory-testing-tips-best-practices/",
    "title": "Exploratory Testing: Tips and Best Practices",
    "body": "2016/11/05 - In a previous post we discussed Why Exploratory Testing is Important in Agile Projects. In this article, Neil Fletcher provides his top 10 tips to exploratory testing. Key questions that come up are: what is exploratory testing and how should we do it? Exploratory testing helps quality analysts and others involved in the testing field ensure systems and applications work for their users. Exploratory testing is often misunderstood as an approach but there a number of pointers you can follow to ensure you’re on the right track. Here are my top 10. 1) Focus on goals: Exploratory testing helps you exercise a system like a user while actively looking to identify bugs. Focus on these goals to maximise the value of your tests. Remember that exploratory testing can complement other testing methods that examine systems in different ways. 2) Plan your tests but don’t script them: You are not exploratory testing if you are following a script.  However, exploratory testing doesn’t mean testing without control or good practice. You do need to plan your testing in advance. Planning helps you clarify specific aspects of a system you want to examine including special data requirements or system needs. 3) Don’t aim to test too much: The aim of exploratory testing is not coverage – it’s to find the defects and issues in a system that you won’t find through other forms of testing. Typically these defects arise through edge cases of testing, but that doesn’t mean they are low impact. Quite often edge case defects will have a high level of severity even if they are less likely to arise. This is due to the nature of exploratory testing – it focuses on the parts of a system that are away from the normal usage pattern and are less likely to be well tested. 4) Exploratory testing is a skilled activity: Typically, exploratory testing needs a greater level of testing skill and experience than other testing techniques. You are explicitly using and relying on the skill of the person doing the testing, so make sure they are the best you can get. 5) Keep a clear record of what you did: Don’t document something if there’s no value in doing so but do keep a clear record of what you did, how you did it and what you found out. This will give you an indication of how effective the session was, allowing you to optimise the process in the future. When you need to formally document the outcome of a session, your report may include:  a test charter outlining the scope and goals of your test a list of features tested notes on how the testing was conducted notes on any bugs found a list of issues (questions and concerns about the product or project that have arisen during testing) extra materials used to support testingYou can also report how much of the Exploratory Testing session you spent on each different activity, including:  creating and executing tests investigating and reporting bugs setting up the session6) Use exploratory testing alongside automated testing: Automated testing checks a system performs as the development team thinks it should, according to the identified needs. Exploratory testing checks the system performs as a user might expect. It’s important to coordinate both testing types to ensure the values of both exploratory testing and automated testing are realised, e. g. when exploratory testing finds a defect, you can add an automated test to stop the issue from happening again. 7) Performance and non-functional testing can be exploratory: Performance and non-functional testing can also be exploratory, e. g. tracking an increasing load on a system, or measuring the time it takes a use case to fully complete from start to finish. While performance and other non-functional testing hold a limited scope, they can still be exploratory. Whether you are tracking an increasing load on a system or measuring the time it takes an application to complete from start to finish, you can do so with the mindset of a user. You outline the scope of your testing in your test charter. 8) Choose the Exploratory Testing techniques that meet your needs: You’ll need to:  research current exploratory testing techniques establish a common understanding of the techniques  you’ll use and share this with all stakeholders decide on your scope (including timescales, process, and when exploratory testing  will be used) ensure that the system is built to support exploratory testing, e. g. build functionality in slices that can be tested from start to finish as early as possible. 9) Don’t confuse exploratory testing with user acceptance testing: User acceptance is a testing activity that can (and probably should) be performed in an exploratory testing way. Don’t confuse the way of working with the type of test required. Exploratory testing isn’t a phase of the development lifecycle; it’s an approach and technique that you should use throughout the life of the project.  As soon as your bits of a system under development have a testable flow through them, you must test that flow.  Exploratory techniques are a good way of doing that quickly and with high value output. 10) Don’t go mad on tools: There are many different tools you can use to do exploratory testing, from fully automated video capture and logging tools, to planning tools, to walls full of process diagrams and feature descriptions with accompanying timebox plans. However, the only tool you really need to do exploratory testing is a pen and some paper. Tools are nice to have, but don’t put off starting exploratory testing if you don’t have access to them. Do you have any tips around exploratory testing you would like to share?  Add them in the comments box and let everyone know. Source: https://governmenttechnology. blog. gov. uk/2014/11/28/top-10-tips-to-exploratory-testing/ "
    }, {
    "id": 190,
    "url": "localhost:4000/10-characteristics-bad-software-tester/",
    "title": "10 Characteristics of a Bad Software Tester",
    "body": "2016/11/04 - Traits to Avoid as a Tester: [caption id=”attachment_10202” align=”aligncenter” width=”622”] 10-characteristics-of-bad-tester[/caption] After reading 10 Characteristics of a Bad Software Engineer which lists some bad habits or attributes of a bad software engineer, a question was raised on TestHuddle on what could be the characteristics of a bad software tester. A good answer was posted by Kasper 1- The I found a bug bot: This person stops at the first sign of a bug and directly files his bug report. Don’t get me wrong filing bug reports is very important – how else can bugs be fixed? But a little investigation into the own test or environment could make a big difference in filing VALID bug reports. 2- The I-am-not-a-programmer: I don’t know how to code, I don’t want to know how to code, that is the programmers job. This person does not understand the technicalities of the software under test or the technical implications of the bugs he/she stumbles upon. At best the person behaves like a user functionally looking at the software, at worst the person revels at placing v’s in checkboxes. 3- The I-need-all-the-documentation-or-I-can’t-test: Some people get stuck in the test basis intake steps. They have no imagination and can not just start testing based on the product, code and information from the programmer. This tester believes that the world (or at least the company) will end if not everything is in place before the person begins with any testing activities. 4- The ugly: My tests work, but:I can not write a decent bug reportMost of what I write boils down to “It does not work. ”There is no investigation. No consistent testing convention, or reporting convention, or communication. Bug reports all over the place, etc. 5- The short term investor: The person tests. The person files reports. The person moves on. No attempt to learn the product, code or developers. You get tested software but nothing more is achieved. There is no knowledge added to the team. 6- The protester: The code sucks, the test plan sucks, I can’t do this, let somebody with more technical, domain, or any other knowledge tackle this. I hate this (ten times an hour). 7- The dictator: My way or the high way. It’s their “ideas” vs “your ideas”, not “project ideas”. It’s their solution vs your solution. I bet there will be an argument for sure. Somehow they will keep coming back to a test that you performed. This person is a big bottleneck to productivity and will be the first person to crumble under pressure and start pointing fingers. This person is not good for the team, however experienced/good a tester he may be. 8- The overcautious: The testers that freeze if not all requirements are set in stone. The tester that panicked when learning that not all documentation is available. The tester that cringes at not having 100% coverage (code-, functionality-, or anything else). These people will do anything to avoid getting out of their comfort zone. Good testers show a tendency to slowly/swiftly move out of their comfort zone in exploration. 9- The careless: Forgets to take a backup, snapshots, can’t reproduce bugs etc. This is a newbie tendency and gets better with more professional exposure. 10- The lazy software cracker: They pride themselves at using the latest tools and methods to test complex software. “This fourth generation, behaviour driven, automatically self testing software tool will solve all our quality problems!” 99 out of a 100 times this is a pose. They will invest a lot of time in getting the tools / environment ready and then it does not work without a lot of new investments. Getting the software ready and tested will cost much more than having tested it right the first time.  See more at: http://testhuddle. com/forums/topic/characteristics-of-a-bad-software-tester/"
    }, {
    "id": 191,
    "url": "localhost:4000/what-makes-good-agile-tester/",
    "title": "What Makes a Good Agile Tester?",
    "body": "2016/11/03 - Are You a Good Agile Tester?: In previous article, we looked at 10 Characteristics of a bad software tester. In contrast, this article focuses on characteristics that good agile testers possess. Testing in an agile environment is different that the traditional methodologies such as waterfall.  Agile is an iterative model of delivery which requires continuous collaboration between the team members, providing quick feedback and be able to self-manage. Quite often there are challenges in testing in an agile environments such as lack of documentation, changing priorities, less time to test, but with the right mindset and attitude, testers in agile team can provide a lot of value and help the team deliver good quality software on continuous basis. So, let’s see what makes a good agile tester in an agile team? Difference Between Testing and Quality Assurance: A good agile tester knows that his job is not limited to only executing test scripts, reporting defects and signing off on releases. Testing is only a portion of the wider quality assurance practice. Testing is no longer a phase in agile software delivery. It’s a continuous activity before, during and after each sprint.  In an agile team everyone is responsible for the quality of the software and quality should be baked in right from the start and not an afterthought. If any of the stakeholders, BAs, Developers or even other testers in the team are not quality focused, it is the job of the tester to remind the team about the consequences of ignoring good practices to build a quality software. Technical Knowledge and Test Automation: Test Automation is vital to the success of an agile project because automated tests can provide fast and reliable feedback to the development team. Tests can be automated at different levels with different purposes. A good agile tester with sound technical knowledge is able to:  Determine and advise which tests should be automated at which layer.  Choose the right set of tools to help the testing Help the developers in writing automated tests and analyze the results of the automated tests.  Create different automation suites, such as smoke pack, full regression pack, end-to-end regression pack, etc.  Minimize the execution time for the automated tests in order to obtain quick feedback Execute tests on a continuous basis Provide valuable metrics to the business Utilize the facilities of different testing tools to help with manual testingAgile testers also know that no matter how good the automated tests are, exploratory testing is still required to complement test automation, because not all bugs can be found by test automation. To get the most benefit out of test automation, best practices should be followed. Provide Continuous Feedback: One of the key benefits of agile development is being able to deliver a working solution quickly. In order to move fast, we need to get quick feedback on each version of the code. We should be able to know, within a short period of time, whether new or updated code has caused any regression bugs. Hence, one of the objectives of testing in agile is to provide relevant information about the health of the application quickly. When issues are reported early, we can fix them straight away and move on. If the feedback loop is delayed, the team have moved on and it becomes more difficult and time consuming to identify the root cause of the issue. As Kniberg and Skarin put it:  Change something=&gt; Find out how it went =&gt; Learn from it =&gt; Change something again. Generally speaking you want as short a feedback loop as possible, so you can adapt your process quickly. Feedback can be provided in many forms such as:  Pair Programming Code Reviews Unit Tests Automated Integration Tests Automated Acceptance Tests Automated Regression Tests Exploratory TestingOf course the agile tester should ensure that proper and effective tests are written and executed at each level. Well Versed in Agile Methodologies: Good agile testers have read and understood the agile manifesto and implement its principles on their daily tasks. Agile testers know that they are part of the delivery team and that there is no separation of testing phase and development phase, but rather testing is a continuous activity which happens as part of the development. Good agile testers know that change is inevitable and that priorities change on a daily basis. There might be last minute urgent production bug fixes which requires testing as well as testing the new features and functionality. Agile Testers understand the agile terminologies and participate in the activities. They read books such as Agile Testing by Lisa Crispin and Janet Gregory, User Stories Applied by Mike Cohn, Specifications By Example by Gojko Adzic. Domain Knowledge: In order to be able to design effective tests which are aimed at finding bugs and execute a successful exploratory testing session, agile testers need to have good understanding and knowledge of the domain application. Good agile testers spend time to learn the terminology of the specific domain, understand architectural diagrams and help devise meaningful business case scenarios. Although domain knowledge is vital in agile testing environments, because of the short time and crazy workload, good agile testers are highly skilled in the test profession so that they can design less tests with more coverage and are comfortable using techniques such as pairwise to design tests. Domain knowledge can be obtained by talking to BAs and Developers, working with the application, and reading specifications. Eager to Learn and Improve: An Agile team should, between the team members, have all the necessary skills to build and deliver a good solution, encompassing technical and business skills. Team members in agile teams are multi-skilled. Developers know the importance of testing (or at least they should) and write automated tests where appropriate and applicable. Likewise, good agile testers keep up with the changing technologies, learn new skills, such as coding/programming, HTTP, databases, API testing, technical testing in order to help their peer developers to keep moving fast. Having said that, it does not mean that if a tester cannot code has no place in an agile team. Highly skilled testers provide a lot of value to the agile team, however having technical knowledge helps develop their career further and be more in demand. Conclusion: From dsdm. org  The key drivers to a successful Agile team are the mentality and the attitude of the individual team members, together with everyone sharing a team objective and a team measure of success. This ensures the team and the individuals within the team are driven and motivated by the “All for one and one for all” mentality. What we look for is the “What can I do to help here?” attitude, rather than the “That’s not my problem” mentality. "
    }, {
    "id": 192,
    "url": "localhost:4000/no-thing-negative-testing/",
    "title": "No Such Thing As Negative Testing?",
    "body": "2016/11/02 - [caption id=”attachment_10084” align=”aligncenter” width=”640”] what-is-negative-testing[/caption] “What is Negative Testing?”: This is a question I like to ask all the candidates I interview for QA positions. The answer I’m usually given is that it’s checking a piece of software doesn’t do what it’s not supposed to do, along with the textbook example of putting a numerical value in a text field and getting an appropriate error message. But I challenge that line of thinking. By definition, a text field will not accept numerical input, and the error message is therefore expected behaviour. That’s what the software is supposed to do, and you’re testing to make sure it does it. So doesn’t that mean that this is a positive test for an error scenario rather than a negative test? And if that’s the case, is there really such a thing as negative testing? There is, at least according to the standard definition. And it’s something that any QA department worth their salt is already doing to some degree. But, just to make things even more confusing, we call it something else. The only testing discipline that can really be considered negative by the textbook definition is exploratory testing. Shining a light into the dark corners of your software, doing odd stuff that’s not even in the same postcode as the Happy Path - that really is the art of making sure the software doesn’t do things it’s not supposed to. I know there are those who believe exploratory testing is a bit wishy-washy. That it’s just aimless prodding in the hope of finding something, and something to fill time until the next iteration of code is available. Some even consider it a flimsy justification for the existence of manual QA in an increasingly automated world. But as automation takes the strain and ramps up the potential speed of software development, exploratory QA has become a highly skilled position. Yes, automation is quite clearly the wave of the future, and efficient automation is compulsory for anyone who wants to be either a market leader or a fast follower in software development. But smart exploratory testing is the next evolution of manual QA. Knowing what to prod, when to prod it, and what to prod it with are enormously important in preventing manual QA from becoming a bottleneck. It is required to maintain efficiency in agile software development teams, while still being able to give a confident assurance of quality for the code that’s being progressed to production. And most importantly, it’s something that can’t be automated. Robots can deal with the repetitive stuff with greater efficiency than a manual tester ever could by testing in parallel, running multiple threads in pairwise testing and so on. But in the same way a skilled engineer can hear a single bearing that’s out of kilter and will eventually grind an entire device to a halt long before any warning systems throw up an alert, a manual QA should know precisely how the latest addition to their area of the code base is likely to affect the overall system. Automation is carpet bombing. Exploratory testing is a series of targeted strikes. A manual QA should therefore know exactly where to focus their exploratory testing, the precise moment where they should stray from the happy path, and how far into negative territory they need to wander. It’s just not the negative territory that you think it is. "
    }, {
    "id": 193,
    "url": "localhost:4000/can-you-really-automate-a-user-journey/",
    "title": "Can You Really Automate a User Journey?",
    "body": "2016/11/01 - [caption id=”attachment_10071” align=”aligncenter” width=”600”] automating-user-journey[/caption] Automating user journeys is an important activity during the development of a system because as the system evolves, we need to ensure that core business functionality is not broken as changes to the system is made. It is no surprise then that many companies have a large set of automated user journeys at the layer that the customer interacts with the system. These automated tests are are typically end-to-end and are usually automated through the user interface using tools such as selenium webdriver. But are these automated tests, really test a user journey? First, let’s see What is a User Journey?: A user journey is a series of steps which represent a scenario in which a user might interact with a system. Typically, a user journey has a starting point, i. e. an entry point into the system, a series of transitions from one state to another and a set of triggers which cause the transitions. User journeys can help you identify customer behavior and how the users use the system or how they could potentially use the system. When we are creating user journeys, we need to be thinking about:  Context – Where is the user? What is around them? Are there any external factors which may be distracting them? Progression – How does each step enable them to get to the next? Devices – what device are they using?Are they a novice or expert? What features does the device have? Functionality – What type of functionality are they expecting? Is it achievable? Emotion – What is their emotional state in each step? Are they engaged, bored, annoyed? Read more about mapping emotion to user journeysThe important part here, is that a User Journey is a_“mental_” and “lived” experience. The journey is deeply linked to_“emotions”_ and these emotions usually have a bearing on the users perception of quality. Whilst some of the above factors can be accounted for when writing automated tests, we certainly cannot know about user’s emotions, it is for this reason you cannot automate a user journey. So, if by definition, we cannot automate user journeys, then what can we automate?: Well, we can at least check that the system functions as we expect it under certain conditions. That is, we can start mapping out the most common paths through the system and think about how users would interact with the system in each flow. That way, we can at least ensure that users don’t hit blank pages along the way, that correct and relevant information is displayed to the user and that it is possible to complete a flow or path through the system. This form of testing is quite different to functional testing as I don’t believe we should be testing the functionality through the interface. This “application path testing” doesn’t really verify functionality but focuses on transitions from one state to another and verifies whether these transitions are actually possible and make sense for the user. "
    }, {
    "id": 194,
    "url": "localhost:4000/q-not-testers-qa/",
    "title": "Q: Are we not testers? A: We are QA!",
    "body": "2016/10/31 - [caption id=”attachment_10135” align=”aligncenter” width=”520”] qa-vs-testing[/caption] With the advances being made in technology project management and delivery, and the ongoing adoption of Agile development methodologies, the role of true QA professionals has never been more important. But as the playing field of technology is shifting, it is apparent that QA and Testing are very different games, and that the distinction between the two really should be a lot clearer. The business of testing has come a long way in the last ten years, and there have been many improvements and reinventions along the way. Back in the day, QA as a function didn’t really exist. Development was carried out Waterfall style, and finished code was dropped on testers infrequently. While the developers put together their interpretation of what the business had asked for, testers would be using the same business case to document exactly how they were going to test that code in chapter and verse. The mantra from test teams across the world was ‘You must write test scripts that anyone can run’. Because that’s pretty much what a tester was – any old geek off the street who could use a PC, write and / or follow a step-by-step script, and tick a box. Indeed, that’s still how parts of the tech world still see QA – unskilled nit-pickers that somehow have the audacity to tell developers what they’ve done wrong. A constraint, a box to be checked on the way to production. But today, to call a QA professional a tester is a slap in the face. It is a gross undervaluation of the skills and the mindset required to be effective in the field, and the clue is in the modern job title. A QA professional is not just a tester. A QA professional is the guardian of the production codebase, and a provider of an assurance that the applications and platforms that our departments release will not compromise our business. We’re not the last point on a checklist. A QA professional is a skilled asset to the development team, and is involved from the moment the business team approaches technology with something they’d like to see implemented. They are vital to the prevention of (rather than detection of) defects, and understand that this is the only viable approach in modern software development. We are not mindless. Exploratory Testing is a real skill, and will be the future of Manual QA. But robust automation is required to release your manual QA Engineers from the shackles of repetitive testing, and a working knowledge of automated testing is an essential skill for a QA professional. If it feels robotic, make a robot do it so your human testers can be human. We are not obsessed with documentation, or bound by Test Management tools. Agile methodologies &amp; shorter SDLCs = No documentation beyond user stories. Everything moves faster, meaning shorter feedback loops, and a shorter time to market. And most importantly, Release Testing is not Regression Testing. But… but… all your teams have completed their development for this release cycle, and all of your apps have been signed off. You’ve got a production candidate release all set up, and it gets deployed to your pre-production environment for regression testing, right? No, no, a thousand times no. Because if your teams have signed off, it’s too late for regression testing. The sign off (and it should be a team sign off - the quality of the codebase isn’t just the responsibility of QA, even if they are its guardians) is the team’s assurance that the code committed will not adversely affect the overall code base, and a declaration of adherance to a ‘do no harm’ rule. If you haven’t carried out regression testing before signing off, you’re giving a false statement of confidence. ISTQB defines the purpose of regression testing as:  “to verify that modifications in the software or the environment have not caused any unintended adverse side effects and that the system still meets its requirements. ” Your release testers are not bug catchers. They aren’t a safety net, or a last line of defence against functional defects, and they shouldnt be treated as such. And by the way, if your release testers are finding functional defects, some stern words need to be had with the QAs in your development teams. Your release test team are integration testers, so their chief role should be non-functional testing - studying the behaviour of your system end-to-end, checking the interactions of your APIs with the use of automated integrity checks, and deep exploratory testing based around any improvements and new features, all carried out with the kind of expert knowledge that is only carried by folks who know the software inside out. I spoke in more a little more detail about exploratory testing and how it should be directed in my article ‘There’s no such thing as Negative Testing’. It kills me to see smart, creative folks used to run the same series of tests from a spreadsheet week in and week out. The repetitive grunt work should be automated as much as possible - that’s the main purpose of automation, after all - giving the manual testers the best possible opportunity to carry out exploratory testing around new features, and generally making things more interesting than just running a test script from top to bottom. So as I mentioned earlier, if it feels mechanical, get something mechanical to do it. Then use that mechanisation to improve your efficiency, and either increase the time your manual testers have for exploratory testing, or to reduce the overall time your release spends in pre-production. As soon as your release is available, kick off your automated smoke tests. If your release manager is an amenable sort and they have their scheduling sorted out, have them schedule the release so that it finishes with just enough time to run your automated smoke pack before your release testers arrive at work. That way, as soon as they’re at their desks, they either have a green light to begin manual testing, or an alert indicating any problems (which will also have been sent to your ops team), meaning ops could potentially start looking into issues before the release testers have even had a chance to pester them. Then, as the levels of automation for release testing are increased, the manual testing carried out becomes proportionately more exploratory, allowing your release testers to really dedicate themselves to sniffing out and hunting down integration issues like a pack of mad dogs. They will exist solely to try to break things in the most interesting ways possible. And that sounds a lot more interesting than the robotic execution of the same set of test scripts in every single release, right? "
    }, {
    "id": 195,
    "url": "localhost:4000/top-10-books-every-agile-tester-should-read/",
    "title": "Top 10 Books Every Agile Tester Should Read",
    "body": "2016/10/30 - Top 10 Books for Agile Testers: [caption id=”attachment_10186” align=”aligncenter” width=”307”] Top-10-books-for-agile-testers[/caption] What books should Agile Testers read? Here, we have compiled a list of the top 10 books that every agile tester should read in order to understand the agile workflow and methodologies and succeed in their roles as agile testers. Please note, the list is not in any particular order. 1. Agile Testing: [caption id=”attachment_10140” align=”aligncenter” width=”260”] agile-testing-book[/caption] What does it really mean to be an “agile tester?” Do agile teams actually need members with QA backgrounds? What is the true role of a tester in Agile? Testing is a key component of agile development. The widespread adoption of agile methods has brought the need for effective testing into the limelight, and agile projects have transformed the role of testers. Much of a tester’s function, however, remains largely misunderstood. In Agile Testing, Crispin and Gregory define agile testing and illustrate the tester’s role with examples from real agile teams. They teach you  How to get testers engaged in agile development Where testers and QA managers fit on an agile team What to look for when hiring an agile tester How to transition from a traditional cycle to agile development How to complete testing activities in short iterations How to use tests to successfully guide development How to overcome barriers to test automationAgile Testing book is a must for agile testers, agile teams, their managers, and their customers. Get the Book! 2. User Stories Applied: [caption id=”attachment_10142” align=”aligncenter” width=”260”] user-stories-applied[/caption] The best way to build software that meets users’ needs is to begin with “user stories”: simple, clear, brief descriptions of functionality that will be valuable to real users. In User Stories Applied, you’ll learn what makes a great user story, and what makes a bad one. You’ll discover practical ways to gather user stories, even when you can’t speak with your users. Then, once you’ve compiled your user stories, Mike Cohn shows how to organize them, prioritize them, and use them for planning, management, and testing. By reading this book, you will learn  User role modeling: understanding what users have in common, and where they differ Gathering stories: user interviewing, questionnaires, observation, and workshops Working with managers, trainers, salespeople and other “proxies” Writing user stories for acceptance testing Using stories to prioritize, set schedules, and estimate release costs Includes end-of-chapter practice questions and exercisesAnd much more! User Stories Applied will be invaluable to every software developer, tester, analyst, and manager working with any agile method: XP, Scrum… or even your own home-grown approach. Get the Book!  3. Specification by Example: [caption id=”attachment_10145” align=”aligncenter” width=”239”] specifications-by-example[/caption] Specification by Example is a collaborative method for specifying requirements and tests. In this book, author Gojko Adzic distills interviews with successful teams worldwide, sharing how they specify, develop, and deliver software, without defects, in short iterative delivery cycles. Case studies in this book range from small web startups to large financial institutions, working in many processes including XP, Scrum, and Kanban. In Specification By Example the author describes the concept of executable specifications which are automated tests that read like documentation. This kind of documentation is always up to date, because it’s run daily against the software to test it. This book is written for developers, testers, analysts, and business people working together to build great software because it emphasizes how important it is to understand customer requirements and how to get it implemented so it meets the customer’s needs. Get the Book! 4. Continuous Delivery: [caption id=”attachment_10146” align=”aligncenter” width=”260”] continuous-delivery[/caption] Getting software released to users is often a painful, risky, and time-consuming process. After reading this book, you’ll learn the principles and technical practices that enable rapid, incremental delivery of high quality, valuable new functionality to users. Through automation of the build, deployment, and testing process, and improved collaboration between developers, testers, and operations, delivery teams can get changes released in a matter of hours—sometimes even minutes–no matter what the size of a project or the complexity of its code base. This book covers  Automating all facets of building, integrating, testing, and deploying software Implementing deployment pipelines at team and organizational levels Improving collaboration between developers, testers, and operations Developing features incrementally on large and distributed teams Implementing an effective configuration management strategy Automating acceptance testing, from analysis to implementation Testing capacity and other non-functional requirements Implementing continuous deployment and zero-downtime releases Managing infrastructure, data, components and dependencies Navigating risk management, compliance, and auditingGet the Book! 5. Experiences of Test Automation: [caption id=”attachment_10148” align=”aligncenter” width=”260”] experiences-of-test-automation[/caption] Test Automation has become a necessity for agile development. As applications and systems grow and become more complex, manual testing cannot cope. As technology changes, and more organizations move into agile development, testing must adapt—and quickly. Test automation is essential, but poor automation is wasteful—how do you know where your efforts will take you? This book addresses both management and technical issues, describing failures and successes, brilliant ideas and disastrous decisions and, above all, offers specific lessons you can use. Coverage includes  Test automation in agile development How management support can make or break successful automation The importance of a good testware architecture and abstraction levels Measuring benefits and Return on Investment (ROI) Management issues, including skills, planning, scope, and expectations Model-Based Testing (MBT), monkey testing, and exploratory test automation The importance of standards, communication, documentation, and flexibility in enterprise-wide automation Automating support activities Which tests to automate, and what not to automate Hidden costs of automation: maintenance and failure analysis The right objectives for test automation: why “finding bugs” may not be a good objective Highlights, consisting of lessons learned, good points, and helpful tipsExperiences of Test Automation will be invaluable to everyone considering, implementing, using, or managing test automation. Testers, analysts, developers, automators and automation architects, test managers, project managers, QA professionals, and technical directors will all benefit from reading this book. Get the Book! 6. Agile Lean ATDD: [caption id=”attachment_10149” align=”aligncenter” width=”248”] lean-agile-atdd[/caption] Within the framework of Acceptance Test-Driven-Development (ATDD), customers, developers, and testers collaborate to create acceptance tests that thoroughly describe how software should work from the customer’s viewpoint. By tightening the links between customers and agile teams, ATDD can significantly improve both software quality and developer productivity.  This book provides clear, straightforward guidance on how to use business-facing tests to drive software development. I’m excited about the excellent information in this book. It’s a great combination of the author’s experiences, references to other experts and research, and an example project that covers many angles of ATDD. A wide range of readers will learn a lot that they can put to use, whether they work on projects that call themselves lean or agile or simply want to deliver the best possible software product. Coverage includes  How to develop software with fully testable requirements How to simplify and componentize tests and use them to identify missing logic How to test user interfaces, service implementations, and other tricky elements of a software system How to identify requirements that are best handled outside software How to present test results, evaluate them, and use them to assess a project’s overall progress How to build acceptance tests that are mutually beneficial for development organizations and customers How to scale ATDD to large projectsGet the Book! 7. The Cucumber Book: [caption id=”attachment_10150” align=”aligncenter” width=”260”] the-cucumber-book[/caption] If you are a tester in an agile team, chances are that you have acceptance tests for user stories that you want to automate. This book teaches you the fundamental pieces of BDD, how to write Gherkin in correct and proper format that everyone understands, even your automated tests. You’ll learn how to use Cucumber’s Gherkin DSL to describe - in plain language - the behavior your customers want from the system. The cucumber book will show you how to express your customers’ ideas as a set of clear, executable specifications that everyone on the team can read. You’ll learn how to feed those examples into Cucumber and let it guide your development. You’ll build just the right code to keep your customers happy, and not a line more. Written by the creator of Cucumber and one of its most experienced users and contributors, The Cucumber Book is an authoritative guide that will give you and your team all the knowledge you need to start using Cucumber with confidence. Get the Book! 8. Explore It!: [caption id=”attachment_10151” align=”aligncenter” width=”261”] explore-it[/caption] In Agile development projects, Exploratory Testing is often seen as a complementary testing activity to Test Automation. In fact, Exploratory Testing, discovers more bugs than any other testing method. Software is full of surprises. No matter how careful or skilled you are, when you create software it can behave differently than you intended. Exploratory testing mitigates those risks. Learn essential skills of a master explorer, including how to analyze software to discover key points of vulnerability, how to design experiments on the fly, how to hone your observation skills, and how to focus your efforts. Part 1 introduces the core, essential skills of a master explorer. Part 2 builds on that foundation. Part 3 brings the techniques back into the context of a software project. Get the Book! 9. Agile Tester - One for all, All for one: [caption id=”attachment_10152” align=”aligncenter” width=”231”] agile-tester[/caption] This eBook will go through the basics of the ISTQB Agile Test Foundation materials. It discusses the full learning materials and will prepare you for certification.  Agile Software Development Fundamental Agile Testing Principles, Practices and Processes Agile Testing Methods, Techniques and ToolsThe eBook also cover the material you need to pas the International Agile Tester Foundation certification from www. scrum. as which is the new strong education schema growing rapidly all over the world. This have much lower examination fee and can be taken from home. Get the Book! 10. Lessons Learned in Software Testing: [caption id=”attachment_10153” align=”aligncenter” width=”260”] lessons-learned-in-software-testing[/caption] And last but not least…The book that Every Tester Should Read. This book is filled with over 200 lessons gleaned from over 30 years of combined testing experience. Each lesson is an assertion related to software testing, followed by an explanation or example that shows you the how, when, and why of the testing lesson. More than just tips, tricks, and pitfalls to avoid, Lessons Learned in Software Testing speeds you through the critical testing phase of the software development project without the extensive trial and error it normally takes to do so. The ultimate resource for software testers and developers at every level of expertise. Get the Book! "
    }, {
    "id": 196,
    "url": "localhost:4000/why-would-you-want-to-automate-a-test/",
    "title": "Why Would You Want To Automate a Test?",
    "body": "2016/10/29 - [caption id=”attachment_10128” align=”aligncenter” width=”750”] why-automate-testing[/caption] Why would you automate a test? What benefits do we get with test automation? Quite often when people get involved in automated testing, their main focus shifts from designing good tests to ensuring that the automated code can actually execute and run the test. During the sprint when team members are under pressure to deliver the stories in a limited time frame, there is usually not enough time to test all the planned scenarios, let alone writing automated test scripts to test the new functionality. We can get bogged down with the details of the work, coding, reviewing, executing and forget about the main reason why we actually automate a test! Why do we automate a test?: This is one of the questions I ask when I interview candidates for a Test Automation role and to my surprise, many candidates seem to miss the main and most important reason to automate a test. Some of the answers I get from candidates are quite credible, but still not the answer that I’m looking for. Some of the answers I get to the above question are: Increase Test Coverage: This answer is quite valid, but how do we define coverage? If we have 100 tests, how can we measure the percentage coverage? With a mature test automation practice in place, you could be running hundreds of tests in a relatively short period of time. Because of this, we can create more test cases, more test scenarios and test with more input data for a given feature and thus gain more confidence that they system is working as expected. However, in testing and especially test automation, more tests don’t really mean better quality or more chance of finding bugs. In a post by Martin Fowler, where he discuses Test Coverage, he mentions  If you make a certain level of coverage a target, people will try to attain it. The trouble is that high coverage numbers are too easy to reach with low quality testing. At the most absurd level you have AssertionFreeTesting. But even without that you get lots of tests looking for things that rarely go wrong distracting you from testing the things that really matter. Save Time: This answer is also true as you can spend valuable time doing interesting exploratory testing while the automated tests are running. However, for a brand new feature that has been developed, it could actually take longer to write automated scripts than to test the feature manually in the first instant. So, it is important to note that to save time from automated tests, it requires an initial increased effort in scripting the automated tests, making sure they are code reviewed, and that there are no hiccups in the execution of automated tests. Find More Bugs: This answer worries me sometimes as I have never seen any metrics that suggests there were more bugs found by automation than manual / exploratory testing. Automated tests generally check for any regression in the system after new code has been implemented. There is always more chance of finding bugs in new features than in existing functionality. Furthermore, there are other reasons why automated tests fail to find defects. Replace Manual Testers: This is probably the worst answer I have heard in regards to why we automate a test. There is a clear distinction between what a manual tester does and what an automated test checks. Automated testing is not testing, it is checking of facts. In order to be able to automate a test, we have to know the expected outcome so that we can check for the valid or invalid outcome. This is what gives us true or false, positive or negative, pass or fail. Testing on the other hand is an investigation exercise, where we design and execute tests simultaneously. Many things can behave differently where only an observant human tester can notice. Good manual testers will always be needed because of the different mindset and the ability to question the system. Improve Quality: Although automated tests are capable of giving us quick feedback and alert us about the health of an application, so that we can revert any code change that has broken the system, automated testing on its own does not improve quality. Just because we have a mature test automation in place does not guarantee that no bugs escape in to production. We can improve quality by ensuring correct practices are followed from start to finish of a development cycle. Quality is not an afterthought; it should be baked in right from the beginning. It is not enough to rely on automated tests to get a picture of the quality of the product. So, what is the main reason we automate a test?: The short answer is _repeatability.  _We automate a test because we need to execute the same tests over and over again. Would you want to automate a test if you were only going to run it once and forget about it? Of course not! The time and effort that you spend on automating the test, you could have executed it manually. Now, by definition, we automate repeatable tests, i. e. regression tests, that we need to execute frequently. So, next time, when you want to automate a test, take a step back and think how often are you likely to execute this test? Is it really worth the effort to automate the test? "
    }, {
    "id": 197,
    "url": "localhost:4000/risk-based-testing-agile/",
    "title": "Why Risk Based Testing is Important in Agile Projects",
    "body": "2016/10/28 - Risk Based Testing in Agile: [caption id=”attachment_10242” align=”aligncenter” width=”624”] risk-based-testing[/caption] In previous article, we looked at Why Exploratory Testing is Important in Agile Projects. In this article, Dave Higgins explains why short SDLCs in agile software development require a risk based testing from QA - and why it’s nothing to be scared of. As a QA professional, one of your biggest fears will always be allowing something big to get past you. You miss something that ends up with your company directors being dragged out of bed in the middle of the night, and requires diversion to a shunt page or honest-to-goodness downtime for your site to get fixed. That will inevitably end up with all those awkward questions being asked about why this issue was missed in testing. I don’t have an immediate answer to those questions, and your mileage may vary depending on the scale of your issue and the reason behind it, but I’d strongly advise against saying ‘Hey, it’s not like QA put the bug in there in the first place!’ and throwing your developers under the bus unless you want to completely alienate yourself within your technology team. In short, if you’ve missed a P1 shipstopper issue you’re in trouble, so prepare to suck it up. But how can you make sure that this never happens to you? You can’t. And that’s okay. We’ve all heard the trite saying about the one thing that you don’t test being the one thing that will break production. But to me, that particular pearl of wisdom can be lumped into the same category as your keys always being in the last place you look. By definition, edge case issues occur in areas that you’d never dream of testing, or involve steps that you’d never believe that anyone would actually take. So even if, for some insane reason, you’ve opted to attempt 100% test coverage, and you’ve decided to test every user situation that you can think of, you cannot and will not cover everything. Taking zero issues to production is an utterly impractical goal that will only lead to frustration and disappointment when it is inevitably not met. Most folks in modern technology organisations understand that shorter SDLCs come with risks, so in these environments, QA’s function is not to catch everything, but to keep the risk of issues making it to production to a minimum. Sadly, not all business stakeholders see things that way, and it’s down to technology directors to make them understand that going faster comes at a price, and as per Brooks’s Law, throwing more people at QA will only muddy the waters. So it’s important that QA thinks carefully about their priorities when testing at speed. Of course, it’s vital that you ensure that requirements have been met, and that your software does what it has been designed to do (according to the precise needs of the business, not your interpretation or your development team’s interpretation of those needs - if your sprint planning sessions are done right, you’ve already nailed this). But that isn’t the be-all and end-all of your testing scope, and of course, just testing the happy path is a recipe for disaster. As a QA professional you know what the software is supposed to do in detail, but end users haven’t read the user stories, and they inevitably wander off and do stuff they’re not supposed to. So once you’ve established the software’s fitness for purpose, exploratory testing is necessary to ensure your technology director doesn’t get that 3am phone call from the company president telling him that his latest release is causing satellites to drop out of the sky. But how far down the exploratory testing rabbit hole do you go? There’s an old joke that goes something like this: A QA Engineer walks into a bar. He orders a beer. He orders 3 beers. He orders 2976412836 beers. He orders 0 beers. He orders -1 beer. He orders q beers. He orders nothing. Él ordena una cerveza. He orders a deer. He tries to leave without paying. He starts ordering a beer, then throws himself through the window half way through. He orders a beer, gets his receipt, then tries to go back. He orders a beer, goes to the door of the bar, throws a handful of cookies into the street, then goes back to the bar to see if the barmaid still recognises him. He orders a beer, and watches very carefully while the barmaid puts his order into the till to make sure nothing in his request got lost along the way. He starts ordering a beer, and tries to talk the barmaid into handing over her personal details. He orders a beer, sneaks into the back, turns off the power to the till, and waits to see how the barmaid reacts, and what she says to him. He orders a beer while calling in thousands of robots to order a beer at exactly the same time. Risk Based Testing: With a bit more time than I’m willing to put into it, that list could go on and on, and in the same way, you could easily overdo exploratory testing. So you must properly identify the areas that your software touches on and flows through, and the situations which are most likely to occur on a regular basis to reduce the time the software spends in test, and to help in speeding up your development cycle. And that’s the thinking behind risk based testing. In a world where short SDLCs and being first to production, or at least the fastest of followers, is business critical, this is the only feasible approach for QA. The idea is that you pinpoint the essential function of the change, determine the scope for testing in and around that change, analyse the associated risks, then plan and prioritise your testing accordingly. So, you start by making sure the change is fit for purpose and, just as importantly, does no harm. This is non-negotiable, and you can’t sign off without giving this assurance. That should be followed by smart, correctly prioritised exploratory testing of the areas which are next most likely to cause problems, as determined by your intimate knowledge of the system under test. You’d be forgiven for missing an edge case that only happens at 23:15 on one day of the year on the Kenyan version of your software when it is accessed via IE6. But a quick study of your application’s user metrics will allow you to properly assess which points of sale, browsers, devices etc. , are the most popular with your users, and that will allow you to properly prioritise which access points you use while testing. Because that’s the real key to using risk based testing properly - strong knowledge of your systems and architecture, and a good understanding of the paths your users will take. As a QA Engineer, you should be familiar with all the touch points around the functions you are responsible for testing, how they interact with each another as well as other applications in your overall architecture, and all the paths the user will take into, through, and out of your area. This will allow you to easily identify and isolate the important areas for any given change, and allow you to test just around those areas. Do you cover everything? No, absolutely not. Like I said before, that’s an unrealistic expectation. But properly planned and executed risk based testing will allow you to go faster AND stop phones from ringing in the middle of the night. Unless, of course, you’re testing software to automate alarm calls. Then that’s WAD. "
    }, {
    "id": 198,
    "url": "localhost:4000/top-8-open-source-bug-tracking-tools/",
    "title": "Top 8 Open Source Bug Tracking Tools",
    "body": "2016/10/27 - Open source Bug Tracking Tools: : A bug tracking system or defect tracking system is a software application that keeps track of reported software bugs in software development projects. It may be regarded as a type of issue tracking system. Below is a list of Open source Bug Tracking Systems. Bugzilla: Bugzilla is a Mozilla Foundation supported / developed bug tracking system that allows its users to log and track defects in their product effectively. It is a very mature and feature rich application with features like advanced search capabilities, bug lists in multiple formats, scheduled reports, automatic duplicate bug detection, capability to file / modify bugs by email, time tracking, request system, private attachment and comments, patch viewer etc. It is a widely adapted product used by various big open source projects like Linux Kernel dev team, Apache dev team, GNOME dev team and popular companies like Open Office, NASA, Facebook etc. and is one of the most recommended bug tracking systems. Best Open Source Test Management Tools Download Bugzilla Mantis BT: Mantis BT is a web-based bug tracking system that not only keeps track of bugs, but includes a user system so that multiple users can interact and multiple projects can be tracked. The application has features like an integrated wiki, chat, RSS feeds, time tracking, source code integration, built in reporting, email notifications, attachments, multi-DBMS support, support for mobile devices etc. Easier to install and administer and infinitely cheaper than other commercial software, Mantis is an obvious choice for any small to medium sized company. Useful Open Source Testing Tools for Agile Testers Download Mantis Trac: Trac is an enhanced wiki and issue tracking system for software development projects. It provides a simplistic and easy to use web interface. Features include an interface to Subversion (and other version control systems), convenient reporting facilities, project management features including roadmap and milestone tracking, user management, wiki and support for a range of plugins. It is a stable and light weight system; however you may lose out some of the advanced features provided by other bug tracking systems. Open Source Mobile Test Automation Tools Download Trac Redmine: Redmine is a free and open source, web-based project management and bug tracking tool. It provides integrated project management features, supports multiple projects, issue tracking, support for multiple version control options, flexible role based access control, calendar &amp; Gantt charts to aid visual representation of projects and their deadlines, feeds &amp; email notifications, time tracking, project wiki, project forums etc. Feature rich product recommended where stability isn’t a critical requirement. Download Redmine Request Tracker: Request Tracker is an enterprise-grade ticketing / helpdesk software which enable a group of people to intelligently and efficiently manage tasks, issues, and requests submitted by a community of users. It is widely used as a helpdesk system. RT manages key tasks such as the identification, prioritization, assignment, resolution and notification required by enterprise-critical applications including project management, help desk, NOC ticketing, CRM and software development, provides a mobile-optimized interface for iPhone, Android and Web OS devices, Dashboards and relationship graphs, rich text editing, easy branding and custom theming. RT offers a lot of flexibility to its users i. e. by configuring it, it can work the way you want it to work. Download Request Tracker Fossil: Fossil is a distributed bug tracking, version control, wiki and blog mechanism all in a single integrated package. It has a built-in and easy-to-use web interface, supports auto sync mode, is cgi enabled, provides simple networking, is a robust and reliable software and is easy to use &amp; deploy with one single binary that works on every platform you can imagine. Download Fossil Bug-A-Boo: Bug-A-Boo is a web based bug reporting system for Linux. It is released under the terms of the GNU General Public License (GPL). It runs on any web host server providing CGI functionality. Bug-A-Boo does not need any database server but brings along its own local tables it accesses with tdbengine. Thus it is easy to set up and a real performance monster. It features multi language support, 3 different user levels, layouts/themes, email notifications, individual display profiles for every user and it has almost “no limits in numbers”. At the moment there are available either an English or a German translation. Download Bug-a-boo Php Bug Tracker: Php Bug Tracker is a web-based bug tracker with functionality similar to other issue tracking systems, such as Bugzilla. Design focuses on separating the presentation, application, and database layers. Php Bug Tracker is lightweight and easy to install, operate and administer. Most text can be customized for your application. Download Php Bug Tracker "
    }, {
    "id": 199,
    "url": "localhost:4000/7-deadly-sins-of-test-automation/",
    "title": "7 Deadly Sins of Test Automation",
    "body": "2016/10/26 - 7 Deadly Sins of Test Automation: Automated Testing is great. You can run hundreds of tests with a click of a button and get a quick feedback on the health of the system. You can find regression issues relatively quickly and stop a serious defect getting shipped into production. However, senior management often view automated testing as a silver bullet in reducing testing effort/costs and increasing delivery speed, but it should be noted that not all approaches to automated testing are equal and there are some pitfalls that should be avoided. In this article, Adrian Smith of Agile Engineering Design takes a look at the 7 deadly sins of test automation: 1. Envy: Flawed comparison between manual testing and automation Automated tests are not a replacement for manual exploratory testing. A mixture of testing types and levels is needed to achieve the desired quality mitigate the risk associated with defects. This is because testing is not merely a sequence of repeatable actions. The automated testing triangle originally described by Mike Cohn explains the investment profile in tests should focus at the unit level and then reduce up through the application layers. 2. Gluttony: Over indulging on commercial testing tools Many commercial testing tools provide simple features for automating the capture and replay of manual test cases. While this approach seems sound, it encourages testing through the user-interface and results in inherently brittle and difficult to maintain tests. Additionally, the cost and restrictions that licensed tools place on who can access the test cases is an overhead that tends to prevent collaboration and team work. Furthermore, storing test cases outside the version control system creates unnecessary complexity. As an alternative, open source test tools can usually solve most automated testing problems and the test cases can be easily included in the version control system. 3. Lust: Loving the UI so much that all tests are executed through the UI Although automated UI tests provide a high level of confidence, they are expensive to build, slow to execute and fragile to maintain. Testing at the lowest possible level is a practice that encourages collaboration between developers and testers, increases the execution speed for tests and reduces the test implementation costs. Automated unit tests should be doing a majority of the test effort followed by integration, functional, system and acceptance tests. UI based tests should only be used when the UI is actually being tested or there is no practical alternative. 4. Pride: Too proud to collaborate when creating tests Test driven development is an approach to development that is as much a design activity as it is a testing practice. The process of defining test cases (or executable specifications) is an excellent way ensuring that there is a shared understanding between all involved as to the actual requirement being developed and tested. The practice is often associated with unit testing but can be equally applied to other test types including acceptance testing. 5. Sloth: Too lazy to maintain automated tests The cost and rapid feedback benefits of automated tests are best realised when the tests are regularly executed. This has the effect of highlighting failures and providing continuous feedback about the health of the system. If your automated tests are initiated manually rather than through the CI continuous integration system then there is significant risk that they are not being run regularly and therefore may in fact be failing. Make the effort to ensure automated tests are executed through the CI system. 6. Rage: Frustration with slow, brittle or unreliable tests Unreliable tests are a major cause for teams ignoring or losing confidence in automated tests. Once confidence is lost the value initially invested in automated tests is dramatically reduced. Fixing failing tests and resolving issues associated with brittle tests should be a priority to eliminate false positives. 7. Avarice (Greed): Trying to cut costs through automation Testing tool vendors often try to calculate a Return-on-Investment based purely on labour savings. This analysis is unreliable and under values the importance of testing, the investment required to adopt automation practices and the ongoing maintenance costs. "
    }, {
    "id": 200,
    "url": "localhost:4000/overview-of-scrum-agile-development-methodology/",
    "title": "Overview of Scrum Agile Development Methodology",
    "body": "2016/10/25 - What is Scrum?: Scrum is an agile development methodology for managing and completing projects. It is a way for teams to work together to achieve a set of common goals. Scrum is an iterative and incremental approach to software development, meaning that a large project is split into a series of iterations called “Sprints”, where in each sprint, the goal is to complete a set of tasks to move the project closer to completion. Each sprint typically lasts 2 to 4 weeks or a calendar month at most. Building products one small piece at a time encourages creativity and enables teams to respond to feedback and change and to build exactly what is needed. In scrum, product is designed, coded and tested in the sprint.  A key principle of Scrum is its recognition that during a project the customers can change their minds about what they want and need (often called “requirements churn”), and that unpredicted challenges cannot be easily addressed in a traditional predictive or planned manner. As such, Scrum adopts an empirical approach—accepting that the problem cannot be fully understood or defined, focusing instead on maximizing the team’s ability to deliver quickly and respond to emerging requirements. Scrum Framework: The scrum framework has three components: Roles, Events and Artifacts. Roles: Product Owner:  Defines features and release plans Prioritize features every iteration as needed Accept or reject work resultsScrum Master:  Responsible for enacting Scrum values and practices Ensure that the team is fully functional and productive Enable close cooperation across all roles and functionsTeam:  Cross-functional:Programmers, testers, user experience designers, etc.  Members should be full-time Teams are self-organizingSprint Events: Daily scrum meeting:  Daily review meeting for 10-15 mins Status review and not for problem solving All sprint team members participate More on daily scrum meetingSprint review:  Demo of new features to customer/product owner Team presents work accomplished during the sprint All major stakeholders participateSprint retrospective:  Periodic post mortem to review what’s working and what’s not Done after every sprint All major stakeholders participateArtifacts: Product backlog:  A list of all desired work on the project Ideally expressed such that each item has value to the users or customers of the product Prioritized by the product owner Reprioritized at the start of each sprintSprint Backlog:  A list of tasks identified by the Scrum team to be completed during the sprint.  The team selects the items and size of the sprint backlog Sprint Burndown Charts:  Chart updated everyday, shows the work remaining within the sprint Gives an indication of the progress and whether some stories need to be removed and postponed to the next sprint In Summary:    Scrum is an agile development methodology     It is an Iterative and Incremental approach to developing software     There are three main roles in Scrum: Product Owner – Scrum Master – Scrum Team     Each Sprint typically lasts between 2 to 4 weeks     Product Owner creates and prioritizes a list of wishlist items called the product backlog     In Sprint Planning Meeting, the Scrum Team decides how many items from the backlog can be developed in a Sprint     Every day of the Sprint, the team get together and do a stand-up called the Daily Scrum Meeting     Testing and Development is done together rather than separate activities     During the Sprint, Scrum Master tries to remove any impediments and blockers so the Scrum Team can continue to work     At the end of the Sprint, the Team showcase the developed features, which are potentially candidates for release, to the business     At the end of the Sprint, there is also a Sprint Review at the Retrospective Meeting  "
    }, {
    "id": 201,
    "url": "localhost:4000/agile-test-strategy-example-template/",
    "title": "Agile Test Strategy Example Template",
    "body": "2016/10/24 - Agile Test Strategy: In an agile environment, where we work in short sprints or iterations, each sprint is focused on only a few requirements or user stories, so it is natural that documentation may not be as extensive, in terms of both number and content. Previously we concluded that we may not need to have an extensive test plan in agile projects for each sprint due to time constraints, but we do require a high-level agile test strategy as a guideline for the agile teams. The purpose of the agile test strategy document is to list best practices and some form of structure that the teams can follow. Remember, agile does not mean unstructured. Here, we take a look at a sample Agile Test Strategy and what to include in the document. Related: Testing in DevOps A test strategy usually has a mission statement which could be related to the wider business goals and objectives. A typical mission statement could be:  To Constantly Deliver Working Software that Meets Customer’s Requirements _by means of _Providing Fast Feedback _and _Defect Prevention, rather than Defect Detection. Supported by:    No code may be written for a story until we first define its acceptance criteria/tests  A story may not be considered complete until all its acceptance tests pass In the Agile Test Strategy document, I would also include a reminder to everyone about Quality Assurance    QA is a set of activities intended to ensure that products satisfy customer requirements in a systematic, reliable fashion.     In SCRUM (agile) QA is the responsibility of everyone, not only the testers. QA is all the activities we do to ensure correct quality during the development of new products.  Test Levels: [caption id=”attachment_10412” align=”aligncenter” width=”590”] Agile-Testing-Quadrants[/caption]  Unit Testing: WHY: To ensure code is developed correctly WHO:  Developers / Technical Architects WHAT: All new code + re-factoring of legacy code as well as Javascript unit Testing WHEN: As soon as new code is written WHERE: Local Dev + CI (part of the build) HOW: Automated, Junit, TestNG, PHPUnit API / Service Testing: WHY: To ensure communication between components are working WHO:  Developers / Technical Architects WHAT: New web services, components, controllers, etc WHEN: As soon as new API is developed and ready WHERE: Local Dev + CI (part of the build) HOW: Automated, Soap UI, Rest Client Acceptance Testing: WHY: To ensure customer’s expectations are met WHO:  Developer / SDET / Manual QA WHAT: Verifying acceptance tests on the stories, verification of features WHEN: When the feature is ready and unit tested WHERE: CI / Test Environment HOW: Automated (Cucumber) System Testing / Regression Testing / UAT: WHY: To ensure the whole system works when integrated WHO:  SDET / Manual QA / Business Analyst / Product Owner WHAT: Scenario Testing, User flows and typical User Journeys, Performance and security testing WHEN: When Acceptance Testing is completed WHERE: Staging Environment HOW: Automated (Webdriver) Exploratory Testing Product Backlog: Most common cause of software development failure is due to unclear requirements and different interpretation of requirements by different members of the team. User stories should be simple, concise and unambiguous. As a good guideline, it is best to follow the INVEST model for writing user stories. A good user story should be: Independent (of all others) Negotiable (not a specific contract for features) Valuable (or vertical) Estimable (to a good approximation) Small (so as to fit within an iteration) Testable (in principle, even if there isn’t a test for it yet) The following format should be used to write user stories As a [role] I want [feature] So that [benefit] It is important not to forget the “Benefit” part, as everyone should be aware of what value they are adding by developing the story. Acceptance Criteria Each of the User stories must contain acceptance criteria. This is possibly the most important element which encourages communication with different members of the team. Acceptance criteria should be written at the same time the user story is created and should be embedded within the body of the story. All acceptance criteria should be testable. Each Acceptance Criteria should have a number of Acceptance Tests presented as scenarios written in Gherkin format, e. g. Scenario 1: Title Given [context] And [some more context]. . . When  [event] Then  [outcome] And [another outcome]. . . Story Workshops / Sprint Planning: In each story workshop, everyone in the team learns about the details of the stories so developers and QA know the scope of the work. Everybody should have the same understanding of what the story is about. Developers should have a good understanding of the technical details that are involved in delivering the story, and QA should know how the story will be tested and if there are any impediments to test the stories. Related:  Is Automated Testing on the UI Worth the Effort? Test Automation Strategy For Agile ProjectsPreventing Defects In story workshops, PO, BA, Dev, and QA must be involved. Scenarios (valid, invalid and edge cases) should be thought of (QA can add huge value here by thinking abstractly about the story) and written down in feature files. It is important to note that it is the scenarios (more than anything else) that will reveal defects when testing the product, so the more effort and time spent on this activity, the best results at the end. Because the majority of defects are due to unclear and vague requirements, this activity will also help prevent implementation of incorrect behavior as everyone should have the same understanding of the story. Likewise, in the sprint planning meetings, the estimates given for a story should include the testing effort as well and not just coding effort. QA (manual and automation) must also be present in the sprint planning meetings to provide an estimate for testing of the story. Development: [caption id=”attachment_10414” align=”aligncenter” width=”590”] test-automation-pyramid[/caption] When development starts, new production code and/or modification to legacy code should be backed by unit tests written by developers and peer-reviewed by another developer or a skilled SDET. Any commit to the code repository should trigger an execution of the unit tests from the CI server. This provides a fast feedback mechanism to the development team. Unit tests ensure that the system works at a technical level and that there are no errors in the logic. Developer Testing: As a developer, behave as if you don’t have any QA in the team or organization. It is true that QAs have different mindset but you should test to the best of your ability. You think you are saving time by quickly moving on to the next story, but in reality, when a defect is found and reported, it takes longer to rectify the issue than spending few minutes making sure the feature works well. Any new code and/or refactoring of legacy code should have appropriate unit tests that will be part of the unit regression test. Automated Acceptance Tests and Non-functional Testing: The automated acceptance tests include Integration Tests and Service Tests and UI tests which aim to prove the software works at a functional level and that it meets user’s requirements and specifications. Automated acceptance tests are usually written in Gherkin language and executed using a BDD tool such as cucumber. Remember: Not all tests need to be automated! Because these tests typically require communication over HTTP, they need to be executed on a deployed application, rather than run as part of the build. Non-functional tests (Performance and Security) tests are as equally important as functional tests, therefore need to be executed on each deploy. Performance Tests should check performance metrics on each deploy to ensure no performance degradation. Security Tests should check for basic security vulnerabilities derived from OWASP It is vital that this should be a completely automated process with very little maintenance to get the most benefit out of automated deployments. This means there should be no intermittent test failures, test script issues, and broken environment. Failures should only be due to genuine code defects rather than script issues, therefore any failing test which is not due to genuine failures should be fixed immediately or removed from the automation pack, to be able to get consistent results. Regression Testing: Not expecting to find many defects. Their purpose is only to provide feedback that we haven’t broken major functionality. There should be a very little amount of manual regression testing. Smoke pack – Should be no more than 15 mins This pack contains only high-level functionality to make sure the application is stable enough for further development or testing. For example, for an eCommerce website, tests included in this pack could be:  Product Search, Product Review Purchase Item Account Creation / Account LoginFull regression pack – should be no more than 1 hour This pack contains the full regression suite of tests and contains everything else which is not included in the smoke pack. Here, the goal is to get a quick feedback with a larger set of tests. If the feedback takes more than 1 hour, it is not quick. Either reduce the number of tests by using pairwise test technique, create test packs based on risk or run the tests in parallel.  Read more on best practices for regression testing UAT and Exploratory Testing: There is no reason why UAT and exploratory testing cannot run in parallel with the automated acceptance tests. After all, they are different activities and aim to find different issues. The aim of UAT is to ensure that the developed features make business sense and helpful to customers. PO (Product Owner) should run User Acceptance Tests or Business Acceptance Tests to confirm the built product is what was expected and that it meets user’s expectations. Exploratory testing should focus on user scenarios and should find bugs that automation misses. Exploratory testing should not find trivial bugs, rather it should find subtle issues. Done Criteria: Once all the above activities are completed and no issues found, the story is Done! The above are some guidelines on what can be included in an Agile Test Strategy Document. Obviously this needs to be tailored to your organization’s needs, but hopefully, this template would assist you in creating your own Agile Test Strategy document. "
    }, {
    "id": 202,
    "url": "localhost:4000/what-is-daily-stand-up-in-scrum/",
    "title": "What is Daily Stand-up in Scrum?",
    "body": "2016/10/23 -  One of the features of the scrum development methodology is the daily stand-up or daily scrum meeting. The aim of this short meeting is to get an overview of how the team is progressing. Characteristics of the daily stand-up:    The meeting usually takes about 15 minutes and happens at the start of the day     Participants are Scrum Master, the Scrum Team and Product Owner     The meeting is held with all people standing up so as to not prolong the meeting more than 15 minutes     The Scrum Master takes charge of the meeting   Each member of the Scrum Team is expected to answer three questions:     What did you do yesterday?   What will you do today?   Are there any blockers or impediments preventing you from doing your work?    Each member of the Scrum Team should take no more than 2 to 3 minutes to answer the above questionsThe first two questions are about progress, and the last question is about removing any obstacles to progress. This Agile Training Video covers the following topics    What is the purpose of the daily stand-up? When do we have the meeting?     Example answers to the three questions: What I did yesterday, what I will do today, what impedes me     Organizational impediments and the role of the Scrum Master during Sprint execution.     Team self organization during the Sprint. (“The team is utterly self managing. ” – Ken Schwaber)     Team’s use of the task-board (sometimes mislabeled “Kanban board”) to represent the Sprint Backlog.     Example Sprint Tasks.     Team’s collective ownership of Product Backlog Items and Sprint Tasks.     Less skilled team member as point person of a Sprint Task.     Cursory overview of Agile engineering practices: Pair programming, Test-Driven Development (TDD), refactoring, and continuous integration.     Should the Product Owner attend the Daily Scrum?     Use of the sidebar to stay within the 15-minute time-box.     Involving traditional QA people in Agile development.     What happens when team members ignore team agreements?  "
    }, {
    "id": 203,
    "url": "localhost:4000/best-open-source-test-management-tools/",
    "title": "Best Open Source Test Management Tools",
    "body": "2016/10/22 - Open source and Free Test Management tools. Here we have selected the top best open source test management tools. They are totally free to download and to use in your projects. Test Management tools are very important to any test team. Test teams use these tools to help capture requirements, design test cases, map test cases to requirements, test execution reports and much more. Companies may use one to many tools for this, which range from very expensive to open source. My advice would be to pick a tool that can meet most of your current and near future needs. Related:  Open Source Tools for Agile Testers Open Source Mobile Test Automation Tools TestLodge - Test Management ToolBelow is a list of completely free and open source test management tools that may come in handy. Klaros-Testmanagement: : Klaros-Test­management features components for planning, executing and evaluating tests and supports requirement coverage as well as agile development methodologies like Scrum or Kanban. Interfaces to issue tracking systems, test automation tools and continuous integration servers allow a seamless integration in your development environment. Built-in reporting capabilities support the creation of individual reports for comprehensive evaluation of test results. Download Klaros-Testmanagement Tarantula Agile Test Management Tool: Tarantula is a modern tool for managing software testing in agile software projects. Tarantula is free, licensed as open source software under GNU GPLv3. Tarantula aims to be the best open source test management tool, especially in: *  Agile Testing*  Testing management*  Reporting*  Usability**[Download Tarantula](http://www. testiatarantula. com/  Download Tarantula Open Source Test Management Tool )**## Testcube![testcube-open-source-test-management](http://69. 164. 212. 71/wp-content/uploads/2010/01/testcube-open-source-test-management-e1426288203795. png)Jataka Testcube is a Web-based test case management tool designed to integrate &amp; track enterprise-wide Test Cases. TestCube includes everything needed to manage the test process, it can save testers the hassle of installing separate applications that are necessary for the testing process. [**Download Testcube**](http://www. jatakasource. org/testcube/)## QABook Free Test Management Tool![qa-book-free-test-management-tool](http://69. 164. 212. 71/wp-content/uploads/2010/01/qa-book-free-test-management-tool-e1426288468100. png)QABook™ can be deployed for individuals, teams or an entire company through the three versions available. QABook™ has been designed to address many of the issues that exist within other test management products. It allows you to create, edit and manage requirements, test cases, defects, environments, project success criteria, reporting and more. **[Download QABook](http://www. freetestmanagementtool. com/index. html  Download Free Test Management Tool )**Testopia: A software testing case management extension for Bugzilla. It is designed to be a generic tool for tracking test cases, allowing for testing organizations to integrate bug reporting with their test case run results. Though it is designed with software testing in mind, it can be used to track testing on virtually anything in the engineering process. Download Testopia qaManager: qaManager is a platform independent web-based application for managing QA Projects Effectively with a very simple installation. qaManager has Project tracking, Resource Management, TC Management, Online Library, Alerts and more. It’s Powered by OpenXava. Download qaManager Radi: Application Radi-testdir is a light-weight test Management tool. Radi supports test directory features like configuring the test plan, updating (create/edit) the test results for the test image/build, Backup, User Management. Download Radi RTH: a web-based tool designed to manage requirements, tests, test results, and defects throughout the application lifecycle. The tool provides a structured approach to software testing and increases the visibility of the testing process by creating a common repository for all test assets including requirements, test cases, test plans, and test results. Download RTH RTH-Turbo: An optimized version of RTH, a testing management tool, that allows: requirement management; test case management; defect tracking; create test plans; analyze your test results. This project was originally created from RTH version 1. 2, and this new branch and version is more powerful and optimized. Download RTH-Turbo TCW: Test Case Web (TCW) is an online TCM system built with PHP and a SQL back-end. It provides an efficient means for generation, organization, and execution reporting of test cases among projects and by multiple testers and versions. It provides various at-a-glance views of the test suite for easy status determination and test suite navigation. TCW also provides basic reporting capabilities and per-project access control. Download TCW Testitool: A Web-based application for QA test planning. It creates a test plan and populates it with test cases, maps test cases to functional requirements, instantiates a test plan, begins executing test cases and marks them as successful or failed, generates reports on your test plans, copies test plans and test cases, and tailors test plan instances by adding and removing test cases from them. Download Testitool TestLink: Web-based software testing management and test execution system allowing QA teams to create, manage, execute and track test cases and organize them into test plans. Download Testlink TestMaster: Testmaster is a test case logging, reporting, and test automation tool, much like the commercial product test director. It was conceived while I was working in a testbed and was asked to perform testing by taking some printed sheets from a folder, marking off which tests I had executed and emailing my progress every day. Needless to say, I didn’t do that for long and Testmaster was born. Download TestMaster WebTst: WebTst is an open-source test management tool aimed at creating and managing user-centric testing. Download WebTst XQual Studio (XStudio): A free 100% graphical and modular in design test management application that handles the complete life-cycle of your QA/testing projects from end to end: users, requirements, specifications, development projects (scrum oriented), SUTs, tests, test plans, test reports, and test campaigns. Download XQual Please comment below on your thoughts/experience on any of the open source test management tools listed above and/or if you know of any other tools that should be added. "
    }, {
    "id": 204,
    "url": "localhost:4000/how-to-test-responsive-web-design/",
    "title": "How to Test Responsive Web Design",
    "body": "2016/10/21 - Testing Responsive Web Design: [caption id=”attachment_10607” align=”aligncenter” width=”550”] testing-responsive-design[/caption] How do you test a responsive website? What are the challenges involved in testing websites in different devices? How is testing a website on a desktop monitor different from testing on a handheld device such as a mobile phone? What tools can we use to test responsive websites? What is responsive web design?: Responsive web design (RWD) is an approach to web design aimed at crafting sites to provide an optimal viewing experience—easy reading and navigation with a minimum of resizing, panning, and scrolling—across a wide range of devices (from desktop computer monitors to mobile phones). A site designed with RWD adapts the layout to the viewing environment by using fluid, proportion-based grids, flexible images, and CSS3 media queries, an extension of the @media rule, in the following ways:    The fluid grid concept calls for page element sizing to be in relative units like percentages, rather than absolute units like pixels or points.     Flexible images are also sized in relative units, so as to prevent them from displaying outside their containing element.     Media queries allow the page to use different CSS style rules based on characteristics of the device the site is being displayed on, most commonly the width of the browser.  Challenges in testing responsive web design: Many people nowadays use their mobile phones or tablets to access websites, so testing a responsive web design is important because the user experience on mobile devices is quite different from desktops. Possibly the most challenging part of testing a responsive website is making sure the website works as expected on multiple devices and platforms, but actual testing on all the mobile devices in the market isn’t practical for most of us. Many testers who start testing responsive web design, they usually start by resizing the browser’s window to fit the viewport or breakpoints sizes of a mobile phone, tablet, and desktop. This technique is usually adequate for a quick visual check of the website in different viewports and helps us to identify major rendering issues as we shrink or enlarge the browser window. However, testing on real mobile devices is a totally different experience as you now have gestures like finger swipes, tapping, pinch-to-zoom, portrait or landscape. Likewise, on desktops, you have hovering, right-clicking, mouse scrolls, etc. Responsive design should take into consideration all these variances. Using Emulators: A mobile emulator is a web-based simulation of how websites and applications will appear and function in a mobile environment. You can download an Android Emulator from Google We all want to support as many devices as possible so, buying or using third-party services to gain access to real devices can be useful for seeing how a web application functions in “real world” conditions, but is significantly more expensive and more difficult to scale than using emulators. While emulators can’t give you the exact testing facilities that you might need they are still powerful and a cost-effective solution to test a website’s functionality on a high-level, i. e. what works, and how the components squeeze, expand and adjust with varying screen size. Google DevTools - Device Mode: Google Chrome’s DevTools has a feature called device mode that’s loaded with helpful tools for testing and debugging responsive designs. Unlike most other responsive design testing tools which simply resize your viewport, device mode actually emulates the mobile device experience, particularly touchscreen interactions like tapping and swiping, right in your web browser. The tools features are:    Test your responsive designs by emulating different screen sizes and resolutions, including Retina displays.     Evaluate your site’s performance using the network emulator, without affecting traffic to other tabs.     Visualize and inspect CSS media queries.     Accurately simulate device input for touch events, geolocation, and device orientation.     Enhance your current debugging workflow by combining device mode with the existing DevTools.  Get started with Device Mode.   Some General Rules for Testing Responsive Web Design:    Text, controls and images are aligned properly     Hover and selection states highlight and color changes     Suitable clickable area     Color, shading, and gradient are consistent     Check for correct padding around the edges     Text, images, controls, and frames do not run into the edges of the screen     Font size, style and color are consistent for each type of text     Typed text (data entry) scrolls and displays properly     Pages should be readable on all resolutions.     Never visualize the horizontal bar in the page.     Content deﬁned ‘important’ need to be visible in all breakpoints.  Breakpoints Each breakpoint requires an adaptation of the layout, with modules that change their position and rules. Another possibility is to have a ﬂuid layout, with text and images that ﬁt proportionately in relation to the width of the page. Modules Check for location of modules as you shrink and expand the browser window or as you rotate a mobile device. Different modules may disappear as you go from desktop to mobile, but make sure you know exactly which modules should be displayed in which viewport. Finally:    Decide how your web application is used. You can get a great wealth of information from Google Analytics tool to see which devices your customers use to reach your website     From the analytics, narrow down your choice of device testing to target the majority, i. e. make sure your website works for majority of people as there is no practical way to test on every device combination.     Know exactly the breakpoints and what should appear as you go from one breakpoint to another     Utilize automated tools and emulators to do the basic checks and high-level functional testing and combine that with real device manual testing  "
    }, {
    "id": 205,
    "url": "localhost:4000/role-of-qa-manager-in-agile-project/",
    "title": "Role of QA Manager in Agile Project",
    "body": "2016/10/20 - What is the role of the QA Manager in an agile environment? Do we really need QA Managers in Agile projects? The role and responsibilities of QA Managers have changed a lot over the past few years, mainly due to many organizations moving to agile development methodologies where there are clusters of Agile Teams working together to deliver business objectives. Many QA Managers often feel confused about their roles and feel out of place when put in an agile context, especially when they have been in charge of managing a testing team and defining QA processes for an organization. No Testing Department: For starters, in a proper agile setup, there is no such thing as “Testing Department”, where a group of testers are sat together, usually away from the developers and managed by a Test Lead or Test Manager. Also in an agile environment, there is much less emphasis on heavy documentation such as detailed test plans which is usually the job of the QA Manager to write these documents in traditional methods. In Scrum, which is a popular agile development methodology, there are three main roles: Product Owner, Scrum Master, and Scrum Team. The Scrum Team is self-managing and composed of developers, designers and testers and the team itself is responsible to deliver high-quality software. QA Manager in Agile is not needed to manage the testers and the testing effort, as in Agile testers become part of the Scrum Team. Qualities of a Good Agile Leader No Accountability: Gone are the days when the QA Manager was held accountable when there was a defect leaked to production. In Agile, everyone is accountable and quality is everyone’s responsibility. When a production incident is encountered, everyone gathers together to see what went wrong and how it can be avoided in future. There is no place for QA Manager in Agile because it indirectly takes away team responsibility for QA which is the whole reason why good Scrum teams deliver much higher quality. It is important to realize that QA and thus testing, is an inherent part of Agile development methodologies. No Day-to-Day Management of Testers: In Agile, business priorities change frequently and the Scrum Team needs to accommodate the changing priorities. It is almost impractical to keep up with all the changes especially when there are multiple Scrum Teams in a large organization. As Stephen Janaway cites in his blog post on “The End of Road for Test Managers?”  Being a Test Manager in an Agile environment can be isolating at times, particularly when the department is big, and the number of agile teams is large.  It requires an ability to balance a lot of information, priorities, and tasks, across a number of areas. Stakeholder management and influence become key. Context switching comes as standard. Often it’s not much fun. More Developers Test: In Agile teams, developers are encouraged to test their own code and to write sufficient and effective unit tests to ensure the new code has no obvious errors and to get notified quickly as soon as something is broken. When we have a solid foundation of good unit tests that we can rely on, it removes the responsibility of testers having to test for obvious mistakes; instead, they can focus more on exploratory testing and assist with UAT which doesn’t require extensive planning and documentation. Role of QA Manager in Agile: Although the traditional role and responsibilities of a QA Manager might not be seen as necessary in the Agile context, there are certain areas where QA Managers can add value. A QA Manager in Agile needs to be an experienced tester to be able to provide advice on challenging situations. They have to know how testing fits into an agile project. The points covered on blog post Test Manager in Agile by Katrina Clokie (aka Katrina the Tester) gives a good summary of the new role of QA Manager in Agile:  Facilitation of inter-team communication across many agile projects within an organization Presenting an aggregate view of testing to the high-level management Personal support, mentoring, and professional development for testers Being an escalation point for testers Budgeting or forecasting for testing as a service dependent on organizational processOther areas where QA Managers in Agile can add value are:  Be an advocate of QA throughout the organization Recruitment of QAs and Automation Engineers Providing technical expertise, e. g. proper use of test techniques in appropriate cases Ensuring the teams (Scrum Teams) implement and follow best practices to prevent defectsTo summarize, the role of a QA Manager in Agile is more of a support, training, facilitating and consulting other QAs and other team members and to ensure QA best practices are established and that quality is baked in from start. "
    }, {
    "id": 206,
    "url": "localhost:4000/how-to-locate-web-elements-in-webdriver/",
    "title": "How to Locate Web Elements in WebDriver",
    "body": "2016/10/19 - One of the most important skills of a test automation engineer working with Selenium WebDriver is to be able to use appropriate methods to locate elements on a page. As a user, the first thing you do when opening a web page is to try to find the part of the page you’re interested in. This could be clicking on a link, verifying a message is displayed or clicking a button to submit a form. As such, WebDriver provides a wide variety of methods to locate elements on a page. Without the ability to find those elements, it’s not possible to do any interaction with the page. This makes the techniques necessary to do so incredibly important. This tutorial covers all the main methods for locating elements on a page. What is a search context?: WebDriver users the SearchContext interface to locate elements on any page. The SearchContext interface has two methods: 1234public interface SearchContext {    List findElements(By by);    WebElement findElement(By by);}This interface provides two methods. The first method finds all the elements that match an instance of what is known as a locator, and the second method finds the first element that matches or throws a NoSuchElementException if it is not found. That means the findElements method is useful for finding elements when you’re not sure if they will be on the page, or if you want to make sure they’re not on the page. What is a locator?: A locator describes what you want to find on a page. In Java, we create a locator by using the By class. For example, if we wanted to find an h1 heading element on a page, we would write 1WebElement h1Element = driver. findElement(By. tagName( h1 ));Or, if we wanted to find all the paragraph elements on a page, we would use 1List pElements = driver. findElements(By. tagName( p ));By link text: This method locates elements by the exact text it displays. This method is normally the preferred locator for links on a page. For example, suppose we have this link on a page: 1&lt;a href= #  id= change-password  class= btn  &gt;Forgotten Password&lt;/a&gt;Then, the link can be located using: 1driver. findElement(By. linkText( Forgotten Password ));By partial link text: When we are not sure of the exact wording of the link text but want to find a link or links that contains a given text, we can use 1driver. findElement(By. partialLinkText( Forgotten  ));or 1driver. findElement(By. partialLinkText( Password ));You should be careful when using findElement with this locator as there could be other elements that contain the same partial text, so this should not be used to locate a single element on its own. It is best to use it to locate a group of elements using the findElementsmethod. By class attribute: This locates elements by the value of the class attribute. This can be used only for those elements having a class attribute, but it is not a good selector to use with the findElement method. The class attribute is used for styling pages, and so chances are that many elements are likely to have the same class. As findElement always returns the first element it finds, if the element you want is not in the first place, you won’t be able to use this to locate it. Using the same example above with the link, the “Forgotten Password” link has one CSS class: btn which can be used to locate it 1&lt;a id= change-password  class= btn  href= # &gt;Forgotten Password&lt;/a&gt;Then, the link can be located using: 1driver. findElement(By. className( btn ));By id: Locates elements by the value of their id attribute. The link in the above example has an id that we can use: 1&lt;a id= change-password  class= btn  href= # &gt;Forgotten Password&lt;/a&gt;Then, the link can be located using: 1driver. findElement(By. id( change-password ));If ID is available, then it should be used as the first preferred choice. By name: Locates elements by the value of their name attribute. Normally it can only be used to locate form elements built using: &lt;input&gt; , &lt;button&gt; , &lt;select&gt; , and &lt;textarea&gt; . On a typical login page, you have input fields which could be like: 1&lt;input class= form-control  name= email  type= text  placeholder= Email  /&gt;We can then locate the email field by the input name attribute 1driver. findElement(By. name( email ));By tag name: This locator finds elements by their HTML tag name. Since there are often many repeating uses of most tags, it is not often possible to use this method to locate a single element. But it can be combined with other locators to effectively locate elements. One time you will find it useful is for locating the page’s heading, as there is usually only one of these: 1&lt;h1&gt;Welcome to SDET World!&lt;/h1&gt;We can then locate the email field by the input name attribute 1driver. findElement(By. tagName( h1 ));By Css selectors: Locates elements via the driver’s underlying W3 CSS Selector engine. CSS selector locator is powerful as it can be used to locate any element on a page. 1&lt;a id= change-password  class= btn  href= . /some-link &gt;Forgotten Password&lt;/a&gt;We can then locate the email field by the input name attribute 1driver. findElement(By. cssSelector( #change-password ));Here, # represents id of the element. And the .  notation represents the class attribute of an element. For example: 1driver. findElement(By. cssSelector( . btn ));By XPath: XPath locators are the most complex selector to use. It requires knowledge in XPath query language, so if you’re not fluent in that query language, you will find it difficult to find elements using XPath queries. Let’s look at an example usage of an XPath for this HTML: 1&lt;a id= change-password  href= # &gt;Change Password&lt;/a&gt;We can then locate the email field by the input name attribute 1driver. findElement(By. xpath( //a[@id='change-password'] ));"
    }, {
    "id": 207,
    "url": "localhost:4000/css-selectors-selenium-webdriver/",
    "title": "CSS Selectors in Selenium WebDriver with Example",
    "body": "2016/10/18 - CSS Selectors Tutorial: How to use CSS selectors in Selenium WebDriver? This tutorial shows how to locate web elements using CSS selectors. One of the most important aspects of test automation is to be able to identify different elements on the page to interact with. Locating elements by CSS is the preferred way as it is faster than XPath. In WebDriver, in order to interact with a web element, such as clicking, or typing, we first need to locate the elements. There are different ways we can locate elements in WebDriver.  In this tutorial, we look at how we can use CSS Selectors in detail with different examples to interact with web elements. Using CSS selectors to locate elements has some benefits:  It’s faster More readable And used more oftenhttps://www. testingexcellence. com/click-link-href-value-webdriver/ Locating Elements by Attribute: Let’s imagine we have a tag with the following attributes [id, class, name, value] 1&lt;input type= text  id= fistname  name= first_name  class= myForm &gt;The generic way of locating elements by their attribute in CSS Selectors is 1css = element_name[&lt;attribute_name&gt;='&lt;value&gt;']e. g. css=input[name='first_name'] We can use the same approach to locate by id and class attributes, however, there are short forms that we can use to make it more readable. In CSS, we can use # notation to select the id: 1css= input#firstname  or just css= #firstname We can also use the . notation to select the class 1css= input. myForm  or just css= . myForm Take extra care when using the short form notations, especially the . class notation as there could be many web elements on the HTML source with the same class attribute. https://www. testingexcellence. com/webdriver-explicit-implicit-fluent-wait/ Locating elements with More Than One Attribute: Sometimes there is a need to be more specific with the selection criteria in order to locate the correct element. Suppose you have an HTML snippet as below 1&lt;div class= ajax_enabled  style= display:block &gt;The value of the display could either be “none” or “block” depending on the ajax call. In this situation, we have to locate the element by both class and style. We could use 1css= div[class='ajax_enabled'] [style='display:block'] Locating Child Element: 1&lt;div id= child &gt;&lt;img src= . /logo. png &gt;&lt;/div&gt;To locate the image tag, we would use: 1css= div#child img There are occasions when there are multiple child elements within the same parent element such as list elements 12345&lt;ul id= fruit &gt;  &lt;li&gt;Apple&lt;/li&gt;  &lt;li&gt;Orange&lt;/li&gt;  &lt;li&gt;Banana&lt;/li&gt;&lt;/ul&gt;As can be seen, the individual list elements don’t have any id associated with them. If we want to locate the element with text ‘Orange’, we have to use “nth-of-type” 1css= ul#fruit li:nth-of-type(2) Similarly, if we need to select the last child element, i. e. ‘Banana’, we can use 1css= ul#fruit li:last-child Strings and Randomly Generated Ids: We can also use string matchers to locate elements. This is particularly useful when we want to find elements that start with a certain character(s), end with a certain character(s) or contain a particular character(s). Starts with, Ends with and Contains: In this example, all the three div elements contain the word ‘random’. 123&lt;div id= 123_randomId &gt;&lt;div id= randomId_456 &gt;&lt;div id= 123_pattern_randomId &gt;If we want to select the first div element, we would use ^= which means ‘starts with’: 1css= div[id^='123'] To select the second div element, we would use $= which means ‘ends with’: 1css= div[id$='456'] And to select the last div element we would use *= which means ‘sub-string’ 1css= div[id*='_pattern_'] We can also use the ‘contains’ 1css= div:contains(_pattern_) Attribute NOT contain a specific value: In WebDriver, how do you find elements whose attribute contain values which you don’t want to select? This CSS selector example shows how NOT to select by specific attribute value Suppose you have many elements which share the same attribute and attribute value, but some of those elements have other variables appended to the value. e. g: 1234&lt;div class= day past calendar-day-2017-02-13 calendar-dow-1 unavailable &gt;&lt;div class= day today calendar-day-2017-02-14 calendar-dow-2 unavailable &gt;&lt;div class= day calendar-day-2017-02-15 calendar-dow-3 &gt;&lt;div class= day calendar-day-2017-02-16 calendar-dow-4 &gt;In the above snippet, we want to select an available day (i. e. the two last divs) As can be seen, all four divs contain “calendar-day-“ but the first two also contain “unavailable” which we don’t want. The CSS selector for Not selecting the first two divs is 1css =  div[class*=calendar-day-]:not([class*='unavailable']) "
    }, {
    "id": 208,
    "url": "localhost:4000/top-ten-myths-agile-testing/",
    "title": "Top 10 QA Myths of Agile Testing",
    "body": "2016/10/17 - What is Agile Testing?: One definition of Agile Testing can be:  Testing practice for projects using agile technologies, treating development as the customer of testing and emphasising a test-first design philosophy. In agile development, testing is integrated throughout the lifecycle, testing the software throughout its development. QA professionals in Agile teams can sometimes feel uncomfortable – In the ideal world, they would have a ‘finished’ product to verify against a finished specification. To be asked to validate a moving target against a changing backdrop is counter intuitive. It means that the use of technology and automation are much more difficult, and it requires a new approach to testing, in the same way that it does for the users and the developers. Surely, all the agile approaches have an impact on the role of the QA professional. However, this is now an excellent opportunity for QA to take leadership of the agile processes; who else is better placed to bridge the gap between users and developers, understand both what is required, how it can be achieved and how it can be assured prior to deployment? QA should have a vested interest in both “the how” and “the result”, as well as continuing to ensure that the whole evolving system meets the business objectives and is fit for purpose. But it requires QA professionals to be fluid and agile themselves, discarding previous paradigms and focusing on techniques to optimize a new strategy to testing. Quality Assurance teams need to know the real impact of an agile methodology as there are boundless myths circulating within the industry. This white paper from original software addresses the following myths about Agile Testing: 1. You only need to unit test - TDD testing is sufficient 2. You can re-use unit tests to build a regression test suite 3. We no longer need testers or automation tools 4. Unit tests remove the need for manual testing 5. User Acceptance Testing is no longer necessary 6. Automation is impossible 7. Developers have adequate testing skills 8. The unit tests form 100% of your design specification 9. TDD is applicable on every project 10. Developers and Testers are like oil and water Download the whitepaper "
    }, {
    "id": 209,
    "url": "localhost:4000/software-testing-practical-tips-for-software-testers/",
    "title": "Software Testing - Practical Tips for Software Testers",
    "body": "2016/10/16 -  Below are a list of guidelines and tips for software testers and QA professionals when involved in testing applications. These software testing tips are collected from many years of experience in testing web applications in an agile environment. If you want to share your testing tips, then add it in the comments field. Some guidelines for QAs when testing for story/bug:    Don’t leave any questions unanswered. The acceptance criteria must be complete in order to ensure you fully understand what the feature/story wants to achieve.     Ensure you know how to test the feature/story.     Consider the full end-to-end flows when thinking about test cases.     Consider all related error scenarios, e. g. web service connection down, invalid inputs, etc.     Consider different browsers – as per the supported browsers.     Consider mobile impact – mobile web and tablet – should any of the features behave differently when used on a touch device, compared to using a keyboard to navigate?     Consider basics of security testing, such as https both URL and resources for protected areas of the site.     Consider whether this story warrants being included in the automation test suite. As a rough guide: only scenarios where its failure would result in a P1 or P2 in production will be automated. This also includes scenarios with a lot of data to be checked through, which would be very repetitive to do manually.     When you find bugs related to a story, raise them as bug-subtasks, to ensure the link to the story is kept.     When signing a story or bug off as testing complete, ensure a comment is added in Jira which includes the test environment and code version on which the tests were signed off.     If the story or bug can’t, or won’t be tested by a QA and will be tested by a developer instead, ensure you review the test approach and add a note in Jira that you approve of the dev’s test approach, ideally with a short description.  Ensure the dev adds which version is being signed off.  On Daily Tasks:    Understand the area of the application being modified by developers     What unit tests have been written by developers     What are the high priority stories and prioritise work depending on day of sprint     Get clarifications on stories that are vague     Review of the automated checks to see if there were any failures  On Sprint Planning:    Estimate testing for each story     Talk with PO to resolve any misunderstandings on new stories     Ensure the stories are testable     Be very proactive in the meeting by asking questions to get ideas for test     Start thinking about high level test scenarios  On Test Design in collaboration with Dev and PO:    Thinking of test cases to validate features, applying various test techniques, positive, negative, Boundary Values, Equivalent Partitions, etc     Use Mindmaps to assist with test scenarios and user journeys     Consider risks - provide more test conditions around a feature of high risk     Always think about “What if”, “what else”, “how else” when designing test cases     Think about integration tests, how is this feature affecting nearest-neighbour features     Really understand what is going on when interacting with a feature rather than just looking at if from a surface. Think about what back-end systems / DB / Web services are being touched     Candidates for automation - what test cases are best to be automated     When there are a lot of combinations of data to test, how can the permutations be reduced without compromising quality / testing - e. g. using pair-wise test technique     Peer reviews of test conditions - discussing with developers what test cases have been designed  On Test Execution / Completion:    Test Environments / Prerequisite setup before execution     Test as soon as a feature is ready and available     Ensure quick feedback is provided to the developers     Review of the automated checks to see if there were an failures     Does the new developed feature make business sense     Talk to developers to improve testability of a feature     Ensure existing tests are updated if there is a change in the workflow     Maintain the test packs and ensure all tests are up to date  On Process Improvement / Self Development:    Learn about new developments in software testing     What are current issues with the QA process / How can current issues be solved, improved     Learn technical skills such as Databases, Coding, Web technologies to get a better understanding of what is happening when testing     Discuss with the team their thoughts about process improvements  "
    }, {
    "id": 210,
    "url": "localhost:4000/what-if-there-isnt-enough-time-for-thorough-testing/",
    "title": "What to Test When There is Not Enough Time to Test",
    "body": "2016/10/15 - Not Enough Time To Test: Quite often testers will find themselves running out of time when testing an application. One of the major tasks of a Test Manager is to prioritize which tests need to be run when there is not enough time to execute all the tests. Use risk analysis to determine where testing should be focused. : Since it’s rarely possible to test every possible aspect of an application, every possible combination of events, every dependency, or everything that could go wrong, risk analysis is appropriate to most software development projects. This requires judgment skills, common sense, and experience. (If warranted, formal methods are also available. ) Considerations can include:    Which functionality is most important to the project’s intended purpose?     Which functionality is most visible to the user?     Which functionality has the largest safety impact?     Which functionality has the largest financial impact on users?     Which aspects of the application are most important to the customer?     Which aspects of the application can be tested early in the development cycle?     Which parts of the code are most complex, and thus most subject to errors?     Which parts of the application were developed in rush or panic mode?     Which aspects of similar/related previous projects caused problems?     Which aspects of similar/related previous projects had large maintenance expenses?     Which parts of the requirements and design are unclear or poorly thought out?     What do the developers think are the highest-risk aspects of the application?     What kinds of problems would cause the worst publicity?     What kinds of problems would cause the most customer service complaints?     What kinds of tests could easily cover multiple functionalities?     Which tests will have the best high-risk-coverage to time-required ratio?  "
    }, {
    "id": 211,
    "url": "localhost:4000/how-to-create-update-and-delete-cookies-in-webdriver/",
    "title": "How to Create, Update and Delete Cookies in WebDriver",
    "body": "2016/10/14 - Almost all websites use cookies in one form or another. Cookies are a way of remembering users and their interaction with the site by storing information in the cookie file as key-value pairs. When testing a website with Selenium WebDriver, sometimes it is necessary to handle cookies, such as creating new cookies, updating existing cookies with new information or deleting cookies. In this WebDriver tutorial, we look at handling cookies in WebDriver. Java code examples of how to create, update and delete cookies using Selenium WebDriver. https://www. testingexcellence. com/cookies-selenium-webdriver-rest-assured/ To use any of the cookie handling methods in WebDriver, we first need to import the Cookie class. To do that, we use 1import org. openqa. selenium. Cookie;Retrieve All Cookies: 1234//This method gets all the cookiespublic Set&lt;Cookie&gt; getAllCookies() {    return driver. manage(). getCookies();    }Retrieve a named cookie: 1234//This method gets a specified cookiepublic Cookie getCookieNamed(String name) {    return driver. manage(). getCookieNamed(name);    }Retrieve the value of a cookie: 1234//This method gets the value of a specified cookiepublic String getValueOfCookieNamed(String name) {    return driver. manage(). getCookieNamed(name). getValue();    }Add a Cookie: 12345//This method adds or creates a cookiepublic void addCookie(String name, String value, String domain, String path, Date expiry) {    driver. manage(). addCookie(    new Cookie(name, value, domain, path, expiry));    }Add a set of cookies: 123456789101112//This method adds set of cookies for a domainpublic void addCookiesToBrowser(Set&lt;Cookie&gt; cookies, String domain) {    for (Cookie c : cookies) {      if (c != null) {        if (c. getDomain(). contains(domain)){          driver. manage(). addCookie(          new Cookie(name, value, domain, path, expiry));        }      }    }    driver. navigate(). refresh();}Delete a specific Cookie: 1234//This method deletes a specific cookiepublic void deleteCookieNamed(String name) {    driver. manage(). deleteCookieNamed(name);    }Delete all Cookies: 1234//This method deletes all cookiespublic void deleteAllCookies() {    driver. manage(). deleteAllCookies();    }"
    }, {
    "id": 212,
    "url": "localhost:4000/web-testing-tips-how-to-test-web-applications/",
    "title": "Web Testing Tips - How to Test Web Applications",
    "body": "2016/10/13 - Web Testing Guidelines: Web Testing is different to desktop application testing. In Web Application Testing, we are typically using a browser (the client) to request a website from a web server by communicating with the server over HTTP or HTTPS. It is important that, as testers, when we are involved in Web Testing, we should be familiar with the basics of HTTP to get a good understanding of how web applications work. In Web Testing, apart from functional testing of individual and integrated components, some of the testing types such as Performance, Security, Cross-browser and Responsiveness which are not necessarily needed in desktop application testing, become of high importance in Web Application Testing. This is because Web Applications are open to a lot of audience so performance has to be accounted for. In addition Web Applications are more susceptible to security attacks such as DDos and SQL Injection, and if a website is targeted, the downtime can be very costly, so great emphasis should also be put on security testing. Web Services Testing: More websites are being built using web services. These provide an opportunity for testers to test the web application in isolated components rather than a full blown integrated web application. The benefits of testing web services in isolation are:    No browser involved - We can directly communicate with a web service as long as we know its end-point and what parameters to send.     Much faster - As we are targeting isolated web service, there is no images, javascript or css to load, so the response is much quicker.     Easier debugging - when testing a web service, if we encounter an issue, it is much easier to locate the cause of the issue and so debugging becomes less of a pain.     More control - we have direct control over what request we submit to the web service, so we can use all sorts of data for negative testing of web services  We can use SopaUI tool to test a web service or a browser plugin such as REST Client for Firefox or Advanced REST Client for Chrome Performance Testing: Performance Testing is particularly important in Web Testing as the web application is exposed to potentially large number of audience. When testing web applications, not only do we have to ensure functionally the website is stable, we also have to make sure the application doesn’t crash when subjected to a large load on the server. Unfortunately, most people forget about performance testing of the web application, or postpone the testing just before release which is too late. If there is something fundamentally wrong in the design or code that could impact performance, we would not know about it till it’s too late. Best approach is to run a performance check as often as the functional regression tests so we have confidence that the performance has not regressed as part of the changes to the code base. Jmeter is a popular opensource load testing tool that can be used to check for a site’s performance. It can also be integrated in a CI server. Cross-browser Web Testing: As there are different number of browsers, we need to ensure our web application works as expected on all of them (at least the major ones, i. e. Google Chrome, Mozilla Firefox and Microsoft Internet Explorer), not to forget Opera and Safari. As with all testing, we need to know which browsers and their versions the application supports and then plan the testing accordingly. Testing everything on every browser can be very time consuming, hence we can use automated tools to verify functionality on different browsers. Moreover, there are online cross browser testing tools which make life easier for testers to execute their tests on different browsers. Speaking from personal experience, the number of browser-related issues are very few and mostly related to very old versions of browsers or the CSS doesn’t render properly giving layout issues. Therefore it may not be necessary to run all test cases in all browsers as it can be very time consuming (even when automated) for very little gain, and chance of something not working in very low. The best approach is to run all the test cases in one major browser, and then select a handful of most important scenarios and run them on the rest of the browsers. Test Automation: Majority of companies developing Web Applications work in an agile development model with frequent releases, hence a need for frequent testing. In Web Testing, Test Automation can be of great benefit because it removes the burden of repetitive work. As well as verifying functionality, we can also use automated scripts to generate test data that we need during Web Testing. Another way automation can help in manual testing is tools such as Selenium WebDriver can take screenshots of the actual browser page. If we need to visually check for a large number of pages, e. g. we want to know how the localized text renders on different webpages, we can use the tool to go through the pages and take screenshots and then quickly verify visually. For more information, please refer to Test Automation Tips and Best Practices Analyzing HTTP Traffic: Quite often there is a need to analyse the HTTP traffic from the browser to the downstream servers. By analyzing the web traffic we can dig down to the details of each request and response. In Web Testing, analyzing HTTP traffic  is particularly useful when testing third party tracking tags, such as Google Analytics tags or omniture tags on webpages. Not only can we verify the tags hold correct values, we can actually test that the requests are fired off to the appropriate third party systems and that we get a valid response, usually 200 OK response code. In order to be able to visualize and record HTTP traffic we have to use an appropriate tool that acts as a proxy and can listen to the requests and responses between the client, usually a browser, and the servers. Here are some of the most popular tools we can use to analyze HTTP traffic: Wireshark if you want to see everything going on in the network. Fiddler if you want to just monitor HTTP/s traffic. Live HTTP Headers if you’re in Firefox and want a quick plugin just to see the headers. FireBug can get you that information too and provides a nice interface when your working on a single page during development. I’ve used it to monitor AJAX transactions. BrowserMob Proxy is also a very nice tool that can hook with Selenium WebDriver when running automated tests. Responsive Websites and Mobile Testing: More people are accessing websites from their mobile phones than their desktop computers. This means that Web Testing is no longer restricted to browsers on desktops. We now have to test web applications on mobile platforms as well as desktops. There are two types of web applications for mobile devices, ones which are purposely developed for mobile platforms, and ones which are “responsive”, i. e. there is only one version of the web application built for desktop and mobile devices but the application renders and is displayed differently depending on the size of the device. Both types require testing on mobile devices and/or simulators. For more information on Web Testing on Mobiles read How to Test Responsive Web Design Other Important elements for Web Testing: During Web Testing, as well as functional testing, we also need to check for and not limited to:  Javascript CSS Cookies Accessibility Dead-links UX and Layout HTML Validity Security Browser Refresh Window Resizing"
    }, {
    "id": 213,
    "url": "localhost:4000/testing-e-commerce-websites/",
    "title": "Testing E-commerce Websites",
    "body": "2016/10/12 - Guidelines for Testing E-commerce Websites: Testing E-commerce Websites requires knowledge of web testing techniques and the e-commerce domain. Most E-commerce Websites share a general common theme and structure, e. g:  Homepage Search Results Page Product Details Page Order Form Page Order Confirmation Page Login Form Page and Accounts PagesOf course, there are many other pages on a typical e-commerce website, but the main core user journey would entail touching the above pages and that’s where testing e-commerce websites should focus on: The Checkout Journey. These “front-end” pages most likely communicate with “back-end” web services, such as Product Search Service, Content Service, Booking Engine, Payment Services, Accounts Services, etc. Therefore, it is important when testing e-commerce websites that we test individual services in isolation as well as integrated as a whole system. A typical user journey flow would start at the homepage, or a product landing page, searching for a product, reviewing the product, adding product(s) to the shopping cart, fill in order details and payment details and submitting the order. Ideas for Testing E-commerce Websites: We have already discussed tips and guidelines for testing web applications and common test methods and test techniques for web application testing which are also applicable to testing e-commerce websites. In this article, we examine some common test cases which are specific for testing e-commerce websites. The ideas presented here are some generic high-level test cases which are applicable to most e-commerce websites, and you can use this guide to get started with testing e-commerce websites. Testing Shopping Cart: Shopping carts are one of the main features of an e-commerce website and thus form the centerpiece of testing e-commerce websites. It allows for customers to select and store multiple items in the cart and purchase them all at once. Nowadays, shopping carts have become “intelligent” in a sense that they remember what items you store in them so you can retrieve them at a later date or even from another device. In most cases, cookies are used to store cart data or if the user has an active account and is logged in, a session id can be stored against the user in the database. Either way, there are some key test cases which should be part of testing a shopping cart. Add one item to the cart - the cart should be updated with the item with correct name, image, and price. Increase the quantity of the item from the cart - the price should be updated to reflect the correct figure. Add the same item multiple times - there should be one item in the cart, but the quantity should reflect the number of additions and the total price should reflect the sum of the price of each item. Add multiple items of different types - For each item added, we should see a corresponding name, image, and price and total price of all items. Remove some items from the cart - the cart should update showing the existing items in the cart, total price should reflect the new sum. Remove all items from the cart - cart balance should be zero, no items should be displayed in the cart. Click on an item in the cart - we should be able to see more information about the product we just clicked either as a popup or redirecting to the product page. Add item(s) to the cart, close the browser and reopen the same site - ideally, the cart should still hold your items. N. B this particularly depends on the requirements on how the cart should behave. Coupons - need to check that the price of the cart is discounted when we apply a coupon and not discounted when we apply an invalid or expired coupon. Search Form, Sorting, Filtering, Pagination: The search form is usually present on multiple pages to allow users to search for products wherever they are on the site. Therefore, it is important that the search feature is tested on applicable pages. Most probably the code for the search module is reused in multiple pages or templates, or it could be part of the header section which is displayed across the whole site. If this is the case, the behavior of the search feature should be the same wherever it occurs and running all test cases on all pages is a waste of exercise. Testing e-commerce websites wouldn’t be fun without testing the most feature rich page on the site, the Search Results Page. When we search for a product, we get redirected to the Search Results Page (SRP) with all the relevant items we searched for. There are many things to check for and many features to test, but the three features that are of most important and relevant specifically to SRP are sorting, filtering and pagination. Relevant products - check that the products displayed are related to what was searched for. Product information - the products should display an image, name, price and maybe customer ratings and number of reviews. The number of products per page - check that the number of products per page matches the requirement. Pagination - check that all items on next page are different to the previous page, i. e. no duplicates Sorting - there could be four to five options to select from a drop-down menu. Sorting is usually single-select, i. e. you can sort by one parameter only. Sorting and Pagination - when there are products in multiple pages when you sort by a parameter, the sort order should remain as you paginate, or more products loaded (if it is an Ajax load) Filtering - unlike sort option, filter options are multi-select, that is you can filter by multiple parameters. It is a good idea to explore single filters and multi-filter options. Filtering and Pagination - Again, this is important, when we filter in one page, ideally, as we paginate we would want the filter to be applied throughout. Sorting and Filtering - an important test case is mixing the sorting and filtering options together, e. g. filter by price and then sort by price high-to-low, or the other way round. Whilst the individual features on their own might work correctly, when combined with another feature, the functionality of one or both features might break, so it is essential that we check the results when combining filtering with sorting. Sorting, Filtering, and Pagination - this is checking that when both sort and filter have been applied, they remain as we paginate or more products are loaded. Create Account and Login: Some e-commerce websites allow you to purchase an item as a guest, i. e. without the need to create an account, and then an optional step to create an account when an order is placed. When an account is created, the user can log in at any stage during a purchasing journey. It is important that we test all these variations along the user journey when testing e-commerce websites. Purchase an item as a guest - If the site permits, test that you can purchase an item without having to create an account. Existing and new accounts - purchase an item with an existing account and with a newly created account. Create an account and log in before purchase - this is to test that the item you purchase gets added and connected to the correct account. Also, you should not be prompted to log in again once you have already been logged in. Login redirects - check the behavior of login feature on different pages. Some sites redirect the user back to the same page where they clicked the login link and some sites redirect the user to the accounts pages. This should be tested thoroughly. Login session - when you log in check that you stay logged in as you browse products. Also, you need to test the behavior when the user doesn’t interact with the site for some time. Will the session expire after a period of time? Make sure the user has actually been logged out after the session times out. Login and Logout - when you are logged in, log out and make sure you are logged out and that you cannot access any of the accounts pages. Payments: Payments are an essential part of testing e-commerce websites. After all, this is what allows users to purchase their items without the need to call a number to place their order. Payment types - Different payment types should all be tested, e. g. Credit Card, Paypal, Bank Transfers, Instalments, etc Card Details Storage - does the site store customer’s credit card details? If so are they securely stored? Is it PCI compliant? Post-Purchase Test: When we place an order, there are many actions that users can do related to their purchase. Testing the post-purchase functionality is also an important aspect of testing e-commerce websites. These could be:  Cancel the order or change the quantity of the order Review your recent order and history of purchased items Changes to the account, such as billing address, shipping address, password, profile information such as name, email address and even deleting an account. No doubt that testing e-commerce websites is challenging and requires a lot of skill. This article is just the tip of the iceberg of all the relevant test cases that can be executed when testing e-commerce websites and it can be used as a starting point. There are a lot more functionalities to be tested as part of testing e-commerce websites such as:  Product carousels and recommended products.  Correct display of information on the Product Details Page which is usually content heavy.  Database of product - how is the data modified after an item is purchased? Warehouse System - how is the warehouse or third-party gets notified when an order is placed? Contacting the customer, confirmation emails, contents of the email, returns, complaints, etc…What’s most important when testing e-commerce websites, is to make sure that each feature has correctly implemented its requirements. "
    }, {
    "id": 214,
    "url": "localhost:4000/jmeter-tutorial-testing-rest-web-services/",
    "title": "JMeter Tutorial: Testing REST Web Services",
    "body": "2016/10/11 - In this Jmeter Tutorial, we look at how we can test a REST API or Web Service using Jmeter tool. We can use Jmeter to send Json request to a RESTful Web Service and also parse the Json response. Test Plan for REST Web Service:  Thread Group HTTP RequestLike with any Jmeter tests, we first need to create a Thread Group along with a HTTP Request Sampler.  If you now run the test, you may get an error with a response code of 415 and a response message “Unsupported Media Type”. This is because the REST API might expects ”Content-Type” and “Access” parameters in the header request.   HTTP Header ManagerNext we need to add a HTTP Header Manager to send parameters in the header of the request. We need to send “Content-Type” and “Access” variables as request headers.  Most probably, you need to register your application via an API key. This needs to be sent as a POST method to the REST API in the body of the request.  POST data in the Body of Request And the response in Json format Next is to extract or parse the Json Response.  Extract Json ResponseJmeter has a handy plugin called JsonPath which can be used to parse Json responses. This plugin is in the Extras with Libs Set. Once you have installed the above plugin, we can use the Json Path Extractor as a post processor Once we have added Json Path Extractor to our test plan, we can use the dot notation to reference the Json elements. In this example, we want to extract the value of the “client_id”: The value of the “client_id” will be saved in the variable named “client_id_value”. You can give any meaningful name you wish. Once the value is saved in the variable name, we can recall the value by using that variable name in the format ${client_id_value} "
    }, {
    "id": 215,
    "url": "localhost:4000/test-automation-advantages-and-disadvantages/",
    "title": "Test Automation Advantages and Disadvantages",
    "body": "2016/10/10 - Test Automation, when done correctly can have many advantages and be very beneficial to the project and organization. There are however some pitfalls or disadvantages of test automation that we need to be aware of. In this post we list a summary of advantages and disadvantages of Automated Testing. Test Automation Advantages: Confirmation of the known Automated checks are a great way of confirming that the application still functions properly after changes made to it. It is possible that when a new feature is added to an application or a bug is fixed, it impacts the functionality of the working software, i. e. a regression bug is introduced. By running a set of automated regression checks when the application is updated, we can identify any new bugs introduced as a result of the changes. The key information here is to run automated checks as often as the application is upgraded. You may not need to run the full set of automated suites, but a quick smoke regression test should be enough to pick up any major issues. Quick feedback Another big advantage of automated checks are that they can provide a quick feedback on the health of the application as soon as the application is updated. This is important for the development team, as they should fix anything which is broken before moving on to code other stuff, so a quick feedback is important. Please note that this quick feedback can only be achieved with unit tests and API tests where the UI is not involved. If we check functionality from UI or at system level, it can take a long time to complete before we can get the results of the tests which is one of the disadvantages of automated testing, so it is best to have few automated checks at the UI layer. Fast execution of checks Although automated checks can take a while to script, when we execute them they are generally fast and can go through various steps much quicker than a human being. Therefore, they help with providing a quick feedback to the development team. This is especially true of a data driven test where the same test(s) are executed multiple times but with different data sets. Frees up the time of the testers Regression tests which need to be run on a regular basis, when automated, they free up the time of the testers, so they can focus more on interesting scenarios and exploratory testing. By the same token, when implemented properly, automated checks can run automatically with minimum or no supervision or manual intervention. The development team can contribute Automated checks are usually written in the same language as the application under test. For this reason the responsibility of writing, maintaining and executing the tests becomes a shared responsibility and everyone in the development team can contribute, not only testers. Test Automation Tips and Best Practices Common Myths around Automated Testing. Test Automation Disadvantages: False sense of quality Beware of passing tests! This is specifically important in verifying functionality at UI or System level. An automated check only checks what is been programmed to check. All automated checks in a test suite can happily pass, but there could be major flaws undetected, because the automated check was not supposed to “look” for those failures. Solution: ensure you design good test cases before automating them. In system level or UI automation, make sure to check for important elements as many things can happen as a result of an action. Also complement automated checks with manual / exploratory testing. Not reliable Automated checks can fail due to many factors. If automated checks keep failing due to issues other than genuine bugs, they can raise false alarms. Automated checks can break because a minor UI change was implemented, or a service is down or there are network issues which are not relevant to the application under test but could impact the automated checks. It is best to aim for minimum number of failures during each run so you can get a reliable feedback from the automated checks. Solution: Where possible / applicable, use stubs to overcome issues with connectivity or changes in the 3rd party systems so the automated checks would be independent of any downstream failures. Automation is not testing Unfortunately, many people mistake “Test Automation” with Testing and once they have the tools to automate the testing, they want to “automate all the tests” and get rid of so called manual testers or QAs. The truth is that Testing is an exploration exercise; you need domain knowledge, be inquisitive with a mind to focus on learning the behavior of the application and apply proper test techniques to be able to spot anomalies in the software. Testing is not just executing a set of pre-defined test steps and comparing the actual results with expected results; that can be the job of automated checks. But to properly test an application, a human intelligence is always required. Solution: Understand that for a successful delivery of a project you require both automated and manual testing. One is not a replacement for the other; complement automated checks with manual / exploratory testing. Maintenance Time and Effort You have to accept the fact that if you have automated checks in place, you will need to spend the time upgrading the relevant tests as the application is upgraded. If the regression packs are not kept up to date, you start seeing failing tests that fail due to upgrades rather than identifying real bugs, as well as tests that are no longer applicable. Embarking on test automation is not a one-off effort. In order to get the most benefit from the automated checks, they have to be kept up to date and relevant, which requires time and resource. Solution: Because the maintenance factor is an ongoing activity, make sure you design in a way to reduce the time you spend updating the tests. Use reusable modules, separate the tests from the framework and use good design principles to alleviate the maintenance effort. Slow feedback Occasionally automated checks can take a long time to script depending on the complexity of the test. When a functionality is ready to test, sometimes it is quicker to do a manual check rather than waiting first to automate the test and then run the test and check the results. Also, in terms of UI and System level automated checks, they can take a long time to complete so the results of the overall testing may not be known for several hours in some cases. Solution: Try to automate the tests alongside development so that when development is complete, you can run the automated tests against the new functionality. Also, separate the automated checks in different packs, such as a smoke pack (which should take no longer than 15 minutes) which checks the most important functionalities of the application as soon as the application is updated and run the full regression pack (which can take several hours) overnight, so you have the results ready by next morning. Not many bugs found Majority of the bugs seem to be found by “accident” or when performing exploratory testing. This is probably due to the fact that during each exploratory testing session we could be testing the application in different ways thus finding new loopholes through the application. Automated regression checks on the other hand always follow a given path and sometimes with the same set of test data. This reduces the chance of finding new defects in the application. Also the number of regression bugs seem to be lower than new-feature bugs. Solution: Try to build randomness in the scenario and data. Trying different paths with different data each time can reveal potential issues. "
    }, {
    "id": 216,
    "url": "localhost:4000/resize-browser-window-webdriver/",
    "title": "How to Resize Browser Window in WebDriver",
    "body": "2016/10/09 - How to resize browser window with Selenium WebDriver? Here, we look at three different ways we can resize browser window in WebDriver. Whenever WebDriver starts the browser, it starts it with default settings. Sometimes it is required to resize the browser window, particularly when we are testing for responsive web design because we need to check to see how the different elements on the page render when we resize the browser window. Webdriver has convenient methods and different ways that can allow us to resize the browser window. https://www. testingexcellence. com/webdriver-headless-mode-chrome-driver/ Resize Browser Window in WebDriver: Java using Dimension 123456789101112131415161718import org. openqa. selenium. WebDriver;import org. openqa. selenium. firefox. FirefoxDriver;import org. openqa. selenium. Dimension;public class BrowserOperations {  WebDriver driver;  //this will open browser with default size  public void launchBrowser() {    driver = new FirefoxDriver();  }  public void resizeBrowser() {    Dimension d = new Dimension(800,480);//Resize current window to the set dimension    driver. manage(). window(). setSize(d);  }}Java using Chrome options 12345678910111213141516171819202122import org. openqa. selenium. WebDriver;import org. openqa. selenium. chrome. ChromeDriver;import org. openqa. selenium. chrome. ChromeOptions;import org. openqa. selenium. remote. DesiredCapabilities;public class BrowserOperations {  public static void main(String[] args) {    System. setProperty( webdriver. chrome. driver ;,     /path/to/chromedriver );    ChromeOptions options = new ChromeOptions();    options. addArguments( window-size=800,480 );    DesiredCapabilities cap = DesiredCapabilities. chrome();    cap. setCapability(ChromeOptions. CAPABILITY, options);    //this will open chrome with set size    WebDriver driver = new ChromeDriver(capabilities);    driver. get( https://www. testingexcellence. com/ );  }}If you want to maximize the browser window to the maximum width and height of the screen, you can just call the maximize() method 12Webdriver driver = new FirefoxDriver();driver. manage(). window(). maximize();"
    }, {
    "id": 217,
    "url": "localhost:4000/how-to-test-carousel-rotation-with-selenium-webdriver/",
    "title": "How to Test Carousel Rotation with Selenium Webdriver",
    "body": "2016/10/08 - Some websites have carousel with rotating items in the list. In this webdriver tutorial we look at how to test and verify carousel rotation with webdriver. For this tutorial, we are going to use amazon. com to demonstrate the testing of carousel.  when we inspect the elements in carousel, the structure is like: When we click on the arrows, the content of the carousel changes and then we can verify that the text of the items have changed. Each &lt;li&gt; element is an item of the carousel, so we need to get the text (item’s name) of each item. 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class CarouselTest {  public void test() {    //This will get the number of items in the carousel    String selector =  li[class^=a-carousel-card] ;    ArrayList items = driver. findElements(By. cssSelector(selector));    ArrayList list1 = new ArrayList();    String name;    for (int i = 0; i &lt; items; i++) {      int index = i + 1;      //This will get the name of each item in carousel      name = driver. findElement(By. cssSelector(selector +  [  + index +  ] )). getText();      list1. add(name);    }    //Next we click on the arrow of the carousel    driver. findElement(By. cssSelector( div[class^=a-carousel-col] a )). click();    //Then we new items are loaded in the carousel following the click,    //we get the names again    ArrayList nextItems = driver. findElements(By. cssSelector(selector));    ArrayList list2 = new ArrayList();    String newName;    for (int i = 0; i &lt; nextItems; i++) {      int index = i + 1;      //This will get the name of each item in carousel      newName = driver. findElement(By. cssSelector(selector +  [  + index +  ] )). getText();      list2. add(newName);    }    //Then we compare the two arrayLists are not the same    ArrayList commonList = CollectionUtils. retainAll(list1, list2);    Assert. assertTrue(commonList. size() == 0);  }}"
    }, {
    "id": 218,
    "url": "localhost:4000/software-testing-ask-questions/",
    "title": "Software Testing - Ask the Questions!",
    "body": "2016/10/07 -  After almost 6 years of working in software quality assurance, if someone asks me what makes a good QA resource, I would probably sum it up in 1 line. For good testing practice the most important task is to ask the right questions, at the right time and to the right audience. In practice, the sooner a QA is involved in the SDLC of a new system or an enhancement of an existing one, lesser will be the chances of running into catastrophic bugs at the time of actual testing. In order to start planning, a test analyst should ask as many questions right from the requirement understanding phase so as to uncover the hidden assumptions, incomplete/contradicting requirements, test environments and impact on interfaces or supporting systems. Cross team communication from the very start of a project is the key to effective and timely test execution. A good test analyst would never hesitate to cross question on a requirement that hasn’t been detailed enough or if there is a lack of clarity on the language being used. A requirement can be stated differently in terms of business, technical, functional and lay man user terminology, and this is where the QA resource can play a role to ensure that a requirement is drafted in a way that it can be comprehended easily by everyone. Participation of a QA during requirement analysis can help in producing a comprehensive requirement doc without any gaps. Representation of testing team from the beginning of a project can actually bridge the requirement understanding gap between the project, technical and business teams. In my experience, I have always noticed that documents do not state everything, and making assumptions during impact assessment is the worst mistake a test analyst can make. Analysis of the requirements document or a functional specification can arise n number of queries. These need to be categorized depending on the teams who can address them. Questions can also be classified depending on what area they fall in. It could be related to technical specification or customer impact or interface impact or risks &amp; project planning. An efficient QA is always interested in the bigger picture then be it knowing the objective that drives a project/enhancement or keeping oneself proactively informed of planning &amp; timelines. Being aware of these helps the testers plan their work more effectively. Categorize the queries on the basis of who can answer what:    Project Sponsor/Project Manager – Anything related to vision behind the new development is something that the sponsor or PM would know. For example - What is the objective of constructing a new product or making changes to an existing system? What purpose shall it serve? What benefit does the change hold for the users? Anything related to overall project plan as well sits with the person heading the change.     Actual User community/Teams dealing with actual users – It may not be possible to talk to the actual user community in all circumstances but anything regarding user experience can always be put forth to the teams that deal with them. A test analyst must know what is most important for the actual user in order to design the right scenarios. What are the areas of a system that are most critical to the customer, what are the problems that refrains the customer to use a system? Answers to these can facilitate in producing a comprehensive test design.     Test Manager/Lead – In a large teams, a test analyst may not have direct access to all the information. In such a scenario he/she can also have questions for the test lead. Test environments, test management and automation tools, reporting procedures, test evidence, test cycles etc needs to be agreed as part of test planning.     Development Team – Anything that is technical or relating to a specific area of code lies with the developers. For example – What part of the code is changing? What is the impact of introducing a new field on a web form? Such information helps a tester in determining and limiting the regression test suite.     Solution Architect – Who knows a system better than a person that builds the end to end architectural design for a problem. Any questions regarding component interactions, middle-ware, web services, databases should ideally be for the person who converts the functional requirements into design artifacts that are in turn used by the development team to build the code.     Support Team – When a change is done to an existing solution which is used by a wide user community, inputs from the help-desk team also prove valuable. They know what problems a customer faces while using a system.  Transparent communication channel between cross functional teams ensure consistency between business requirements and actual proposed solution. It helps in identifying non-testable requirements, environmental limitations and scope of testing very early in the life-cycle. Something that may look like a minor change on the UI may actually have a wider impact on other components; a QA has to be aware of this so as to ensure maximum test coverage. Questions like - How does a UI change on one page of the website affects the parameters on a connecting page, what is the impact of “a new field in a form” on rest of the interfaces that may use various modes to transfer the data to other components(these modes of transfer could be XMLs, messages,  data base tables etc). What is the error messaging text, what is the font &amp; formatting scheme followed throughout applications/websites/ products and is it consistent with the branding of the product/website/application, what is valid data for a field on a web page, how does access rights work? These may look very basic but is often information missing from the specifications. It is not unusual that competence of QA resources is often being measured against developers. The comparison, however, is irrelevant and unfair. Each has its own value add in the construction of a product/website/application. Both parties are required to work as a team to deliver successful software release and possess a skill set unique to them self.   As a software test analyst it is important to break a system by putting the most innovative scenarios to test. And that requires a questioning mind, so don’t shy away from giving way to your curiosity. Ask the Questions. "
    }, {
    "id": 219,
    "url": "localhost:4000/head-of-qa-roles-and-responsibilities/",
    "title": "Head of QA - Roles and Responsibilities",
    "body": "2016/10/06 - What are the roles and responsibilities of a Head of QA?: In a previous article, we discussed the role of a QA Manager in Agile. Here will take a look of the typical skills required and the responsibilities of a Head of QA. Head of QA role is a senior position within an organization which is normally the next level up from a QA manager role. Depending on the role and the organization, the Head of QA role can either be hands-on from a technical point of view or hands-off with a focus on strategy and processes, or it could be a mixture of both. Typically, there is only one role of Head of QA in an organization which will define the QA strategy and approach for all the company’s products and be ultimately responsible for ensuring product quality. The role requires strategic thinking and planning and provide expertise throughout the entire product development life cycle with a strong sense of quality ownership making sure that quality is baked in from the start. Because the role of Head of QA is the next natural progression from a QA Manager role, the individual must have a proven track record of building QA teams, managing the function and direction of the QA teams. The manager will provide regular direction, mentoring, and coaching to QA team members, ensuring the success of the team’s manual and automation efforts. The Head of QA will have ownership of QA environments across all products. Working closely with the DevOps team to define the optimal solution for each platform. The Head of QA will also take responsibility for ensuring all development tasks meet quality criteria through test planning, test execution, quality assurance and issue tracking. It is important for the Head of QA to oversee the delivery and maintenance of automated scenarios and frameworks based on industry best practices. Skills and Experiences of a Head of QA: A typical Head of QA person should have the following skills (not an exhaustive list by any means!)  QA Management experience across multiple projects, off-shore and in-house.  Be a strong leader with experience in implementing and shaping the company’s QA processes and strategies.  Have strong technical skills, both functional and non-functional, manual and automation, ideally in a continuous delivery environment.  Strong communication skills with all the key stakeholders to ensure QA vision is understood and implemented correctly.  Be an advocate of Quality Assurance, Continuous Improvement and industry recognized Best Practices.  Excellent knowledge of Risk Management, Risk Identification and Risked Based Testing.  Experience managing testing departments or testing functions, managing large and complex activities and processes.  Flexible with the ability to and work under pressure.  Proactive, strong-minded, quick thinker and assertive.  Able to motivate a team, recognize good talent and bring out the best out of each individual.  A mature and professional individual who is self-motivated and enthusiastic.  Excellent communicator, influencing skills and negotiation skills to get management buy-in on ideas and concepts.  Able to communicate with all levels of management and peers within the organization.  Providing leadership Building and maintaining relationships.  The ability to prioritize work and tasks under pressure.  Ability to handle conflict effectively.  Ability to build, implement and direct quality assurance principles and maintain the quality of delivery. Main Responsibilities of a Head of QA::  Responsible for Defining QA strategy, approach and execution in development projects.  Responsible for Leading and directing the QA leadership team.  Provide leadership and technical expertise within Test Automation and Quality Assurance.  Be accountable for the test automation projects, mentor, and provide leadership to the QA automation developers and managers.  Participate in interviews, induction, training and performance evaluation of all QA leads.  Provide technical leadership and expertise within the field of Quality Assurance and Testing.  Ensuring that the development teams adhere to the principles, guidelines and best practices of the QA strategy as defined.  Focus on continuous QA improvements including usage of appropriate testing tools, test techniques, test automation.  Building and maintenance of quality standards as well as enforcing technical and testing standards.  Monitoring of all the QA activities, test results, leaked defects, root cause analysis and identifying areas of improvement. Implement steps required to improve the processes.  Gather and present testing metrics and testing activities for the projects to key stakeholders.  Ensure the proper usage of available tools to gain the maximum benefit of the QA effort. This includes testing tools for functional, performance, automation, etc.  Manage training and continuous learning of QA staff by means of short courses, conferences, meetups, certifications, etc.  Be an escalation point for all matters related to testing and quality assurance and operate as a primary point of contact for the QA teams.  Direct the development of the QA strategy, methodology, discipline and framework.  Driving and improving the QA team in areas of automated testing and agile testing.  Provide technical expertise in Test Automation, Testing Methodologies, Testing Processes, Tools and Techniques across the teams.  Work with QA managers, Development managers and the Software Development Director to develop and execute QA strategies to meet and exceed department and corporate quality goals. "
    }, {
    "id": 220,
    "url": "localhost:4000/bad-requirements-software-testers-nightmare/",
    "title": "Bad Requirements – A Software Tester’s Nightmare!",
    "body": "2016/10/05 - The real world is never an “ideal” place, and the same applies to so many assignments that one might work on. Numerous times in the past, as a quality professional I have been caught up in testing projects that are “not so ideal” and lack the basic documents and governance. The worst form being the one’s that either “lack” documented requirements or have some “loosely written” documents. Working on such projects literally gives me jitters and at times even sleepless nights. (It isn’t an exaggeration, the thought of making sense out of disjoint pieces of information looms in your mind all the time. ) But accept it or not, projects like these are a reality and mostly one has no option but to work on them. A Bad requirement itself is a very broad term and can be one of the following –    Missing Requirements –A functionality that is totally missing from the documentation. For example, “Error messaging” in case of data validation or other forms of failure not being considered and documented or not detailing the need for a certain link available as per the access rules on an application.     Conflicting Requirements – When two or more requirements expect the system to do different things that can’t possibly be done at the same time. They need to be identified as early in the lifecycle as possible to avoid rework.     Incomplete/Unclear Requirements – Requirements that lack all the necessary information constitute this lot. Most of the times requirements are elicited in business terms and which is nowhere close to what it demands at a granular level. For example – “The system should have the capability to filter search results” is incomplete. The details around filter criteria is not been provided and thus raises unnecessary queries.     Ambiguous Requirements – A requirement statement that can be interpreted in different ways by different people is an example of this.  Howsoever, a test analyst might crib about the quality of requirement documentation, at the end he/she can always build a test pack by using some alternative sources of information and the following practices–    Explore &amp; Discover – If it is an existing system that is being rebuilt or new functions are being added to it, explore its test environment. Exploratory testing comes handy when you are trying to figure out on how something works. If there is a regression test suite available it will make the task easier and even if not just try out all the links/buttons/try different things and document as much as you can. With a basic level of what the new changes are and a fair understanding of the existing system, a tester can start designing some test cases. Of course there will be doubts and queries which can then be directed to relevant teams.     Use Common Sense &amp; Experience – A test analyst who has worked in the same domain as the system under test can help. A lot of missing links in the requirements can be identified through common knowledge that comes from experience For example, someone who has worked on a Travel based application testing would know the fundamental tests needed. Also, think from the user’s perspective, what is it that would matter to a user?     Use HTML Designs/Wireframes – HTML Designs and wireframes can act as an alternative to a requirement specification. Make use of these as visual representation of what is expected of a system/application that you are going to test. A working wireframe can also help the tester understand a basic flow, however, with static HTMLs try to build a journey through pages. However, there will be a need to get this understanding signed off by business users and development teams.     Discussions, Emails and Meeting Notes – When the requirements are flaky, notes from all of these can assist in joining the missing links. Testers should proactively involve themselves in any such discussions and meetings. They are a good platform to raise questions. But don’t forget to document the outcomes from any of these. Tools like IBM’s Rational, Atlassian’s Confluence etc can help in building a central repository for these.     Query Log and Workshops with Stakeholders - Having gathered all the information that one could, it is important to collate them in a query log and share with all the stake holders. This could as well be a starting point for getting into some workshops that may help in filling the missing blanks. As a result of these workshops, it is important to update whatever documents are available. Even though the ownership of doing this does not lie with the test team, there is no harm in keeping a local copy and making changes as &amp; when some updates happen. Again various tools can be used to track the trail of queries and comments.     Peer Reviews - With all of the above, a tester would definitely reach a point where he/she can start scripting the scenarios and test cases. In projects with dodgy requirements, it is good practice to get the high level scenarios reviewed by the business teams so as to ensure nothing that’s critical to the user is being missed.     Change Management – Doing all of the above in parallel to writing the test scenarios would require some change management. Keeping track of any new information fed into the project or any changes in draft requirements is a key task. More importantly to implement these in the working documents (specific to testing) play an important role for an effective test plan and design.  The not so perfect projects can be an opportunity for a tester to do something outside of their usual domain and learn. It is challenging to be testing with poorly documented requirements but it is in challenges that great things lie. So connect the loose threads and test. Happy Testing! "
    }, {
    "id": 221,
    "url": "localhost:4000/useful-tools-for-testing-websites-on-mobile-devices/",
    "title": "Useful Tools for Testing Websites on Mobile Devices",
    "body": "2016/10/04 - As there are more and more people using their mobile devices to browse the web, it is important to make sure that your website is compatible with the different devices with different screen sizes and operating systems. Testing websites on mobile devices can be very time consuming and expensive due to the vast number of different mobile devices. Luckily, there are useful tools that we can use for testing websites on mobile devices. These tools simulate a real device and will display how a website renders on a particular device with different screen resolutions. In this article, we look at some of the most common ones: iPhony: Looking for a way to see how your web creations will look on iPhone? Look no further. iPhoney gives you a pixel-accurate web browsing environment—powered by Safari—that you can use when developing web sites for iPhone. It’s the perfect 320 by 480-pixel canvas for your iPhone development. And it’s free. iPhoney is not an iPhone simulator but instead is designed for web developers who want to create 320 by 480 (or 480 by 320) websites for use with iPhone. It gives you a canvas on which to test the visual quality of your designs. iPadPeek: iPadPeek lets you see how your website renders when accessed via an iPad. This useful tool has different sizes as well as portrait and landscape orientations. W3C mobileOK Checker: This checker performs various tests on a Web Page to determine its level of mobile-friendliness. The tests are defined in the mobileOK Basic Tests 1. 0 specification. A Web Page is mobileOK when it passes all the tests. Mobile Friendly Test Tool: This tool from Google tests whether your website meets the criteria for being mobile friendly.  The tool will analyze a given URL and report if the page has a mobile-friendly design. Screenfly: With Screenfly you can easily test your website on a range of view ports, from mobile phone to tablet, pc and even TV as well as having your own custom size resolution. You can also rotate, scroll and use a proxy with this tool. Responsive Design Checker: This is a very easy to use tool that only checks for the responsive design. It has an intuitive interface with a range of view port sizes and popular devices to choose from. This tool isn’t intended to test mobile site versions, so it won’t show you if your site redirects to a mobile version. Some devices, including the iPhone, automatically resize websites to fit the screen, but that’s not responsive design, so you won’t see that here, either. More on this topic:    How to Test Responsive Web Design     Opensource Mobile Test Automation Tools  "
    }, {
    "id": 222,
    "url": "localhost:4000/ecommerce-testing-can-make-break/",
    "title": "Ecommerce Testing - It can be make or break!",
    "body": "2016/10/03 -  Living in the times of omnichannel retail, seamless shopping experience and innumerable alternatives available to the customers, a test professional has a very collaborative role to play and be a part of the bigger picture when working on an e-commerce platform. Testing E-commerce comes with its own challenges but at the same time for a test analyst, it is also an opportunity to be innovative, creative and at times test as someone who does not really know the system too well. Exploratory testing and not knowing too much detail about a system are the some of the ways to replicate “real” user behavior and thus, uncover hidden issues before the user spots them post go-live.  Apart from doing the usual stuff, a tester can in such cases also add additional value by making usability suggestions and advice on ways to improve the overall user experience. The retail industry is moving fast towards integrating different sales channels giving the customers a common view irrespective of where they choose to shop. The customer’s very first bad experience on an e-commerce website can make them abandon an application/website forever.  A second chance is a rare thing and success/failure directly impacts the brand image and revenues. There are some key areas that need focus while e-commerce testing, a lot of these need attention during the requirements gathering and the design phase rather than during actual test phase. The primary focus during static and dynamic testing of an e-commerce platform should always be on what is highly visible to the customer and matter the most to them. A QA needs to don a “User’s” hat and make relevant suggestions on what would give the customer a reason to return to the same website and also drive them to stores.    User Experience – This is the most important aspect of an e-commerce platform and it constitutes much more than the look &amp; feel, colors, text, logos etc. Think of the bottlenecks that can lead a customer to abandon the basket midway, analyze and identify if there are any scenarios that might take the customer to a dead end where they wouldn’t know what to do next. Are the error messages appropriate and convey the meaning clearly? Are there any unnecessary distractions in the checkout steps that may take the customer away from completing the checkout? The earlier a QA identifies a tricky scenario, lower is the cost, time &amp; complexity of implementing a change.     Inventory &amp; Stock - A customer should ideally have one view of the inventory irrespective of where they shop. In this area, for a QA it is worth concentrating on - Is the customer encouraged to use an alternative channel when a product is not available in the customer’s preferred medium? Is there any benefit offered to a customer for them to choose a channel of less preference for a product that isn’t stocked in the channel of their first preference? These benefits may include enabling a promotion or discount applicable only on the channel that has available stock.     Drive the customer to store &amp; Order Fulfilment – Ever wondered if an online retail website has good enough ways to drive the customers to stores and then once they are in the stores, is there an option to order online from the store? Integration is the key to increase both online and in-store sales. Today, the customer wants to buy from anywhere and ship from anywhere/to anywhere. A single shopping journey may span across different channels and how efficiently order fulfillment is designed can have a strong impact on sales. QA’s can contribute in identifying such scenarios by participating early in the project lifecycle.     Ease of Returns - Almost every retailer today that has some online presence competes with the likes of Amazon, eBay, and Google. Be it deals, the ease of shopping or returns, the market is led by these giants. Thus, even as a medium scale retailer, it is important to build an easy to use interface for returns and refunds.  Does an e-commerce platform allow a customer return a product on any channel irrespective of from where it was originally bought? Focus on refund/return scenarios is equally important during testing.     Cross Browser/Cross-Device – The market is flooded with a variety of hardware devices that customers nowadays use to access websites and applications. These devices use a different browser and OS combinations. It is very critical to identify the most popular browser, device, OS combinations that a company’s customers use and then decide on which ones need more focus. What a user can do through a desktop, he/she should be able to do the same from an iPad or an iPhone or an Android phone. Is your website/application compatible with variety of devices? This is an essential part of the test planning that QA’s need to look at.  Any job can get monotonous when it lacks creativity. As a tester, you sometimes get interesting opportunities to participate in something that lies a little outside one’s domain. In e-commerce testing, grab that opportunity and add value to the product that is under test. Move from quality control to quality assurance. Fit into the bigger picture. Until the next post, enjoy testing! "
    }, {
    "id": 223,
    "url": "localhost:4000/there-is-no-qa-team-in-agile/",
    "title": "There is NO QA Team in Agile",
    "body": "2016/10/02 - Agile is all about working collaboratively with people who have different skills and mindsets to achieve a common goal. When we look at a typical scrum team, it consists of developers (both front-end and back-end), QAs and scrum master. It surprises me when some people who are agile advocates with many years of experience working in agile environments still refer to as having or building up a QA team to support the agile projects. When we start referring to QA as a team, it immediately creates a partition between developers and testers and removes the responsibility of developers doing their due diligence to test their own work and produce quality code, because there is a “QA Team” who will work hard to find all the bugs in the system. This model of working resembles waterfall and V-model projects with throwing the code “over-the-wall” attitude which produces low quality software, the very essence of which agile methodologies are aiming to fix! In agile projects, QA should be embedded in the scrum teams because testing and quality is not an afterthought. Quality should be baked in right from the start. By constructing a QA team, we fall in the danger of separating the testers from vital conversations with the product owners, developers, etc. Testers can add immense value to the quality of the project when they participate in sprint planning meetings, solution work shops, and pairing with developers to ensure code is tested with good and meaningful unit tests. Technical QAs embedded in agile teams can help with automating acceptance tests along with development making sure that new features work as intended. Some organizations have a QA function with possibly a QA Manager whereby a number of testing experts provide the overall testing practice, strategy, guidance and approach to testing for the QAs in agile teams.   The QA function is not directly affiliated to any of the agile teams but act as SMEs across different teams and are responsible for advocating best practices to make quality software. The QAs in the agile teams are encouraged to be the voice of QA for their respective teams, ensuring that their team follows the best practices as set out by the QA function and work towards Continuous Testing. So, in agile organizations, instead of talking about “having a QA team” maybe we should be referring to building up a QA practice and the good QA practice will imply that the QAs should be embedded in the agile teams ensuring quality throughout the software development. "
    }, {
    "id": 224,
    "url": "localhost:4000/best-practices-for-continuous-testing-in-agile/",
    "title": "Best Practices for Continuous Testing in Agile",
    "body": "2016/10/01 - What is Continuous Testing?: In Agile, where we frequently release software to production, we need to ensure that software is of high quality throughout the development. We need to test early and we need to test often. We need to make sure that we get correct requirements to begin with, and to ensure that we test throughout development and not leave testing just before release. Below are a set of best practices that we can follow to implement and improve testing throughout the development lifecycle. 1. Lean Testing: Continuous Testing requires being fully focused on providing value for the business. Rather than spending time and effort on producing artifacts that don’t provide value, we should organize testing in a lean way  Pair developers with testers to ensure effective unit testing is performed.  Reduce unnecessary testing artifacts, such as extensive test plans and test cases, reduce waiting times for testing.  Adapt a more exploratory attitude to testing when testing manually. 2. Collaborate With Business: Continuous Testing means testing correctly from the very start. We have to make sure we get good requirements from business to start development.  QA should build a close relationship with Business Analysts.  Remove ambiguity from user stories - ensure every user story is testable and includes acceptance criteria.  Don’t ignore non-functional testing such as performance and security. Do both functional and non-functional testing from the very start of the project.  Build meaningful end-to-end test scenarios by utilizing trends, data and analytics from the production website to gather information about user activities and user journeys through the application. 3. Implement a QA Practice:  Build a strong testing/QA practice which drives development. Define an Agile QA Testing Strategy.  Run regular QA workshops where the testers can improve their technical skills as well as soft skills.  Implement appropriate Test Techniques, leveraging technical architecture diagrams, models of the application and mind maps.  Embed QA within the teams, so that they are aware of any changes to the application. 4. Automate Testing: Continuous Testing requires testing early and testing often. We can use automated testing to get quick feedback on the status of the application.  Apply Best Practices on Test Automation Know when to automate tests and when to leave them as manual tests Test automation is the responsibility of both developers and testers.  Automate regression tests as well as non-functional performance and security tests where possible.  Ensure you follow the Test Automation Pyramid principle by increasing automated unit tests, API and Integration tests, and only a handful of automated tests through the UI.  Run automated tests from a Continuous Integration (CI) server.  Create smoke regression packs that run fast and run them as often as the application is updated.  Automate new functionality and stories along development rather than leaving them for later. 5. Automate Deployments:  In order to make the most of continuous testing, the steps involved in every stage should be seamless, trouble-free and automated.  Rather than waiting for DevOps to deploy the latest release in a test environment for QA to test, this process should be automated.  Embrace Task Automation.  Automation is not just for testing and verification. Any repetitive heavy-processed manual work should be automated.  Standardize the test environments so deployment is smooth across different environments and the results of the automated tests are reliable.  Make use of visualization to scale automated testing to get quick feedback"
    }, {
    "id": 225,
    "url": "localhost:4000/what-is-a-web-service/",
    "title": "What is a Web Service?",
    "body": "2016/09/30 - A Web Service is a program that can be accessed by other programs over the web (http). For example, let’s assume that you have a function that prints a text in HTML format. The application’s target is the web browser which renders the output and a human being can easily read the text on the page. On the other hand, a web service’s target audience is other programs or other web services which consume the data served by the web service.  The output is normally in a standard language which can be understood by other programs. Take the above example, if the web service outputs the text in say XML format, then other web services which can read or understand XML, can use the output. The main advantage of a Web Service is that applications can be written in any language, but they can communicate and exchange data with each other through a Web Service.  Software applications written in various programming languages and running on various platforms can use web services to exchange data over the internet (HTTP). This interoperability (e. g. , between Java and Python, or Windows and Linux applications) is due to the use of open standards (XML, SOAP, HTTP).  SOAP (Simple Object Access Protocol) UDDI (Universal Description, Discovery and Integration) WSDL (Web Services Description Language)How many different kinds of Web Services are there?: Primarily, there are two types of Web Services, Simple Object Access Protocol (SOAP) and Representational State Transfer (REST). A SOAP Web Service, accepts a request in XML format and generates an output in XML format. A REST Web Service is more versatile and can accept XML as well as JSON as request and generates an output in XML as well as JSON, or even HTML "
    }, {
    "id": 226,
    "url": "localhost:4000/webdriver-how-to-open-new-browser-window-with-javascript/",
    "title": "WebDriver - How to Open New Browser Window With Javascript",
    "body": "2016/09/29 - In previous WebDriver tutorial, we showed how to open a new browser tab in Selenium WebDriver. In this tutorial, we take a look at how to open a new browser window using JavaScript in WebDriver. First, let’s see how to execute JavaScript code in Selenium WebDriver 1234WebDriver driver = new FirefoxDriver();    if (driver instanceof JavascriptExecutor) {    ((JavascriptExecutor)driver). executeScript( javaScriptCode(); );    }To open a new browser window by JavaScript in WebDriver, we can use the example below: 1234WebDriver driver = new FirefoxDriver();    if (driver instanceof JavascriptExecutor) {    ((JavascriptExecutor)driver). executeScript( window. open(); );    }Once the new browser window is opened, then we can navigate to it using: 12ArrayList&lt;String&gt; tabs = new ArrayList&lt;String&gt;(driver. getWindowHandles());    driver. switchTo(). window(tabs. get(0));You can find more documentation on this here, in the documenation, or, preferably, in the JavaDocs of JavascriptExecutor "
    }, {
    "id": 227,
    "url": "localhost:4000/webdriver-how-to-restore-cookies-in-new-browser-window/",
    "title": "WebDriver - How to Restore Cookies in New Browser Window",
    "body": "2016/09/28 - Suppose we have to test for the following scenario: 1. Go to login page and login to the application2. Close the browser3. Open the browser and go to the login page - the user should not see the login form and should be already logged in. On the first login, cookies are stored in the browser. In WebDriver, when the browser window is closed, all session data and cookies are deleted, so the testing of the above scenario becomes impossible. Luckily, WebDriver has functionality to read the cookies from the browser before closing it and then restore the cookies in the new browser window. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com. testingexcellence. webdriverimport org. openqa. selenium. By;import org. openqa. selenium. Cookie;import org. openqa. selenium. WebDriver;import org. openqa. selenium. firefox. FirefoxDriver;import org. testng. Assert;import java. util. Set;public class CookieTest {  WebDriver driver;  @Test  public void login_state_should_be_restored() {    driver = new FirefoxDriver();    driver. get( http://www. example. com/login );    driver. findElement(By. id( username )). sendKeys( admin );    driver. findElement(By. id( password )). sendKeys( 12345 );    driver. findElement(By. id( login )). click();    Assert. assertTrue(        driver. findElement(By. id( welcome )). isDisplayed());    //Before closing the browser, read the cookies    Set allCookies = driver. manage(). getCookies();    driver. close();    //open a new browser window    driver = new FirefoxDriver();    //restore all cookies from previous session    for(Cookie cookie : allCookies) {      driver. manage(). addCookie(cookie);    }    driver. get( http://www. example. com/login );//Login page should not be disaplyed    Assert. assertTrue(        driver. findElement(By. id( welcome )). isDisplayed());    driver. close();  }}"
    }, {
    "id": 228,
    "url": "localhost:4000/testng-run-all-test-classes-package-testngxml-suite/",
    "title": "Run All Test Classes in a Package from testng.xml Suite",
    "body": "2016/09/27 - 1234567&lt;suite name= Suite1  verbose= 1 &gt;  &lt;test name= all-tests &gt;    &lt;packages&gt;      &lt;package name= com. testingexcellence. tests. ui /&gt;    &lt;/packages&gt;  &lt;/test&gt;&lt;/suite&gt;If you need to run all tests from multiple packages, you can use: 12345678&lt;suite name= Suite2  verbose= 1 &gt;  &lt;test name= all-tests &gt;    &lt;packages&gt;      &lt;package name= com. testingexcellence. tests. ui /&gt;      &lt;package name= com. testingexcellence. tests. api /&gt;    &lt;/packages&gt;  &lt;/test&gt;&lt;/suite&gt;If there are many packages with tests that all need to be executed, rather than listing all package names individually, we can use regular expression to include all packages, such as: 1234567&lt;suite name= Suite-3  verbose= 1 &gt; &lt;test name= all-packages &gt;  &lt;packages&gt;   &lt;package name= . *  /&gt;  &lt;/packages&gt; &lt;/test&gt;&lt;/suite&gt;Note, there is a “. ” before the * in the package name, which indicates all package names. "
    }, {
    "id": 229,
    "url": "localhost:4000/how-to-get-response-status-code-with-selenium-webdriver/",
    "title": "How to get Response Status Code with Selenium WebDriver",
    "body": "2016/09/26 - Quite often when you are running automated checks with Selenium WebDriver, you also want to check the response status code for a resource, such as a web service or other web pages on the site. You can also check for broken links on the site as you are executing Selenium WebDriver scripts. Let’s review the different HTTP status codes: 2xx - OK3xx - Redirection4xx - Resource not found5xx - Server error In Selenium WebDriver there is no direct method to check the response status code, so we have to use another library for this. We can use Apache HttpClient or I prefer to use REST-assured library from Jayway https://www. testingexcellence. com/webdriver-headless-mode-chrome-driver/ To get the response code using REST-assured we can use: 12345678910111213141516import io. restassured. RestAssured;public class HttpResponseCode {  public int httpResponseCodeViaGet(String url) {      return RestAssured. get(url). statusCode();  }  public int httpResponseCodeViaPost(String url) {    return RestAssured. post(url). statusCode();  }  public static void main(String args[]) {    new HttpResponseCode(). httpResponseCodeViaGet( http://www. google. com );  }}Output: 200 To check for broken links on the page while executing Selenium WebDriver tests, we can use: 1234567891011121314151617181920212223242526272829303132333435import org. openqa. selenium. By;import org. openqa. selenium. WebDriver;import org. openqa. selenium. WebElement;import org. openqa. selenium. firefox. FirefoxDriver;import java. util. List;public class HttpResponseCode {  WebDriver driver;  int statusCode  public void checkBrokenLinks() {    driver = new FirefoxDriver();    driver. get( http://www. testingexcellence. com );//Get all the links on the page    List&lt;WebElement&gt; links = driver. findElements(By. cssSelector( a ));    String href;    for(WebElement link : links) {      href = link. getAttribute( href );      statusCode = new HttpResponseCode(). httpResponseCodeViaGet(href);      if(200 != statusCode) {        System. out. println(href +   gave a response code of   + statusCode);      }    }  }  public static void main(String args[]) {    new HttpResponseCode(). checkBrokenLinks();  }}https://www. testingexcellence. com/capture-network-traffic-xhr-cypress/ "
    }, {
    "id": 230,
    "url": "localhost:4000/difference-between-driver-get-and-driver-navigate-tourl-in-webdriver/",
    "title": "What is the Difference Between driver.get() and driver.navigate().to(“url”) in Webdriver?",
    "body": "2016/09/25 - What is the difference between using driver. get() method or driver. navigate(). to(“url”) method in WebDriver? Is one faster than the other? You can use both methods to navigate to a URL. Because navigating to a URL is very common, then driver. get() is a convenient way. However, it does the same function as the driver. navigate(). to(“url”) The driver. navigate() also has other functions, such as driver. navigate(). back()driver. navigate(). forward()driver. navigate(). refresh() Related:  WebDriver Wait For Page to Load Example in Java WebDriver Implicit, Explicit and Fluent Wait Examples WebDriver - How to Restore Cookies in New Browser Window WebDriver - How to Open New Browser Window With Javascript"
    }, {
    "id": 231,
    "url": "localhost:4000/jmeter-tutorial-how-to-send-a-json-file-as-request-in-body/",
    "title": "Jmeter Tutorial: How to Send a JSON File as Request in Body",
    "body": "2016/09/24 - In this JMeter Tutorial, we explain how to send one or multiple JSON files in the body of the HTTP request. When testing a RESTful API, we normally send a POST request to the REST API in JSON format. The request parameters in JSON format needs to be sent in the body of the HTTP request. First, you will need a text file with the JSON request. We will use this file to send to our REST API in the body of the POST request. Suppose, the file is located in /Users/testing-excellence/Perf/blog/json_request. txt Our JMeter script will look something like this: In other words, we need to select the Body Data in the HTTP Sampler and insert the following line of code 1${__FileToString(/Users/testing-excellence/Perf/blog/${__eval(${json_file})}. txt,,)}Obviously, the path will be different on your machine. The above line takes the contents of the file named json_file. txt and sends the contents in the body of the request to the REST API. As JMeter is mainly used for performance and load testing, we can load test our REST API by sending multiple JSON requests. To do that we make use of the JMeter’s CVS Data Set Config element. In the CSV file, we have a column with the names of the JSON request files. This CSV file serves as a reference to the JSON files. Suppose we have 10 JSON files, with filenames 100. txt, 101. txt, 103. txt…. 110. txt And the CSV file will look like: Then in JMeter, we add the CSV Data Set Config element to our test plan The variable is JSON_FILE which takes the values of 100, 101, 102, etc… from the CSV file. Then we need to reference this variable in our __FileToString()  JMeter function, i. e.  When we execute this JMeter test, it will loop through the CVS, taking each file name and extract the contents of each file to send as a JSON in the body of the request. "
    }, {
    "id": 232,
    "url": "localhost:4000/automated-ui-testing-worth/",
    "title": "Is Automated Testing on the UI Worth the Effort?",
    "body": "2016/09/23 - Automated UI Testing: Is it really worth it to spend time and effort on Automated UI Testing? I’m using Selenium WebDriver to automate my testing of a web application, which is an e-commerce application. When I run my automated tests, there are always many failures related to UI changes, slowness of the application or problems with third-party services. Our web application communicates with at least 7 different third-party web services. In most cases the, selenium automated scripts face intermittent failures. It is very annoying as one time it passes and next time it fails. It is not possible to get a green build that I can rely on consistently. So, given all the problems I face during automated UI testing, are they really worth the effort? Automated Testing whether on UI or otherwise should provide value to be worthwhile. If you find yourself spending more time fixing broken tests and maintaining scripts than writing meaningful tests, then you need to change your strategy in how you automate and run your tests.  Test Automation Strategy Can you really automate a user journey? Can agile succeed without automated testing?Many agile teams seem to prefer UI level automation or think that such level of testing is necessary to prove the required business functionality. However, within six to nine months after starting this effort, they will soon realize that the cost of maintaining UI level tests is higher than the benefit they bring. Many have thrown away the tests at that point and effectively lost all the effort they put into them. We should either avoid UI level test automation or at least keep them to the bare minimum. But if you really have to do significant Automated UI Testing, then here is how to do it right to keep the cost of maintenance low. Three Levels of Automated UI Testing: A very good idea when designing UI level functional tests is to think about describing the test at these three levels:    Business rule/functionality level: what is this test demonstrating or exercising? For example, free delivery is offered to customers who order two or more books.     User interface workflow level: how does a user interact with the UI, on a higher activity level? For example, put two books in a shopping cart, enter address details, verify that delivery options include free delivery.     Technical activity level: what are the technical steps required to exercise the functionality? For example, open the shop homepage, log in with “test_user” and “test_password”, go to the “/book” page, click on the first image with the “book” CSS class, wait for the relative page to load, click on the “Buy now” link… and so on.  Why would you automate a test? Test Automation Pyramid: I would use the “Inversion of the test automation pyramid” principle, where you focus the majority of your tests at the unit layer. If you have web services you can test the application logic at that layer. Then, there would only be a handful of automated end-to-end tests on the UI. That way you have the majority of your tests automated with minimum maintenance as there is no UI involved and they run much quicker.  Test Automation Tips and Best PracticesThe problem with running automated tests through the UI is you have to wait for the browser to launch. Secondly, most modern web applications have third-party tracking tags which could slow down the page load. The aim of automated UI tests is to find major application issues quickly. But because they take a long time to complete, we may not get quick feedback. In most cases, major issues are spotted straight away by someone manually testing. We don’t have to wait for automated tests to tell us something is wrong when we could see the issue straight away. "
    }, {
    "id": 233,
    "url": "localhost:4000/can-agile-succeed-without-automated-testing/",
    "title": "Can Agile Succeed Without Automated Testing?",
    "body": "2016/09/22 - Is Automated Testing really necessary in agile projects? Can we be agile without any automated testing? When we talk about automated testing, we have to know which layer (unit, API, UI) we are talking about. I have worked in many organisations which were agile, but the status of automated testing at all layers was so poor and ineffective that it was like non-existent, YET, they were releasing software every two weeks in production without much hiccup. I’m not saying that automated testing is a waste of time, but I have seen people releasing software by just manual testing. However, the problem with not having any automated tests is that whenever you want to release software to production you release with fear and no confidence that the software is robust, because there is only so much you can test manually. I would say, you do need automated unit tests and automated integration/api tests, but maybe not necessary to have a full suite of long automated end-to-end tests through the UI, as they are slow to run and costly to maintain. So, to conclude, automated testing helps agile projects deliver better quality code through continuous checking and providing fast feedback, so one would say it is an essential element of agile projects, however, it provides the most value when the whole team is responsible for test automation and that the tests are automated at unit and API layer. Tests through the UI should only check user journeys rather than a full functional verification of every feature. "
    }, {
    "id": 234,
    "url": "localhost:4000/opensource-agile-testing-tools/",
    "title": "9 Useful Open Source Testing Tools for Agile Testers",
    "body": "2016/09/21 - If you are a technical tester in an agile project, most likely you will be using various testing tools to verify the functionality of the application you are testing. We have compiled a list of useful tools to help your testing activities in agile projects. All the tools and libraries listed here are open source. Selenium WebDriver: Selenium WebDriver is the most widely used test tool for browser test automation. By running automated tests on the UI, we can simulate what the user sees when they interact with the web application. Remember, Selenium is only used for web application automation and not desktop automation. One of the main advantages of using Selenium WebDriver over other UI automation tools is that you can write your automated tests in a variety of supported programming languages, such as Java, C#, Ruby, Python, and PHP. https://www. testingexcellence. com/testing-microservices-beginners-guide/ Selenium is often used in Agile projects because there is a heavy emphasis on automated testing and that the whole team can contribute to automated tests. While Selenium can provide benefit to the agile team, you need to be careful not to get carried away and automate every test because potentially you could reach a point where you are spending more time on dealing with issues rather than be productive. Jmeter: Jmeter is an opensource performance testing tool written entirely in Java. It can be used to load test websites (HTTP, HTTPS) as well as Web Services (SOAP and REST) and Databases. The HTTP(S) Test Script Recorder can be used to record and replay requests. Jmeter can be extended by plugins to support further functionalities and there is also a Jenkins plugin which means you can run performance tests as part of the delivery pipeline. SoapUI: SoapUI tool is primarily used for functional testing of Web Services. In its early days, it only supported SOAP (XML) but now also supports REST (JSON) formats. The tool is relatively easy to use and you can create tests for web services in just a few minutes. You can execute tests and analyze the reports all inside SoapUI GUI. A nice feature of SoapUI is its ability to create mock web services which is handy when you are creating tests for a web service which is not yet developed. https://www. testingexcellence. com/testing-quality-assurance-agile/ WireMock: Testing Web Services can sometimes be a challenge, particularly when the web service is not available or is down. In these cases, we can use a mock service. This is where WireMock comes into play. It is a flexible library for stubbing and mocking web services. Unlike general purpose mocking tools, it works by creating an actual HTTP server that your code under test can connect to as it would a real web service. It supports HTTP response stubbing, request verification, proxy/intercept, record/playback of stubs and fault injection, and can be used from within a unit test or deployed into a test environment. VirtualBox: These days, most applications need to be tested against multiple browsers and operating systems. Instead of having physical servers with different operating systems and browsers, VirtualBox provides an easy solution to create virtual machines with different configurations. You can run VirtualBox on any operating system to create virtual machines and you can even have multiple virtual machines with different operating systems on the same box. https://www. testingexcellence. com/automated-ui-testing-worth/ Selenium Grid: Selenium tests can take a long time to run particularly when you have too many of them running regularly or as part of a release. As such the feedback loop can be very slow Thankfully, we have Selenium Grid which can execute Selenium tests in parallel. This is very useful in cases when you need to run the same tests on multiple browsers and/or against different operating systems. Appium: Nowadays many websites are accessed via mobile or tablet devices. This means that we need to test web applications on mobile devices. Appium is an open source test automation framework for use with native, hybrid and mobile web apps. It drives iOS and Android apps using the WebDriver protocol. Appium is “cross-platform” which means it allows you to write tests against multiple platforms (iOS, Android), using the same API. This enables code reuse between iOS and Android test suites. XMind: XMind in the most popular and feature-rich mind mapping tool. You can use it to create stunning mind maps to highlight the features of a website, or to create a user journey flow through the application. Mind maps have become very popular in the world of software testing because they provide nice visuals and can be of great help when designing test cases. https://www. testingexcellence. com/webdriver-headless-mode-chrome-driver/ Cucumber: If you are doing Behaviour Driven Development, whereby there is close collaboration between the business, the customer, and the technology team, then you need a way to specify the requirements which is in plain English that can be understood by all interested stakeholders. The Cucumber tool takes the specifications and binds them to automated tests, effectively creating live executable documentation. It also aids the collaboration between team members in specifying requirements, guides development, drives automated tests and describes the system. https://www. testingexcellence. com/reactjs-test-automation-tools/ "
    }, {
    "id": 235,
    "url": "localhost:4000/difference-between-performance-testing-and-load-testing/",
    "title": "Difference Between Performance Testing and Load Testing",
    "body": "2016/09/20 -  What is the difference between performance testing, load testing, and stress testing? Performance Testing: Performance Testing measures the response time of an application with an expected number of users. The aim of this is to get a baseline and an indication of how an application behaves under normal conditions. Does it meet the required response time? Load Testing: Load Testing is measuring the response time when the application is subjected to more than the usual number of users. The response time will increase, i. e. the application will be slower under heavy load, but the aim of load testing is to see whether the application can sustain the increased load on the server or will it crash and kill the servers. Load testing is usually started as low numbers and gradually increased over a given period of time until it reaches the desired load on the system and then it ramps down. Stress Testing or Soak Testing: Stress Testing or Soak Testing is like load testing but we resume the load on the server for a long period, say 1 hour. The aim of stress testing is to ensure that under a constant load for a long duration, the servers don’t crash, albeit responding slowly. Stress testing starts of the same as load testing, e. g. gradually increasing the load on the servers, but once this load is reached, we resume the same load on the server for a given duration and then measure the response times. Break Point: If we keep increasing the load on the server, there comes a point when the server cannot handle any more requests and it crashes, most probably starting to give an HTTP error 500 response code. Once this happens, we get an indication of the capacity of the application, i. e. how many users can the application handle. "
    }, {
    "id": 236,
    "url": "localhost:4000/automate-stories-during-sprint/",
    "title": "Is it Possible to Automate Stories During the Sprint?",
    "body": "2016/09/19 - Test Automation During Sprint: Question My team uses scrum agile methodology to develop a web application. As an Automation Tester in the team, I’m often asked to automate the stories within the sprint, even when the developer hasn’t even finished the story. If it’s at the beginning of the sprint, I have time to automate the story during the sprint, but towards the end of the sprint, I don’t get enough time to automate the last stories. Any suggestions on how I can complete the automation of the stories within the current sprint? Answer The automated task for every story should be the story’s definition of done. Ideally you should aim to automate the stories within the current sprint. The way to do this is to have an automation framework which speeds up writing automated scripts, so that you just focus on the scenarios rather than spending time creating functions. In your test automation framework, you need to separate the layers. The base layer should be your application framework code that talks to the automation tool, such as WebDriver. The next layer up is your page objects which model your applications. In these classes or page objects you need to write many functions to full control over writing user scenarios. This is where the magic happens and how things are done. The last layer is your scenarios. These should just call the functions in your page objects.  You only need to define what needs to be done and the page objects should take care of it. In this way even when you have a short time at the end of the sprint, you can quickly create automated scenarios if you have a solid foundation. Automating regression tests during the sprint requires discipline. The scope of the regression tests increases and so the maintenance also increases. You need to be aware that not all tests require to be automated. You should only automate the tests that provide value for the business. "
    }, {
    "id": 237,
    "url": "localhost:4000/selenium-and-cucumber-ui-automation-challenges/",
    "title": "Why Selenium and Cucumber Should Not Be Used Together",
    "body": "2016/09/18 - In this post, I will explain why I believe it is a bad idea to write UI automated tests with Selenium and Cucumber. The title of the post mentions Selenium and Cucumber because they are the most popular browser automation and BDD tools respectively, however, the context of this article applies to any UI automation tool in combination with any BDD tool. Before I dig deeper, let’s review some background information. What is Selenium?: Selenium is a browser automation testing tool which is capable of interacting with the HTML elements of a web application to simulate user activity. In Selenium WebDriver, we can write scripts in a number of programming languages and can be a great asset for multiple OS and cross-browser testing. What is Cucumber?: Cucumber was created to drive Behaviour Driven Development (BDD) process, such that the customer can describe their requirements as a series of examples called scenarios, in plain text files using the Gherkin language in the Given When Then format. In Cucumber world, these files are called feature files which are reviewed by the Scrum team to get a clear understanding of the requirements before starting the actual development. Once development is underway, the developers and/or QA will write Step Definitions which are essentially snippets of code which bind the scenarios from the feature files to the test code which execute actions against the application under test. Selenium and Cucumber: Both Selenium and Cucumber are great tools for their own purposes but when used together, things don’t marry up nicely! Let’s see why. Stories are generally written from a user’s perspective, for example:  Feature: Login functionality  As a user of website abc. com  I want customers to be able to login to the site  So that they can view their account information. In turn, Scenarios in the feature files are written in a way which describes the behavior of the feature when a user interacts with the application. For example:  Scenario 1: Valid login  Given I am on abc. com Login page  When I enter valid credentials  Then I am redirected to My Account page And so you can add more scenarios to test different data combinations. Because both the story and the feature file are written from a high-level point of view, and because we want to automate the scenarios, it only seems natural to start writing step definitions in Cucumber which call Selenium to drive the application, do the actions and verify the outcome. But, this is where the problem occurs; when we start combining Selenium with Cucumber to write automated UI tests. In all fairness, in simple cases like the Login scenario above, things fit nicely together and the approach seems plausible, and in fact, most examples that you see on the internet, demonstrating the use of Selenium and Cucumber, seem to limit themselves to the famous Login example. The readers of such blogs would assume that they can take the simple Login scenario and apply the same principle to a wider context of an application. Don’t be fooled though, as things can get very sour with Selenium and Cucumber when applied to a real-world large web-based application. Let’s take an example of a search results page of a typical e-commerce application which sells products online. Normally the search results page is full of features, such as filters, sorts, list of products, ability to change search, ability to paginate or auto-load on scrolling, etc, as can be seen in the screenshot below: I’m going to assume that each feature on the search results page, was added to the site on an incremental basis using agile development. Applying the same principle of our simple Login example, as each feature is developed we would have a respective feature file filled with lots of different scenarios. For example: In iteration 1 of the development, “Filter by Price” is developed, so we would have a feature file for it with its own scenarios related to the price filter. In iteration 2 of the development, “Filter by Star Rating” is developed, so we would have a feature file for it with its own scenarios related to the star rating filter, and so on for each new feature. It is important to note that the scenarios in each feature file are only specific to their respective feature. In fact, this is why they are called feature files because the focus is on individual features. As mentioned earlier, when the application is simple, we can survive the challenge of automating the scenarios on UI with Selenium and Cucumber. However, as the application grows and new features are added, complexity arises as there could be dependencies between different features. For instance, I could first filter my search results by price then apply another filter for the star rating. Ah…we now have a problem! Which feature file should this scenario now go? In “Filter by Star Rating” file or “Filter by Price” file? How about if I now add a scenario to apply a sort to my filtered results to sort by highest votes? If a stakeholder wishes to see what our test coverage is, which of the feature files should he look into? Will he get the full picture of scenario coverage by reading just one of the feature files or would he need to read all feature files? At the time of development, when each feature is developed one by one in each iteration, the feature files would be focused on the feature itself, so at some point, when we have multiple features, we need to start thinking about testing these, not only in isolation but also creative scenarios where we combine different features. And in fact, this is what real users of the application will do. They will first enter their search criteria, once on the search results page, they would possibly paginate, then filter, then sort, then go back, and so on, and they can do these actions in any order. There won’t be a prescribed order of events. This is a real user journey and a real test of the system! Majority of the bugs in an application are exposed when either a feature itself is buggy or when two features that work perfectly well in isolation, don’t work together. This is what the Pairwise Testing Model is based upon. So, what’s the big deal with using Selenium and Cucumber together?: Where at all possible, we should not use the web GUI for functional verification. The functionality of a feature should be tested at the API layer by integration tests. UI should only be reserved for checking the user flows through the application, or end-to-end tests and making sure relevant expected modules or widgets are present on the page as the user navigates from one page to another. A typical user journey would entail: 1 - Navigate to the homepage of abc. com website 2 - Search for a product from the homepage 3 - Browse through the list of search results 4 - Apply filter and/or sort 5 - Read product details 6 - Add the product to basket 7 - Continue to check out… Selenium is excellent in automating these scenarios and checking for various elements on each page and as I mentioned above, that’s what we should focus on when testing at UI layer, and testing the different states transitions. As can be seen, each user journey through the application touches on many pages and potentially interacts with multiple features on each and every page, and we would be verifying various things at each step throughout the journey, so using a “feature file” to document these scenarios makes absolute no sense whatsoever, because we’re not testing a feature, we’re testing the integrated system. Things really go pear-shaped when we attempt to write the end-to-end scenarios in a Given-When-Then format. How many Givens are we going to have? How many Thens are we going to have? One could argue that for end-to-end tests we could just use Selenium on its own without the Cucumber and have separate automated tests for each feature using Selenium and Cucumber. Again, I don’t recommend this approach as you will possibly have duplicate tests and we know how slow and brittle UI tests are, so we should aim to have less of them not more! Moreover, you will still have to deal with feature dependencies tests. To summarise: Cucumber is a great tool in checking the behavior of a feature at the API layer with integration tests where each feature can be thoroughly tested. This tool should be used for Story Testing. Selenium is a great tool for automating user scenarios at the UI layer and checking the behavior of the system as a whole. This tool should be used for User Journey Testing, encompassing many user stories. When we get to System Integration Testing or UI Testing, it is best to use Selenium without the underlying Cucumber framework as trying to write Cucumber feature files for user journeys, can get very cumbersome and would not serve the purpose the tool is built for. My article is based on deducing facts!  If there is any value in using cucumber, it is at the feature level.  Checking functionality of a feature is best done outside of UI, e. g. API tests.  Even at API layer tests, cucumber fails miserably.  UI Tests should cover user/business scenarios and not single features. Cucumber works beautifully with a simplistic and naive view of tests and scenarios, such as everyone’s favorite login functionality. Given I am on the login pageWhen I enter valid credentialsThen I should see my account But any savvy tester knows that even a simple login functionality has many many checks. Try converting those checks in cucumber. This is just for login; try writing an end-to-end test in cucumber! UI tests should be covering user journeys which are typically end-to-end and exercise multiple features of an application. There is a lot that goes on in a single user journey across the application. Cucumber is definitely NOT the right tool for user/business scenario testing. "
    }, {
    "id": 238,
    "url": "localhost:4000/4-different-ways-iterate-map-java/",
    "title": "Different Ways to Iterate Through a Map in Java",
    "body": "2016/09/17 - Looping over a Map in Java. In this post, we look at four different ways we can iterate through a map in Java. As of Java 8, we can use the forEach method as well as the iterator class to loop over a map. Method #1: Iterating over entries using For-Each loop: 1234Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;();for (Map. Entry&lt;Integer, Integer&gt; entry : map. entrySet()) {  System. out. println( Key =   + entry. getKey() +  , Value =   + entry. getValue());}Method #2: Iterating over keys or values using For-Each loop: 1234567891011Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;();//iterating over keys onlyfor (Integer key : map. keySet()) {  System. out. println( Key =   + key);}//iterating over values onlyfor (Integer value : map. values()) {  System. out. println( Value =   + value);}Method #3: Iterating using Iterator. : Using Generics: 123456Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;();Iterator&lt;Map. Entry&lt;Integer, Integer&gt;&gt; entries = map. entrySet(). iterator();while (entries. hasNext()) {  Map. Entry&lt;Integer, Integer&gt; entry = entries. next();  System. out. println( Key =   + entry. getKey() +  , Value =   + entry. getValue());}Without Generics: 12345678Map map = new HashMap();Iterator entries = map. entrySet(). iterator();while (entries. hasNext()) {  Map. Entry entry = (Map. Entry) entries. next();  Integer key = (Integer)entry. getKey();  Integer value = (Integer)entry. getValue();  System. out. println( Key =   + key +  , Value =   + value);}Method #4: Iterating over keys and searching for values: 12345Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;();for (Integer key : map. keySet()) {  Integer value = map. get(key);  System. out. println( Key =   + key +  , Value =   + value);}Using Java 8 ForEach: 123456Map&lt;String, Integer&gt; items = new HashMap&lt;&gt;();    items. put( key 1 , 1);    items. put( key 2 , 2);    items. put( key 3 , 3);    items. forEach((k,v)-&gt;System. out. println( Item :   + k +   Count :   + v));Related:  Loop over ArrayList in Java Convert List to Array in Java Parse JSON in Java"
    }, {
    "id": 239,
    "url": "localhost:4000/agile-testing-challenges-qa-agile-projects/",
    "title": "How to Overcome Agile Testing Challenges",
    "body": "2016/09/16 -  What are the most common agile testing challenges faced by software testers or QA in agile projects? What is it like to be a QA in a scrum team? Ever since agile development methodologies were introduced in software development, the role of QA in agile projects has changed considerably.  There is no longer a team of QA sitting in a corner, away from the developers and designers, waiting for the development team to handover a piece of work for testing. One of the most important elements for QA in agile projects is having a good understanding of the agile development methodologies and processes. Many agile companies follow the Scrum framework for delivering quality software, so ensure you are familiar with Scrum. Agile Testing Challenges: The very essence of agile development is delivering working software frequently, each time adding or enhancing a small feature which is of value to the customer. That itself poses a lot of challenge not only for testers but also developers and anyone else involved in the delivery of application. In this article I list some of the most common agile testing challenges for QA in agile projects and how to overcome them. Changing Requirements / Last Minute Changes: Changing requirements or dropping stories mid-sprint is not uncommon in agile projects. This can be a nightmare for the whole team as it means that the work already carried out might be scrapped completely or changes should be made to what’s already half done. These requirement changes and last minute requests can affect the scope of testing which can frustrate testers. How to overcome: Testers should be able to respond to change, knowing that in agile projects, change is inevitable. When requirements change especially towards the end of the sprint when there is not enough time to test adequately, testers should provide as much information as possible about what tests have been run and which part of the application hasn’t been tested well so that the team can make an informed decision (possibly based on risk) whether to release the feature or not. Try getting the developers involved in testing as well, as testing and quality should be the whole team responsibility. Not Enough Information on the Story: There will be times when a product owner who writes user stories, has some idea about a new feature but doesn’t have all the details to write a good set of acceptance criteria to fully define the behaviour of the feature. They ask the development team to create a prototype so they can get more ideas about the functionality and behaviour of the feature. This creates a challenge for testers because there is a lack of understanding and requirements, so proper test cases can’t be constructed. How to overcome: You don’t need very detailed requirements to start testing, so start by thinking about high level scenarios that test the concept of the story, rather than waiting to get full clarification about the feature. By drafting high level test scenarios, even when the details change, the context should still be the same. Continuous Testing: In agile, testing is not a phase, it’s an activity. Testing starts from the very beginning, even before the development starts. In order to have a smooth ride during the sprint, the stories in the backlog should have been elaborated during the story grooming sessions. This means the QA should collaborate with product owners to learn the details of the story and then help write good acceptance criteria. Providing early feedback to developers is crucial and challenging for testers. As testers, not only we have to make sure that the new feature works as specified according to its acceptance criteria, we have to also make sure that the new code hasn’t broken existing functionality, i. e. we haven’t regressed, and we have to provide this information quickly. How to overcome: Ensure each story has adequate acceptance criteria and that the context of the story is well understood by everyone before starting work on development. Start creating tests (automated or manual) as soon as possible so that when the feature is available for testing you can begin straight away. Testers should encourage developers to give early visibility to the feature by deploying regularly to a test environment where testers and/or product owners can run their tests, rather than waiting for the feature to be complete before testing. Automate regression tests to alleviate some of the testing effort and liberate your time for exploratory testing. Technical Skills / Test Automation: Working in an agile environment, means that the testers should be technically competent to help the developers with Integration Testing and API Testing, as well as scripting UI automation checks with Selenium or similar tool. If the testers come from a purely manual or exploratory background, they will find it difficult to keep-up with the pace of delivery as they need to test on a continuous testing. Performance testing is also important particularly for web based applications, to ensure the application can sustain high load during peak times. If your company doesn’t have a dedicated performance tester, it is expected the functional testers to also be involved in performance testing. How to overcome: Start by learning couple of scripting or programming languages, such as Ruby and Java - these are the most popular languages within the technical testing community. If you already are familiar with programming and you get stuck, get help from developers. Selenium tool is the most popular browser automation testing tool, so if the project is web based, having a good knowledge of the tool is a great asset. Jmeter is also another great tool to have knowledge of. It is an open source performance testing tool and relatively easy to learn, so download it and start playing around with some of its features. You can read more about the tools useful for technical testers. Multiple Browsers / Multiple Devices: Nowadays, the architecture of many websites consists of a “back-end” and a “front-end”. The front-end piece is largely based on JavaScript and CSS which could potentially behave differently when viewed from different browsers or devices. Ensuring that a website functions as expected in all major browsers and popular mobile devices or tablets is indeed a top challenge for testers in agile projects. How to overcome: Automation is key here. Writing a test and running it on multiple browsers is what automation does best. You can use Selenium Grid with Docker to manage and run your automated tests in parallel on multiple browsers. Another great tool out there for multi-browser testing is BrowserSync. Communication: No matter how good the process is or how well the above items are carried out, if there is a lack of communication amongst the team members or with product owners, designers, etc, nothing will work. How to overcome: Make sure there is effective communication amongst the team. Engage with developers and product owners on a continuous basis. Ensure there is a process in place and that each team member adheres to that process. Quite often, major issues or bugs are not identified early because the process was not followed and the team failed to communicate with each other. "
    }, {
    "id": 240,
    "url": "localhost:4000/possible-sufficient-testing-without-qa-resource/",
    "title": "Is it Possible to do Sufficient Testing Without QA Resource?",
    "body": "2016/09/15 -  A while back, Yahoo decided to get rid of their entire test and quality assurance team and instead handing the responsibility of testing to the developers. The move was part of project Warp to move closer to continuous delivery model.  The shift wasn’t easy, Yahoo tech execs say, and required some “tough parenting. ” But the result has been fewer errors because “when you have humans everywhere, checking this, checking that, they add so much human error into the chain that, when you take them out, even if you fail sometimes, overall you are doing better. ” And the pain wasn’t as great as expected. Yahoo’s chief architect and SVP of science and technology discuss the transition. Now the question that remains to be answered is, is it possible to do sufficient testing of software application with just the developers and BAs and no QA resource? There are two schools of thoughts here: One is the belief that all bugs are related to code and that if you have a very high percentage of test coverage for your code, then essentially you should have no bugs. As testers, we all know that this is not true! The other belief is that you do sufficient unit testing and also do integration, system and user acceptance testing to ensure application is fit for purpose. While this seems a nice idea, it is not practical as developers need to get on coding new features! Both of these beliefs are extreme. Testing your own code can be effective, because as a developer you know which part of your code is complex and more likely to be buggy, so you would focus on that area. Also, knowing there is no more QA, you are forced to write quality code, as one developer puts it  In my first job, I didn’t have QA. It was up to me to make sure my own code was quality enough before releasing it, and that aspect terrified me enough that I did learn to write quality code (which basically means you are testing your own code thoroughly, doing your own QA). Is Developer Testing Enough?: I believe it is a good move to encourage software developers to take ownership of the quality of their own code, however when you test your own code, you’re more than likely to miss an entire classes of bugs. You can be very effective at catching the kinds of bugs you can think of, but those are always the easiest bugs to catch in the first place. The tests you write for yourself will never do a good job of catching errors in your assumptions about what the code should do, what kinds of inputs it needs to handle, etc. Catching those kinds of conceptual bugs really requires adversarial testing from somebody who isn’t starting from the same set of assumptions.  Working as an automation tester meant that I had to focus on testing and coding both at the same time, and I often struggled! When I was coding the tests, I just wanted to make sure the code executes and make the test pass, I wasn’t too bothered about what the actual test was because my main focus was on coding.  Soon I realised I was automating useless tests which provided no value. Another important point to note is that unit testing only catches programmer errors in code, unit testing does not detect failures in the application, which means if you have 100% code coverage, that does not mean a bug free application.  While it’s always necessary to test your own code via unit tests before it’s passed on, it’s also important to have that second set of eyes on it from a behavioural standpoint. Often we’re too close to the code to really beat it up properly and subject it to really weird edge cases, and good QA people are quite adept at doing that. Testing at the system level by another set of users such as testers can often reveal very interesting bugs. Also, it’s not all about functional testing. We have to care and worry about performance testing, security testing, usability testing, etc, which is required if we want to release a high quality software. Why we Still Need QA?: Testers are sometimes seen as bottleneck to the whole delivery pipeline. Would it not be so much better if everything was automated with no manual intervention and no testers raising bugs to stop the release? Part of the problem when testers are seen as bottlenecks is because of lack of ownership of quality amongst developers. If everyone truly felt that they were responsible for the quality of the product (not just code) then developers and testers work towards the same goal. Testers can pair with developers to write better unit tests and developers can help testers with writing automated checks and also educate testers about the architecture of the application so that they can design good tests to find the areas most likely to break during system testing. In an ideal world, testers should not find any defects, or at least trivial defects. When there is a “team of QA” whose job is to find defects, it is tempting for developers to just rely on testers to find all the defects while the developers focus on development and coding. While Yahoo’s move in eliminating the QA and Testing department encourages developers to take ownership of the quality of the product, it is still not good enough to ensure a robust product. Having said that, even with a team of testers you still cannot guarantee a bug-free software, but what is important is making sure that the software is looked at from various points of views and from different perspectives and that’s where the real benefit of having a good QA function (as opposed to QA team) comes. Testers can ensure developers follow best quality assurance practices and assist with technical and business test designs to help identify the most critical bugs before releasing software. "
    }, {
    "id": 241,
    "url": "localhost:4000/how-to-setup-a-qa-function-from-scratch-for-agile-projects/",
    "title": "How To Setup a QA Function From Scratch For Agile Startups",
    "body": "2016/09/14 - How to setup a QA function from scratch?: It is a usual scenario: a startup company has a new idea and hires a number of developers to build a working model of the idea. Because of the nature of the startups, i. e. not much funding available with a short scale of time to develop the idea, the main effort is focused on building the new product to get it out to public to test the waters, and so naturally, testing and QA is not the top priority for the development team. After it becomes evident that the idea has been a success, the company wants to expand on the idea and starts hiring more developers, but at the same time, they also want the product to be tested before it goes out to public. For a while, testing is done by whoever is available in the company, and it is largely ad-hoc with no proper processes to follow. Then there comes a point when the startup company decides to hire their first senior QA person to start implementing a new QA process for the development team. For the purpose of this article, I’m going to assume that the startup is a web based company, e. g. an e-commerce website. Implementing a QA Process: The main aim of having a Quality Assurance process is to ensure that the right product is built right, the first time. That means, we need to ensure that the requirements are correctly defined and the development team have a solid understanding of the functionality of new features before starting to code. It is important to note that testing is not a phase, it’s an activity and that testing starts from the very beginning of the development process, right from when the user stories are written. Testing should support development and so testing activities are in parallel to the development activities, and at every stage of the development process we need to ensure that the code is thoroughly tested. Before implementing a testing process, we need to know the current development methodology and process and if necessary make adjustments to improve the process. Regression Testing / Sprint Testing: As you start as the first QA person in the company, chances are that there is no regression testing in place and so as new features are developed, you have no idea if they adversely affect the current working website. Moreover, you need to keep up with the development team to test the new features to ensure they function properly and according to specifications. There are at least two tasks in parallel: Testing of new stories in the sprint and performing some degree of regression testing. Testing of the new features takes priority as there is more likelihood of finding bugs in new code than breaking the current working site. But, at the same time, Regression Testing is required to ensure that the existing application keeps functioning as we build new features. A regression testing pack needs to be executed as soon as there is an update to the application, so development team can get fast feedback on the health of the application. There is not enough time to write regression tests as well as keeping up with testing of new features. How can we break this cycle? Usually, during the first few days of the sprint, developers are busy coding and so the new features won’t be ready to test for a while. Here is a good chance to start working on the regression tests. There are best practices for regression testing, but generally, the approach would be to identify the main core user journeys throughout the website, so that on each new release of the website, we can be confident that the application is still usable by majority of its users. There doesn’t need to be an exhaustive list of these scenarios, just the main and most important ones will be sufficient to start a small regression pack that can be executed on every build. Later, as the regression pack matures, we can begin to add more scenarios. Most importantly, these regression scenarios should be automated. Automated Testing: In an agile project, where a sprint typically lasts about two weeks, there is not enough time to do all the testing manually. There is testing of new stories as well as regression testing. While it makes sense to do exploratory testing to test new features, regression tests should be automated to reduce the mundane task of repeatedly executing the same tests manually. Deployment / Build Pipeline: A deployment or build pipeline in an agile project defines how a story gets from product backlog to live production site. It defines a process and the activities that happen at each stage. In order to implement a successful QA process that ensures we are frequently releasing quality code, the deployment pipeline must be defined and be adhered to by all stakeholders. The deployment pipeline is the spine of software delivery. The pipeline should be based on best practices and encompass the activities that occur at each stage. Story Workshops: One of the most important activities in an agile project is frequent story workshop sessions. This is when the product owner, developers and testers gather in a room and start elaborating and fleshing out the details of the stories. This is important because everyone should have the same understanding of the story before starting the development work. Quality Assurance is about defect prevention rather than detection and so in the story workshops, the team get the chance to ask questions about the details of the story, any technical or design constraints and any blockers to developing the stories. Here is a great opportunity to start writing out the acceptance criteria for the stories. Everyone should contribute and start thinking about the possible scenarios for each story, as each one will have a different idea, so the more heads on the story, the more scenarios can be thought of and the higher chance of preventing defects getting live. Once everyone is certain on the detail and scope of each story, development starts. Developer Testing / Testing During Development: Everyone should be responsible for quality of the product and not just testers. As such, there needs to be sufficient amount of “developer testing” to ensure that the code written is of high quality before being deployed to a test environment for further testing. Certainly each new piece of functionality should be well unit tested. On top of that, there needs to be integration tests, API tests as well as UI tests. Peer code reviews or “buddy testing” can put a second eye on the work of the developer. A tester can help in reviewing the unit tests and well as the API tests to ensure correct tests have been written, as well as helping to write the high-level automated UI tests. Read more on Best Practices for Continuous Testing in Agile projects. Continuous Integration / Test Environments: In order to effectively test new features, we need to ensure the code works not only on the developer’s machine but also on other environments, and integrated with other developer’s code. Continuous Integration helps in identifying any build problems early on in the process, so that when the deployment fails we can start to look where the issue is coming from. Test Environments give testers and other team members the chance to test the new features before going live. Non-Functional Testing: When required, we should also perform non-functional testing, such as performance, load and security testing. Quite often the focus is on ensuring the functionality works well, however non-functional testing should be given the same priority, especially for web applications as they could be subjected to heavy load and / or attacks. By performing non-functional testing, we can be sure that our application can handle load during peak times and that is not open to security threats. Other points to consider for setting up a QA function from scratch:  Cross-browser, Cross device testing Mobile and Tablet Testing Parallel execution of automated tests Exploratory Testing Tools, such as Jira, Jenkins, Selenium, etc… Continuous Improvement Recruitment of Testers"
    }, {
    "id": 242,
    "url": "localhost:4000/agile-terminologies-definitions-complete-glossary/",
    "title": "Agile Terminologies and Definitions - Complete Glossary",
    "body": "2016/09/13 -  Complete Glossary of Agile Terminologies and Definitions: Acceptance Testing Formal testing conducted to determine whether or not a system satisfies its acceptance criteria and to enable the customer to determine whether or not to accept the system. Agile Software Development Methodology Agile software development puts a heavy emphasis on collaboration, responsiveness to change, and the reduction of waste throughout the development cycle. Agile software development focuses on keeping code simple, testing often, and delivering functional bits of the application as soon as they’re ready. An important agile principle is to deliver (potentially) releasable software after every iteration. Backlog Grooming Backlog grooming is the process of adding new user stories to the backlog, re-prioritizing existing stories as needed, creating estimates, and deconstructing larger stories into smaller stories or tasks. Rather than grooming the backlog sporadically throughout an iteration, the team may hold a backlog grooming session once per iteration. Breaking the Build When a developer adds changes to the source code repository that result in the failure of a subsequent build process, the developer has “broken the build. ” It should be a team commitment to avoid breaking the build as it will slow down the development and can be a bottleneck for other developers. When the build is broken, the development team is to take immediate action to fix the build. The build is broken if the build process cannot be successfully completed for any number of reasons including (but not limited to) failure to compile, compiling with unacceptable warnings, or the failure of any number of automated tests. Build Process / Build Pipeline The build process or build pipeline, is the process in which a story goes from inception to production, usually going through different stages and checks to ensure quality. The build pipeline defines the workflow for software delivery and what happens at each stage. Burndown Chart A graph that displays the total task hours remaining per day. It shows where the team stands regarding completing the tasks that have been committed to the sprint. The X-axis represents days in the sprint, while the Y-axis is effort remaining. Chicken In scrum, chicken is a slang word used for someone who is interested in a project but has no responsibility for working on a task in the active iteration. They may observe team meetings but cannot vote or talk. Continuous Integration Continuous Integration (CI) is an eXtreme Programming (XP) practice where members of a delivery team frequently integrate their work (e. g. hourly, or at least once daily). Each integration is verified by an automated build, which also performs testing, to detect any integration errors quickly and automatically. The main goal of CI is to avoid what is commonly called integration or merge hell. Cross-Functional Team Team comprised of members with all functional skills and specialties (often called multi-skilled) necessary to complete a project from start to finish. Customer Customer is normally defined as the recipient or user of the product. Customers may be internal or external to the organization. The customer may be one person, a department, or a large group. Internal customers are sometimes called the “Business. ” Daily Standup A daily team meeting usually held first thing in the morning to provide a status update to the team members. The meetings are usually time-boxed to 5-15 minutes, and are held standing up to remind people to keep the meeting short and to the point. Definition of Done (DoD) The criteria for accepting work as completed. Specifying these criteria is the responsibility of the entire team, including the business. Generally, there are three levels of “Done” (also known as Done-Done-Done):  Done: Developed, runs on developer’s box Done: Verified by running unit tests, code review, etc.  Done: Validated as being of deliverable quality with functional tests, reviews, etc. The exact criteria for what constitutes “Done” varies to meet the specific needs of different organizations and initiatives. Epic A very large user story that is eventually broken down into smaller stories. Epics are often used as placeholders for new ideas and related stories to be developed in subsequent sprints. Epic stories help Agile development teams effectively manage and groom their product backlog. Estimation The process of agreeing on a size measurement for the stories or tasks in a product backlog. On agile projects, estimation is done by the team responsible for delivering the work, usually using a planning game or planning poker. Extreme Programming An agile software development methodology which is intended to improve software quality and responsiveness to changing customer requirements. XP advocates frequent “releases” in short development cycles, which is intended to improve productivity and introduce checkpoints at which new customer requirements can be adopted. Other elements of extreme programming include: pair programming, extensive code reviews, unit testing, Continuous Integration to name a few. Feature A coherent business function or attribute of a software product or system. Features normally comprise many detailed (unit) requirements. A single feature is typically implemented through many stories. Features may be functional or non-functional; they provide the basis for organizing stories. Fibonacci Sequence A sequence of numbers in which the next number is derived by adding together the previous two (e. g. 1, 2, 3, 5, 8, 13, 21, 34…). The sequence is used to size stories in Agile estimation techniques such as planning poker. Impediment Anything that prevents a team member from performing work as efficiently as possible is an impediment. Each team member has an opportunity to announce impediments during the daily standup meeting. The ScrumMaster’s job is to ensure impediments are removed as soon as possible so the team can continue to be productive. Iteration A period (from 1 week to 2 months in duration) during which the Agile development team produces an increment of completed software. All system lifecycle phases (requirements, design, code, and test) must be completed during the iteration and then demonstrated for the iteration to be accepted as successfully completed. At the beginning of the iteration, the business or the product owner identifies the next (highest priority) chunk of work for the team to complete. The development team then estimates the level of effort and commits to completing a segment of work during the iteration. Kanban Kanban is a tool derived from lean manufacturing and is associated with the branch of agile practices loosely referred to as Lean Software Development. Kanban constrains how much work in progress is permitted to occur at the same time. The main difference between Kanban and Scrum is that Scrum limits work in progress through sprints and Kanban limits work in progress by limiting how much work may occur at one time (e. g. N tasks or N stories). Lean Software Development Lean software development or just Lean is focused on reducing waste and optimizing the software production value stream. Minimum Viable Product (MVP) The smallest working product that can be built and tested and delivered in a given time that provides value to users. Pair Programming An agile software development technique in which two programmers work together at one workstation. One types in code while the other reviews each line of code as it is typed in. The person typing is called the driver. and the person reviewing the code is called the observer or navigator. The two programmers switch roles frequently. Pig Someone who is responsible for doing a task on an active iteration. It is the opposite to Chicken. Pigs are actively involved in the project. Planning Poker Planning Poker is a consensus-based technique for estimating, mostly used to estimate effort or relative size of tasks in software development. The team use the fibonacci series or T-shirt sizing to estimate stories during the planning poker game. Product Broadly speaking, product refers to a collection of features that are integrated and packaged into software releases that offer value to a customer or to a market. Product Owner Product Owner is one of the key roles in Scrum. The responsibilities of the Product Owner include:  Establishing, nurturing, and communicating the product vision Creating and leading a team of developers to best provide value to the customer Monitoring the project against its ROI goals and an investment vision Making decisions about when to create an official releaseProduct Backlog Product backlog is like a wish list of features that business want to deliver in the long term. It is a collection of stories and tasks the team will work on at some point in the future. The Product Owner maintains this list of product backlog in accordance to business priorities and needs. The items in the backlog should reflect the business roadmap. Refactoring Changing existing software code in order to improve the overall design. Refactoring normally doesn’t change the observable behavior of the software; it improves its internal structure. Release Plan The release plan is a schedule for releasing software into production. Typical release plans include the key features to be delivered, along with corresponding release dates. Retrospective A timeboxed meeting held at the end of the sprint in which the team examines its processes to determine what succeeded and what could be improved. The retrospective is key to continuous improvement. A positive outcome for a retrospective is to identify one or two high-priority action items the team wants to work on in the next iteration or release. Scrum Scrum is a framework for developing complex software products in an iterative and incremental fashion and is the most widely recognized Agile framework. Scrum is comprised of a series of short iterations – called sprints – each of which ends with the delivery of an increment of working software. Scrum Team The scrum team is a cross-functional and self-organizing group that is responsible for delivering the software. The scrum team includes multi-skilled people who understand customer requirements and conduct software design, coding and testing. Additional skills (e. g. UI design, usability, etc. ) may also be included. The scrum team is responsible for all work commitments and outcomes. ScrumMaster The ScrumMaster is responsible for maintaining the Scrum process and the overall health of the team. The ScrumMaster assures that the team is fully functional and productive by removing any obstacles that may be impeding the team’s progress.  The ScrumMaster also organizes the Scrum ceremonies. Spike A story or task aimed at answering a question or gathering information, rather than implementing product features, user stories, or requirements. Sometimes a user story is generated that cannot be estimated until the development team does some actual work to resolve a technical question or a design problem. The solution is to create a “spike,” which is a story whose purpose is to provide the answer or solution. Sprint In product development, a sprint is a set period of time during which specific work has to be completed and made ready for review. A typical sprint length is usually 2 weeks and normally not any longer than 4 weeks. Sprint Backlog A list of features, user stories or tasks that are pulled from the product backlog for consideration for completion during the upcoming sprint. Product backlog features and user stories are broken down into tasks to form the sprint backlog during the sprint planning meeting. Story Grooming In story grooming sessions, the details of user stories are fleshed out. Acceptance Criteria are written and elaborated.  Stories are also estimated at this stage. The aim of this session is to ensure that everyone who is involved in developing and testing the stories share a common understanding of the context of the stories before beginning development of the stories. Story grooming sessions are usually held mid-sprint for the following sprint so that the team are aware of the workload for the next sprint. Participants are the scrum team, scrum master and the product owner. Sprint Planning Sprint planning sessions are held just before the start of a new sprint. In this session the team identify the tasks that needs to be done and decide how many story points they can commit to for the upcoming sprint. Before sprint planning sessions, the stories should have been elaborated and estimated during the Story Grooming sessions, so that no time is wasted during sprint planning. Participants are scrum master and the scrum team. User Story A User Story (a. k. a Story) can be thought of as a requirement, feature which has some business value. Stories describe the work that must be completed to deliver a feature for a product. Stories are the basic unit of communication, planning, and negotiation between the Scrum Team, Business Owners and the Product Owner. Stories consist of the following elements:  A description, usually in business terms A size, for rough estimation purposes, generally expressed in story points (such as 1, 2, 3, 5) One or more Acceptance Criteria, giving a short description of how the story will be validatedTask Tasks are descriptions of the actual work that an individual or pair does in order to complete a story. They are manageable, doable, and trackable units of work. Typically, there are several tasks per story. Technical Debt A term coined by Ward Cunningham to describe the obligation that a software organization incurs when it chooses a design or construction approach that’s expedient in the short term but that increases complexity and is more costly in the long term. T-Shirt Sizing A method of estimating the work needed to complete a story in T-shirt sizes, i. e. Small (S), Medium (M), Large (L) or X-Large (XL) Timebox A timebox is a time period of fixed length allocated to achieve some objective. In agile development, iterations and sprints are examples of timeboxes that limit work in process and stage incremental progress. Velocity Velocity measures how much work a team can complete in an iteration. Velocity is often measured in stories or story points. Velocity may also measure tasks in hours or an equivalent unit. Velocity is used to measure how long it will take a particular team to deliver future outcomes by extrapolating on the basis of its prior performance. Work In Progress Any work that has not been completed but that has already incurred a capital cost to the organization. Any software that has been developed but not deployed to production can be considered a work in progress. "
    }, {
    "id": 243,
    "url": "localhost:4000/test-automation-strategy-agile-projects/",
    "title": "Test Automation Strategy For Agile Projects",
    "body": "2016/09/12 - This Test Automation Strategy example assumes a continuous delivery model with multiple agile teams. In previous articles, an overarching Agile Test Strategy document as well as how to set up a QA function from scratch for an agile project and how automated testing is one of the key items in the initial setup. In this Test Automation Strategy example, I list down the key points to consider to get the most out of the test automation endeavor. Executive Summary: Automated Testing is a core activity of any agile development methodology. As we move towards continuous deployment, test automation becomes ever more important due to the quick feedback response that it provides to the development team about the health of the application. In order to get this quick feedback, automated tests need to be executed continuously, should be fast and test results should be consistent and reliable. In order to achieve these, the majority of the verifications should be done as part of the development of new features. In other words, development and testing should be a coherent activity, and quality should be “baked in” right from the start by ensuring that what is being developed works and that it hasn’t broken existing functionality. This requires “inverting the test automation pyramid” by pushing down GUI tests that take a long time to execute, to lower levels e. g. API layer that can run straight after unit tests as part of the build to provide the initial level of confidence. Related:  How to choose which tests to automate? Where to start test automation for existing website Should Test Automation be Done by Separate Dedicated Team?Test Automation Strategy Overview: Prevention rather than detection – while every effort should be spent on preventing the introduction of defects in the application in the first place, the techniques and methods for that are outside of the scope of this post. Here, the methodologies are defined to allow for quick detection of bugs when they are introduced into the system and feedback to development. Quality should be favored over quantity. In most cases, it is better to release with one feature that is rock solid rather than multiple features that are flaky. As a minimum release criterion, any newly developed feature should not have introduced any regression defects. As already mentioned, quick feedback on the health of the application is of huge importance to support continuous delivery, therefore, a process and a mechanism by which we can obtain feedback quickly is formulated. One way of getting quick feedback is by increasing the number of unit tests, integration tests, and API tests. These low-level tests will provide a safety net to ensure the code is working as intended and helps prevent defects escaping in other layers of testing. Unit Tests form the foundations for test automation at higher levels. The second element of improvement is running the regression tests more frequently and aligned with the process of Continuous Integration, see later. Automation Testing should not be seen as an isolated task, but rather as a coherent activity embedded in the SDLC. Definition of Regression Packs: Automated regression tests are the core of the Test Automation Strategy. Smoke Regression Pack, which is a sanity check that the application can be loaded and accessed. Also, just a few key scenarios should also be run to make sure application is still functional. The aim of the smoke test pack is to catch the most obvious issues, such as application not loading, or a common user flow cannot be executed; for this reason, the smoke tests should last no longer than 5 minutes to give quick feedback in case something major is not working. The smoke test pack runs on every deploy and can be a mixture of API and/or GUI tests. Functional Regression Packs, which is meant to check the functionality of the application in more detail than the smoke test. Multiple regression packs shall exist for different purposes.  If there are multiple teams working on different sections of the application, then ideally there should be different regression packs that can be focused on the area the team is working on. These packs should be able to run in any environment as and when required, provided the behavior of the features remain consistent throughout the environments. They are executed multiple times a day and should last no longer than 15 to 30 minutes. As these functional tests are more detailed, then they will take longer to run therefore, it is important to have the majority of functional tests at API layer where tests can be executed faster so we could be within the 15 to 30 minutes time limit. End-to-End Regression Pack, which tests the whole application as a whole. The aim of these tests is to ensure that various parts of the application which connect to various databases and third-party applications work properly. The End-to-End tests are not meant to test all of the functionalities as those are already tested in the functional regression packs, however, these tests are “light-weight” which just check the transitions from one state to another and a handful of the most important scenarios or user journeys. These tests are mainly executed through the GUI, as they are checking how users would use the system. The time taken to execute these can vary from one application to another but they are usually run once a day or night. Test Automation Strategy for Multiple Agile Teams:  Automated Unit Tests Test Automation starts at the unit level. Unit tests should be written by developers for any new feature that is developed. These Unit Tests form the foundation of a larger automation practice that spans all the way up to the System GUI Tests. It is the responsibility of the developers to ensure that for every new feature that is developed, a set of coherent and solid Unit Tests are written to prove that the code works as intended and meets the requirements. Unit Tests provide the most ROI to the team as they are very quick to run, easy to maintain and modify (as there are no dependencies) and when there are errors in code, it is quickly fed back to the developer. Unit tests are run on the developer’s machine as well as the CI environment. Automated Integration / API or Service Tests While Unit Tests are based on testing the functions within a class, Integration Tests form the next level up from Unit Tests to test the classes that collectively make up the component to deliver a piece of functionality. These tests are executed only when the Unit Tests have run and passed. Service Tests are naturally run at API layer without the intervention of the GUI web interface; hence tests would be able to verify functionality in a pure form and because the tests talk directly to the components, they are fast to execute and will be part of the build. Where necessary, mocks such as wiremock will be used to factor out the dependence of other 3rd party systems and when the downstream systems are not available to provide the data required for testing. Integration Tests and/or Service Tests can be run on the developer’s machine as well and be part of the build, but if they start to take a long time, then it is best to run on the CI environment. Tools such as SoapUI can be used for Service Tests. Application Testing A typical e-commerce application can be split into different applications or “apps” that provide different functionalities. The concept of “App Testing” is where a group of tests that test the functionality of an App are organized together and run against the desired App. This pack will be useful in cases when a team wishes to release an individual App and would like to know whether it is functioning correctly. Application Tests typically require an interface to interact with the different components, therefore it is anticipated that these tests are run via a browser on the GUI. The purpose of App Testing is to ensure that features of the application are functionally correct. Because the tests are organized in a manner to provide confidence in the health of a particular app, these tests are normally referred to as Vertical Tests, since they execute “down” a particular app. The tests are very thorough and coverage is large. Selenium WebDriver could be used to run these automated tests against the browser. This tool is the most popular for browser automation tests and provides a rich API to allow for complex verifications. End-to-End Scenario Tests The GUI automated tests which are run against the system, serve as typical user flows, journeys or end-to-end scenarios. Due to issues with this type of tests (discussed below), these will be kept to a minimum. The end-to-end scenarios are included in the nightly regression pack. Inverting the Test Automation Pyramid: As part of the Test Automation Strategy, we need to ensure to minimize the number of automated tests that are run at GUI layer. Whilst running automated tests through the GUI provides good and meaningful tests in terms of simulating a user’s interaction with the application, it is prone to many issues as listed below: Brittle – Because the tests rely on the HTML locators to identify web elements to interact with, as soon as an id is changed the tests fail, therefore they bear a lot of maintainability costs. Limited Testing – The GUI could confine the tester’s ability to fully verify a feature as the GUI may not contain all the details from the web response to allow verification. Slow – Because tests are executed through the GUI, the page load times can substantially increase the overall testing time and as such the feedback to the developers is relatively slow. Least ROI – Because of the above-mentioned issues, the GUI automated tests provide the least ROI. The Browser Automation Tests will be kept to a minimum and will be used to simulate a user’s behavior incorporating common user flows and end-to-end scenarios where the system as a whole is exercised. "
    }, {
    "id": 244,
    "url": "localhost:4000/delivery-pipeline-agile-project/",
    "title": "Delivery Pipeline For Agile Projects",
    "body": "2016/09/11 - What is a Delivery Pipeline?: A delivery pipeline which is also known as a deployment or build pipeline, is how a story from a product backlog makes its way through to development, testing and deployment to production. In this post, I will provide a sample Delivery Pipeline for an agile project with details for each step. At the bottom of the post, you can download the full delivery pipeline diagram. Delivery Pipeline Step 1: Dev Local: Developer writes code and fixes bugs. The coding activities can be reviewed by a peer developer which is called peer reviews or done by two developers working together also known as Pair Programming. Developer also writes unit tests and integration tests or API tests. In case of “front-end” developers, there will be Javascript unit tests or JSUnit tests. Any new code which contains logic should be unit tested. The above testing activities can also be supported by testers where they can help with reviewing the test cases in particular integration and API tests. Because unit tests are very quick to run and that we want to only commit good code to the repository, unit tests and JSUnit tests are run on the developer’s local environment. Once the unit tests have been reviewed and passed on the developer’s machine, the developer commits the code to the repository. QA Local: As developers are building new features, QA or Testers work in parallel to write the automated acceptance tests for the new features. Here, dev can also participate and help the non-technical testers to write automated checks. Delivery Pipeline Step 2: CI Server: Once the developers commit their code to the repository, (remember there are multiple developers working on one or more project) the commit will trigger an automated build where the project is built and artifacts are created. First unit tests are run. Once all unit tests are passed, then integration tests are run. It is often the case that integration or API tests require custom data from different sources, such as databases and/or 3rd party APIs. For this reason, it is best to mock any external connections so that we could be free from any downtime or unavailable services and fully focus on the tests. Delivery Pipeline Step 3: Integration: Once all the unit tests and integration / API tests have passed in Jenkins build, and automated deployment job is kicked off to deploy the latest artifacts into an integration environment. In the integration environment, the new code is integrated with existing production code, hence the name integration. When multiple teams exist, it is important that each team have their own integration environment so that the execution of the automated checks are not affected by other teams’ deployments. Once the deployment job is complete and the application is deployed, first an automated smoke test pack is run to make sure the application is up and running and can be accessed, then if everything is OK, we run a full suite of automated acceptance tests for the new functionality and existing functionality, i. e. new and regression. In integration environment, the application points to real data and services and we will run a mixture of API and UI automated tests against the application. Delivery Pipeline Step 4: QA: The next step in this delivery pipeline is a manual deployment to “QA” environment. As mentioned before, when there are multiple agile teams, each will have their own integration environment. So when we want to deploy different features from multiple teams into production, then we will do a manual deploy to the QA environment to test the different features together. Similar to the integration environment, the QA environment also point so production data and has the latest stable production code plus the new features. Once the manual deployment to QA environment is complete, the automated smoke tests are run to make sure application is up and running and can be accessed. Also on the QA environment, we would run manual/exploratory tests, and the product owners, BAs and designers can run User Acceptance Tests and make sure the new features are fit for purpose. The QA environment will only contain the tested code that we’re about to deploy to production. Delivery Pipeline Step 5: Stage: Once everyone is happy with their testing efforts of new features and regression tests, we could deploy straight to production. However, it is best to have a “rehearsal” deployment to production by deploying to a “production like” environment which in this case is called Stage. Stage environment is our last chance of checking things are in good order before finally pushing to live. Stage is not and should not be used for heavy testing and checking because we have already gone through rigorous testing in previous steps, therefore, a quick sanity check and the automated some test will suffice. Delivery Pipeline Step 6: Going Live: The final step in the delivery pipeline is “push to production” and we would just execute the automated smoke regression pack. When we put all the pieces of the above delivery pipeline steps together, we will end up with the following delivery pipeline diagram: [caption id=”attachment_11960” align=”aligncenter” width=”700”] delivery_pipeline_agile[/caption] Download delivery pipeline diagram "
    }, {
    "id": 245,
    "url": "localhost:4000/automated-versus-manual-testing-make-informed-decision/",
    "title": "Automated versus Manual Testing – Make an Informed Decision!",
    "body": "2016/09/10 - Being a manual software testing resource, like many others I have lived the past few years under the constant fear of my job being taken over by the hype of “Automation”. I have worked in domains ranging from telecom, hospitality and retail and have mostly followed the principles of old school manual testing for ensuring quality for a variety of software systems/applications/websites etc. Not that I haven’t had a chance to pick up a few automation skills, but I instead chose to do a rational analysis of manual versus automation rather than quickly switching roles. After weighing the two sides against different parameters, I realized that there will always be space for both in the industry. And thus, I decided to stick to what I love best, thinking of every possible click, trying to figure out the various turns and U-turns that a software journey can take, put a system through a subjective as well objective analysis and then accordingly designing the manual test scripts. The argument that automation will eventually annihilate manual test practice, I think is way too optimistic. It’s like saying that robots might someday take over everything that a human does. I have my doubts for any of this to happen. Automation no doubt has its advantages and can complement manual testing. However, for any company, program or project, it is important to continuously evaluate and counter balance the two.  Automation, manual or combination of both, the decision is driven by certain key factors. Some of these are: Repeatability:  It is one of the prime factors that drives the automation versus manual testing decision. Automation is no magic wand; it requires specific skill set, tools, time, effort and budget. Is there a good ROI for investing in so many resources? Definitely, yes if there is a high reusability of the automated test scripts. Thus, for a project that has multiple runs of the same test scenarios or that requires regression tests at regular intervals are some of the best candidates for automation. Cost &amp; Benefit Analysis:  Automation Testers, frameworks, tools, maintenance, training all add up to contribute majorly in project costs. A Test Lead/Manager has to weigh this additional cost against possible benefits. For example, for a short term project or a minor change it does not make sense to automate. In such a scenario Manual Tests will be more cost efficient and would add equal value as automation might as well do. Project Type:  Another key driver when deciding between manual and automation testing is the size, scale and type of project. Automation can be helpful when there are too many data driven tests where same tests need to be run for different data, or there is a multi-browser test involved. On the contrary a project that is highly GUI oriented or lays emphasis on customer experience; manual tests would be best suited to them and would be cheaper as well. Similarly, if it’s a large project with too many testers working on it, with both front end and back end to be tested, it would be perfect ground for a mix of automation &amp; manual testing. Value Addition:  And finally as a PM or test manager one needs to ask the question - does spending on automation adds value to the project and does it really saves time and effort. If it does then just go for it. If not, it’s probably not worth it. Adding value can mean different things in different projects – uncovering additional bugs, uncovering bugs earlier in the test cycle, uncovering bugs in lesser time, quicker retests, fewer resources required to test or simply making life easier for manual testers. In a good sized project with a variety of testing to be carried out, manual and automation testing should tie in together. Instead of dismissing each other, automation and manual tests should be used in a collaborative manner, so as to get the best out of both. Even though testing as a subject is never really taught in universities, it still can’t be termed as a job that anyone can do. One has to have a specific mindset to be a good test professional. A mindset that looks at a system at large, a mindset that always seeks the visibility to overall objective and purpose of a system under test, a mindset capable of constructive criticism so as to identify the break points of an application, to think from the perspective of not one but various types of users, to simulate a user behavior that the software is not ready to tackle. And this is why automation testing cannot take over manual testing. Automation can provide the tools to implement and execute, but it needs a manual (read human) tester to do prep work. Automation can be very effective and cost friendly in the implementation of some of the objective scenarios; however, for a subjective point of view there isn’t an alternative to manual testing. It is wise to automate that can be quantified but in my experience quality cannot always be judged by facts and figures. For the qualitative factors companies still need the human interface. "
    }, {
    "id": 246,
    "url": "localhost:4000/webdriver-tutorial-open-browser-extensions/",
    "title": "WebDriver Tutorial - How to Open a Browser With Extensions",
    "body": "2016/09/09 - In this WebDriver tutorial we look at how we can use WebDriver to open Chrome and FireFox browsers with extensions using ChromeOptions and FirefoxProfile. Open Chrome Browser With Extensions: 12345678910111213141516import org. openqa. selenium. WebDriver;import org. openqa. selenium. chrome. ChromeDriver;import org. openqa. selenium. chrome. ChromeOptions;import java. io. File;public class Tutorials {  WebDriver driver;  public void openChromwWithExtensions() {    ChromeOptions options = new ChromeOptions();    options. addExtensions(new File( src\test\resources\extensions\extension. crx ));    driver = new ChromeDriver(options);  }}This will open a Chrome browser with the specified extension. Open FireFox Browser with Extensions: 1234567891011121314151617181920212223import org. openqa. selenium. WebDriver;import org. openqa. selenium. firefox. FirefoxDriver;import org. openqa. selenium. firefox. FirefoxProfile;import java. io. File;import java. io. IOException;public class Tutorials {  WebDriver driver;  public void openFireFoxWithFirebug() {    String firebugFilePath =  C:\FF_addons\firebug. xpi ;    FirefoxProfile profile = new FirefoxProfile();    try {      profile. addExtension(new File(firebugFilePath));// Add more FF addons if required    } catch (IOException err) {    }    driver = new FirefoxDriver(profile);  }}This will open FireFox Browser with Firebug addon. "
    }, {
    "id": 247,
    "url": "localhost:4000/sdlc-methodologies-advantages-disadvantages/",
    "title": "Overview of SDLC Methodologies in Software Testing",
    "body": "2016/09/08 -  SDLC Methodologies: The Software Development Life Cycle (SDLC) provides a systematic process for building and delivering software applications from inception to completion. There are a number of different SDLC methodologies that can be used to deliver projects and in this post, we will give an overview of the different SDLC models out there and their advantages and disadvantages. 1. Waterfall Model: [caption id=”attachment_3478” align=”aligncenter” width=”350”] waterfall-model-software-testing[/caption] Waterfall is the oldest and most straightforward of the structured SDLC methodologies. There are strict phases and each phase needs to be completed first before going to the next phase. There is no going back. Each phase relies on information from the previous stage and has its own project plan. Waterfall is easy to understand and simple to manage. However, it is usually prone to delays as each phase needs to be reviewed and fully signed off before the next phase can begin. Also, since there is little room for revisions once a stage is completed, problems can’t be fixed until you get to the maintenance stage. This model works best when all requirements are known and flexibility is not required and the project has a fixed timeline. One disadvantage of waterfall model is that all requirements need to be known before development starts. Therefore if a requirement is wrong or missing, it won’t become apparent until the late stages of the life cycle. 2. V Model: V Model which is also known as the Verification and Validation model, was the next logical step from the Waterfall model with the aim of introducing testing at each stage of development rather than at the end of the project. Like Waterfall, each stage begins only after the previous one has ended. This model is useful when there are no unknown requirements, as it’s still difficult to go back and make changes. The advantage of V Model is that each stage has a corresponding testing activity which helps to identify missing requirements, and incorrect design early in the life cycle. The disadvantage is that the each stage has to wait for the previous stage to be finalized and signed off. 3. Iterative Model: [caption id=”attachment_10210” align=”aligncenter” width=”600”] iterative-model[/caption] With the Iterative model, software is built in small chunks, each time adding more functionality. Unlike the waterfall model which requires fully specified requirements before starting the implementation, with the Iterative model, you implement a small set of software requirements, then test, evaluate and refine the requirements. With each iteration, new requirements are added and a new version of the software is produced. This process is repeated until the application is fully developed and all requirements implemented. One advantage of Iterative model over the other SDLC methodologies is that we get a working version of the application early in the process and so it less expensive to implement changes. One disadvantage is that resources can quickly be eaten up by repeating the process again and again. 4. Spiral Model: One of the most flexible SDLC methodologies, the **Spiral model **takes ideas from the Iterative model and its repetition but also combined with the structured and systematic development of the waterfall model with a heavy emphasis on risk analysis. The project passes through four phases (identification, design, build, evaluation and risk analysis) over and over in a “spiral” until completed, allowing for multiple rounds of refinement. It allows for incremental releases of the product, or incremental refinement through each iteration around the spiral. This model allows for the building of a highly customized product, and user feedback can be incorporated from early on in the project. But the risk you run is creating a never-ending spiral for a project that goes on and on. 5. Agile Model: The agile model is a combination of both iterative and incremental model by breaking a product into components where on each cycle or iteration, a working model of a component is delivered. The model produces ongoing releases (iterative), each time adding small changes to the previous release (iterative). During each iteration, as the product is being built, it is also tested to ensure that at the end of the iteration the product is shippable. The Agile model emphasizes collaboration, as the customers, developers and testers work together throughout the project. An advantage of the Agile model is that it quickly delivers a working product and is considered a very realistic development approach. One disadvantage of this model is that because it depends heavily on customer interaction, the project can head the wrong way if the customer is not clear about the requirements or the direction he or she wants to go. "
    }, {
    "id": 248,
    "url": "localhost:4000/12-qualities-good-agile-leader/",
    "title": "12 Qualities of a Good Agile Leader",
    "body": "2016/09/07 - How do you spot a good Agile leader? Agile development methodology has been around for a number of years now and has become the norm for many tech companies. But why is it that some organisations really succeed in Agile, while others struggle? Even worse is when some teams think they are Agile because they practice agile concepts like daily stand-ups and retrospectives, but in reality are far from being Agile. I believe the difference is all about the leaders, be it the ScrumMaster, Delivery Manager or the CTO who have the authority to lay the foundations of an Agile working culture in the organisation and in this post we look at 12 qualities of a good Agile leader. What are the qualities of a good Agile leader?: 1. Vision and Mission: Everyone in the organisation should know what they are working towards. It is often the case that individuals get too bogged down on the details of everyday work that they lose sight of the big picture. A Good Agile Leader should ensure that the goals and mission of the organisation is clear to everyone involved in the delivery of the project, this includes the scrum teams customers and stakeholders. Ensure that any work being done has a clear purpose and is moving towards the vision. Likewise, it is important to set the boundaries and scope of the work so that the teams don’t do what is not necessary. 2. Small Releases: Ensure that work is divided in tasks and sub-tasks so that features can be released in an iterative and incremental fashion rather than big bang releases. Large projects should be split into smaller ones whenever possible. In essence, this is the concept of an agile delivery model, iterative and incremental. 3. Pre-Planning Meetings: The agile leader should ensure that the items in the backlog are maintained and that planning sessions happen before the sprint kick-off. Ideally stories should be groomed and discussed one sprint ahead so that before the sprint starts, the planning session is quick. Keep a track of the teams’ velocity so that scope of sprints can be forecasted.  Any constraints or changes in priorities should be communicated to everyone. Role of QA Manager in Agile Project 4. Short Feedback Loop: Ensure a short feedback loop between development team, design, product and customers by engaging them in frequent communication.  Work should be demoed and discussed early and continuously to remove any misunderstandings and assumptions. Ensure that progress is based on actual value delivered for the business rather than comparing against a plan. 5. Continuous Improvement / Knowledge Sharing: Ensure that knowledge from different team members are shared across different parts of the organisation and that small improvements to any process happens continuously. Retrospectives and “Scrum of Scrums” is usually a good opportunity to learn about the impediments and difficulties faced during the sprint so an action plan can be put together to address the obstacles. Best Practices for Continuous Testing in Agile 6. Fail Fast: A good agile leader should ensure that teams have courage to try out new technologies and approaches.  Create an environment where small failures can happen early and often, thereby reducing the risk of a big failure at the end of the project. 7. Communication: Create a friendly environment which facilitates good face-to-face communication and minimises the need for unnecessary documents, emails, and other forms of low-bandwidth communication.  For example, it is much more effective to have a physical kanban board where face-to-face discussions happen between the team members rather than Jira or similar tools. There is NO QA Team in Agile 8. Focus and Aligned: Ensure that the team is focused, dedicated and tuned to the work rather than multitasking. Everyone should be focused on working on the highest priority tasks that deliver value for the business. Work smarter not harder. Work with managers to ensure that the right people and teams are available at the right time to maximise the velocity and chance of success. 9. Removal of Obstacles: In order for the team to deliver high quality product on time they need to be focused solely on the work and not having to deal with daily clutter or obstacles. A good agile leader should ensure that impediments are removed as soon as possible when encountered, or even foresee the likelihood of an obstacle before it starts to impede the team. Look for bottlenecks and queues, and apply systems thinking and lean principles to streamline the delivery of business value. 10. Visibility of Progress: Ensure that everyone in the business has clear visibility of the progress and that everyone can see the “big picture”. Can use dashboards on screens which clearly shows the progress at a high level and is visible at all times. How to Build a QA Function From Scratch for Agile Startups 11. Self-organisation and Autonomy: Make the goal and current situation clear so that people can think and act autonomously, with no need for you to tell them what to do. Ensure people are given problems to solve rather than tasks to execute. Remember that becoming a self-organising team does not happen overnight.  Self-organisation is not just about the whole team within its specific organisational context. Each team member needs to be self-organised. 12. Cross-functional Collaboration and Dependencies: A good Agile Leader should ensure that teams are not blocked waiting for each other to deliver their work and that teams are cross-functional by co-locating individuals across different teams and silos are minimised. "
    }, {
    "id": 249,
    "url": "localhost:4000/software-testing-interview-questions-preparation-checklist/",
    "title": "30+ Essential Software Testing Questions to Prepare for Interview",
    "body": "2016/09/06 - Whether you are preparing for a Software Testing Interview or you are interviewing candidates for a QA role, this mind map will help you with the preparation and to remember the main essential topics on Software Testing. Here is a checklist of 30+ Essential Software Testing Interview Questions which you can revise and download for reference.  Where applicable, I have given some suggestions or quick hints and links to useful material for further reading, but purposely, I have left out the answers, so you can go and hunt for the relevant information yourself. Of course, you should mostly rely on your experience at first instance. Download Interview Questions mind map Introduction: The introduction part of the interview is mainly finding out about your current and past experiences, what interests you, how you got into the world of Software Testing and what motivates you to stay as a tester.  Current and past workplace experience How did you get into testing? What are your career aspirationsTesting knowledge: Most likely, you will be asked to provide definitions for Software Testing and Quality, in the form of what is Software Testing or what does Quality mean to you? These are broad subjects, so you need to come up with the definition that you think is the best. There are many definitions of Software Testing which you can review and pick the appropriate ones. Also, Quality means different things to different people as everyone has a different perception of quality.  What is Software Testing? What is Quality? What is a defect or a bug? Risk Based Testing Session Based Testing Test Charters Rapid Software Testing Context Driven TestingDefect This is an interesting question, as surprisingly, there seems to be a lot of disagreement on what a defect is. In short, a defect is if:  The team knew what it was supposed to do And it doesn’t do that thing And the team said they were doneBasically, when a feature of an application doesn’t behave the way it is meant to behave, then that is a defect, a deviation from expected results. Of course much of the expected results come from the requirements or acceptance criteria, so if a desired behaviour of a feature wasn’t requested in the first place, then technically that’s not a software defect, it’s a form of communication defect. Risk Based Testing I believe all software testing activities is and should be risk based. The problem is that we would never have enough time to test an application to its full extent because there are just too many combinations / scenarios to cover. For this reason, we have to prioritize testing of features and functions in the applications, based on the risk of failure, their importance and likelihood or impact of failure.  Likelihood of a failure occurring Impact of the failure if it occursThe aim is to identify high risk areas in the application and have enough test coverage around those areas to boost the confidence in workability of the application before releasing it to the public. Once the risk identification exercise is done, then we can prioritize the testing effort, starting with testing the high risk areas first and then if we still have time, test other parts of the application. Why Risk Based Testing is Important in Agile Projects Exploratory Testing Exploratory Testing, as the name suggests, is about exploring or finding out about the software, by designing and executing tests simultaneously. Exploratory Testing is very closely associated with James Bach who first described the technique in early 2000. Exploratory Testing is opposite of scripted testing where test scenarios are thought of and documented before executing the software. With scripted testing the expected behaviour is also specified with each test case, whereas in Exploratory Testing we may not know how the system would behave, therefore it is also a learning exercise. Testing Misconceptions:  Testing vs Checking Exploratory vs Adhoc Automation vs Manual BDD (Feature Files) vs TDD Documenting Exploratory TestingThere is a famous post on Testing vs Checking and I urge you to read it if you already haven’t. Checking can be done manually or automated, whereas Testing is done manually. BDD A lot of people mistake Behaviour Driven Development, (BDD), with Test Driven Development or Test Driven Design, (TDD). BDD is not the next level up from TDD. The main aspect of BDD is collaboration between all the stakeholders that are involved in the project, i. e. the business and the tech teams so that everyone is aware of the context of each feature before starting with the development work. TDD on the other hand is a technical exercise and its scope is only within the development team. Developers write tests to drive their design and development. Both BDD and TDD are ”Test First” Development methodologies. However, BDD can be thought of as “outside-in-development” and TDD as “inside-out-development”. BDD Guidelines and Best Practices Document Exploratory Testing By definition, you don’t really document Exploratory Testing; i. e. you don’t read from a test script and follow the test steps in the document to execute tests. Exploratory Testing is more about exploring the system without the confinement of a pre-written test conditions. The only thing you might document is the summary of the areas of the application that was covered in the Exploratory Testing session. Agile Experience: As more companies are implementing an agile development practice, it is expected that the QAs have knowledge of Agile Terminologies and experience in working as an “Agile Tester”. Some essential Agile knowledge that you need to have:  Scrum Kanban Agile Methodologies As a tester when do you get involved in testing? How is testing in Agile different to waterfall? Agile ManifestoYou can also read the Agile Testing Interview Questions and Answers Scrum is an Agile framework for completing projects. The Product Owner creates and maintains a backlog of stories which will be developed in succession periods called Sprints. The team then do a planning meeting and decide which stories will be developed in the next Sprint. During the Sprint, the team have daily stand-up meetings and at the end of the Sprint there is a showcase and a retrospective. Read more on Scrum Kanban Kanban, like Scrum is another framework used to implement agile, but unlike Scrum, there is no fixed-length iterations. A kanban team is only focused on the work that’s actively in progress. Once the team completes a work item, they take the next work item from the product backlog. The product owner is free to re-prioritize work in the backlog to keep the most important work items on top of the backlog so that the development team is assured they are delivering maximum value back to the business. As a tester when do you get involved This is an interesting agile testing question because it shows whether the tester has grasped the principles of agile development or not. Basically, testers should get involved from the very start of the project. They need to be involved in Story writing, making sure each story has meaningful acceptance criteria before development starts. How is testing in agile different to waterfall In Agile, the level of documentation is far less than the traditional waterfall model. There are no requirement documents and no extensive test case documents. For this reason, the testers may feel a bit lost and without reference. Instead, in Agile there is heavy emphasis on communication and collaboration between team members to flesh out the requirements. Throughout the Sprint, the QA need to be involved in testing the features as soon as they are ready, i. e. testing should be inline with development, not left towards the end of the Sprint. Quick feedback to the development team is necessary. Remaining Relevant: The remaining relevant section is usually about finding out if you really are interested in software testing and are keeping up with the industry by attending conferences or meet-ups, as well as following high profile professional testers on Twitter and blogging your own ideas on software testing topics. At the interview you most likely be asked any of the following questions  Last conference or meet-up attended Personal blog or publications Favourite testing blog or book How do you keep up with the industry?Test Automation: Test Automation is a hot topic and you need to know both the theory and practical aspect of automated testing. Some interesting interview questions on Test Automation:  Why would you automate a test? How do you choose which tests to automate? What tests can’t you automate? Advantages and Disadvantages of Automated Testing Test automation pyramidOther Testing Questions:  What do you include in a bug report? Pairing with devs / teamwork Do you need requirements to start testing? What do you enjoy about testing? SDLC vs STLCAre there any other areas which you think should be included in this Software Testing Interview Questions mind map for interview preparation? "
    }, {
    "id": 250,
    "url": "localhost:4000/automated-testing-setting-right-expectations/",
    "title": "Automated Testing – Setting the Right Expectations",
    "body": "2016/09/05 - How to set the right expectations in test automation so that you get the most out of your automated tests and you don’t get disappointed by your efforts. This post looks at the myths and realities on automated testing. I want everything to run at the click of a button – Does this statement sound familiar? Well, am sure most of the automation test engineers can relate to this statement.  Everyone loves automation.  Its fast, reliable, makes optimal use of the resources by running overnight and doesn’t need human intervention. For management, they have finally found a solution that reduces testing effort and is more efficient when compared to a manual tester. But does it really happen that way? Not really. Here are some of the key points to consider when automating an application and what to expect as an output. Common Myths of Test Automation Myth #1: There is no need to invest time in the studying the existing framework or the test cases when automating a new application. Reality: Automation takes time - Automation when used in the right way and with the right set of expectations can help the organization in a big way. But for that to happen, we need to invest time, money and most importantly patience.   Building automated scripts requires testers to understand the domain, the test cases to be automated and then choosing a framework accordingly. It is like setting your foundation strong. Automation is similar to application development which needs to be tested as well.   Scripts developed through automation must be tested thoroughly with all set of possible test data as well as negative testing.   Not doing a proper testing and handing over a partly tested tool results in failure of automated scripts during execution, thus eventually leading to losing confidence in the tool. Solution:    Spend initial time and effort in understanding the application to be automated. When setting the timeline for automating the scripts, one need to factor in the time needed for requirement gathering, design, coding and testing.     To do a proper feasibility study in order to avoid rework during actual implementation.     Discuss with the manual team/developers on what are the key areas to be automated and then decide on the suitable framework and automation tools needed for developing it.  Test Automation Interview Questions and Answers Myth #2: Automation can replace manual testers. Reality: Once the scripts are developed,  the common misconception is that we can immediately replace manual testers doing this job. This is only partly true. Automation is a program written to test the flow of the system. Even a small bug might go unnoticed during execution if it’s not programmed to look for it, but a manual tester might have easily detected it during his/her execution.  Also, in most cases the application under goes changes frequently which might results in automation missing out on the coverage and also in the failure of the scripts. In such a case, a manual tester is needed to keep testing the changes while the scripts are being updated. Even though automation might take over some of the testing done by manual testers, one needs to spend time in analyzing the test results and make sure that the automation has not missed out on any critical issues. Solution:    To think that the machines will take over testing is an unrealistic expectation. Just like robots cannot take over the humans, the same applies for testing as well. We need a human brain that can analyze the test results rather than just relying on a program.     For applications that are frequently changing, automation results must be used only as a reference and not as a replacement for manual tester.     Automation must be replaced for manual testers only in those applications which are static, independent of other modules and needs to be checked during regression testing.  Myth #3: Automation gives faster execution when compared to manual testing Reality:  Yes, automation runs faster when compared to manual testing, but it some cases it takes more time in identifying objects when the properties involved for the object are not straight forward. For example, if there are number of headers in a page, and if the properties of those objects are similar, then automation might take more time to identify those headers than a manual tester who will be doing an eyeball check for its existence. Also in situations which involve preparation of data beforehand, a manual tester might be faster in doing it as they know which data to choose/reuse for executing these test cases. Whereas in automated testing, we need to write the logic to prepare /search the test data which might increase the execution speed. In applications which involve communicating with multiple systems, the executing time is same as a manual testing due to the dependency on external system. Automation also requires the same wait time as in manual testing. Solution:    During requirement analysis, take into account the time needed for execution, the complexity of the system involved and also number of external system involved. Do a feasibility study on the time taken for execution and the effort incurred in automating an application.     Give a clear visibility to the stakeholders on what to expect in automating such an application and the effort involved.     The effort estimation must be calculated after taking into factors such as complexity of the objects, flow of the system, time needed for building the scripts and lastly the execution time of automated scripts versus manual testing.  Test Automation Tips and Best Practices Myth #4: End users of automated scripts just need to click one button to execute the test cases Reality: When the automating is completed and handed over to the end users (typically manual testers, developers for doing unit testing), they assume that the scripts can be executed without any changes in test data. It is a rare situation that we come across an application where we just have to execute the scripts without any test data. Hence it comes as a rude shock to them when they have to spend their time in preparing the test cases for execution.  This is because they consider executing scripts as an add-on job and not as a primary one. Executing scripts requires end users to understand the flow of test case, keywords used and also what data needs to be given. Solution:    Have periodic discussion with the end users during the scripting stage informing them about the test case flow, test data etc. so as to avoid any wrong expectation.     Take into account which data are used as input and which can be constant. By doing so, you will minimize the number of data inputs needed for each test case.  Test Automation Advantages and Disadvantages Myth  #5: Expecting 100% automation execution during test execution without any failures. Reality: Automation is like software development which again has its own set of issues and limitations. To execute all the scripts without failure is practically impossible. There can be number of reasons why scripts fail and not all may be due to automation. It can due to slowness in the system, environment down, data issues, changes in UI and so on.  This is especially true in case of application which is constantly changing. Solution:    It is important for the end users to understand the reason behind the failure and do a bit of troubleshooting before passing it to the automation team. By doing so, the end users can familiarize themselves with the flow of the execution and the inputs needed for it rather than depending on automation team  to investigate for every single issue.     Automation must be done only for stable systems or which the development is completed.     Make sure all the test cases are updated on the latest test data and there is no external factor affecting the system during the execution of the scripts.  Conclusion Automation testing can deliver benefits in the long term but may not provide immediate results as the scripts need to be constantly updated and maintained. Instead of thinking of automation as a magic tool in meeting your deadlines for execution, we must understand its limitations and use it accordingly to get the desired output. Test Automation Strategy for Agile Projects "
    }, {
    "id": 251,
    "url": "localhost:4000/webdriver-wait-page-load-example-java/",
    "title": "Automated Testing – Setting the Right Expectations",
    "body": "2016/09/04 - In this WebDriver tutorial, we take a look at how to wait for a page to complete loading before doing other actions. Two examples in Java on wait for page to load in WebDriver. Wait For Page To Load - Method #1: 12345678910111213141516171819202122232425262728import org. openqa. selenium. JavascriptExecutor;import org. openqa. selenium. WebDriver;import org. openqa. selenium. firefox. FirefoxDriver;import org. openqa. selenium. support. ui. ExpectedCondition;import org. openqa. selenium. support. ui. WebDriverWait;import org. testng. Assert;public class Tutorials {  WebDriver driver = new FirefoxDriver();  public void waitForPageLoaded() {    ExpectedCondition&lt;Boolean&gt; expectation = new        ExpectedCondition&lt;Boolean&gt;() {          public Boolean apply(WebDriver driver) {            return ((JavascriptExecutor) driver). executeScript( return document. readyState ). toString(). equals( complete );          }        };    try {      Thread. sleep(1000);      WebDriverWait wait = new WebDriverWait(driver, 30);      wait. until(expectation);    } catch (Throwable error) {      Assert. fail( Timeout waiting for Page Load Request to complete.  );    }  }}Wait For Page To Load Method #2: 123456789101112131415161718import org. openqa. selenium. JavascriptExecutor;import org. openqa. selenium. WebDriver;import org. openqa. selenium. support. ui. ExpectedCondition;import org. openqa. selenium. support. ui. WebDriverWait;public class Tutorials {  public void waitForLoad(WebDriver driver) {    ExpectedCondition&lt;Boolean&gt; pageLoadCondition = new        ExpectedCondition&lt;Boolean&gt;() {          public Boolean apply(WebDriver driver) {            return ((JavascriptExecutor)driver). executeScript( return document. readyState ). equals( complete );          }        };    WebDriverWait wait = new WebDriverWait(driver, 30);    wait. until(pageLoadCondition);  }}"
    }, {
    "id": 252,
    "url": "localhost:4000/top-10-selenium-webdriver-books/",
    "title": "Top 10 Selenium WebDriver Books",
    "body": "2016/09/03 - Here is our list of Top 10 Selenium WebDriver Books that you can use to learn Selenium. The books are varied and are for beginners to advanced users with many useful examples. Selenium 2 Testing Tools: Beginner’s Guide: Learn to use Selenium testing tools from scratchAutomate web browsers with Selenium WebDriver to test web applicationsSet up Java Environment for using Selenium WebDriverLearn good design patterns for testing web applications In DetailSelenium automates browsers. It is primarily used for automating web applications for testing purposes. Selenium has the support of some of the largest browser vendors who have taken (or are taking) steps to make Selenium a native part of their browser. From setting up the Java environment to running tests on mobile devices, it contains all the information to get a novice up and running on using Selenium. . You will also learn some advanced concepts such as testing complex web applications and running tests in parallel towards the end of the book.  More info… Test Automation Using Selenium Webdriver with Java : Step by Step Guide: Test Automation using Selenium WebDriver, is the latest book released on Selenium 2. 0 using Java as a programming language. This Selenium book has been designed with the objectives of simplicity and ease of understanding. After huge success of author Navneesh Garg’s first book (Test Automation using Unified Functional Testing) this book follows a similar step by step approach to Install, configure and design automation framework using Selenium WebDriver and it components.  More info… ### Selenium Simplified : Selenium-RC, Java &amp; JUnit![selenium simplified](http://69. 164. 212. 71/wp-content/uploads/2016/04/selenium-simplified-231x300. jpg)The updated second edition of the popular tutorial guide to automated testing. Selenium is one of the most popular open-source automated testing tools available today. Understanding Selenium-RC and writing automated tests in a programming language are sought after skills on the job market and a great way of maximising the benefit from automated testing. Contrary to the beliefs of many testers, learning to code does not have to be complicated or hard.  Selenium Simplified  takes you through the process of installing and learning to use all the basic tools needed to write automated tests using Java as the programming language. Written in a tutorial style, this book helps you learn to code even if you haven't programmed before. No time is wasted on the theory of automation or padding about the tools. This book focuses on the practical knowledge needed to automate tests for production systems.  [More info. . . ](http://www. bookdepository. com/book/9780956733238)### Selenium Design Patterns and Best Practices![selenium design patterns best practices](http://69. 164. 212. 71/wp-content/uploads/2016/04/selenium-design-patterns-best-practices-243x300. jpg)Whether you are an experienced WebDriver developer or someone who was newly assigned a task to create automated tests, this book is for you. Since the ideas and concepts are described in simple terms, no previous experience in computer coding or programming is required.  [More info. . . ](http://www. bookdepository. com/book/9781783982707)### Selenium WebDriver Practical Guide![selenium webdriver practical guide](http://69. 164. 212. 71/wp-content/uploads/2016/04/selenium-webdriver-practical-guide-244x300. jpg)Selenium WebDriver is an open source web UI automation tool implemented through a browser-specific browser driver, which sends commands to a browser and retrieves results. Selenium WebDriver Practical Guide will guide you through the various APIs of WebDriver which should be used in automation tests, followed by a discussion of the various WebDriver implementations available. This guide will support you by offering you access to source code files, including the essential HTML files, that allow you to work with jQuery and other examples throughout the book. Finally, you will receive an in-depth explanation of how to deal with the latest features of WebDriver through step-by-step practical tutorials.  [More info. . . ](http://www. amazon. co. uk/Selenium-WebDriver-Practical-Guide-Avasarala/dp/1782168850/)### Selenium Testing Tools Cookbook![selenium testing tools cookbook](http://69. 164. 212. 71/wp-content/uploads/2016/04/selenium-testing-tools-cookbook-244x300. jpg) Selenium Testing Tools Cookbook  is an incremental guide that will help you learn and use advanced features of Selenium WebDriver API in various situations for building reliable test automation. You will learn how to effectively use features of Selenium using simple and detailed examples. This book will also teach you best practices, design patterns, and how to extend Selenium.  Selenium Testing Tools Cookbook  shows developers and testers who already use Selenium, how to go to the next step and build a highly maintainable and reliable test framework using advanced features of the tool.  [More info. . . ](http://www. amazon. co. uk/Selenium-Testing-Cookbook-Unmesh-Gundecha/dp/1849515743/ref=pd_sim_sbs_14_3)### Mastering Selenium WebDriver![mastering selenium webdriver](http://69. 164. 212. 71/wp-content/uploads/2016/04/mastering-selenium-webdriver-243x300. jpg)This book starts with how to solve the difficult problems that you will undoubtedly come across as you start using Selenium in an enterprise environment, followed by producing the right feedback when failing, and what the common exceptions are, explain them properly (including the root cause) and tell you how to fix them. You will also see the differences between the three available implicit waits and explicit waits, and learn to working with effective page objects. Moving on, the book shows you how to utilize the Advanced User Interactions API, how you can run any JavaScript you need through Selenium, and how to quickly spin up a Selenium Grid using Docker containers. At the end, the book will discuss the upcoming Selenium W3C specification and how it is going to affect the future of Selenium.  [More info. . . ](http://www. amazon. co. uk/Mastering-Selenium-WebDriver-Mark-Collin/dp/1784394351/ref=pd_sim_sbs_14_6)### Instant Selenium Testing Tools Starter![instant selenium testing tools starter](http://69. 164. 212. 71/wp-content/uploads/2016/04/instant-selenium-testing-tools-starter-e1459895042829. jpg) Instant Selenium Testing Tools Starter  was born out of the need for a short, yet all-encompassing book that would give you a solid foundation in creating and running tests with Selenium testing tools. This book will enable you to harness the power of Selenium and put it to good use throughout the testing process, quickly and efficiently. The  Instant Selenium Testing Tools Starter  can be used as an end-to-end guide or as a desk reference, with sections that deal with all the key aspects of automating tests for web applications. A step-by-step description of key features is provided with the help of simple and concise examples. Each chapter will help you understand the key features of Selenium with tips and tricks that will become the foundation of your knowledge in the future.  [More info. . . ](http://www. amazon. co. uk/Instant-Selenium-Testing-Tools-Starter/dp/1782165142/ref=pd_sim_sbs_14_10)### Selenium By Example![selenium webdriver by example](http://69. 164. 212. 71/wp-content/uploads/2016/04/selenium-webdriver-by-example-212x300. jpg)Filled with practical examples, taking a Step-by-Step approach Selenium By Example - Volume Iii: Selenium WebDriver will not only give the reader an overview and introduction to Selenium WebDriver, it will also give the reader an overview of best practices in Automated Testing, Automation Frameworks, and advice on introducing Automated Testing. Selenium By Example - Volume Iii: Selenium WebDriver takes a step-by-step approach to teaching the reader how to effectively use Selenium WebDriver.  [More info. . . ](http://www. amazon. co. uk/Selenium-Example-Iii-WebDriver/dp/1326027824/ref=sr_1_23)### Selenium Webdriver Recipes in C# 2015![selenium webdriver recipes](http://69. 164. 212. 71/wp-content/uploads/2016/04/selenium-webdriver-recipes-198x300. jpg)Solve your Selenium WebDriver problems with this quick guide to automated testing of web applications with Selenium WebDriver in C#. Selenium WebDriver Recipes in C#, Second Edition contains hundreds of solutions to real-world problems, with clear explanations and ready-to-run Selenium test scripts that you can use in your own projects.  [More info. . . ](http://www. bookdepository. com/book/9781484217412)"
    }, {
    "id": 253,
    "url": "localhost:4000/whole-team-approach-agile-testing/",
    "title": "What is Whole Team Approach in Agile Testing?",
    "body": "2016/09/02 -  Whole-Team Approach: In Agile, the whole-team approach means involving everyone with different knowledge and skills to ensure project success. The team includes representatives from the customer also known as the Product Owner, and other business stakeholders who determine product features. The team should be relatively small, typically between five to seven, however, successful teams have been observed with as few as three people and as many as nine. Ideally, the whole team shares the same workspace and are sat as a group, as co-location strongly facilitates communication and interaction. The whole-team approach is supported through the daily stand-up meetings involving all members of the team, where work progress is communicated and any impediments to progress are highlighted. The whole-team approach promotes more effective and efficient team dynamics. Also, using the whole-team approach, it means that testers can help developers write automated tests and vice versa and product owners can help with Exploratory and User Acceptance Testing. The use of a whole-team approach to product development is one of the main benefits of Agile development. Its benefits include:  Enhancing communication and collaboration within the team Enabling the various skill sets within the team to be leveraged to the benefit of the project Making quality everyone’s responsibilityIn Agile projects, Testers or QAs are not the only ones responsible for quality of the product but the whole team is responsible for quality. The essence of the whole-team approach lies in the testers, developers, and the business representatives working together in every step of the development process. Testers will work closely with both developers and business representatives to ensure that the desired quality levels are achieved. This includes supporting and collaborating with business representatives to help them create suitable acceptance tests, define definition of done, working with developers to agree on the testing strategy, and deciding on test automation approaches. Testers can thus transfer and extend testing knowledge to other team members and influence the development of the product. The whole team is involved in any consultations or meetings in which product features are presented, analyzed, or estimated. The concept of involving testers, developers, and business representatives in all feature discussions is known as the power of three, or the three Amigos. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});